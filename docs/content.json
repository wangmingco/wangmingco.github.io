{"meta":{"title":"向南","subtitle":"","description":"","author":"向南","url":"https://wangmingco.github.io","root":"/"},"pages":[{"title":"关于","date":"2021-11-24T05:29:10.379Z","updated":"2021-11-24T05:29:10.379Z","comments":false,"path":"about/index.html","permalink":"https://wangmingco.github.io/about/index.html","excerpt":"","text":"Coder"},{"title":"Repositories","date":"2021-11-24T05:28:48.969Z","updated":"2021-11-18T03:12:28.747Z","comments":false,"path":"repository/index.html","permalink":"https://wangmingco.github.io/repository/index.html","excerpt":"","text":""},{"title":"书单","date":"2021-11-24T05:35:32.916Z","updated":"2021-11-24T05:35:32.916Z","comments":false,"path":"books/index.html","permalink":"https://wangmingco.github.io/books/index.html","excerpt":"","text":"douban: user: xxxyy # 豆瓣用户名 start: 0 # 从哪一条记录开始 count: 10 # 获取豆瓣书单数据条数"},{"title":"友情链接","date":"2021-11-24T05:28:48.956Z","updated":"2021-11-18T03:12:28.746Z","comments":true,"path":"links/index.html","permalink":"https://wangmingco.github.io/links/index.html","excerpt":"","text":""},{"title":"分类","date":"2021-11-24T05:28:48.942Z","updated":"2021-11-18T03:12:28.746Z","comments":false,"path":"categories/index.html","permalink":"https://wangmingco.github.io/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2021-11-24T05:32:08.622Z","updated":"2021-11-24T05:32:08.622Z","comments":false,"path":"tags/index.html","permalink":"https://wangmingco.github.io/tags/index.html","excerpt":"","text":""},{"title":"404 Not Found：该页无法显示","date":"2021-11-24T05:33:20.716Z","updated":"2021-11-18T03:12:28.744Z","comments":false,"path":"/404.html","permalink":"https://wangmingco.github.io/404.html","excerpt":"","text":""},{"title":"","date":"2021-12-09T07:28:20.392Z","updated":"2021-12-09T07:28:20.392Z","comments":true,"path":"html/bj_baidu.html","permalink":"https://wangmingco.github.io/html/bj_baidu.html","excerpt":"","text":"北京旅游景点 html{height:100%} body{height:100%;margin:0px;padding:0px} #container{height:100%} function initMap() { var map = new BMapGL.Map(\"container\"); // 创建地图实例 var point = new BMapGL.Point(116.404, 39.915); // 创建点坐标 map.centerAndZoom(point, 15); // 初始化地图，设置中心点坐标和地图级别 map.enableScrollWheelZoom(true); //开启鼠标滚轮缩放 var scaleCtrl = new BMapGL.ScaleControl(); // 添加比例尺控件 map.addControl(scaleCtrl); var zoomCtrl = new BMapGL.ZoomControl(); // 添加缩放控件 map.addControl(zoomCtrl); var bowuguan = [ {x: 116.403757, y: 39.916727, title: '故宫'}, {x: 116.403757, y: 39.916727, title: '中国国家博物馆'}, {x: 116.365278, y: 39.931588, title: '北京鲁迅博物馆'}, {x: 116.417259, y: 39.930527, title: '中国美术馆'}, {x: 116.404162, y: 39.908892, title: '毛主席纪念堂'}, {x: 116.726914, y: 39.967915, title: '中国体育博物馆'}, {x: 116.375341, y: 39.914214, title: '民族文化宫博物馆'}, {x: 116.377722, y: 39.928967, title: '中国地质博物馆'}, {x: 116.469233, y: 39.946976, title: '中国农业博物馆'}, {x: 116.341009, y: 39.943129, title: '中国古动物馆'}, {x: 116.357315, y: 39.987388, title: '北京航空航天博物馆'}, {x: 116.232474, y: 39.857753, title: '中国人民抗日战争纪念馆'}, {x: 116.404705, y: 40.012682, title: '中国科学技术馆'}, {x: 116.330207, y: 39.914976, title: '中国人民革命军事博物馆'}, {x: 116.368633, y: 40.187427, title: '中国航空博物馆'}, {x: 116.406116, y: 39.889525, title: '北京自然博物馆'}, {x: 116.343134, y: 39.94404, title: '北京天文馆'}, {x: 116.348486, y: 39.911876, title: '首都博物馆'}, {x: 116.344611, y: 39.974916, title: '大钟寺古钟博物馆'}, {x: 116.565726, y: 39.909385, title: '北京艺术博物馆'}, {x: 116.400119, y: 39.884358, title: '北京古代建筑博物馆'}, {x: 116.41515, y: 40.002016, title: '炎黄艺术馆'}, {x: 116.255634, y: 40.306283, title: '明十三陵博物馆'}, {x: 116.440066, y: 39.912603, title: '北京古观象台'}, {x: 116.386496, y: 39.955723, title: '北京古代钱币博物馆'}, {x: 115.94351, y: 39.693463, title: '北京西周燕都遗址博物馆'}, {x: 116.365499, y: 39.868291, title: '北京辽金城垣博物馆'}, {x: 116.303623, y: 39.812871, title: '北京大葆台西汉墓博物馆'}, {x: 116.312399, y: 40.001644, title: '北京大学赛克勒考古与艺术博物馆'}, {x: 116.876273, y: 40.24019, title: '焦庄户地道战遗址纪念馆'}, {x: 116.324769, y: 39.954873, title: '中央民族大学民族博物馆'}, {x: 116.368283, y: 40.18738, title: '北京航空馆'}, {x: 116.337993, y: 39.748714, title: '中国印刷博物馆'}, {x: 116.318473, y: 40.019756, title: '圆明园展览馆'}, {x: 116.397809, y: 39.989379, title: '北京中华民族博物院'}, {x: 116.540397, y: 40.013309, title: '观复博物馆'}, {x: 116.33965, y: 39.944841, title: '中国钱币博物馆'}, {x: 116.212632, y: 40.012586, title: '中国蜜蜂博物馆'}, {x: 116.22742, y: 39.856445, title: '卢沟桥历史博物馆'}, {x: 116.433211, y: 39.976518, title: '北京中医药大学中医药博物馆'}, {x: 116.467464, y: 39.782489, title: '北京麋鹿苑博物馆'}, {x: 116.139442, y: 40.168155, title: '坦克博物馆'}, {x: 116.33965, y: 39.944841, title: '中国印钞造币博物馆'}, {x: 116.336798, y: 39.890101, title: '中国铁道博物馆'}, {x: 116.32553, y: 39.982485, title: '北京市海淀区博物馆'}, {x: 116.684891, y: 40.305098, title: '老爷车博物馆'}, {x: 116.437639, y: 39.916824, title: '中国邮政邮票博物馆'}, {x: 116.320303, y: 39.975885, title: '中国人民大学博物馆'}, {x: 116.30852, y: 39.835739, title: '北京汽车博物馆'} ] addToMap(bowuguan, map, 'red') var jingdian = [ {x: 116.419342, y: 39.888663, title: '天坛'}, {x: 116.400824, y: 39.997574, title: '鸟巢'}, {x: 116.34482, y: 39.946348, title: '动物园'}, {x: 116.419654, y: 39.953183, title: '国子监'}, {x: 116.423632, y: 39.953638, title: '雍和宫'}, {x: 116.404153, y: 39.933751, title: '景山'}, {x: 116.315938, y: 40.005466, title: '圆明园'}, {x: 116.291621, y: 40.004603, title: '颐和园'}, {x: 116.395376, y: 39.932886, title: '北海公园'}, {x: 116.392791, y: 39.941922, title: '恭王府'}, {x: 116.32865, y: 39.505009, title: '北京野生动物园'}, {x: 116.502072, y: 39.991088, title: '798艺术区 '}, ] addToMap(jingdian, map, 'blue') } function addToMap(array, map, color) { array.forEach(function(item, index) { map.addOverlay(new BMapGL.Marker(new BMapGL.Point(item.x, item.y))); var opts = { position: new BMapGL.Point(item.x, item.y), // 指定文本标注所在的地理位置 offset: new BMapGL.Size(12, -30) // 设置文本偏移量 }; // 创建文本标注对象 var label = new BMapGL.Label(item.title, opts); // 自定义文本标注样式 label.setStyle({ color: color, borderRadius: '5px', borderColor: '#ccc', padding: '10px', fontSize: '13px', height: '20px', lineHeight: '20px', fontFamily: '微软雅黑' }); map.addOverlay(label); }) } initMap()"}],"posts":[{"title":"北京景点","slug":"html/bj_baidu","date":"2021-12-09T07:40:00.000Z","updated":"2021-12-09T07:04:52.774Z","comments":true,"path":"2021/12/09/html/bj_baidu/","link":"","permalink":"https://wangmingco.github.io/2021/12/09/html/bj_baidu/","excerpt":"","text":"北京景点地图{target=”_blank”}","categories":[],"tags":[]},{"title":"Java 线程状态","slug":"zhihu/java_thread_state","date":"2020-05-13T08:36:00.000Z","updated":"2021-11-24T03:00:30.174Z","comments":true,"path":"2020/05/13/zhihu/java_thread_state/","link":"","permalink":"https://wangmingco.github.io/2020/05/13/zhihu/java_thread_state/","excerpt":"","text":"Java 线程状态","categories":[{"name":"知乎","slug":"知乎","permalink":"https://wangmingco.github.io/categories/%E7%9F%A5%E4%B9%8E/"}],"tags":[]},{"title":"写一个在线Java脚本执行器","slug":"zhihu/java_script_runner","date":"2020-04-14T11:14:00.000Z","updated":"2021-11-24T03:00:24.016Z","comments":true,"path":"2020/04/14/zhihu/java_script_runner/","link":"","permalink":"https://wangmingco.github.io/2020/04/14/zhihu/java_script_runner/","excerpt":"","text":"写一个在线Java脚本执行器","categories":[{"name":"知乎","slug":"知乎","permalink":"https://wangmingco.github.io/categories/%E7%9F%A5%E4%B9%8E/"}],"tags":[]},{"title":"基于SpringBoot/Vue/ElementUI 构建权限系统","slug":"zhihu/springboot_vue_admin","date":"2020-04-14T10:42:00.000Z","updated":"2021-11-24T03:09:30.404Z","comments":true,"path":"2020/04/14/zhihu/springboot_vue_admin/","link":"","permalink":"https://wangmingco.github.io/2020/04/14/zhihu/springboot_vue_admin/","excerpt":"","text":"基于SpringBoot/Vue/ElementUI 构建权限系统","categories":[{"name":"知乎","slug":"知乎","permalink":"https://wangmingco.github.io/categories/%E7%9F%A5%E4%B9%8E/"}],"tags":[]},{"title":"SpringBoot Loader 浅析","slug":"zhihu/SpringBoot_Loader","date":"2020-04-13T10:22:00.000Z","updated":"2021-11-24T03:00:39.388Z","comments":true,"path":"2020/04/13/zhihu/SpringBoot_Loader/","link":"","permalink":"https://wangmingco.github.io/2020/04/13/zhihu/SpringBoot_Loader/","excerpt":"","text":"SpringBoot Loader 浅析","categories":[{"name":"知乎","slug":"知乎","permalink":"https://wangmingco.github.io/categories/%E7%9F%A5%E4%B9%8E/"}],"tags":[]},{"title":"PEG.js 文档 [译]","slug":"zhihu/PEG_js","date":"2020-04-02T10:45:00.000Z","updated":"2021-11-24T03:00:36.425Z","comments":true,"path":"2020/04/02/zhihu/PEG_js/","link":"","permalink":"https://wangmingco.github.io/2020/04/02/zhihu/PEG_js/","excerpt":"","text":"PEG.js 文档 [译]","categories":[{"name":"知乎","slug":"知乎","permalink":"https://wangmingco.github.io/categories/%E7%9F%A5%E4%B9%8E/"}],"tags":[]},{"title":"当Netty遇上Spring Boot","slug":"zhihu/springboot_netty","date":"2019-12-09T12:12:00.000Z","updated":"2021-11-24T02:59:34.854Z","comments":true,"path":"2019/12/09/zhihu/springboot_netty/","link":"","permalink":"https://wangmingco.github.io/2019/12/09/zhihu/springboot_netty/","excerpt":"","text":"当Netty遇上Spring Boot","categories":[{"name":"知乎","slug":"知乎","permalink":"https://wangmingco.github.io/categories/%E7%9F%A5%E4%B9%8E/"}],"tags":[]},{"title":"Java String intern() 实现细节","slug":"zhihu/java_string_intern","date":"2019-07-03T12:01:00.000Z","updated":"2021-11-24T03:00:27.238Z","comments":true,"path":"2019/07/03/zhihu/java_string_intern/","link":"","permalink":"https://wangmingco.github.io/2019/07/03/zhihu/java_string_intern/","excerpt":"","text":"Java String intern() 实现细节","categories":[{"name":"知乎","slug":"知乎","permalink":"https://wangmingco.github.io/categories/%E7%9F%A5%E4%B9%8E/"}],"tags":[]},{"title":"Java NIO原理剖析之 DirectBuffer GC","slug":"zhihu/Java_DirectBuffer_GC","date":"2019-05-20T06:44:00.000Z","updated":"2021-11-24T03:00:11.865Z","comments":true,"path":"2019/05/20/zhihu/Java_DirectBuffer_GC/","link":"","permalink":"https://wangmingco.github.io/2019/05/20/zhihu/Java_DirectBuffer_GC/","excerpt":"","text":"Java NIO原理剖析之 DirectBuffer GC","categories":[{"name":"知乎","slug":"知乎","permalink":"https://wangmingco.github.io/categories/%E7%9F%A5%E4%B9%8E/"}],"tags":[]},{"title":"Java NIO原理剖析之 磁盘IO","slug":"zhihu/java_disc_io","date":"2019-05-20T02:37:00.000Z","updated":"2021-11-24T03:00:14.865Z","comments":true,"path":"2019/05/20/zhihu/java_disc_io/","link":"","permalink":"https://wangmingco.github.io/2019/05/20/zhihu/java_disc_io/","excerpt":"","text":"Java NIO原理剖析之 磁盘IO","categories":[{"name":"知乎","slug":"知乎","permalink":"https://wangmingco.github.io/categories/%E7%9F%A5%E4%B9%8E/"}],"tags":[]},{"title":"Javasist Introspection and customization","slug":"JavaLibrary/Javasist 4 Introspection and customization","date":"2019-05-04T12:15:00.000Z","updated":"2021-11-18T02:32:50.822Z","comments":true,"path":"2019/05/04/JavaLibrary/Javasist 4 Introspection and customization/","link":"","permalink":"https://wangmingco.github.io/2019/05/04/JavaLibrary/Javasist%204%20Introspection%20and%20customization/","excerpt":"","text":"CtClass提供了方法以便于自省. Javassist 的自省能力和Java的反射API很像. CtClass 提供了getName(), getSuperclass(), getMethods()等方法. CtClass仍然提供了修改一个类定义的方法.它允许添加新的字段/构造器/方法. 修改(Instrumenting)方法体也是可以的. CtClass provides methods for introspection. The introspective ability of Javassist is compatible with that of the Java reflection API. CtClass provides getName(), getSuperclass(), getMethods(), and so on. CtClass also provides methods for modifying a class definition. It allows to add a new field, constructor, and method. Instrumenting a method body is also possible. CtMethod实例表示方法. CtMethod提供了一些方法用来修改方法的定义. 注意, 如果一个方法是继承而来的, 那么子类和基类的这个方法是由同一个CtMethod对象表示. 一个CtMethod对象对应一个方法的声明. Methods are represented by CtMethod objects. CtMethod provides several methods for modifying the definition of the method. Note that if a method is inherited from a super class, then the same CtMethod object that represents the inherited method represents the method declared in that super class. A CtMethod object corresponds to every method declaration. 例如, 如果类Point声明了一个方法move(), 它的子类ColorPoint没有重载move()方法, 在Point中声明的move()方法和在子类ColorPoint中继承过来的move()方法是由同一个CtMethod对象表示的. 如果CtMethod对象所表示的方法被修改了, 那么父类和子类的方法都会被修改. 如果你只想修改ColorPoint的move()方法, 你首席必须得把Point里的move()方法制作一个副本, 然后将这个副本添加到ColorPoint里. 可以通过调用CtNewMethod.copy()得到一个CtMethod对象的副本. For example, if class Point declares method move() and a subclass ColorPoint of Point does not override move(), the two move() methods declared in Point and inherited in ColorPoint are represented by the identical CtMethod object. If the method definition represented by this CtMethod object is modified, the modification is reflected on both the methods. If you want to modify only the move() method in ColorPoint, you first have to add to ColorPoint a copy of the CtMethod object representing move() in Point. A copy of the the CtMethod object can be obtained by CtNewMethod.copy(). Javassist不允许删除一个方法或者字段, 但是允许修改它的名字. 索引, 如果一个方法不再需要了, 应该调用CtMethod的setName()将其重命名以及setModifiers()修改它的访问级别到一个私有方法. Javassist does not allow to remove a method or field, but it allows to change the name. So if a method is not necessary any more, it should be renamed and changed to be a private method by calling setName() and setModifiers() declared in CtMethod. Javassist也不允许向一个已经存在的方法添加一个新的参数. 但是, 可以向相同的class里增加一个新的方法, 该方法在老的方法接口上增加新的参数. 例如, 如果你想要在一个方法上添加一个newZ参数: Javassist does not allow to add an extra parameter to an existing method, either. Instead of doing that, a new method receiving the extra parameter as well as the other parameters should be added to the same class. For example, if you want to add an extra int parameter newZ to a method: 1void move(int newX, int newY) &#123; x = newX; y = newY; &#125; in a Point class, then you should add the following method to the Point class: 在Point类中, 你应该添加一个新的方法: 1234void move(int newX, int newY, int newZ) &#123; // do what you want with newZ. move(newX, newY);&#125; Javassist也提供了一些底层API用于修改一个原始的类结构. 例如, CtClass中的getClassFile()返回了一个表示原始类结构的ClassFile对象.CtMethod 中的 getMethodInfo() 返回了一个MethodInfo对象, 该对象表示的类结构中的一个method_info结构. 底层API使用了Java Virtual Machine规范中的词汇. 使用者必须有class文件和字节码的知识. 更多的细节, 使用者应该参考javassist.bytecode包下的内容. Javassist also provides low-level API for directly editing a raw class file. For example, getClassFile() in CtClass returns a ClassFile object representing a raw class file. getMethodInfo() in CtMethod returns a MethodInfo object representing a method_info structure included in a class file. The low-level API uses the vocabulary from the Java Virtual machine specification. The users must have the knowledge about class files and bytecode. For more details, the users should see the javassist.bytecode package. The class files modified by Javassist requires the javassist.runtime package for runtime support only if some special identifiers starting with $ are used. Those special identifiers are described below. The class files modified without those special identifiers do not need the javassist.runtime package or any other Javassist packages at runtime. For more details, see the API documentation of the javassist.runtime package. 4.1 Inserting source text at the beginning/end of a method bodyCtMethod and CtConstructor 中提供了insertBefore(), insertAfter(), and addCatch() 这三个方法. 这些方法用于向一个已经存在的方法中添加代码片段. 这些代码片段可以试Java代码. Javassist包含了一个简单的Java编译器用来编译这些Java源码. 该编译器接受Java语言编写的源代码, 然后将其编译成Java字节码, 然后将其内联到一个方法体中. CtMethod and CtConstructor provide methods insertBefore(), insertAfter(), and addCatch(). They are used for inserting a code fragment into the body of an existing method. The users can specify those code fragments with source text written in Java. Javassist includes a simple Java compiler for processing source text. It receives source text written in Java and compiles it into Java bytecode, which will be inlined into a method body. 如果class文件中包含了line number表的话, 可以在指定的line number中插入一个代码片段. Inserting a code fragment at the position specified by a line number is also possible (if the line number table is contained in the class file). insertAt() in CtMethod and CtConstructor takes source text and a line number in the source file of the original class definition. It compiles the source text and inserts the compiled code at the line number. The methods insertBefore(), insertAfter(), addCatch(), and insertAt() receive a String object representing a statement or a block. A statement is a single control structure like if and while or an expression ending with a semi colon (;). A block is a set of statements surrounded with braces {}. Hence each of the following lines is an example of valid statement or block: 123System.out.println(&quot;Hello&quot;);&#123; System.out.println(&quot;Hello&quot;); &#125;if (i &lt; 0) &#123; i = -i; &#125; The statement and the block can refer to fields and methods. They can also refer to the parameters to the method that they are inserted into if that method was compiled with the -g option (to include a local variable attribute in the class file). Otherwise, they must access the method parameters through the special variables $0, $1, $2, … described below. Accessing local variables declared in the method is not allowed although declaring a new local variable in the block is allowed. However, insertAt() allows the statement and the block to access local variables if these variables are available at the specified line number and the target method was compiled with the -g option.The String object passed to the methods insertBefore(), insertAfter(), addCatch(), and insertAt() are compiled by the compiler included in Javassist. Since the compiler supports language extensions, several identifiers starting with $ have special meaning: $0, $1, $2, ... this and actual parameters $args An array of parameters. The type of $args is Object[]. $$ All actual parameters. For example, m($$) is equivalent to m($1,$2,…) $cflow(...) cflow variable $r The result type. It is used in a cast expression. $w The wrapper type. It is used in a cast expression. $_ The resulting value $sig An array of java.lang.Class objects representing the formal parameter types. $type A java.lang.Class object representing the formal result type. $class A java.lang.Class object representing the class currently edited. $0, $1, $2, …The parameters passed to the target method are accessible with $1, $2, … instead of the original parameter names. $1 represents the first parameter, $2 represents the second parameter, and so on. The types of those variables are identical to the parameter types. $0 is equivalent to this. If the method is static, $0 is not available. These variables are used as following. Suppose that a class Point: 1234class Point &#123; int x, y; void move(int dx, int dy) &#123; x += dx; y += dy; &#125;&#125; To print the values of dx and dy whenever the method move() is called, execute this program: 12345ClassPool pool = ClassPool.getDefault();CtClass cc = pool.get(&quot;Point&quot;);CtMethod m = cc.getDeclaredMethod(&quot;move&quot;);m.insertBefore(&quot;&#123; System.out.println($1); System.out.println($2); &#125;&quot;);cc.writeFile(); Note that the source text passed to insertBefore() is surrounded with braces {}. insertBefore() accepts only a single statement or a block surrounded with braces. The definition of the class Point after the modification is like this: 1234567class Point &#123; int x, y; void move(int dx, int dy) &#123; &#123; System.out.println(dx); System.out.println(dy); &#125; x += dx; y += dy; &#125;&#125; $1 and $2 are replaced with dx and dy, respectively. $1, $2, $3 … are updatable. If a new value is assigend to one of those variables, then the value of the parameter represented by that variable is also updated. $argsThe variable $args represents an array of all the parameters. The type of that variable is an array of class Object. If a parameter type is a primitive type such as int, then the parameter value is converted into a wrapper object such as java.lang.Integer to store in $args. Thus, $args[0] is equivalent to $1 unless the type of the first parameter is a primitive type. Note that $args[0] is not equivalent to $0; $0 represents this. If an array of Object is assigned to $args, then each element of that array is assigned to each parameter. If a parameter type is a primitive type, the type of the corresponding element must be a wrapper type. The value is converted from the wrapper type to the primitive type before it is assigned to the parameter. $$The variable $$ is abbreviation of a list of all the parameters separated by commas. For example, if the number of the parameters to method move() is three, then 1move($$) is equivalent to this: 1move($1, $2, $3) If move() does not take any parameters, then move($$) is equivalent to move(). $$ can be used with another method. If you write an expression: 1exMove($$, context) then this expression is equivalent to: 1exMove($1, $2, $3, context) Note that $$ enables generic notation of method call with respect to the number of parameters. It is typically used with $proceed shown later. $cflow$cflow means “control flow”. This read-only variable returns the depth of the recursive calls to a specific method. Suppose that the method shown below is represented by a CtMethod object cm: 123456int fact(int n) &#123; if (n &lt;= 1) return n; else return n * fact(n - 1);&#125; To use $cflow, first declare that $cflow is used for monitoring calls to the method fact(): 12CtMethod cm = ...;cm.useCflow(&quot;fact&quot;); The parameter to useCflow() is the identifier of the declared $cflow variable. Any valid Java name can be used as the identifier. Since the identifier can also include . (dot), for example, “my.Test.fact” is a valid identifier. Then, $cflow(fact) represents the depth of the recursive calls to the method specified by cm. The value of $cflow(fact) is 0 (zero) when the method is first called whereas it is 1 when the method is recursively called within the method. For example, 12cm.insertBefore(&quot;if ($cflow(fact) == 0)&quot; + &quot; System.out.println(\\&quot;fact \\&quot; + $1);&quot;); translates the method fact() so that it shows the parameter. Since the value of $cflow(fact) is checked, the method fact() does not show the parameter if it is recursively called within fact(). The value of $cflow is the number of stack frames associated with the specified method cm under the current topmost stack frame for the current thread. $cflow is also accessible within a method different from the specified method cm. $r$r represents the result type (return type) of the method. It must be used as the cast type in a cast expression. For example, this is a typical use: 12Object result = ... ;$_ = ($r)result; If the result type is a primitive type, then ($r) follows special semantics. First, if the operand type of the cast expression is a primitive type, ($r) works as a normal cast operator to the result type. On the other hand, if the operand type is a wrapper type, ($r) converts from the wrapper type to the result type. For example, if the result type is int, then ($r) converts from java.lang.Integer to int. If the result type is void, then ($r) does not convert a type; it does nothing. However, if the operand is a call to a void method, then ($r) results in null. For example, if the result type is void and foo() is a void method, then 1$_ = ($r)foo(); is a valid statement. The cast operator ($r) is also useful in a return statement. Even if the result type is void, the following return statement is valid: 1return ($r)result; Here, result is some local variable. Since ($r) is specified, the resulting value is discarded. This return statement is regarded as the equivalent of the return statement without a resulting value: 1return; $w$w represents a wrapper type. It must be used as the cast type in a cast expression. ($w) converts from a primitive type to the corresponding wrapper type. The following code is an example: 1Integer i = ($w)5; The selected wrapper type depends on the type of the expression following ($w). If the type of the expression is double, then the wrapper type is java.lang.Double. If the type of the expression following ($w) is not a primitive type, then ($w) does nothing. $_insertAfter() in CtMethod and CtConstructor inserts the compiled code at the end of the method. In the statement given to insertAfter(), not only the variables shown above such as $0, $1, … but also $_ is available. The variable $_ represents the resulting value of the method. The type of that variable is the type of the result type (the return type) of the method. If the result type is void, then the type of $_ is Object and the value of $_ is null. Although the compiled code inserted by insertAfter() is executed just before the control normally returns from the method, it can be also executed when an exception is thrown from the method. To execute it when an exception is thrown, the second parameter asFinally to insertAfter() must be true. If an exception is thrown, the compiled code inserted by insertAfter() is executed as a finally clause. The value of $_ is 0 or null in the compiled code. After the execution of the compiled code terminates, the exception originally thrown is re-thrown to the caller. Note that the value of $_ is never thrown to the caller; it is rather discarded. $sigThe value of $sig is an array of java.lang.Class objects that represent the formal parameter types in declaration order. $typeThe value of $type is an java.lang.Class object representing the formal type of the result value. This variable refers to Void.class if this is a constructor. $classThe value of $class is an java.lang.Class object representing the class in which the edited method is declared. This represents the type of $0. addCatch()addCatch() inserts a code fragment into a method body so that the code fragment is executed when the method body throws an exception and the control returns to the caller. In the source text representing the inserted code fragment, the exception value is referred to with the special variable $e. For example, this program: 123456789101112CtMethod m = ...;CtClass etype = ClassPool.getDefault().get(&quot;java.io.IOException&quot;);m.addCatch(&quot;&#123; System.out.println($e); throw $e; &#125;&quot;, etype);translates the method body represented by m into something like this:try &#123; the original method body&#125;catch (java.io.IOException e) &#123; System.out.println(e); throw e;&#125; Note that the inserted code fragment must end with a throw or return statement. 4.2 Altering a method bodyCtMethod and CtConstructor provide setBody() for substituting a whole method body. They compile the given source text into Java bytecode and substitutes it for the original method body. If the given source text is null, the substituted body includes only a return statement, which returns zero or null unless the result type is void. In the source text given to setBody(), the identifiers starting with $ have special meaning $0, $1, $2, ... this and actual parameters $args An array of parameters. The type of $args is Object[]. $$ All actual parameters. $cflow(...) cflow variable $r The result type. It is used in a cast expression. $w The wrapper type. It is used in a cast expression. $sig An array of java.lang.Class objects representing the formal parameter types. $type A java.lang.Class object representing the formal result type. $class A java.lang.Class object representing the class that declares the methodcurrently edited (the type of $0). Note that $_ is not available. Substituting source text for an existing expressionJavassist allows modifying only an expression included in a method body. javassist.expr.ExprEditor is a class for replacing an expression in a method body. The users can define a subclass of ExprEditor to specify how an expression is modified. To run an ExprEditor object, the users must call instrument() in CtMethod or CtClass. For example, 1234567891011CtMethod cm = ... ;cm.instrument( new ExprEditor() &#123; public void edit(MethodCall m) throws CannotCompileException &#123; if (m.getClassName().equals(&quot;Point&quot;) &amp;&amp; m.getMethodName().equals(&quot;move&quot;)) m.replace(&quot;&#123; $1 = 0; $_ = $proceed($$); &#125;&quot;); &#125; &#125;); searches the method body represented by cm and replaces all calls to move() in class Point with a block: 1&#123; $1 = 0; $_ = $proceed($$); &#125; so that the first parameter to move() is always 0. Note that the substituted code is not an expression but a statement or a block. It cannot be or contain a try-catch statement. The method instrument() searches a method body. If it finds an expression such as a method call, field access, and object creation, then it calls edit() on the given ExprEditor object. The parameter to edit() is an object representing the found expression. The edit() method can inspect and replace the expression through that object. Calling replace() on the parameter to edit() substitutes the given statement or block for the expression. If the given block is an empty block, that is, if replace(“{}”) is executed, then the expression is removed from the method body. If you want to insert a statement (or a block) before/after the expression, a block like the following should be passed to replace(): 123&#123; before-statements; $_ = $proceed($$); after-statements; &#125; whichever the expression is either a method call, field access, object creation, or others. The second statement could be: 1$_ = $proceed(); if the expression is read access, or 1$proceed($$); if the expression is write access. Local variables available in the target expression is also available in the source text passed to replace() if the method searched by instrument() was compiled with the -g option (the class file includes a local variable attribute). javassist.expr.MethodCallA MethodCall object represents a method call. The method replace() in MethodCall substitutes a statement or a block for the method call. It receives source text representing the substitued statement or block, in which the identifiers starting with $ have special meaning as in the source text passed to insertBefore(). $0 The target object of the method call.This is not equivalent to this, which represents the caller-side this object.$0 is null if the method is static. $1, $2, … The parameters of the method call.$_ The resulting value of the method call.$r The result type of the method call.$class A java.lang.Class object representing the class declaring the method.$sig An array of java.lang.Class objects representing the formal parameter types.$type A java.lang.Class object representing the formal result type.$proceed The name of the method originally called in the expression.Here the method call means the one represented by the MethodCall object. The other identifiers such as $w, $args and $$ are also available. Unless the result type of the method call is void, a value must be assigned to $_ in the source text and the type of $_ is the result type. If the result type is void, the type of $_ is Object and the value assigned to $_ is ignored. $proceed is not a String value but special syntax. It must be followed by an argument list surrounded by parentheses ( ). javassist.expr.ConstructorCallA ConstructorCall object represents a constructor call such as this() and super included in a constructor body. The method replace() in ConstructorCall substitutes a statement or a block for the constructor call. It receives source text representing the substituted statement or block, in which the identifiers starting with $ have special meaning as in the source text passed to insertBefore(). $0 The target object of the constructor call. This is equivalent to this.$1, $2, … The parameters of the constructor call.$class A java.lang.Class object representing the class declaring the constructor.$sig An array of java.lang.Class objects representing the formal parameter types.$proceed The name of the constructor originally called in the expression.Here the constructor call means the one represented by the ConstructorCall object. The other identifiers such as $w, $args and $$ are also available. Since any constructor must call either a constructor of the super class or another constructor of the same class, the substituted statement must include a constructor call, normally a call to $proceed(). $proceed is not a String value but special syntax. It must be followed by an argument list surrounded by parentheses ( ). javassist.expr.FieldAccessA FieldAccess object represents field access. The method edit() in ExprEditor receives this object if field access is found. The method replace() in FieldAccess receives source text representing the substitued statement or block for the field access. In the source text, the identifiers starting with $ have special meaning: $0 The object containing the field accessed by the expression. This is not equivalent to this.this represents the object that the method including the expression is invoked on.$0 is null if the field is static. $1 The value that would be stored in the field if the expression is write access.Otherwise, $1 is not available. $_ The resulting value of the field access if the expression is read access.Otherwise, the value stored in $_ is discarded. $r The type of the field if the expression is read access.Otherwise, $r is void. $class A java.lang.Class object representing the class declaring the field.$type A java.lang.Class object representing the field type.$proceed The name of a virtual method executing the original field access. .The other identifiers such as $w, $args and $$ are also available. If the expression is read access, a value must be assigned to $_ in the source text. The type of $_ is the type of the field. javassist.expr.NewExprA NewExpr object represents object creation with the new operator (not including array creation). The method edit() in ExprEditor receives this object if object creation is found. The method replace() in NewExpr receives source text representing the substitued statement or block for the object creation. In the source text, the identifiers starting with $ have special meaning: $0 null.$1, $2, … The parameters to the constructor.$_ The resulting value of the object creation.A newly created object must be stored in this variable. $r The type of the created object.$sig An array of java.lang.Class objects representing the formal parameter types.$type A java.lang.Class object representing the class of the created object.$proceed The name of a virtual method executing the original object creation. .The other identifiers such as $w, $args and $$ are also available. javassist.expr.NewArrayA NewArray object represents array creation with the new operator. The method edit() in ExprEditor receives this object if array creation is found. The method replace() in NewArray receives source text representing the substitued statement or block for the array creation. In the source text, the identifiers starting with $ have special meaning: $0 null.$1, $2, … The size of each dimension.$_ The resulting value of the array creation.A newly created array must be stored in this variable. $r The type of the created array.$type A java.lang.Class object representing the class of the created array.$proceed The name of a virtual method executing the original array creation. .The other identifiers such as $w, $args and $$ are also available. For example, if the array creation is the following expression, 1String[][] s = new String[3][4]; then the value of $1 and $2 are 3 and 4, respectively. $3 is not available.If the array creation is the following expression, 1String[][] s = new String[3][]; then the value of $1 is 3 but $2 is not available. javassist.expr.InstanceofA Instanceof object represents an instanceof expression. The method edit() in ExprEditor receives this object if an instanceof expression is found. The method replace() in Instanceof receives source text representing the substitued statement or block for the expression. In the source text, the identifiers starting with $ have special meaning: $0 null.$1 The value on the left hand side of the original instanceof operator.$_ The resulting value of the expression. The type of $_ is boolean.$r The type on the right hand side of the instanceof operator.$type A java.lang.Class object representing the type on the right hand side of the instanceof operator.$proceed The name of a virtual method executing the original instanceof expression.It takes one parameter (the type is java.lang.Object) and returns trueif the parameter value is an instance of the type on the right hand side ofthe original instanceof operator. Otherwise, it returns false. The other identifiers such as $w, $args and $$ are also available. javassist.expr.CastA Cast object represents an expression for explicit type casting. The method edit() in ExprEditor receives this object if explicit type casting is found. The method replace() in Cast receives source text representing the substitued statement or block for the expression. In the source text, the identifiers starting with $ have special meaning: $0 null.$1 The value the type of which is explicitly cast.$_ The resulting value of the expression. The type of $_ is the same as the typeafter the explicit casting, that is, the type surrounded by ( ). $r the type after the explicit casting, or the type surrounded by ( ).$type A java.lang.Class object representing the same type as $r.$proceed The name of a virtual method executing the original type casting.It takes one parameter of the type java.lang.Object and returns it afterthe explicit type casting specified by the original expression. The other identifiers such as $w, $args and $$ are also available. javassist.expr.HandlerA Handler object represents a catch clause of try-catch statement. The method edit() in ExprEditor receives this object if a catch is found. The method insertBefore() in Handler compiles the received source text and inserts it at the beginning of the catch clause. In the source text, the identifiers starting with $ have meaning: $1 The exception object caught by the catch clause.$r the type of the exception caught by the catch clause. It is used in a cast expression.$w The wrapper type. It is used in a cast expression.$type A java.lang.Class object representingthe type of the exception caught by the catch clause. If a new exception object is assigned to $1, it is passed to the original catch clause as the caught exception. 4.3 Adding a new method or fieldAdding a methodJavassist allows the users to create a new method and constructor from scratch. CtNewMethod and CtNewConstructor provide several factory methods, which are static methods for creating CtMethod or CtConstructor objects. Especially, make() creates a CtMethod or CtConstructor object from the given source text. For example, this program: 12345CtClass point = ClassPool.getDefault().get(&quot;Point&quot;);CtMethod m = CtNewMethod.make( &quot;public int xmove(int dx) &#123; x += dx; &#125;&quot;, point);point.addMethod(m); adds a public method xmove() to class Point. In this example, x is a int field in the class Point. The source text passed to make() can include the identifiers starting with $ except $_ as in setBody(). It can also include $proceed if the target object and the target method name are also given to make(). For example, 1234CtClass point = ClassPool.getDefault().get(&quot;Point&quot;);CtMethod m = CtNewMethod.make( &quot;public int ymove(int dy) &#123; $proceed(0, dy); &#125;&quot;, point, &quot;this&quot;, &quot;move&quot;); this program creates a method ymove() defined below: public int ymove(int dy) { this.move(0, dy); }Note that $proceed has been replaced with this.move. Javassist provides another way to add a new method. You can first create an abstract method and later give it a method body: 123456CtClass cc = ... ;CtMethod m = new CtMethod(CtClass.intType, &quot;move&quot;, new CtClass[] &#123; CtClass.intType &#125;, cc);cc.addMethod(m);m.setBody(&quot;&#123; x += $1; &#125;&quot;);cc.setModifiers(cc.getModifiers() &amp; ~Modifier.ABSTRACT); Since Javassist makes a class abstract if an abstract method is added to the class, you have to explicitly change the class back to a non-abstract one after calling setBody(). Mutual recursive methodsJavassist cannot compile a method if it calls another method that has not been added to a class. (Javassist can compile a method that calls itself recursively.) To add mutual recursive methods to a class, you need a trick shown below. Suppose that you want to add methods m() and n() to a class represented by cc: 12345678CtClass cc = ... ;CtMethod m = CtNewMethod.make(&quot;public abstract int m(int i);&quot;, cc);CtMethod n = CtNewMethod.make(&quot;public abstract int n(int i);&quot;, cc);cc.addMethod(m);cc.addMethod(n);m.setBody(&quot;&#123; return ($1 &lt;= 0) ? 1 : (n($1 - 1) * $1); &#125;&quot;);n.setBody(&quot;&#123; return m($1); &#125;&quot;);cc.setModifiers(cc.getModifiers() &amp; ~Modifier.ABSTRACT); You must first make two abstract methods and add them to the class. Then you can give the method bodies to these methods even if the method bodies include method calls to each other. Finally you must change the class to a not-abstract class since addMethod() automatically changes a class into an abstract one if an abstract method is added. Adding a fieldJavassist also allows the users to create a new field. 123CtClass point = ClassPool.getDefault().get(&quot;Point&quot;);CtField f = new CtField(CtClass.intType, &quot;z&quot;, point);point.addField(f); This program adds a field named z to class Point. If the initial value of the added field must be specified, the program shown above must be modified into: 123CtClass point = ClassPool.getDefault().get(&quot;Point&quot;);CtField f = new CtField(CtClass.intType, &quot;z&quot;, point);point.addField(f, &quot;0&quot;); // initial value is 0. Now, the method addField() receives the second parameter, which is the source text representing an expression computing the initial value. This source text can be any Java expression if the result type of the expression matches the type of the field. Note that an expression does not end with a semi colon (;). Furthermore, the above code can be rewritten into the following simple code: 123CtClass point = ClassPool.getDefault().get(&quot;Point&quot;);CtField f = CtField.make(&quot;public int z = 0;&quot;, point);point.addField(f); Removing a memberTo remove a field or a method, call removeField() or removeMethod() in CtClass. A CtConstructor can be removed by removeConstructor() in CtClass. 4.4 AnnotationsCtClass, CtMethod, CtField and CtConstructor provides a convenient method getAnnotations() for reading annotations. It returns an annotation-type object. For example, suppose the following annotation: 1234public @interface Author &#123; String name(); int year();&#125; This annotation is used as the following: 1234@Author(name=&quot;Chiba&quot;, year=2005)public class Point &#123; int x, y;&#125; Then, the value of the annotation can be obtained by getAnnotations(). It returns an array containing annotation-type objects. 123456CtClass cc = ClassPool.getDefault().get(&quot;Point&quot;);Object[] all = cc.getAnnotations();Author a = (Author)all[0];String name = a.name();int year = a.year();System.out.println(&quot;name: &quot; + name + &quot;, year: &quot; + year); This code snippet should print: 1name: Chiba, year: 2005 Since the annoation of Point is only @Author, the length of the array all is one and all[0] is an Author object. The member values of the annotation can be obtained by calling name() and year() on the Author object. To use getAnnotations(), annotation types such as Author must be included in the current class path. They must be also accessible from a ClassPool object. If the class file of an annotation type is not found, Javassist cannot obtain the default values of the members of that annotation type. 4.5 Runtime support classesIn most cases, a class modified by Javassist does not require Javassist to run. However, some kinds of bytecode generated by the Javassist compiler need runtime support classes, which are in the javassist.runtime package (for details, please read the API reference of that package). Note that the javassist.runtime package is the only package that classes modified by Javassist may need for running. The other Javassist classes are never used at runtime of the modified classes. 4.6 ImportAll the class names in source code must be fully qualified (they must include package names). However, the java.lang package is an exception; for example, the Javassist compiler can resolve Object as well as java.lang.Object. To tell the compiler to search other packages when resolving a class name, call importPackage() in ClassPool. For example, 12345ClassPool pool = ClassPool.getDefault();pool.importPackage(&quot;java.awt&quot;);CtClass cc = pool.makeClass(&quot;Test&quot;);CtField f = CtField.make(&quot;public Point p;&quot;, cc);cc.addField(f); The seconde line instructs the compiler to import the java.awt package. Thus, the third line will not throw an exception. The compiler can recognize Point as java.awt.Point. Note that importPackage() does not affect the get() method in ClassPool. Only the compiler considers the imported packages. The parameter to get() must be always a fully qualified name. 4.7 LimitationsIn the current implementation, the Java compiler included in Javassist has several limitations with respect to the language that the compiler can accept. Those limitations are: The new syntax introduced by J2SE 5.0 (including enums and generics) has not been supported. Annotations are supported by the low level API of Javassist. See the javassist.bytecode.annotation package (and also getAnnotations() in CtClass and CtBehavior). Generics are also only partly supported. See the latter section for more details.Array initializers, a comma-separated list of expressions enclosed by braces { and }, are not available unless the array dimension is one.Inner classes or anonymous classes are not supported. Note that this is a limitation of the compiler only. It cannot compile source code including an anonymous-class declaration. Javassist can read and modify a class file of inner/anonymous class.Labeled continue and break statements are not supported.The compiler does not correctly implement the Java method dispatch algorithm. The compiler may confuse if methods defined in a class have the same name but take different parameter lists.For example, 12345678class A &#123;&#125; class B extends A &#123;&#125; class C extends B &#123;&#125; class X &#123; void foo(A a) &#123; .. &#125; void foo(B b) &#123; .. &#125; &#125; If the compiled expression is x.foo(new C()), where x is an instance of X, the compiler may produce a call to foo(A) although the compiler can correctly compile foo((B)new C()). The users are recommended to use # as the separator between a class name and a static method or field name. For example, in regular Java,javassist.CtClass.intType.getName()calls a method getName() on the object indicated by the static field intType in javassist.CtClass. In Javassist, the users can write the expression shown above but they are recommended to write: 1javassist.CtClass#intType.getName() so that the compiler can quickly parse the expression.","categories":[{"name":"Javasist","slug":"Javasist","permalink":"https://wangmingco.github.io/categories/Javasist/"}],"tags":[]},{"title":"Javasist Class Loader","slug":"JavaLibrary/Javasist 3 Class loader","date":"2019-05-03T12:15:00.000Z","updated":"2021-11-18T02:32:48.065Z","comments":true,"path":"2019/05/03/JavaLibrary/Javasist 3 Class loader/","link":"","permalink":"https://wangmingco.github.io/2019/05/03/JavaLibrary/Javasist%203%20Class%20loader/","excerpt":"","text":"If what classes must be modified is known in advance, the easiest way for modifying the classes is as follows: Get a CtClass object by calling ClassPool.get(), Modify it, and Call writeFile() or toBytecode() on that CtClass object to obtain a modified class file.If whether a class is modified or not is determined at load time, the users must make Javassist collaborate with a class loader. Javassist can be used with a class loader so that bytecode can be modified at load time. The users of Javassist can define their own version of class loader but they can also use a class loader provided by Javassist. 3.1 The toClass method in CtClassCtClass 提供了一个便捷方法 toClass(), 该方法会将CtClass对象所代表的class通过当前线程的context 类加载器加载进虚拟机里. 在调用该方法之前, 调用者必须拥有权限, 否则会抛出 SecurityException 异常. The CtClass provides a convenience method toClass(), which requests the context class loader for the current thread to load the class represented by the CtClass object. To call this method, the caller must have appropriate permission; otherwise, a SecurityException may be thrown. The following program shows how to use toClass(): 下面的程序展示了如何使用toClass(). 1234567891011121314151617public class Hello &#123; public void say() &#123; System.out.println(&quot;Hello&quot;); &#125;&#125;public class Test &#123; public static void main(String[] args) throws Exception &#123; ClassPool cp = ClassPool.getDefault(); CtClass cc = cp.get(&quot;Hello&quot;); CtMethod m = cc.getDeclaredMethod(&quot;say&quot;); m.insertBefore(&quot;&#123; System.out.println(\\&quot;Hello.say():\\&quot;); &#125;&quot;); Class c = cc.toClass(); Hello h = (Hello)c.newInstance(); h.say(); &#125;&#125; Test.main() 在Hello类的say()方法中插入了一个对 println() 的方法调用. 然后将修改过的Hello class构建一个实例出来, 接着调用该实例的say()方法. Test.main() inserts a call to println() in the method body of say() in Hello. Then it constructs an instance of the modified Hello class and calls say() on that instance. 注意, 上面的程序能运行成功取决于在toClass()执行之前, Hello class从来没有被加载过. 如果Hello已经被加载过的话, 在toClass() 加载修改过的Hello class之前, JVM会先将原生的Hello class加载进来. 因此加载修改过的Hello class就会失败(抛出LinkageError 错误). 例如: Note that the program above depends on the fact that the Hello class is never loaded before toClass() is invoked. If not, the JVM would load the original Hello class before toClass() requests to load the modified Hello class. Hence loading the modified Hello class would be failed (LinkageError is thrown). For example, if main() in Test is something like this: 123456public static void main(String[] args) throws Exception &#123; Hello orig = new Hello(); ClassPool cp = ClassPool.getDefault(); CtClass cc = cp.get(&quot;Hello&quot;); :&#125; main 方法的第一行首先将原生的Hello class加载了进来, 后续再调用 toClass() 就会抛出异常, 这是因为同一个类加载器不能同时加载俩个相同版本的Hello class. then the original Hello class is loaded at the first line of main and the call to toClass() throws an exception since the class loader cannot load two different versions of the Hello class at the same time. 如果这个应用程序运行在一些如JBoss或者Tomcat的应用服务器桑, toClass() 直接使用context 类加载器 可能就不太正确了. 在上面的例子中, 你会看到一个未检查异常 ClassCastException 被抛出. 要避免这种异常, 你必须给 toClass() 一个合适的类加载器. 例如, 如果变量 bean 是你的session bean对象的话, 你可以采用下面的代码: If the program is running on some application server such as JBoss and Tomcat, the context class loader used by toClass() might be inappropriate. In this case, you would see an unexpected ClassCastException. To avoid this exception, you must explicitly give an appropriate class loader to toClass(). For example, if bean is your session bean object, then the following code: 12CtClass cc = ...;Class c = cc.toClass(bean.getClass().getClassLoader()); 上面的代码可以正确运行. 你应该将加载你程序的类加载器传递给toClass() (在上面的例子中, 是bean对象的class) would work. You should give toClass() the class loader that has loaded your program (in the above example, the class of the bean object). toClass() 只是一个便捷方法. 如果你需要更复杂的功能, 你应该实现自己的类加载器. toClass() is provided for convenience. If you need more complex functionality, you should write your own class loader. 3.2 Class loading in Java在Java中, 多个class loader是可以共存的, 每个ClassLoader都有它自己的命名空间. 不同的类加载器可以加载相同名称的不同的class. 加载进来的class被视为不一样的. 这个特性允许我们在同一个JVM运行包含相同名称的class的多个应用程序. In Java, multiple class loaders can coexist and each class loader creates its own name space. Different class loaders can load different class files with the same class name. The loaded two classes are regarded as different ones. This feature enables us to run multiple application programs on a single JVM even if these programs include different classes with the same name. 注意, JVM不允许动态重新加载class. 一旦一个类加载器已经加载了一个class, 那么在运行期, 就不允许该类加载器再去加载一个已经修改过的class. 因此当JVM已经加载了一个class之后, 就不允许再去修改该class的定义了. 但是, JDPA(Java Platform Debugger Architecture) 提供了一些工具可以帮助重新加载一个类. See Section 3.6. Note: The JVM does not allow dynamically reloading a class. Once a class loader loads a class, it cannot reload a modified version of that class during runtime. Thus, you cannot alter the definition of a class after the JVM loads it. However, the JPDA (Java Platform Debugger Architecture) provides limited ability for reloading a class. See Section 3.6. 如果相同的class 文件被不同的类加载器加载了, JVM就会创建俩个名称和定义相同的class. 但是这俩个class是被视为是不同的. 因为这俩个class是不同的, 一个class的实例是不允许赋值到另一个class的变量的. 在这俩个class之间的转换操作会失败, 同时抛出一个 ClassCastException. If the same class file is loaded by two distinct class loaders, the JVM makes two distinct classes with the same name and definition. The two classes are regarded as different ones. Since the two classes are not identical, an instance of one class is not assignable to a variable of the other class. The cast operation between the two classes fails and throws a ClassCastException. 例如, 下面的代码片段抛出的异常. For example, the following code snippet throws an exception: 1234MyClassLoader myLoader = new MyClassLoader();Class clazz = myLoader.loadClass(&quot;Box&quot;);Object obj = clazz.newInstance();Box b = (Box)obj; // this always throws ClassCastException. Box class 被俩个类加载器加载. 假设一个类加载器 CL将上面的代码片段的一个类. CL会将上述代码片段的MyClassLoader, Class, Object, and Box进行加载(除非CL被代理给了其他类加载器). 因此变量b的类型是Box 是被CL加载的. 然而, myLoader 也加载了Box class. 变量obj指向的对象就是被myLoader加载的Box的实例. 因此最后语句就会抛出异常ClassCastException, 因为obj的class和变量b所引用的class不是同一个. The Box class is loaded by two class loaders. Suppose that a class loader CL loads a class including this code snippet. Since this code snippet refers to MyClassLoader, Class, Object, and Box, CL also loads these classes (unless it delegates to another class loader). Hence the type of the variable b is the Box class loaded by CL. On the other hand, myLoader also loads the Box class. The object obj is an instance of the Box class loaded by myLoader. Therefore, the last statement always throws a ClassCastException since the class of obj is a different verison of the Box class from one used as the type of the variable b. 不同的类加载器构成了一个树结构. 除了bootstrap类加载器, 每个类加载器都有一个父加载器, which has normally loaded the class of that child class loader. 因为被请求加载的类可以被代理给这个层级中的其他类加载器, 因此一个class也许可以被不是你想使用的其他类加载器加载. 因此, 你希望加载类C的类加载器也许和实际加载类C的加载器不是同一个. 因此为了区分这俩个类加载器, 我们把前一个类加载器称为the initiator of C, 后一个类加载器称为the real loader of C. Multiple class loaders form a tree structure. Each class loader except the bootstrap loader has a parent class loader, which has normally loaded the class of that child class loader. Since the request to load a class can be delegated along this hierarchy of class loaders, a class may be loaded by a class loader that you do not request the class loading. Therefore, the class loader that has been requested to load a class C may be different from the loader that actually loads the class C. For distinction, we call the former loader the initiator of C and we call the latter loader the real loader of C. 此外, 如果被请求加载类C的类加载器(the initiator of C)被代理给了父加载器PL, 那么类加载器CL也不会再起加载类C中依赖的任何其他的类. 类加载CL就不再是哪些类的initiator, 它的父加载器PL就成为了initiator, 然后PL负责去加载哪些类. 类C定义中指向的那些类将会被类C的真实加载器进行加载. Furthermore, if a class loader CL requested to load a class C (the initiator of C) delegates to the parent class loader PL, then the class loader CL is never requested to load any classes referred to in the definition of the class C. CL is not the initiator of those classes. Instead, the parent class loader PL becomes their initiators and it is requested to load them. The classes that the definition of a class C referes to are loaded by the real loader of C. 下面看一个例子, 深入理解一下: To understand this behavior, let’s consider the following example. 12345678910111213141516public class Point &#123; // loaded by PL private int x, y; public int getX() &#123; return x; &#125; :&#125;public class Box &#123; // the initiator is L but the real loader is PL private Point upperLeft, size; public int getBaseX() &#123; return upperLeft.x; &#125; :&#125;public class Window &#123; // loaded by a class loader L private Box box; public int getBaseX() &#123; return box.getBaseX(); &#125;&#125; 假设类Window是被类加载器L加载的. 那么类Window的initiator和真实加载器都是L. 因为Window定义里面指向了类Box, JVM还将事业L去加载类Box. 这里, 假设, L将加载动作委托给了父加载器PL. Box的initiator就是L, 但是真实加载器就成PL. 在这个例子中, Point的initiator就成了PL而不是L, 因为它和Box的真实加载器是一样的. 因此L从来都不会加载Point. Suppose that a class Window is loaded by a class loader L. Both the initiator and the real loader of Window are L. Since the definition of Window refers to Box, the JVM will request L to load Box. Here, suppose that L delegates this task to the parent class loader PL. The initiator of Box is L but the real loader is PL. In this case, the initiator of Point is not L but PL since it is the same as the real loader of Box. Thus L is never requested to load Point. Next, let’s consider a slightly modified example. 下面的例子对刚才进行了一些稍微的修改: 12345678910111213141516171819public class Point &#123; private int x, y; public int getX() &#123; return x; &#125; :&#125;public class Box &#123; // the initiator is L but the real loader is PL private Point upperLeft, size; public Point getSize() &#123; return size; &#125; :&#125;public class Window &#123; // loaded by a class loader L private Box box; public boolean widthIs(int w) &#123; Point p = box.getSize(); return w == p.getX(); &#125;&#125; 现在, Window的定义也指向了Point. 在这个例子中, 如果类加载器L要加载Point, 它必须也被代理给PL. 你必须避免有俩个类加载器俩次加载相同一个类. 这俩个类加载器中的一个必须代理给另一个. Now, the definition of Window also refers to Point. In this case, the class loader L must also delegate to PL if it is requested to load Point. You must avoid having two class loaders doubly load the same class. One of the two loaders must delegate to the other. 当Point被加载的时候, 如果L没有被代理给PL, widthIs() 将会抛出一个ClassCastException. 因为Box的真实类加载器是PL, Box中关联的Point也会被PL加载. 因此, getSize()真实调用的实例是由PL加载的类Point产生的, 而widthIs()中的变量p是由L加载的类Point. JVM将他们视作俩个类型, 因此会因为类型不匹配抛出一个异常. If L does not delegate to PL when Point is loaded, widthIs() would throw a ClassCastException. Since the real loader of Box is PL, Point referred to in Box is also loaded by PL. Therefore, the resulting value of getSize() is an instance of Point loaded by PL whereas the type of the variable p in widthIs() is Point loaded by L. The JVM regards them as distinct types and thus it throws an exception because of type mismatch. 这个行为看起来是有点不方便, 但是却很必须的. 看下面的代码: This behavior is somewhat inconvenient but necessary. If the following statement: 1Point p = box.getSize(); 这就不会抛出异常, 写Window的程序员破坏了Point对象的封装. 例如, 被PL加载的类Point中有个字段x是私有的. 如果L加载下面程序描述的Point, Window类就可以直接访问x的值. did not throw an exception, then the programmer of Window could break the encapsulation of Point objects. For example, the field x is private in Point loaded by PL. However, the Window class could directly access the value of x if L loads Point with the following definition: 12345public class Point &#123; public int x, y; // not private public int getX() &#123; return x; &#125; :&#125; 更多关于Java类加载器的细节, 下面的文章会更优帮助: For more details of class loaders in Java, the following paper would be helpful: Sheng Liang and Gilad Bracha, “Dynamic Class Loading in the Java Virtual Machine”,ACM OOPSLA’98, pp.36-44, 1998. 3.3 Using javassist.LoaderJavassist 提供了一个类加载器javassist.Loader. 这个类加载器使用javassist.ClassPool对象来读取class文件. Javassist provides a class loader javassist.Loader. This class loader uses a javassist.ClassPool object for reading a class file. 例如, javassist.Loader 可以用来加载被Javassist修改过的class. For example, javassist.Loader can be used for loading a particular class modified with Javassist. 12345678910111213141516import javassist.*;import test.Rectangle;public class Main &#123; public static void main(String[] args) throws Throwable &#123; ClassPool pool = ClassPool.getDefault(); Loader cl = new Loader(pool); CtClass ct = pool.get(&quot;test.Rectangle&quot;); ct.setSuperclass(pool.get(&quot;test.Point&quot;)); Class c = cl.loadClass(&quot;test.Rectangle&quot;); Object rect = c.newInstance(); : &#125;&#125; 这个应用程序修改了类test.Rectangle. test.Rectangle的父类被设置为了test.Point. 然后应用程序将修改过的class加载, 最后创建出一个新的test.Rectangle实例出来. This program modifies a class test.Rectangle. The superclass of test.Rectangle is set to a test.Point class. Then this program loads the modified class, and creates a new instance of the test.Rectangle class. 如果用户想要当class被加载后, 后台会自动修改class, 可以通过向javassist.Loader添加事件监听器来完成. 当类加载器加载类的时候会自动通知注册了的事件监听器. 事件监听器必须下面的接口. If the users want to modify a class on demand when it is loaded, the users can add an event listener to a javassist.Loader. The added event listener is notified when the class loader loads a class. The event-listener class must implement the following interface: 123456public interface Translator &#123; public void start(ClassPool pool) throws NotFoundException, CannotCompileException; public void onLoad(ClassPool pool, String classname) throws NotFoundException, CannotCompileException;&#125; 当通过调用javassist.Loader的addTranslator()向javassist.Loader添加完成事件监听器后, start()方法就会被调用. onLoad()方法会在javassist.Loader加载类之前被调用. 可以在onLoad() 方法中修改一个类的定义. The method start() is called when this event listener is added to a javassist.Loader object by addTranslator() in javassist.Loader. The method onLoad() is called before javassist.Loader loads a class. onLoad() can modify the definition of the loaded class. 例如, 下面的事件监听器在class被加载之前全部被修改成public. For example, the following event listener changes all classes to public classes just before they are loaded. 12345678910public class MyTranslator implements Translator &#123; void start(ClassPool pool) throws NotFoundException, CannotCompileException &#123;&#125; void onLoad(ClassPool pool, String classname) throws NotFoundException, CannotCompileException &#123; CtClass cc = pool.get(classname); cc.setModifiers(Modifier.PUBLIC); &#125;&#125; 注意, onLoad()方法中不用调用toBytecode() 或者 writeFile() 方法, javassist.Loader会自动去调用那些方法. Note that onLoad() does not have to call toBytecode() or writeFile() since javassist.Loader calls these methods to obtain a class file. To run an application class MyApp with a MyTranslator object, write a main class as following: 1234567891011import javassist.*;public class Main2 &#123; public static void main(String[] args) throws Throwable &#123; Translator t = new MyTranslator(); ClassPool pool = ClassPool.getDefault(); Loader cl = new Loader(); cl.addTranslator(pool, t); cl.run(&quot;MyApp&quot;, args); &#125;&#125; To run this program, do: 运行程序: 1% java Main2 arg1 arg2... 类MyApp和程序中其他的类都会被MyTranslator修改. The class MyApp and the other application classes are translated by MyTranslator. 注意, 程序中像MyApp这样的类不能访问oader classes, 例如Main2, MyTranslator, and ClassPool, 因为它们是被不同的加载器加载的. 应用程序的类是被javassist.Loader而loader classes(例如Main2)是被Java默认的类加载器加载的. Note that application classes like MyApp cannot access the loader classes such as Main2, MyTranslator, and ClassPool because they are loaded by different loaders. The application classes are loaded by javassist.Loader whereas the loader classes such as Main2 are by the default Java class loader. javassist.Loader搜索类的顺序和java.lang.ClassLoader不一样. ClassLoader首先会将加载动作委托给他们父加载器, 只有当父加载器找不到, ClassLoader自己才会去加载. 而javassist.Loader 在委托给父类加载器之前, 自己首先加载一遍. 直接委托父加载器加载只取决于 在调用ClassPool对象的get()方法是没有找到搜索的类 或者通过delegateLoadingOf()设置指定由父加载器去进行加载. javassist.Loader searches for classes in a different order from java.lang.ClassLoader. ClassLoader first delegates the loading operations to the parent class loader and then attempts to load the classes only if the parent class loader cannot find them. On the other hand, javassist.Loader attempts to load the classes before delegating to the parent class loader. It delegates only if: the classes are not found by calling get() on a ClassPool object, or the classes have been specified by using delegateLoadingOf() to be loaded by the parent class loader. 这种搜索顺序允许Javassist 加载修改过的类. 一旦它由于某些原因找不到修改过的类, 它仍然会将搜索动作委托给父加载器进行加载. 一旦类被父加载器加载到了, 那么类中其他的类也会被父加载器进行加载, 因此这些被父加载器加载的类是永远也不是被修改过的. 回想一下前文介绍的, 在类C中包含的类也会被C的真实加载器进行加载. 如果你的程序加载修改过的类失败了, 你应该确认一下使用那些类的其他类是否也被javassist.Loader进行加载的. This search order allows loading modified classes by Javassist. However, it delegates to the parent class loader if it fails to find modified classes for some reason. Once a class is loaded by the parent class loader, the other classes referred to in that class will be also loaded by the parent class loader and thus they are never modified. Recall that all the classes referred to in a class C are loaded by the real loader of C. If your program fails to load a modified class, you should make sure whether all the classes using that class have been loaded by javassist.Loader. 3.4 Writing a class loaderA simple class loader using Javassist is as follows: 使用Javassist中的类加载器很简单: 12345678910111213141516171819202122232425262728293031323334353637import javassist.*;public class SampleLoader extends ClassLoader &#123; /* Call MyApp.main(). */ public static void main(String[] args) throws Throwable &#123; SampleLoader s = new SampleLoader(); Class c = s.loadClass(&quot;MyApp&quot;); c.getDeclaredMethod(&quot;main&quot;, new Class[] &#123; String[].class &#125;) .invoke(null, new Object[] &#123; args &#125;); &#125; private ClassPool pool; public SampleLoader() throws NotFoundException &#123; pool = new ClassPool(); pool.insertClassPath(&quot;./class&quot;); // MyApp.class must be there. &#125; /* Finds a specified class. * The bytecode for that class can be modified. */ protected Class findClass(String name) throws ClassNotFoundException &#123; try &#123; CtClass cc = pool.get(name); // modify the CtClass object here byte[] b = cc.toBytecode(); return defineClass(name, b, 0, b.length); &#125; catch (NotFoundException e) &#123; throw new ClassNotFoundException(); &#125; catch (IOException e) &#123; throw new ClassNotFoundException(); &#125; catch (CannotCompileException e) &#123; throw new ClassNotFoundException(); &#125; &#125;&#125; 类MyApp是一个应用程序. 执行程序之前, 首先要将该类放到./class目录下, 但是不能包含在类搜索路径里. 否则MyApp.class会被系统默认的类加载器进行加载(会被SampleLoader父加载器加载). 通过在构建器中调用 insertClassPath() 设置了路径的名称./class. 你也可以不用./class, 换一个其他的名称, 然后执行: The class MyApp is an application program. To execute this program, first put the class file under the ./class directory, which must not be included in the class search path. Otherwise, MyApp.class would be loaded by the default system class loader, which is the parent loader of SampleLoader. The directory name ./class is specified by insertClassPath() in the constructor. You can choose a different name instead of ./class if you want. Then do as follows: 1% java SampleLoader 类加载器会从./class/MyApp.class加载类MyApp, 然后调用MyApp.main()方法. The class loader loads the class MyApp (./class/MyApp.class) and calls MyApp.main() with the command line parameters. 这是使用Javassist最简单的方式. 然而, 如果你写了一个复杂的类加载器, 你必须熟悉java类加载机制的细节. 例如, 上面的应用程序将MyApp放到了与SampleLoader所属的不同的一个名称空间里, 因为这俩个类是由不同的类加载器进行加载的. 因此MyApp不能直接访问类SampleLoader. This is the simplest way of using Javassist. However, if you write a more complex class loader, you may need detailed knowledge of Java’s class loading mechanism. For example, the program above puts the MyApp class in a name space separated from the name space that the class SampleLoader belongs to because the two classes are loaded by different class loaders. Hence, the MyApp class cannot directly access the class SampleLoader. 3.5 Modifying a system class系统类例如java.lang.String除了系统类加载器之外不能被其他的类加载加载. 因此, 上面提到的SampleLoader或者javassist.Loader在加载时不能修改系统的类. The system classes like java.lang.String cannot be loaded by a class loader other than the system class loader. Therefore, SampleLoader or javassist.Loader shown above cannot modify the system classes at loading time. 但是如果你的程序想要修改系统类, 那么系统类必须被静态修改. 例如下面的程序在java.lang.String添加了一个字段hiddenValue: If your application needs to do that, the system classes must be statically modified. For example, the following program adds a new field hiddenValue to java.lang.String: 123456ClassPool pool = ClassPool.getDefault();CtClass cc = pool.get(&quot;java.lang.String&quot;);CtField f = new CtField(CtClass.intType, &quot;hiddenValue&quot;, cc);f.setModifiers(Modifier.PUBLIC);cc.addField(f);cc.writeFile(&quot;.&quot;); 这个程序产生了一个文件./java/lang/String.class. This program produces a file “./java/lang/String.class”. To run your program MyApp with this modified String class, do as follows: 在MyApp中使用这个修改过的类String, 例如: 1% java -Xbootclasspath/p:. MyApp arg1 arg2... 假设MyApp定义如下: Suppose that the definition of MyApp is as follows: 12345public class MyApp &#123; public static void main(String[] args) throws Exception &#123; System.out.println(String.class.getField(&quot;hiddenValue&quot;).getName()); &#125;&#125; 如果修改过的String被正确地加载, MyApp会打印hiddenValue的值. If the modified String class is correctly loaded, MyApp prints hiddenValue. 注意, 应用程序使用这个技术在覆盖rt.jar中的系统类的时候不应该被部署, 否则会违反Java 2 Runtime Environment binary code license 授权. Note: Applications that use this technique for the purpose of overriding a system class in rt.jar should not be deployed as doing so would contravene the Java 2 Runtime Environment binary code license. 3.6 Reloading a class at runtime如果JVM在运行时JPDA开启了, 类就可以动态重加载了. JVM加载一个类后, 旧版本的class可以被卸载, 新版本的class可以再次加载进来. 这样一来就完成了在运行期动态修改类. 但是, 新版本的类定义必须兼容旧版本的类定义. JVM不允许这俩个版本的类的schema发生改变. 他们必须拥有相同的方法和字段. Javassist提供了一个工具类用于在运行期动态重加载. 更多的细节信息参考API文档javassist.tools.HotSwapper. If the JVM is launched with the JPDA (Java Platform Debugger Architecture) enabled, a class is dynamically reloadable. After the JVM loads a class, the old version of the class definition can be unloaded and a new one can be reloaded again. That is, the definition of that class can be dynamically modified during runtime. However, the new class definition must be somewhat compatible to the old one. The JVM does not allow schema changes between the two versions. They have the same set of methods and fields. Javassist provides a convenient class for reloading a class at runtime. For more information, see the API documentation of javassist.tools.HotSwapper.","categories":[{"name":"Javasist","slug":"Javasist","permalink":"https://wangmingco.github.io/categories/Javasist/"}],"tags":[]},{"title":"Javasist ClassPool","slug":"JavaLibrary/Javasist 2 ClassPool","date":"2019-05-02T12:15:00.000Z","updated":"2021-11-18T02:32:45.522Z","comments":true,"path":"2019/05/02/JavaLibrary/Javasist 2 ClassPool/","link":"","permalink":"https://wangmingco.github.io/2019/05/02/JavaLibrary/Javasist%202%20ClassPool/","excerpt":"","text":"A ClassPool object is a container of CtClass objects. Once a CtClass object is created, it is recorded in a ClassPool for ever. This is because a compiler may need to access the CtClass object later when it compiles source code that refers to the class represented by that CtClass. ClassPool对象是CtClass对象的集合. 一旦CtClass对象被创建出来, 它就会被永远地保存在ClassPool中. 这是因为编译器在编译源码的时候可能还需要访问这些CtClass对象. For example, suppose that a new method getter() is added to a CtClass object representing Point class. Later, the program attempts to compile source code including a method call to getter() in Point and use the compiled code as the body of a method, which will be added to another class Line. If the CtClass object representing Point is lost, the compiler cannot compile the method call to getter(). Note that the original class definition does not include getter(). Therefore, to correctly compile such a method call, the ClassPool must contain all the instances of CtClass all the time of program execution. 例如, 向Point类的CtClass对象添加一个新的getter()方法. 然后程序将某段调用Point的getter()方法的源码片段进行编译, 然后将编译好的代码片段放到另外一个类里. 如果找不到代表Point的CtClass的话, 编译器就没办法编译对getter()方法的调用. 注意, 原先的class是不包含getter()方法的. 因此, 为了能正确进行编译, 在程序运行期间, ClassPool必须包含全部的CtClass实例. Avoid out of memoryThis specification of ClassPool may cause huge memory consumption if the number of CtClass objects becomes amazingly large (this rarely happens since Javassist tries to reduce memory consumption in various ways). To avoid this problem, you can explicitly remove an unnecessary CtClass object from the ClassPool. If you call detach() on a CtClass object, then that CtClass object is removed from the ClassPool. For example, 按照上文描述的那样, 如果CtClass实例数量飞速增长的话, ClassPool就有可能会引起巨大的内存消耗(但是实际上这种情况很少发生, 因此Javassist会通过多种方式减少内存消耗). 为了解决这种问题, 你可以显式地从ClassPool里面删除不需要的CtClass实例. 如果你在CtClass对象上调用detach()方法的, 该对象就会从ClassPool里面移除. 例如: 123CtClass cc = ... ;cc.writeFile();cc.detach(); 当 detach() 方法被调用之后, CtClass实例的其他方法就不再允许被调用. 但是你可以接着调用ClassPool的get()方法, 再获得一个相同class的新的CtClass实例. 如果你调用了get()方法, ClassPool会重新读取class 文件, 然后再创建一个新的CtClass对象. You must not call any method on that CtClass object after detach() is called. However, you can call get() on ClassPool to make a new instance of CtClass representing the same class. If you call get(), the ClassPool reads a class file again and newly creates a CtClass object, which is returned by get(). 另一种思路是再重新创建一个ClassPool, 然后将旧的那个舍弃掉. 如果旧的ClassPool被gc掉了, 那么原先ClassPool里的CtClass对象也都被gc掉了. 如果要创建一个新的ClassPool实例, 执行下面的代码即可: Another idea is to occasionally replace a ClassPool with a new one and discard the old one. If an old ClassPool is garbage collected, the CtClass objects included in that ClassPool are also garbage collected. To create a new instance of ClassPool, execute the following code snippet: 12ClassPool cp = new ClassPool(true);// if needed, append an extra search path by appendClassPath() 刚才创建的ClassPool的行为和通过调用ClassPool.getDefault()返回的默认ClassPool是一样的. 注意ClassPool.getDefault()是出于便捷目的而存在的一个单例工厂方法. ClassPool.getDefault() 会像上面那样创建一个ClassPool 对象, 然后作为单例存在, 一直复用它. 通过getDefault()返回的ClassPool并没有特殊的规则. getDefault() 只是一个快捷方法. This creates a ClassPool object that behaves as the default ClassPool returned by ClassPool.getDefault() does. Note that ClassPool.getDefault() is a singleton factory method provided for convenience. It creates a ClassPool object in the same way shown above although it keeps a single instance of ClassPool and reuses it. A ClassPool object returned by getDefault() does not have a special role. getDefault() is a convenience method. 注意 new ClassPool(true) 是一个快捷构造器, 它只是构建了一个ClassPool对象, 然后将系统搜索路径添加到这上面. 该构造器方法和下面方法等同.Note that new ClassPool(true) is a convenient constructor, which constructs a ClassPool object and appends the system search path to it. Calling that constructor is equivalent to the following code: 12ClassPool cp = new ClassPool();cp.appendSystemPath(); // or append another path by appendClassPath() Cascaded ClassPools如果应用程序是运行在一个web 服务器上, 那么就有可能需要创建多个ClassPool实例. 每个class Loader都需要创建一个ClassPool实例. 在这种背景下, 就需要通过ClassPool的构造器创建ClassPool实例, 而不能再通过getDefault()方法获得了. If a program is running on a web application server, creating multiple instances of ClassPool might be necessary; an instance of ClassPool should be created for each class loader (i.e. container). The program should create a ClassPool object by not calling getDefault() but a constructor of ClassPool. Multiple ClassPool objects can be cascaded like java.lang.ClassLoader. For example, 多个ClassPool对象可以像java.lang.ClassLoader那样呗级联起来. 例如: 123ClassPool parent = ClassPool.getDefault();ClassPool child = new ClassPool(parent);child.insertClassPath(&quot;./classes&quot;); 如果child.get()方法被调用, child ClassPool首先将该请求委托给上一级ClassPool. 如果上一级ClassPool没有找到目标class文件, 那么child ClassPool就会尝试在./classes目录里查找class文件. If child.get() is called, the child ClassPool first delegates to the parent ClassPool. If the parent ClassPool fails to find a class file, then the child ClassPool attempts to find a class file under the ./classes directory. 如果 child.childFirstLookup 被设置为true的话, child ClassPool就会首先尝试尝试查找class文件, 找不到再去上一级ClassPool中查找. 例如: If child.childFirstLookup is true, the child ClassPool attempts to find a class file before delegating to the parent ClassPool. For example, 1234ClassPool parent = ClassPool.getDefault();ClassPool child = new ClassPool(parent);child.appendSystemPath(); // the same class path as the default one.child.childFirstLookup = true; // changes the behavior of the child. Changing a class name for defining a new classA new class can be defined as a copy of an existing class. The program below does that: 一个新的class可以通过从已经存在的class的副本中制作出来. 例如L 123ClassPool pool = ClassPool.getDefault();CtClass cc = pool.get(&quot;Point&quot;);cc.setName(&quot;Pair&quot;); 上面的程序首先获得了Point对应的CtClass对象. 然后它调用setName()设置了一个新的名称Pair. setName()被调用之后, CtClass对象中的所有该class 名称都从Point转换成了Pair. 但是class 定义的其他部分并没有变. This program first obtains the CtClass object for class Point. Then it calls setName() to give a new name Pair to that CtClass object. After this call, all occurrences of the class name in the class definition represented by that CtClass object are changed from Point to Pair. The other part of the class definition does not change. 注意CtClass的setName()也会改变ClassPool中的记录. 从实现角度来说, 一个CLassPool对象就是CtClass对象的一个hash表. setName()也会将hash表中和CtClass对象关联的key也更改掉. key从原先的class名称换到了新的class名称.Note that setName() in CtClass changes a record in the ClassPool object. From the implementation viewpoint, a ClassPool object is a hash table of CtClass objects. setName() changes the key associated to the CtClass object in the hash table. The key is changed from the original class name to the new class name. 因此, 如果再次调用ClassPool的get(“Point”)方法, 再也不会返回cc所指向的CtClass对象. ClassPool会再次读取Point.class文件, 然后构建出一个新的Point的CtClass对象出来. 这厮因为和Point名称关联的CtClass对象已经不复存在了. 例如: Therefore, if get(“Point”) is later called on the ClassPool object again, then it never returns the CtClass object that the variable cc refers to. The ClassPool object reads a class file Point.class again and it constructs a new CtClass object for class Point. This is because the CtClass object associated with the name Point does not exist any more. See the followings: 123456ClassPool pool = ClassPool.getDefault();CtClass cc = pool.get(&quot;Point&quot;);CtClass cc1 = pool.get(&quot;Point&quot;); // cc1 is identical to cc.cc.setName(&quot;Pair&quot;);CtClass cc2 = pool.get(&quot;Pair&quot;); // cc2 is identical to cc.CtClass cc3 = pool.get(&quot;Point&quot;); // cc3 is not identical to cc. cc1和cc2指向的是和cc指向的相同的对象, 而cc3则不是. 注意, cc.setName(“Pair”) 方法执行之后, cc和cc1指向CtClass对象也代表着Pair class.cc1 and cc2 refer to the same instance of CtClass that cc does whereas cc3 does not. Note that, after cc.setName(“Pair”) is executed, the CtClass object that cc and cc1 refer to represents the Pair class. ClassPool对象被用来维持class和CtClass对象之间的一对一映射. 在同一个ClassPool中, Javassist从不允许俩个不同的CtClass对象代表同一个class. 对于程序转换来说, 这是一个非常有意义的特性. The ClassPool object is used to maintain one-to-one mapping between classes and CtClass objects. Javassist never allows two distinct CtClass objects to represent the same class unless two independent ClassPool are created. This is a significant feature for consistent program transformation. 如果你有俩个ClassPool对象, 那么你可以从每个ClassPool里面获得一个相同的class的CtClass对象. 你可以通过修改不同的CtClass对象生成不同版本的class. If you have two ClassPool objects, then you can obtain, from each ClassPool, a distinct CtClass object representing the same class file. You can differently modify these CtClass objects to generate different versions of the class. Renaming a frozen class for defining a new class一旦一个CtClass对象通过writeFile() or toBytecode()方法转换成一个class, Javassist就不允许CtClass对象再次修改了. 因此, 当代表Point的CtClass对象被转换成一个class之后, 你就不能再通过设置setName()的方式来获取一个Point的副本Pair了. 例如下面的代码, 是不合法的. Once a CtClass object is converted into a class file by writeFile() or toBytecode(), Javassist rejects further modifications of that CtClass object. Hence, after the CtClass object representing Point class is converted into a class file, you cannot define Pair class as a copy of Point since executing setName() on Point is rejected. The following code snippet is wrong: 1234ClassPool pool = ClassPool.getDefault();CtClass cc = pool.get(&quot;Point&quot;);cc.writeFile();cc.setName(&quot;Pair&quot;); // wrong since writeFile() has been called. To avoid this restriction, you should call getAndRename() in ClassPool. For example, 对于这种限制, 你应该调用ClassPool的getAndRename()方法, 例如: 1234ClassPool pool = ClassPool.getDefault();CtClass cc = pool.get(&quot;Point&quot;);cc.writeFile();CtClass cc2 = pool.getAndRename(&quot;Point&quot;, &quot;Pair&quot;); getAndRename()被调用之后, ClassPool首先读取Point.class, 然后创建出一个代表Point class的CtClass对象. 在存储ClassPool的hash表之前, 它将CtClass名称从Point重新命名为Pair. 因此, getAndRename() 可以再writeFile() or toBytecode()被调用之后 再次调用. If getAndRename() is called, the ClassPool first reads Point.class for creating a new CtClass object representing Point class. However, it renames that CtClass object from Point to Pair before it records that CtClass object in a hash table. Thus getAndRename() can be executed after writeFile() or toBytecode() is called on the the CtClass object representing Point class.","categories":[{"name":"Javasist","slug":"Javasist","permalink":"https://wangmingco.github.io/categories/Javasist/"}],"tags":[]},{"title":"Javasist Reading and writing bytecode","slug":"JavaLibrary/Javasist 1 Reading and writing bytecode","date":"2019-05-01T12:15:00.000Z","updated":"2021-11-18T02:32:42.398Z","comments":true,"path":"2019/05/01/JavaLibrary/Javasist 1 Reading and writing bytecode/","link":"","permalink":"https://wangmingco.github.io/2019/05/01/JavaLibrary/Javasist%201%20Reading%20and%20writing%20bytecode/","excerpt":"","text":"Javassist is a class library for dealing with Java bytecode. Java bytecode is stored in a binary file called a class file. Each class file contains one Java class or interface. Javassist 是一个用于处理 Java 字节码的类库, Java 字节码被存储在一个后缀为 class 的二进制文件中. 每个 class 文件包含一个 Java 类或者 Java 接口. The class Javassist.CtClass is an abstract representation of a class file. A CtClass (compile-time class) object is a handle for dealing with a class file. The following program is a very simple example: Javassist.CtClass 类是对 class 文件的一个抽象表示. 一个 CtClass (compile-time class) 对象处理一个 class 文件. 下面的程序是一个非常简单的示例: 1234ClassPool pool = ClassPool.getDefault();CtClass cc = pool.get(&quot;test.Rectangle&quot;);cc.setSuperclass(pool.get(&quot;test.Point&quot;));cc.writeFile(); This program first obtains a ClassPool object, which controls bytecode modification with Javassist. The ClassPool object is a container of CtClass object representing a class file. It reads a class file on demand for constructing a CtClass object and records the constructed object for responding later accesses. To modify the definition of a class, the users must first obtain from a ClassPool object a reference to a CtClass object representing that class. get() in ClassPool is used for this purpose. In the case of the program shown above, the CtClass object representing a class test.Rectangle is obtained from the ClassPool object and it is assigned to a variable cc. The ClassPool object returned by getDefault() searches the default system search path. 这个程序首先获得了一个ClassPool对象, 该对象在 Javassist 中用于控制字节码的修改. ClassPool 对象是一个 CtClass对象的容器. ClassPool将读取的class文件构建出CtClass对象, 同时将构建出来的对象缓存起来, 以便后期访问. ClassPool的get()方法正是出于上述目的. 在上面的代码中, 从ClassPool得到的CtClass对象表示的是一个test.Rectangle对象, 然后将该对象分配给了一个变量cc. getDefault()方法会从默认的系统搜索路径中进行搜索, 然后返回ClassPool对象. From the implementation viewpoint, ClassPool is a hash table of CtClass objects, which uses the class names as keys. get() in ClassPool searches this hash table to find a CtClass object associated with the specified key. If such a CtClass object is not found, get() reads a class file to construct a new CtClass object, which is recorded in the hash table and then returned as the resulting value of get(). 从实现上来说, ClassPool是一个CtClass对象的哈希表, 将class的名称作为key. ClassPool中的 get() 方法会根据指定的key对整个哈希表进行搜索找到一个CtClass对象. 如果搜索不到的话, get()方法会尝试读取class文件, 然后构造出一个新的CtClass对象, 将新的CtClass对象缓存后, 再返回出去. The CtClass object obtained from a ClassPool object can be modified (details of how to modify a CtClass will be presented later). In the example above, it is modified so that the superclass of test.Rectangle is changed into a class test.Point. This change is reflected on the original class file when writeFile() in CtClass() is finally called. 从ClassPool中拿到的CtClass对象可以对其进行修改(修改CtClass的细节会在后续的文章中讲解). 在上面的例子中, 通过CtClass的修改就将test.Rectangle的父类修改了test.Point. 如果我们调用了CtClass的writeFile()方法, 这个修改也对原先的class文件生效了. writeFile() translates the CtClass object into a class file and writes it on a local disk. Javassist also provides a method for directly obtaining the modified bytecode. To obtain the bytecode, call toBytecode(): writeFile()将CtClass对象转换成一个class文件, 然后将该文件写到本地磁盘上. Javassist还提供了用于直接获得修改后的字节码的方法-toBytecode(): 1byte[] b = cc.toBytecode(); You can directly load the CtClass as well: 你也可以直接将Class加载进去. 1Class clazz = cc.toClass(); toClass() requests the context class loader for the current thread to load the class file represented by the CtClass. It returns a java.lang.Class object representing the loaded class. For more details, please see this section below. toClass()方法 会使用当前线程的context class loader将CtClass内的字节码加载进JVM里, 然后返回一个java.lang.Class对象. Defining a new classTo define a new class from scratch, makeClass() must be called on a ClassPool. 从头开始定义一个新的class, 必须调用ClassPool的makeClass() 方法. 12ClassPool pool = ClassPool.getDefault();CtClass cc = pool.makeClass(&quot;Point&quot;); This program defines a class Point including no members. Member methods of Point can be created with factory methods declared in CtNewMethod and appended to Point with addMethod() in CtClass. 上面的程序定义了一个没有任何成员的名称为Point的class. 可以通过CtNewMethod里声明的一些工厂方法为Point类生成一些方法, 然后通过调用CtClass的addMethod()方法, 将这些新生成的方法加到Pointclass里面去. makeClass() cannot create a new interface; makeInterface() in ClassPool can do. Member methods in an interface can be created with abstractMethod() in CtNewMethod. Note that an interface method is an abstract method. makeClass() 不能创建新的接口, 但是可以使用ClassPool中的makeInterface()创建一个新的接口. 接口中的方法可以使用CtNewMethod的abstractMethod()方法创建出来. 注意, 一个接口方法就是一个抽象方法. Frozen classesIf a CtClass object is converted into a class file by writeFile(), toClass(), or toBytecode(), Javassist freezes that CtClass object. Further modifications of that CtClass object are not permitted. This is for warning the developers when they attempt to modify a class file that has been already loaded since the JVM does not allow reloading a class. 如果CtClass对象通过writeFile(), toClass(), or toBytecode()等方式转换成一个class文件, Javassist会将CtClass对象冻结. 被冻结的CtClass对象不允许再次修改. 这是为了警告开发者, 他们尝试修改一个已经被load的class文件, 而JVM不允许重新加载class. A frozen CtClass can be defrost so that modifications of the class definition will be permitted. For example, 被冻结的CtClass也可以进行解冻, 解冻之后就可以继续就那些修改了, 例如: 12345CtClasss cc = ...; :cc.writeFile();cc.defrost();cc.setSuperclass(...); // OK since the class is not frozen. After defrost() is called, the CtClass object can be modified again. 当defrost()方法被调用之后, CtClass就可以再次修改了. If ClassPool.doPruning is set to true, then Javassist prunes the data structure contained in a CtClass object when Javassist freezes that object. To reduce memory consumption, pruning discards unnecessary attributes (attribute_info structures) in that object. For example, Code_attribute structures (method bodies) are discarded. Thus, after a CtClass object is pruned, the bytecode of a method is not accessible except method names, signatures, and annotations. The pruned CtClass object cannot be defrost again. The default value of ClassPool.doPruning is false. 如果ClassPool.doPruning被设置为true的话, 当Javassist冻结CtClass对象的时候, 会对其内部的数据结构进行精简. 为了减少内存消耗, pruning精简了attribute_info结构里不必要的属性. 例如方法体里面的Code_attribute结构就会被舍弃掉. 因此一旦CtClass对象被精简之后, 方法除了名称, 签名, 注解等其他信息都不可再被访问到. 而且被精简过后的CtClass对象也不可以再被解冻. ClassPool.doPruning默认值是false. To disallow pruning a particular CtClass, stopPruning() must be called on that object in advance: 如果将要设置某个特殊的CtClass不允许精简, 必选提前调用CtClasss对象的stopPruning()方法. 12345CtClasss cc = ...;cc.stopPruning(true); :cc.writeFile(); // convert to a class file.// cc is not pruned. The CtClass object cc is not pruned. Thus it can be defrost after writeFile() is called. 上面CtClass对象没有被精简, 因此当它调用了writeFile()方法之后, 还可以被解冻. Note: While debugging, you might want to temporarily stop pruning and freezing and write a modified class file to a disk drive. debugWriteFile() is a convenient method for that purpose. It stops pruning, writes a class file, defrosts it, and turns pruning on again (if it was initially on). 注意: 在调试阶段, 你也许想要临时地停止精简和冻结操作, 然后将一个修改过的class文件写到磁盘中, 此时你可以调用debugWriteFile()方法. 它首先停止精简操作, 然后对class文件执行写入操作, 最后再解冻, 最后回复精简状态. Class search pathThe default ClassPool returned by a static method ClassPool.getDefault() searches the same path that the underlying JVM (Java virtual machine) has. If a program is running on a web application server such as JBoss and Tomcat, the ClassPool object may not be able to find user classes since such a web application server uses multiple class loaders as well as the system class loader. In that case, an additional class path must be registered to the ClassPool. Suppose that pool refers to a ClassPool object: ClassPool.getDefault()返回的默认的ClassPool是基于JVM的path上面搜索得到的. 如果应用程序是运行在一个web应用服务器上(例如JBoss或者Tomcat), ClassPool对象可能会找不到用户定义的class, 因为web应用服务器可能会使用多个class Loader. 在这种情况下可以向ClassPool上注册一个新的class path. 1pool.insertClassPath(new ClassClassPath(this.getClass())); This statement registers the class path that was used for loading the class of the object that this refers to. You can use any Class object as an argument instead of this.getClass(). The class path used for loading the class represented by that Class object is registered. You can register a directory name as the class search path. For example, the following code adds a directory /usr/local/javalib to the search path: 12ClassPool pool = ClassPool.getDefault();pool.insertClassPath(&quot;/usr/local/javalib&quot;); The search path that the users can add is not only a directory but also a URL: 用户能添加的search path不仅仅是目录, 还可以添加URL: 123ClassPool pool = ClassPool.getDefault();ClassPath cp = new URLClassPath(&quot;www.javassist.org&quot;, 80, &quot;/java/&quot;, &quot;org.javassist.&quot;);pool.insertClassPath(cp); 这个应用程序添加了一个http://www.javassist.org:80/java/url到search path上. 只有当搜索属于org.javassist这个包下的类的时候, 才会去这个URL上进行搜索. 例如当加载org.javassist.test.Main类时, 它的class 文件将会从http://www.javassist.org:80/java/org/javassist/test/Main.class上进行加载. This program adds “http://www.javassist.org:80/java/&quot; to the class search path. This URL is used only for searching classes belonging to a package org.javassist. For example, to load a class org.javassist.test.Main, its class file will be obtained from: http://www.javassist.org:80/java/org/javassist/test/Main.class Furthermore, you can directly give a byte array to a ClassPool object and construct a CtClass object from that array. To do this, use ByteArrayClassPath. For example, 另外, 你可以直接向ClassPool对象里指定一个byte数组, ClassPool会从这个byte数组里构建出一个CtClass对象. 想要使用这种方案, 可以用ByteArrayClassPath, 例如: 12345ClassPool cp = ClassPool.getDefault();byte[] b = a byte array;String name = class name;cp.insertClassPath(new ByteArrayClassPath(name, b));CtClass cc = cp.get(name); The obtained CtClass object represents a class defined by the class file specified by b. The ClassPool reads a class file from the given ByteArrayClassPath if get() is called and the class name given to get() is equal to one specified by name. 获取到的CtClass对象就是从b数组里定义出来的. 当get()方法被调用的时候, ClassPool会从给定的ByteArrayClassPath里读取出一个class文件, class名称就是参数name. If you do not know the fully-qualified name of the class, then you can use makeClass() in ClassPool:如果你不知道class的全限定名称, 你可以使用ClassPool的makeClass()方法. 123ClassPool cp = ClassPool.getDefault();InputStream ins = an input stream for reading a class file;CtClass cc = cp.makeClass(ins); makeClass() returns the CtClass object constructed from the given input stream. You can use makeClass() for eagerly feeding class files to the ClassPool object. This might improve performance if the search path includes a large jar file. Since a ClassPool object reads a class file on demand, it might repeatedly search the whole jar file for every class file. makeClass() can be used for optimizing this search. The CtClass constructed by makeClass() is kept in the ClassPool object and the class file is never read again. makeClass()方法会从给定的输入流里构建出一个CtClass对象. 你可以使用makeClass()方法先一步地将class文件传给给ClassPool对象. 如果在搜索路径里面有一个特别大的jar文件时, 这有可能提升性能. 因为ClassPool在后台读取class文件时, 有可能将每一个class文件都在jar文件中匹配一遍. makeClass() 可以优化类似的搜索. 通过makeClass()构建出来的CtClass可以缓存在ClassPool里, 当再次查找相同class时, 就不需要再次去class path上搜索了. The users can extend the class search path. They can define a new class implementing ClassPath interface and give an instance of that class to insertClassPath() in ClassPool. This allows a non-standard resource to be included in the search path. 用户可以拓展class search path. 他们可以将ClassPath接口实现类的实例通过insertClassPath()方法添加到ClassPool里. 这就可以允许一个非标准的资源路径加载到search path上.","categories":[{"name":"Javasist","slug":"Javasist","permalink":"https://wangmingco.github.io/categories/Javasist/"}],"tags":[]},{"title":"CGLib 动态代理 原理解析","slug":"zhihu/CGLib","date":"2019-04-28T11:34:00.000Z","updated":"2021-11-24T02:59:27.088Z","comments":true,"path":"2019/04/28/zhihu/CGLib/","link":"","permalink":"https://wangmingco.github.io/2019/04/28/zhihu/CGLib/","excerpt":"","text":"CGLib 动态代理 原理解析","categories":[{"name":"知乎","slug":"知乎","permalink":"https://wangmingco.github.io/categories/%E7%9F%A5%E4%B9%8E/"}],"tags":[]},{"title":"JavaIO原理剖析之 网络IO","slug":"zhihu/java_net_io","date":"2019-04-14T10:28:00.000Z","updated":"2021-11-24T03:00:20.112Z","comments":true,"path":"2019/04/14/zhihu/java_net_io/","link":"","permalink":"https://wangmingco.github.io/2019/04/14/zhihu/java_net_io/","excerpt":"","text":"JavaIO原理剖析之 网络IO","categories":[{"name":"知乎","slug":"知乎","permalink":"https://wangmingco.github.io/categories/%E7%9F%A5%E4%B9%8E/"}],"tags":[]},{"title":"JDK 动态代理实现与原理","slug":"zhihu/java_dyn_proxy","date":"2019-03-25T06:48:00.000Z","updated":"2021-11-24T03:00:17.457Z","comments":true,"path":"2019/03/25/zhihu/java_dyn_proxy/","link":"","permalink":"https://wangmingco.github.io/2019/03/25/zhihu/java_dyn_proxy/","excerpt":"","text":"JDK 动态代理实现与原理","categories":[{"name":"知乎","slug":"知乎","permalink":"https://wangmingco.github.io/categories/%E7%9F%A5%E4%B9%8E/"}],"tags":[]},{"title":"图解 LinkedBlockingQueue实现原理","slug":"zhihu/LinkedBlockingQueue","date":"2019-02-13T03:51:00.000Z","updated":"2021-11-24T03:00:33.226Z","comments":true,"path":"2019/02/13/zhihu/LinkedBlockingQueue/","link":"","permalink":"https://wangmingco.github.io/2019/02/13/zhihu/LinkedBlockingQueue/","excerpt":"","text":"图解 LinkedBlockingQueue实现原理","categories":[{"name":"知乎","slug":"知乎","permalink":"https://wangmingco.github.io/categories/%E7%9F%A5%E4%B9%8E/"}],"tags":[]},{"title":"PEG.js 文档 [译]","slug":"前端/pegjs-document","date":"2018-12-15T02:21:00.000Z","updated":"2021-11-18T02:38:12.473Z","comments":true,"path":"2018/12/15/前端/pegjs-document/","link":"","permalink":"https://wangmingco.github.io/2018/12/15/%E5%89%8D%E7%AB%AF/pegjs-document/","excerpt":"","text":"PEG.js 是JavaScript里一个简单的parser生成器, 它能够非常快的生成parser, 而且如果在生成过程中遇到了问题, 也会给出非常明确的错误报告. 你可以很轻松地用它处理复杂的数据结构或者计算机语言, 也可以构建出transformers, interpreters, compilers 等其他工具. 特性PEG.js具有如下特性 简单而富有表现力的语法 集成了词法和语法分析. 生成的解析器具有出色的错误报告功能 基于parsing expression grammar, 生成的parser 比传统的 LL(k) 和 LR(k) parser更加强大. 适用于浏览器, 命令行或者JavaScript API 等多种环境. 安装Node.js在命令行中使用pegjs命令编译, 需要使用全局模式安装PEG.js: 1$ npm install -g pegjs 如果要使用pegjs提供的 JavaScript API, 则需要在当前工作目录安装 PEG.js: 1$ npm install pegjs 如果既要使用pegjs命令又要使用JavaScript API, 那么你需要将上面俩种方式都安装一遍. Browser在浏览器中使用, 可以直接下载库文件PEG.js或者通过Bower安装PEG.js: 1$ bower install pegjs 生成 ParserPEG.js将解析表达式文法解析后, 生成parser. 解析表达式文法描述描述了 将何种输入进行解析然后输出何种输出.(通过执行输入字符的匹配部分的语义操作). 通过一个简单api就可以可以生成一个parser JS对象. 命令行生成想要将grammar文件生成parser, 直接使用pegjs进行编译即可: 1$ pegjs arithmetics.pegjs 上面的命令会将生成的parser的源码输出到与grammar文件同名的js结尾的文件中. 当然也可以输出到指定文件中: 1$ pegjs -o arithmetics-parser.js arithmetics.pegjs 但是如果你将输入输出文件都忽略了, 那么系统将会采用标准输入输出.在默认设置下, 生成的parser代码是以Node.js module format 进行组织代码的, 但也可以通过指定--format选项选择其他方式. 下面的选项介绍中也有对该选项的介绍, 详情请参考[译]神马是AMD, CommonJS, UMD? 你可以通过如下几个命令来修改生成的parser的默认行为. --allowed-start-rules: 指定parser开始从哪个rule开始解析. (默认是文法中的第一个rule) --cache: 开启parser的缓存功能. parser会将parse出来的结果缓存起来, 避免极端情况下解析时间成指数级增加, 但坏处是parser可能会变慢. --dependency: 让parser依赖一个指定的依赖.(该参数可以多次使用) --export-var: --extra-options: 传递给peg.generate的额外参数(JSON 形式). --extra-options-file: 传递给peg.generate的额外参数文件(JSON 形式). --format: 生成的parser格式, 可选值有amd, commonjs, globals, umd(默认是commonjs) --optimize: 为生成的parser在parsing时的优化方式, 可以选择解析速度(speed)或者parse结果代码大小(size). (默认是speed) --plugin: 为PEG.js配置插件(可以配置多个, 即多次配置) --trace: 开启parser的trace功能. API生成在node.js中, 直接require(&quot;pegjs&quot;) 就可以使用peg.js的parser生成器了. 1var peg = require(&quot;pegjs&quot;); 在浏览器中, 需要在&lt;script&gt;标签引入PEG.js库. 如果 PEG.js 检测到一个 AMD loader, 它会把自己定义成一个 module, 否则我们只能通过peg这个全局对象使用pegjs的api了.生成一个parser非常简单, 把解析器文法参数传递进peg.generate方法就可以了: 1var parser = peg.generate(&quot;start = (&#x27;a&#x27; / &#x27;b&#x27;)+&quot;); 根据参数的不同, 这个方法可能会返回一个新生成的parser对象或者是一个包含parser源码的字符串. 如果文法参数不合法, 则会抛出一个异常(异常中会包含这个错误的详细信息). 可以通过向peg.generate方法传递第二个参数(该参数是一个对象)改变生成的parser的默认行为. 支持的参数如下: allowedStartRules: 指定parser开始的rule. (默认是文法中第一个rule.) cache: 如果设置为true, parser会将parse的结果缓存起来, 可以避免在极端情况下过长的解析时间, 但同时它带来的副作用是会使得parser变慢(默认false). dependencies: 设置parser的依赖, 其值是一个对象, 其key为访问依赖的变量, 而value为需要加载的依赖module id.只有当format参数被设置为&quot;amd&quot;, &quot;commonjs&quot;, &quot;umd&quot; 该参数才生效. (默认为&#123;&#125;) exportVar: Name of a global variable into which the parser object is assigned to when no module loader is detected; valid only when format is set to “globals” or “umd” (default: null). format: 生成的parser格式, 可选值为(&quot;amd&quot;, &quot;bare&quot;, &quot;commonjs&quot;, &quot;globals&quot;, or &quot;umd&quot;). 只有output设置为source, 该参数才生效 optimize: 为生成的parser选择一个优化方案, 可选值为&quot;speed&quot;或者&quot;size&quot;. (默认&quot;speed&quot;) output: 设置generate()方法返回格式. 如果值为&quot;parser&quot;, 则返回生成的parser对象. 如果设置为&quot;source&quot;, 则返回parser source字符串 plugins: 要使用的插件 trace: 追踪parser的执行过程(默认是false). 使用 Parser使用生成的parser也非常简单, 只需要调用parser对象的parse方法, 然后将一个字符串参数传递进该方法就可以了. 然后该方法会返回一个parse结果(已经在定义parser的文法中描述了返回何种类型的值), 或者如果字符串不合法的话抛出一个异常. 异常会输出详细的错误信息. 123parser.parse(&quot;abba&quot;); // returns [&quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;a&quot;]parser.parse(&quot;abcd&quot;); // throws an exception 同样的, parse方法也支持选项参数. 支持的参数如下: startRule: Name of the rule to start parsing from. 开始从哪个rule执行. tracer: Tracer to use. 开启tracer. Parsers 也可以自定义参数, 以支持定制化的需求. 语法和语义peg.js的语法和JavaScript非常像, 但是有俩点不同, pegjs不是line-oriented, 而且peg.js会忽略tokens之间的空白符. 同样地可以在peg.js中使用//...和/* ... */进行注释.下面是个peg.js文法示例, 该示例生成的parser会识别出算数表达式 2*(3+4), 然后将该值计算出来. 1234567891011121314151617start = additiveadditive = left:multiplicative &quot;+&quot; right:additive &#123; return left + right; &#125; / multiplicativemultiplicative = left:primary &quot;*&quot; right:multiplicative &#123; return left * right; &#125; / primaryprimary = integer / &quot;(&quot; additive:additive &quot;)&quot; &#123; return additive; &#125;integer &quot;integer&quot; = digits:[0-9]+ &#123; return parseInt(digits.join(&quot;&quot;), 10); &#125; 总体来说, 文法是由rule组成的(例如上面的例子中有5个rule). 每个rule都有一个名字(例如上例中integer) 和 一个解析表达式(例如上例中:digits:[0-9]+ &#123; return parseInt(digits.join(&quot;&quot;), 10); &#125;). 表达式部分首先是一个匹配输入字符串的匹配规则, 然后可能后面还会有一个匹配成功之后要执行的JavaScript代码. rule也可以设置一个更加易于理解的别名, 例如上例中的integer就有一个别名, 该别名主要用于发生解析异常时, 输出日志便于解决问题. 解析动作从第一个rule开始, 我们通常以start命名这个rule. rule名称必须符合JavaScript的标识符规则. rule名称后跟一个=符号, 然后=后面是一个解析表达式. 如果rule名称要跟一个别名的话, 该别名必须在rule名称与=之间. rule之间需要由空白行进行分割, rule后也可以跟一个分号; 第一个规则之前可以设置一个初始化器, 初始化器由花括号(“{“和”}”)和花括号内的JavaScript代码组成. 初始化器会在parser开始解析之前被执行. 初始器里定义的变量和方法可以被后续的rule访问到. 初始器可以通过访问options参数访问到传递给parser的参数. 初始化器必须由大括号括起来, 缺一不可. 下面我们看一个简单的使用了初始化代码的示例: 1234567891011121314151617181920212223&#123; function makeInteger(o) &#123; return parseInt(o.join(&quot;&quot;), 10); &#125;&#125;start = additiveadditive = left:multiplicative &quot;+&quot; right:additive &#123; return left + right; &#125; / multiplicativemultiplicative = left:primary &quot;*&quot; right:multiplicative &#123; return left * right; &#125; / primaryprimary = integer / &quot;(&quot; additive:additive &quot;)&quot; &#123; return additive; &#125;integer &quot;integer&quot; = digits:[0-9]+ &#123; return makeInteger(digits); &#125; peg.js会将输入的字符串与rule中定义的解析表文法进行匹配. 但是存在着很多不同类型的表达式, 例如匹配字符或者字符类型, 或者匹配可选部分, 或者匹配重复情况等等. 表达式可能还包含其他rule的引用. 当parser将输入字符串与表达式成功的时候, parser会生成一个JavaScript对象的匹配结果. 例如 表达式匹配到了一个字符串字面量的话, 它会返回一个包含该字符串的JavaScript字符串对象. 当表达式匹配到重复的子表达式的时候, 会将所有匹配结果放到一个JavaScript数组对象里返回. 如果rule A在表达式B被引用了, 那么这个rule A的匹配结果也会传递表达式B, 接着会层层传递, 一直传递到start rule里. 当parser全部解析完成成功之后, 会直接将start rule的匹配结果返回出去. 解析表达式中比较特殊的是parser action,一段包含在大括号内的JavaScript代码，这段代码可以处理表达式中引用的其他rule的匹配结果，然后自己再返回一个JavaScript对象作为当前表达式的处理结果。这个对象就是当前表达式的匹配结果，换句话说，parser action就是一个匹配结果转换器。 在我们的运算示例中，有许许多多的parser action. 看一下表达式中的这个action digits:[0-9]+ &#123; return parseInt(digits.join(&quot;&quot;), 10); &#125;. 它拿到了[0-9]+的匹配结果digits(digits 是一个包含数字的字符串数组)。它将这些数字字符转换成一个数字，然后转换成一个js数字对象。 解析表达式类型解析表达式可以分为很多种类, 而且有一些还包含子表达式, 包含子表达式的就形成了一种递归结构. &quot;literal&quot; &#39;literal&#39;严格匹配字面量字符串, 然后直接返回该字符串字面量. 在pegjs里字符串语法和JavaScript里相同. 在常量最后加一个i表示不区分大小写. 输入的字符串必须与该字符串一模一样(可以加i忽略大小写) .严格匹配任意单个字符, 然后将它作为一个字符串返回. [characters]单个字符匹配, 将匹配成功的单个字符作为字符串返回. The characters in the list can be escaped in exactly the same way as in JavaScript string. 匹配模式中的字符列表也可以指定一个范围(例如[a-z]表示要匹配全部小写字符). 如果匹配规则中有^表示匹配规则相反. (例如[^a-z] 表示匹配除了小写字符之外的全部字符). 如果匹配规则后面跟有i的话, 表示忽略大小写. [characters] 通常会和*, + 组合到一起使用, 匹配字符串. 与&#39;literal&#39; 不同的是, 只要单个字符符合[characters] 中任意一个字符即可. rule在表达式中引用其他rule, 然后与引用的rule进行匹配, 然后返回引用rule的匹配结果. ( expression )匹配一个子表达式, 并返回它的匹配结果. 匹配不成功则会抛出异常 expression *将表达式匹配0次或多次, 然后将匹配结果通过一个数组返回. 这种匹配形式会尽可能多地尝试匹配. 与正则表达式不同的是, 它们不会进行回溯. 匹配不成功则会抛出异常 expression +将表达式匹配1次或多次, 然后将匹配结果通过一个数组返回. 这种匹配形式会尽可能多地尝试匹配. 与正则表达式不同的是, 它们不会进行回溯. 匹配不成功则会抛出异常 expression ?尝试去匹配表达式. 如果匹配成功, 则返回匹配结果, 否则返回null. 与正则表达式不同的是, 它们不会进行回溯. 匹配不成功则会抛出异常 &amp; expression尝试去匹配表达式. 如果匹配成功, 则返回undefined而且不会消耗输入字符串, 否则认为匹配失败. 匹配不成功则会抛出异常 ! expression尝试去匹配表达式. 如果匹配不成功, 则返回undefined而且不会消耗输入字符串, 否则认为匹配失败. 匹配不成功则会抛出异常 &amp; &#123; predicate &#125;The predicate is a piece of JavaScript code that is executed as if it was inside a function. It gets the match results of labeled expressions in preceding expression as its arguments. It should return some JavaScript value using the return statement. If the returned value evaluates to true in boolean context, just return undefined and do not consume any input; otherwise consider the match failed. The code inside the predicate can access all variables and functions defined in the initializer at the beginning of the grammar. The code inside the predicate can also access location information using the location function. It returns an object like this: 1234&#123; start: &#123; offset: 23, line: 5, column: 6 &#125;, end: &#123; offset: 23, line: 5, column: 6 &#125;&#125; The start and end properties both refer to the current parse position. The offset property contains an offset as a zero-based index and line and column properties contain a line and a column as one-based indices. The code inside the predicate can also access options passed to the parser using the options variable. Note that curly braces in the predicate code must be balanced. ! &#123; predicate &#125;The predicate is a piece of JavaScript code that is executed as if it was inside a function. It gets the match results of labeled expressions in preceding expression as its arguments. It should return some JavaScript value using the return statement. If the returned value evaluates to false in boolean context, just return undefined and do not consume any input; otherwise consider the match failed. The code inside the predicate can access all variables and functions defined in the initializer at the beginning of the grammar. The code inside the predicate can also access location information using the location function. It returns an object like this: 1234&#123; start: &#123; offset: 23, line: 5, column: 6 &#125;, end: &#123; offset: 23, line: 5, column: 6 &#125;&#125; The start and end properties both refer to the current parse position. The offset property contains an offset as a zero-based index and line and column properties contain a line and a column as one-based indices. The code inside the predicate can also access options passed to the parser using the options variable. Note that curly braces in the predicate code must be balanced. $ expression尝试匹配该表达式. 如果匹配成功, 不会返回匹配结果, 而是返回匹配成功的字符串. 匹配不成功则会抛出异常 label : expression匹配表达式, 然后将匹配结果存储在label里. label必须是一个JavaScript标识符. expression1 expression2 ... expressionn匹配一个表达式列表, 将全部的匹配结果放到一个数组中返回. expression &#123; action &#125;如果匹配表达式成功, 则运行action, 否则认为匹配失败. 匹配失败返回异常. action是一段JavaScript代码, 可以把它当做一个方法来运行. labeled表达式的匹配结果会被当做action的参数, 传递给action. action应该通过return返回一个JavaScript结果, 该结果会被当做前面表达式的匹配结果. 在action代码块中, 遇到非预期情况, 想要中断parse可以调用expected方法, 该方法会抛出一个异常. expected方法接受俩个参数, 第一个参数是description, 表明当前位置期望输入以及可选的location信息(默认值是what location would return). description会被当做exception中的message的一部分. 在action代码中也可以调用error方法, 该方法也会抛出一个异常. error方法接受俩个参数, 第一个参数是error message, 第二个参数是可选的location信息(默认值是 what location would return). message会在抛出异常中使用.action中的代码块可以访问初始器中定义的方法和变量. action代码块的左右大括号必须都在.action 代码块中可以通过text方法访问匹配成功的字符.action代码块中还可以通过访问location方法得到location信息, 该方法会返回下面这种对象. 1234&#123; start: &#123; offset: 23, line: 5, column: 6 &#125;, end: &#123; offset: 25, line: 5, column: 8 &#125;&#125; start属性指向了表达式开始位置, end属性指向表达式的结束位置. offset是一个基于0 的offset索引位置, line和 column 属性是基于1的索引位置. action 代码块中可以通过options变量访问传递给parser的options. expression1 / expression2 / ... / expressionn按照顺序从左往右一次匹配, 返回第一个匹配成功的结果. 如果都匹配不成功, 则认为匹配失败. 匹配失败返回异常. Compatibilityarser generator 和 generated parsers 在以下环境都可以正常运行. Node.js 0.10.0+ Internet Explorer 8+ Edge Firefox Chrome Safari Opera","categories":[{"name":"前端","slug":"前端","permalink":"https://wangmingco.github.io/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"PEG.js","slug":"PEG-js","permalink":"https://wangmingco.github.io/tags/PEG-js/"}]},{"title":"Mac下使用VSCode搭建Common Lisp 开发环境","slug":"zhihu/Common_Lisp","date":"2018-12-03T08:44:00.000Z","updated":"2021-11-24T03:00:01.135Z","comments":true,"path":"2018/12/03/zhihu/Common_Lisp/","link":"","permalink":"https://wangmingco.github.io/2018/12/03/zhihu/Common_Lisp/","excerpt":"","text":"Mac下使用VSCode搭建Common Lisp 开发环境","categories":[{"name":"知乎","slug":"知乎","permalink":"https://wangmingco.github.io/categories/%E7%9F%A5%E4%B9%8E/"}],"tags":[]},{"title":"高并发无锁无IO等待分布式ID生成方案","slug":"distributed-id","date":"2018-11-18T03:40:00.000Z","updated":"2021-11-17T07:51:14.545Z","comments":true,"path":"2018/11/18/distributed-id/","link":"","permalink":"https://wangmingco.github.io/2018/11/18/distributed-id/","excerpt":"A)网络上现在有很多的分布式ID生成算法, 各大厂商也开源了自己的分布式id生成算法. 前段时间项目里有个生成唯一id的需求, 思考了一下, 将flick的id生成方案和Twitter的id生成算法结合到一起, 写了个小算法, 也算是站在巨人的肩膀上做了点小东西, lol B)原理大致是这样的, 利用mysql insert来计算出集群中某个节点处于集群中的位置, 算出serverId, 然后利用雪花算法在该id上生成分布式id. 目前的实现是采用long来进行存储的, 因此只能在生成时间维度, 节点数量, 和每毫秒内生成的数量上进行调节, 如果你们可以存储字符串的话, 那么可以拓展一下该算法, 加大时间和空间的容量.","text":"A)网络上现在有很多的分布式ID生成算法, 各大厂商也开源了自己的分布式id生成算法. 前段时间项目里有个生成唯一id的需求, 思考了一下, 将flick的id生成方案和Twitter的id生成算法结合到一起, 写了个小算法, 也算是站在巨人的肩膀上做了点小东西, lol B)原理大致是这样的, 利用mysql insert来计算出集群中某个节点处于集群中的位置, 算出serverId, 然后利用雪花算法在该id上生成分布式id. 目前的实现是采用long来进行存储的, 因此只能在生成时间维度, 节点数量, 和每毫秒内生成的数量上进行调节, 如果你们可以存储字符串的话, 那么可以拓展一下该算法, 加大时间和空间的容量. C)算法实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160/** * ID 生成器 * &lt;p&gt; * 整个ID算法很简单, * 1. 参考Flickr ID生成算法, 使用MYSQL获得一个自增ID, 然后对ID取模, 算出一个服务器ID * 2. 参考Twitter的雪花算法, 算出一个long型ID * &lt;p&gt; * 该算法保证在30年内, 6万台机器, 单机每秒可以产出128, 000个不重复ID * &lt;p&gt; * &lt;p&gt; * CREATE TABLE `account_server_id` ( * `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT, * `stub` char(1) DEFAULT NULL, * PRIMARY KEY (`id`), * UNIQUE KEY `stub` (`stub`) * ) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8; * &lt;p&gt; * &lt;p&gt; * |1, 000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0000, 0 |000, 0000, 0000, 0000, 0 |000, 0000 | * | | 时间戳(40位) | 服务器ID(16位) | 单个时间戳内的Id(7位) | */@Servicepublic class IDGeneratorService implements CommandLineRunner &#123; private static final Logger LOG = LoggerFactory.getLogger(IDGeneratorService.class); // 时间戳从哪一年开始计时 private static final int START_YEAR = 2018; // 时间取40位, 保证ID34年内不会重复 private static final int timeBitsSize = 40; private static final int serverIdBitsSize = 16; private static final int countBitsSize = 7; private long maxIdPerMill; // 时间开始时间戳, 相当于System.currentTimeMillis()的1970年 private long startDateTime; // 服务器ID表示位, 在集群中表示一个节点 private long serverIdBits; // 单机中, 某个时刻生长得id private long currentID; private long maxTime; private long lastGenerateTime = System.currentTimeMillis(); private Object lock = new Object(); @Resource private AccountServerIdMapper accountServerIdMapper; public void init() &#123; // 1. 计算出开始生成ID的起始时间戳 LocalDateTime start = LocalDateTime.of(START_YEAR, 1, 1, 0, 0); startDateTime = start.toInstant(ZoneOffset.of(&quot;+8&quot;)).toEpochMilli(); // 2. 算出支持最大年限的时间 maxTime = ((Double) Math.pow(2, timeBitsSize)).longValue(); // 3. 算出每毫秒能产出多少ID maxIdPerMill = ((Double) Math.pow(2, countBitsSize)).longValue(); /** * 4. 根据Mysql自增ID取模, 算出每个服务器ID, 在生产环境中, 应该保证服务器数量是该值的一半, 如此一来就可以避免, 服务器集群整体 * 重启时, 不会拿到与重启之前的服务器相同的Id * 这个值的计算是为了适应这种场景, 在服务器灰度上线的时候, 有可能是原来的服务器还没有关闭, 但是新的服务器已经起来了, 此时会有俩套 * 服务器同时在处理业务逻辑, 那么它们就有可能拿到一样的服务器ID, 从而导致产生一样的ID号 */ long serverSize = ((Double) Math.pow(2, serverIdBitsSize)).longValue(); AccountServerId accountServerId = new AccountServerId(); accountServerIdMapper.nextId(accountServerId); long serverId = (int) (accountServerId.getId() % serverSize); /** * 5. 算出每个服务器ID在long类型中的数据位置, 然后缓存起来 */ serverIdBits = (serverId &lt;&lt; (countBitsSize)); LOG.info(&quot;[ID生成器] 开始时间:&#123;&#125;, 时间戳:&#123;&#125; &quot;, new Date(startDateTime), startDateTime); LOG.info(&quot;[ID生成器] 结束时间:&#123;&#125;, 时间戳:&#123;&#125; &quot;, new Date(startDateTime + maxTime), maxTime); LOG.info(&quot;[ID生成器] 每毫秒生成最大ID数:&#123;&#125; &quot;, maxIdPerMill); LOG.info(&quot;[ID生成器] 当前serverId: &#123;&#125;, serverIdSize:&#123;&#125;&quot;, serverId, serverSize); LOG.info(&quot;[ID生成器] serverIdBits: &#123;&#125;&quot;, Long.toBinaryString(serverIdBits)); &#125; /** * 生成一个64位的GUID * &lt;p&gt; * 在next()方法中, 没有使用任何的对象, 如此一来就可以减轻GC的压力. * * @return */ public long next() &#123; synchronized (lock) &#123; long curTime = System.currentTimeMillis() - startDateTime; if (curTime &gt;= maxTime) &#123; LOG.error(&quot;[ID生成器] 超过负载, &#123;&#125;, &#123;&#125;！返回 -1&quot;, curTime, maxTime); return -1; &#125; if (lastGenerateTime != curTime) &#123; currentID = 0; &#125; else &#123; if (currentID &gt;= maxIdPerMill) &#123; LOG.error(&quot;[ID生成器] 同一毫秒[&quot; + curTime + &quot;]内生成&quot; + currentID + &quot;个ID！返回 -1&quot;); return -1; &#125; ++currentID; &#125; lastGenerateTime = curTime; long gid = (curTime &lt;&lt; countBitsSize + serverIdBitsSize) | serverIdBits; gid |= currentID; return gid; &#125; &#125; public String nextStrId() &#123; return String.valueOf(next()); &#125; public long tryNextId() &#123; for (int i = 0; i &lt; 1000; i++) &#123; long start = System.currentTimeMillis(); long id = next(); long diff = System.currentTimeMillis() - start; if (diff &gt; 3) &#123; String tid = Thread.currentThread().getName(); LOG.warn(&quot;[ID生成器] 线程&#123;&#125; 生成ID: &#123;&#125; 大于3毫秒: &#123;&#125;&quot;, tid, id, diff); &#125; if (id == -1) &#123; try &#123;// LOG.error(&quot;[ID生成器] 生成ID为-1, 可能超过每毫秒内生成最大数量, 等待1毫秒&quot;); TimeUnit.MILLISECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; continue; &#125; return id; &#125; return -1; &#125; public String tryNextStrId() &#123; return String.valueOf(tryNextId()); &#125; @Override public void run(String... args) throws Exception &#123; init(); &#125;&#125; mybatis 12345678@Mapperpublic interface AccountServerIdMapper &#123; @Insert(&quot;REPLACE INTO server_id (stub) VALUES (&#x27;a&#x27;);&quot;) @SelectKey(statement = &quot;SELECT LAST_INSERT_ID()&quot;, keyProperty = &quot;id&quot;, before = false, resultType = Long.class) Long nextId(AccountServerId accountServerId);&#125; SQL 12345678CREATE TABLE `server_id` ( `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT, `stub` char(1) DEFAULT NULL, `create_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#x27;创建时间&#x27;, `update_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &#x27;更新时间&#x27;, PRIMARY KEY (`id`), UNIQUE KEY `stub` (`stub`)) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8; 测试 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106@RunWith(JMockit.class)public class IDGeneratorUtilTest &#123; private static final Logger logger = LoggerFactory.getLogger(IDGeneratorUtilTest.class); private static final int MAX_TIMES = 2000000; private static final int PRINT_TIMES = 100; @Tested private IDGeneratorService idGeneratorUtil; @Injectable private AccountServerIdMapper accountServerIdMapper; /** * 21026 [main] DEBUG c.f.l.service.IDGeneratorUtilTest - 20506 毫秒内生成 2000000 个ID * &lt;p&gt; * 单线程的情况下, 在MacBook Pro上是每毫秒钟生成 97 个id */ @Test public void testOneServerIdGenerate() &#123; new Expectations() &#123; &#123; accountServerIdMapper.nextId((AccountServerId) any); result = 2; &#125; &#125;; idGeneratorUtil.init(); Set&lt;Long&gt; ids = new HashSet&lt;&gt;(); long start = System.currentTimeMillis(); for (int i = 0; i &lt; MAX_TIMES; i++) &#123; long id = idGeneratorUtil.tryNextId(); if (ids.contains(id)) &#123; System.out.println(id); &#125; ids.add(id); &#125; logger.debug((System.currentTimeMillis() - start) + &quot; 毫秒内生成 &quot; + ids.size() + &quot; 个ID&quot;); Assert.assertEquals(ids.size(), MAX_TIMES); Object[] idArray = ids.toArray(); for (int i = 0; i &lt; PRINT_TIMES; i++) &#123; logger.debug(idArray[i] + &quot; : &quot; + Long.toBinaryString((Long) idArray[i])); &#125; &#125; /** * 207703 [Thread-7] DEBUG c.f.l.service.IDGeneratorUtilTest - 207136 毫秒内生成 2000000 个ID * 208031 [Thread-3] DEBUG c.f.l.service.IDGeneratorUtilTest - 207465 毫秒内生成 2000000 个ID * 208626 [Thread-10] DEBUG c.f.l.service.IDGeneratorUtilTest - 208059 毫秒内生成 2000000 个ID * 208630 [Thread-9] DEBUG c.f.l.service.IDGeneratorUtilTest - 208063 毫秒内生成 2000000 个ID * 209153 [Thread-6] DEBUG c.f.l.service.IDGeneratorUtilTest - 208586 毫秒内生成 2000000 个ID * 209170 [Thread-5] DEBUG c.f.l.service.IDGeneratorUtilTest - 208603 毫秒内生成 2000000 个ID * 209373 [Thread-2] DEBUG c.f.l.service.IDGeneratorUtilTest - 208807 毫秒内生成 2000000 个ID * 209412 [Thread-1] DEBUG c.f.l.service.IDGeneratorUtilTest - 208846 毫秒内生成 2000000 个ID * 209508 [Thread-4] DEBUG c.f.l.service.IDGeneratorUtilTest - 208941 毫秒内生成 2000000 个ID * 209536 [Thread-8] DEBUG c.f.l.service.IDGeneratorUtilTest - 208969 毫秒内生成 2000000 个ID * &lt;p&gt; * 多线程的情况下, 在MacBook Pro上是每毫秒钟生成 9 个id, 可见由于锁的竞争, 产生的影响还是非常大的 */ @Test public void testMutilServerIdGenerate() &#123; new Expectations() &#123; &#123; accountServerIdMapper.nextId((AccountServerId) any); result = 2; &#125; &#125;; idGeneratorUtil.init(); Runnable runnable = () -&gt; &#123; Set&lt;Long&gt; ids = new HashSet&lt;&gt;(); long start = System.currentTimeMillis(); for (int i = 0; i &lt; MAX_TIMES; i++) &#123; long id = idGeneratorUtil.tryNextId(); ids.add(id); &#125; logger.debug((System.currentTimeMillis() - start) + &quot; 毫秒内生成 &quot; + ids.size() + &quot; 个ID&quot;); Assert.assertEquals(ids.size(), MAX_TIMES); &#125;; List&lt;Thread&gt; list = new ArrayList&lt;&gt;(); int cpus = Runtime.getRuntime().availableProcessors() + 2; logger.debug(&quot;CPU : &quot; + cpus); for (int i = 0; i &lt; cpus; i++) &#123; Thread thread = new Thread(runnable); list.add(thread); thread.start(); &#125; for (Thread thread : list) &#123; try &#123; thread.join(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;","categories":[],"tags":[]},{"title":"通过Java Agent的redefineClasses实现Mock功能","slug":"zhihu/Java_Agent","date":"2018-11-17T14:08:00.000Z","updated":"2021-11-24T03:00:08.856Z","comments":true,"path":"2018/11/17/zhihu/Java_Agent/","link":"","permalink":"https://wangmingco.github.io/2018/11/17/zhihu/Java_Agent/","excerpt":"","text":"通过Java Agent的redefineClasses实现Mock功能","categories":[{"name":"知乎","slug":"知乎","permalink":"https://wangmingco.github.io/categories/%E7%9F%A5%E4%B9%8E/"}],"tags":[]},{"title":"JMX 笔记","slug":"JavaSE/jmx","date":"2018-11-14T06:13:00.000Z","updated":"2021-11-18T02:40:26.031Z","comments":true,"path":"2018/11/14/JavaSE/jmx/","link":"","permalink":"https://wangmingco.github.io/2018/11/14/JavaSE/jmx/","excerpt":"","text":"参考Java SE Monitoring and Management Guide MBean ServerMBean Server 是MBean的一个仓库, 我们并不直接访问MBean, 而是通过通过一个唯一的ObjectName通过 MBean Server来进行访问. 如果要实现一个MBean Server必须实现javax.management.MBeanServer接口. 如果我们要创建自己的MBean Server的话, 可以使用 MBeanServerFactory.createMBeanServer(); MBeanServerFactory.newMBeanServer(); createMBeanServer()内部会调用newMBeanServer(), 但是createMBeanServer()会将newMBeanServer()创建出来的MBean Server缓存到ArrayList&lt;MBeanServer&gt; mBeanServerList一个列表里. 这点先姑且不去讨论, 集中精力看看Platform MBean Server. 官方也建议我们使用Platform MBean Server(也就是自带的那个MBean Server), 在没有特殊需求之下, 没有必要建立自己的MBean Server. 12345678910import javax.management.MBeanServer;import java.lang.management.ManagementFactory;public class PlatformMBeanServerTest &#123; public static void main(String[] args) &#123; MBeanServer server = ManagementFactory.getPlatformMBeanServer(); System.out.println(&quot;MBeanCount : &quot; + server.getMBeanCount()); &#125;&#125; MBean看完MBServer, 我们来看一下MBean. MXBean 连接首先先看一下MXBean, 什么是MXBean呢? 它是一种用来监控和管理Java VM的MBean. 我们可以通过三种方式来访问MXBean 通过ManagementFactory直接进行访问. 通过MXBean proxy直接访问. 通过MBeanServerConnection间接访问. 如果在同一个VM上的话, 我们可以通过ManagementFactory 提供的API进行直接访问 getClassLoadingMXBean() getGarbageCollectorMXBeans() getRuntimeMXBean()等等 例如 12RuntimeMXBean mxbean = ManagementFactory.getRuntimeMXBean();String vendor = mxbean.getVmVendor(); 如果不在同一个VM的话, 我们可以通过MXBean Proxy的方式进行远程访问. 12345678MBeanServerConnection mbs;...// Get a MBean proxy for RuntimeMXBean interfaceRuntimeMXBean proxy = ManagementFactory.newPlatformMXBeanProxy(mbs, ManagementFactory.RUNTIME_MXBEAN_NAME, RuntimeMXBean.class);// Get standard attribute &quot;VmVendor&quot;String vendor = proxy.getVmVendor(); 通过 1234567891011MBeanServerConnection mbs;...try &#123; ObjectName oname = new ObjectName(ManagementFactory.RUNTIME_MXBEAN_NAME); // Get standard attribute &quot;VmVendor&quot; String vendor = (String) mbs.getAttribute(oname, &quot;VmVendor&quot;);&#125; catch (....) &#123; // Catch the exceptions thrown by ObjectName constructor // and MBeanServer.getAttribute method ...&#125; 当我们通过上述方式拿到MXBean之后, 就可以访问它里面的各种属性了. 12345678com.sun.management.OperatingSystemMXBean mxbean = (com.sun.management.OperatingSystemMXBean) ManagementFactory.getOperatingSystemMXBean();// Get the number of processorsint numProcessors = mxbean.getAvailableProcessors();// Get the Oracle JDK-specific attribute Process CPU timelong cpuTime = mxbean.getProcessCpuTime(); 监控线程和CPUThreadMXBean 提供了对线程和CPU的监控.在使用这个功能之前, 我们可能需要判断一下, Java VM是否开启了线程content监控 1ThreadMXBean.isThreadContentionMonitoringSupported() 如果没有开启的话, 我们调用一下 1setThreadContentionMonitoringEnabled() 开启它就可以了. 还有对线程统计的支持 isThreadCpuTimeSupported()检测是否开启 isCurrentThreadCpuTimeSupported() 上面那个是对任意线程的统计检测, 这个则是对并发线程的检测 同理, 对CPU需要同样地处理 isThreadCpuTimeEnabled 检测CPU setThreadCpuTimeEnabled() 开启检测CPU 操作系统的管理通过OperatingSystem 可以拿到操作系统相关的信息 CPU的运行时间(Process CPU time). 物理内存剩余和总共大小. committed virtual memory数量. (这个值表示的是当前运行的进程还可使用的虚拟内存的大小, 也就是在程序启动时分配的虚拟内存现在还剩下多少). 交换分区剩余和总共大小. 打开的文件()数量(因为Uniux哲学是一切皆文件, 所以这个值只支持Solaris, Linux, or Mac OS X). 日志管理为了记录日志, Java特地提供了一个特殊的接口LoggingMXBean, 使用这个接口我们可以完成下面任务 获取指定logger的日志级别 获取到当前注册的logger列表 获取到指定logger的父名称 设置指定logger新的日志级别 LoggingMXBean 的ObjectName 为java.util.logging:type=Logging. 这个名称存储在LogManager.LOGGING_MXBEAN_NAME里 12LoggingMXBean loggingMXBean = LogManager.getLoggingMXBean();System.out.println(loggingMXBean.getLoggerNames()); 得到的loggerName有 javax.management.snmp global javax.management.notification javax.management.modelmbean javax.management.timer javax.management javax.management.mlet javax.management.mbeanserver javax.management.snmp.daemon javax.management.relation javax.management.monitor javax.management.misc由于我的测试没有使用任何的日志系统, 因此它只打印了Java自带的一些logger, 但是如果你在SpringBoot或者自己添加上log4j的话, 会获取到更多的logger, 我们可以通过这个接口, 在服务器运行阶段动态修改logger级别. 尽管以前也做过修改日志级别的事情, 但是是通过第三方框架自带的api进行修改的, 但是使用这个MXBean, 貌似可以跨框架了, O(∩_∩)O~","categories":[{"name":"Java","slug":"Java","permalink":"https://wangmingco.github.io/categories/Java/"}],"tags":[]},{"title":"Java入门及书单","slug":"JavaSE/java-books","date":"2018-11-14T06:13:00.000Z","updated":"2021-11-18T02:38:55.408Z","comments":true,"path":"2018/11/14/JavaSE/java-books/","link":"","permalink":"https://wangmingco.github.io/2018/11/14/JavaSE/java-books/","excerpt":"入门今天周六, 在家闲来无事, 多写俩篇博客(本想说成写文章, 但想了想该文实在承担不起文章二字, 便罢) 把最近看到的和想到的记录一下(恰好也把俩三年前写博客的热情又拾了起来). 经常在知乎上看到, 有人发问, 新人如何入门Java, 新人应该读哪些Java相关的书籍, 今天来谈谈这个问题. Java入门的话, 分析一下哪些行文算是入门 搭建Java开发环境 掌握Java基础语法(原生类型/包装类型, 变量声明, 循环控制, 方法声明/调用, 类定义, 实例化对象…) 私认为掌握上面这俩点就算Java入门了, 也不需要买什么书籍, 在网上找个教程, 或者去慕课网/B站/油管 上面找个教学教程, 利用3-5天的时间学一学就好了, 会用能记住就ok了, 不必深究语法. 上面第二点只是把当下想到的说了一下, 更多的还请参考(Java 教程). 入门之后干什么呢? 找一个自己喜欢的方向, 做个小项目练练手. 例如写一个web项目, 再学习一下下面的几个技术 SpringBoot: 用于后台web服务器 Mybatis: 替代原生的JDBC, 与mysql打交道的 vue/element-ui: 写前台页面的 基本上用上面这三个技术就能写一个后台管理系统出来, 当然我也只是把我熟悉的技术写了一下, 如果你身边有其他技术栈的同学指导, 也可以采用其他的技术栈. 如果前台从0写起来比较费劲, 可以参考一个开源的前端工程vue-element-admin 随着功能的不断完善, 你对技术的理解也会不断的加深, 开发的兴趣也会不断加大. 只有对一件事情有兴趣了, 我们才想把它做好, 不是吗?","text":"入门今天周六, 在家闲来无事, 多写俩篇博客(本想说成写文章, 但想了想该文实在承担不起文章二字, 便罢) 把最近看到的和想到的记录一下(恰好也把俩三年前写博客的热情又拾了起来). 经常在知乎上看到, 有人发问, 新人如何入门Java, 新人应该读哪些Java相关的书籍, 今天来谈谈这个问题. Java入门的话, 分析一下哪些行文算是入门 搭建Java开发环境 掌握Java基础语法(原生类型/包装类型, 变量声明, 循环控制, 方法声明/调用, 类定义, 实例化对象…) 私认为掌握上面这俩点就算Java入门了, 也不需要买什么书籍, 在网上找个教程, 或者去慕课网/B站/油管 上面找个教学教程, 利用3-5天的时间学一学就好了, 会用能记住就ok了, 不必深究语法. 上面第二点只是把当下想到的说了一下, 更多的还请参考(Java 教程). 入门之后干什么呢? 找一个自己喜欢的方向, 做个小项目练练手. 例如写一个web项目, 再学习一下下面的几个技术 SpringBoot: 用于后台web服务器 Mybatis: 替代原生的JDBC, 与mysql打交道的 vue/element-ui: 写前台页面的 基本上用上面这三个技术就能写一个后台管理系统出来, 当然我也只是把我熟悉的技术写了一下, 如果你身边有其他技术栈的同学指导, 也可以采用其他的技术栈. 如果前台从0写起来比较费劲, 可以参考一个开源的前端工程vue-element-admin 随着功能的不断完善, 你对技术的理解也会不断的加深, 开发的兴趣也会不断加大. 只有对一件事情有兴趣了, 我们才想把它做好, 不是吗? 书单我基本上没有买过/看过Java基础书, 类似于Java从入门到精通这一类的, 所以我给出的一些书单都具有一些方向性. 网络相关 Java网络编程: 将Java中网络相关的包都讲解了一下, 写的不错 Netty权威指南: 由于我是做游戏出身的, 工作上基本上netty就是标配了, netty对我在代码架构上有比较大的影响(各种继承, 抽象, 笑哭.jpg) Tomcat架构解析: 对Tomcat剖析的非常深入的一本书, Java程序员必读 图解TCP/IP: 同样的是一本好书, 在轻松氛围下对tcp/ip协议栈有一个比较清晰的认识, 算是tcp/ip协议栈的入门书籍吧. zeroc ice权威指南: 这本书其实没啥好说的, 如果公司在用ice而自己又不熟悉ice的话, 直接买来读就是了, 如果没有用, 暂时也不必入这个坑 并发相关并发编程, 按照下面的顺序去读这三本书就好了. Java7 编发编程实战手册, 这本书新手读起来就不错了, 详细介绍了Java中各种并发API的使用. Java并发编程实战, 刚开始编程时不推荐这本书, 新人学习起来难度大一些, 概念颇多. 多处理器编程的艺术, 如果想要深入各种锁的实现, 并发原理的话, 这本书着实该读. JVM相关提到Java永远也绕不过去jvm Java虚拟机规范 深入理解Java虚拟机 实战Java虚拟机 垃圾回收的算法与实现 其他 算法(第四版) 大话数据结构 Effective Java 目前能想到的书就这么多, 可以根据自己的兴趣和方向选择来读哈.","categories":[{"name":"Java","slug":"Java","permalink":"https://wangmingco.github.io/categories/Java/"}],"tags":[]},{"title":"通过Java Agent的redefineClasses实现Mock功能","slug":"JavaSE/agent-mock","date":"2018-11-05T12:15:00.000Z","updated":"2021-11-18T02:36:28.121Z","comments":true,"path":"2018/11/05/JavaSE/agent-mock/","link":"","permalink":"https://wangmingco.github.io/2018/11/05/JavaSE/agent-mock/","excerpt":"A)最近组内项目有个模块进行了较大规模的重构, 需要跑一下压力测试, 看一下性能如何. 但是介于产品的模式, 在正常场景下需要向通道发送消息, 然而在压测中, 我们希望这段行为能被mock掉.当时想到的方案可以采用Spring AOP, JMockit或者自己通过Javasisit/ASM这种字节码框架来实现功能. 由于项目中我自己很少使用Spring AOP来做一些功能, 便没让它当首选方案, 研究了一下JMockit实现, 发现是使用动态Agent实现的.ok, 那么便初步定了一下方案Agent+Javasisit来实现(ASM手写字节码实在太痛苦). B) 这一段貌似是废话, 你们也看不见代码发生的真实地转变, 我只是记录一下心路历程. 利用了2个小时, 采用Agent+Javasisit实现了一个小的模块, 基本功能也都实现了, 但是使用起来实在是太麻烦了, 代码耦合性太高. 于是又换了个思路, 去掉了Javasisit框架, 也完美地实现了功能. C)整个mock框架分为俩部分. agent-core, mock的核心代码 agent-client, 在这个工程中, 我们只需要在pom中引入需要替换的工程的依赖, 然后再agent-client中把要替换的类重写一遍就好了","text":"A)最近组内项目有个模块进行了较大规模的重构, 需要跑一下压力测试, 看一下性能如何. 但是介于产品的模式, 在正常场景下需要向通道发送消息, 然而在压测中, 我们希望这段行为能被mock掉.当时想到的方案可以采用Spring AOP, JMockit或者自己通过Javasisit/ASM这种字节码框架来实现功能. 由于项目中我自己很少使用Spring AOP来做一些功能, 便没让它当首选方案, 研究了一下JMockit实现, 发现是使用动态Agent实现的.ok, 那么便初步定了一下方案Agent+Javasisit来实现(ASM手写字节码实在太痛苦). B) 这一段貌似是废话, 你们也看不见代码发生的真实地转变, 我只是记录一下心路历程. 利用了2个小时, 采用Agent+Javasisit实现了一个小的模块, 基本功能也都实现了, 但是使用起来实在是太麻烦了, 代码耦合性太高. 于是又换了个思路, 去掉了Javasisit框架, 也完美地实现了功能. C)整个mock框架分为俩部分. agent-core, mock的核心代码 agent-client, 在这个工程中, 我们只需要在pom中引入需要替换的工程的依赖, 然后再agent-client中把要替换的类重写一遍就好了 核心部分123456789101112131415├── pom.xml└── src ├── main │ ├── java │ │ └── co │ │ └── wangming │ │ └── agent │ │ ├── Agent.java │ │ └── ClassesLoadUtil.java │ └── resources │ └── META-INF │ └── MANIFEST.MF └── test └── java └── Test.java 核心就是俩个Java文件和一个MF文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384public class Agent &#123; static ScheduledExecutorService scheduledExecutorService = new ScheduledThreadPoolExecutor(1); static List&lt;String&gt; hashCached = new ArrayList&lt;&gt;(); public static void premain(String agentArgs, Instrumentation instrumentation) &#123; System.out.println(&quot;Agnet 进入!!! &quot; + agentArgs); scheduledExecutorService.scheduleAtFixedRate(() -&gt; tryRedefine(instrumentation, agentArgs), 0, 10, TimeUnit.SECONDS); &#125; private static void tryRedefine(Instrumentation instrumentation, String agentArgs) &#123; Class[] allLoadedClasses = instrumentation.getAllLoadedClasses();// System.out.println(&quot;allLoadedClasses数量:&quot; + allLoadedClasses.length); Map&lt;String, Class&gt; finupAllLoadedClasses = new HashMap&lt;&gt;(); try &#123; for (Class loadedClass : allLoadedClasses) &#123; if (loadedClass == null) &#123; continue; &#125; if (loadedClass.getCanonicalName() == null) &#123; continue; &#125; if (!loadedClass.getCanonicalName().startsWith(&quot;com.finup&quot;)) &#123; continue; &#125; if (hashCached.contains(loadedClass.getCanonicalName())) &#123; continue; &#125; finupAllLoadedClasses.put(loadedClass.getCanonicalName(), loadedClass); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; Map&lt;String, byte[]&gt; rewriteClasses = ClassesLoadUtil.getRewriteClasses(agentArgs); for (String className : hashCached) &#123; rewriteClasses.remove(className); &#125; if (finupAllLoadedClasses.size() == 0 || rewriteClasses.size() == 0) &#123; return; &#125; System.out.println(&quot;finupAllLoadedClasses数量:&quot; + finupAllLoadedClasses.size()); for (String className : rewriteClasses.keySet()) &#123; byte[] classBytes = rewriteClasses.get(className); if (classBytes == null || classBytes.length == 0) &#123; System.out.println(&quot;从 rewriteClasses 找不到class: &quot; + className); continue; &#125; Class redefineClass = finupAllLoadedClasses.get(className); if (redefineClass == null) &#123; System.out.println(&quot;从 finupAllLoadedClasses 找不到class: &quot; + className); continue; &#125; System.out.println(&quot;开始redefineClasses: &quot; + className); ClassDefinition classDefinition = new ClassDefinition(redefineClass, classBytes); try &#123; instrumentation.redefineClasses(classDefinition); hashCached.add(className); System.out.println(&quot;结束redefineClasses: &quot; + className); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; catch (UnmodifiableClassException e) &#123; e.printStackTrace(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public class ClassesLoadUtil &#123; private static final Map&lt;String, byte[]&gt; path2Classes = new ConcurrentHashMap&lt;&gt;(); private static final Map&lt;String, byte[]&gt; className2Classes = new ConcurrentHashMap&lt;&gt;(); private static boolean havaLoaded = false; private static void loadFromZipFile(String jarPath) &#123; try &#123; ZipFile zipFile = new ZipFile(jarPath); Enumeration&lt;? extends ZipEntry&gt; entrys = zipFile.entries(); while (entrys.hasMoreElements()) &#123; ZipEntry zipEntry = entrys.nextElement(); entryRead(jarPath, zipEntry); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; private static boolean entryRead(String jarPath, ZipEntry ze) throws IOException &#123; if (ze.getSize() &gt; 0) &#123; String fileName = ze.getName(); if (!fileName.endsWith(&quot;.class&quot;)) &#123; return true; &#125; if (!fileName.contains(&quot;finup&quot;)) &#123; return true; &#125; try (ZipFile zf = new ZipFile(jarPath); InputStream input = zf.getInputStream(ze); ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream()) &#123; if (input == null) &#123;// logger.error(&quot;Code Reload cant find file : &quot; + fileName); return true; &#125; int b = 0; while ((b = input.read()) != -1) &#123; byteArrayOutputStream.write(b); &#125; byte[] bytes = byteArrayOutputStream.toByteArray(); path2Classes.put(fileName, bytes); String name1 = fileName.replaceAll(&quot;\\\\.class&quot;, &quot;&quot;); String name2 = name1.replaceAll(&quot;/&quot;, &quot;.&quot;); className2Classes.put(name2, bytes); System.out.println(&quot;加载文件: fileName : &quot; + fileName + &quot;. className:&quot; + name2); &#125; &#125; else &#123;// System.out.println(ze.getName() + &quot; size is 0&quot;); &#125; return false; &#125; public static Map&lt;String, byte[]&gt; getRewriteClasses(String agentArgs) &#123; synchronized (className2Classes) &#123; if (!havaLoaded) &#123; loadFromZipFile(agentArgs); havaLoaded = true; &#125; &#125; return className2Classes; &#125;&#125; MF 1234Manifest-Version: 1.0Premain-Class: co.wangming.agent.AgentCan-Redefine-Classes: trueCan-Retransform-Classes: true 基本上这三个文件就可以完成功能了. agent-client1234567891011121314├── pom.xml└── src ├── main │ ├── java │ │ └── co │ │ └── wangming │ │ └── agent_client │ │ └── service │ │ └── TestService │ └── resources │ └── META-INF │ └── MANIFEST.MF └── test └── java 1234Manifest-Version: 1.0Premain-Class: co.wangming.agent.AgentCan-Redefine-Classes: trueCan-Retransform-Classes: true 我们只需要把需要覆盖的TestService类在这里重写一下就好了, 但是注意, 不能删除/增加 方法/字段, 不能修改继承结构. 总而言之就是不能修改类的结构, 但是只是修改方法实现应该也能满足大多数需求了. 以后有时间再想想怎么用Spring AOP来实现","categories":[{"name":"Java","slug":"Java","permalink":"https://wangmingco.github.io/categories/Java/"}],"tags":[]},{"title":"工作/生活中用到的软件/插件/小工具","slug":"work-knife","date":"2018-10-30T12:43:00.000Z","updated":"2021-11-17T07:51:14.547Z","comments":true,"path":"2018/10/30/work-knife/","link":"","permalink":"https://wangmingco.github.io/2018/10/30/work-knife/","excerpt":"Chrome Awesome Autocomplete for GitHub Enhanced Github Octotree OneTab Pinbox Tampermonkey Mac这部分参考自有哪些命令行的软件堪称神器？ bat: cat 替换工具 mycli: mysql客户端 brew: mac安装包管理 ag：比grep、ack更快的递归搜索文件内容。 jq: json文件处理以及格式化显示 shellcheck：shell脚本静态检查工具 fzf：命令行下模糊搜索工具 mosh：基于UDP的终端连接 you-get: 非常强大的媒体下载工具 glances：更强大的 htop / top 代替者 figlet: 将输入字符转换成艺术字体。 Pandoc: 可以将 markdown 转成各式各样的格式：PDF、DOCX、EPUB、MOBI httpie: asciinema: 终端下的录制分享软件 ttygif: 终端录屏工具 Teleport prettyping: ping 替代品 fzf aria2 ncdu jenv nnn: 文件管理器 fd: find替代命令 htop sz/rz ip fcrackzip，破解zip压缩包密码。 Rename-CLI alder fasd","text":"Chrome Awesome Autocomplete for GitHub Enhanced Github Octotree OneTab Pinbox Tampermonkey Mac这部分参考自有哪些命令行的软件堪称神器？ bat: cat 替换工具 mycli: mysql客户端 brew: mac安装包管理 ag：比grep、ack更快的递归搜索文件内容。 jq: json文件处理以及格式化显示 shellcheck：shell脚本静态检查工具 fzf：命令行下模糊搜索工具 mosh：基于UDP的终端连接 you-get: 非常强大的媒体下载工具 glances：更强大的 htop / top 代替者 figlet: 将输入字符转换成艺术字体。 Pandoc: 可以将 markdown 转成各式各样的格式：PDF、DOCX、EPUB、MOBI httpie: asciinema: 终端下的录制分享软件 ttygif: 终端录屏工具 Teleport prettyping: ping 替代品 fzf aria2 ncdu jenv nnn: 文件管理器 fd: find替代命令 htop sz/rz ip fcrackzip，破解zip压缩包密码。 Rename-CLI alder fasd VSCode Code Runner Markdown Preview Enhanced MySQL Syntax Open in Browser Path Intellisense PEG.js Language Prettier - Code formatter REST Client Settings Sync Terminal IDEA列举一下idea中常用的插件(仅限于自己要安装的) ASM Bytecode Outline BashSupport Free Mybatis Plugin Grep Console JavaCC Plugin Translation","categories":[],"tags":[]},{"title":"Spring-loaded","slug":"jvm/Spring-loaded","date":"2016-11-02T16:00:00.000Z","updated":"2021-11-18T02:43:35.299Z","comments":true,"path":"2016/11/03/jvm/Spring-loaded/","link":"","permalink":"https://wangmingco.github.io/2016/11/03/jvm/Spring-loaded/","excerpt":"","text":"在前面的文章里分别都说过了instrument和Hotswap, 显然这俩个技术在代码热更方面都有比较大的局限性. 今天测试一下Spring出品的Spring-loaded. 它可以动态地添加删除方法, 属性字段等. Spring-loaded 的用法非常简单, 下载springloaded.jar这个jar包, 然后使用代理的方式将它挂载到JVM上就可以了. 1java -javaagent:&lt;pathto&gt;/springloaded.jar -noverify SomeJavaClass 尽管有了很高的灵活性,但是还是多少稍微有一些限制, 如果想要reload的文件不能以下列字符串开头 123456789101112131415161718antlr/org/springsource/loaded/com/springsource/tcserver/com/springsource/insight/groovy/groovyjarjarantlr/groovyjarjarasm/grails/java/javassist/org/codehaus/groovy/org/apache/org/springframework/org/hibernate/org/hsqldb/org/aspectj/org/xml/org/h2/ 还可以设置一些系统参数 1java -Dspringloaded=explain -javaagent:&lt;pathto&gt;/springloaded.jar -noverify SomeJavaClass explainmode会输出无法reload的诊断信息,例如 123Feb 05, 2014 11:00:51 AM org.springsource.loaded.TypeRegistry couldBeReloadableINFO: WhyNotReloadable? The type org/apache/maven/model/building/ModelBuilder is using a package name &#x27;org/apache/&#x27; which is considered infrastructure and types within it are not made reloadable 除了explain还有verbose模式, 这个模式会使用java.util.Logging输出reload过程详细信息. 123456Watcher Observed last modification time change for /Users/aclement/play/grails10411/jira-reload/target/classes/br/ com/app/domains/CategoryController.class (lastScanTime=1391628759166)Watcher Firing file changed event /Users/aclement/play/grails10411/jira-reload/target/classes/br/ com/app/domains/CategoryController.classReloadableType Loading new version of br/com/app/domains/CategoryController, identifying suffix OV1YS1A, new data length is 27209bytes 当然, 上面俩个模式并不是互斥的, 我们可以对spring-loaded指定多个参数 1-Dspringloaded=verbose;explain;profile=grails 看到了这么多, 其实还有一些特性没有测试到， 但是不想再自欺欺人了, 只有一个原因-noverify, 它关闭了JVM的字节码检查功能, 它让JVM坐上火箭去了月球","categories":[{"name":"JVM","slug":"JVM","permalink":"https://wangmingco.github.io/categories/JVM/"}],"tags":[]},{"title":"Java Float","slug":"JavaSE/Java  Float","date":"2016-10-30T16:00:00.000Z","updated":"2021-11-18T02:39:39.831Z","comments":true,"path":"2016/10/31/JavaSE/Java  Float/","link":"","permalink":"https://wangmingco.github.io/2016/10/31/JavaSE/Java%20%20Float/","excerpt":"","text":"今天有个以前的同事问了我一段代码, 12345678910public class SimplePrint &#123; public static void main(String[] args) &#123; long i = System.currentTimeMillis(); System.out.println(i); float h = 0.0f; i -= h; System.out.println(i); &#125;&#125; 前后俩个i输出结果不一致, 想了一下, 应该是 i 或者 h在转型时出的问题.于是写了段程序测试了一下 1234567891011121314151617181920public class SimplePrint &#123; public static void main(String[] args) &#123; long l = System.currentTimeMillis(); System.out.println(l); l -= 0.0f; System.out.println(l); l = System.currentTimeMillis(); l = (long)(l - 0.0f); System.out.println(l); l = System.currentTimeMillis(); float f = (float)l; System.out.println(l); System.out.println(f); l = (long)(f - 0.0f); System.out.println(l); &#125;&#125; 果真是如我所想, l 转换成了 Float,但是有点知其然不知其所然，于是跑到stackoverflow上问了一下, 有个大大回答的很好: 1E1 op= E2 等于 1E1 = (T) ((E1) op (E2)) T的类型就是E1, 而在上面的例子中当float和long运算时, long会转换成float. 我们知道在计算机中存储浮点数采用科学计数法, 也就是浮点数, 数字向右移动移动到小数点后面.3.1415 被转化为 0.31415x10^1 Float是在Java中是用32个bit存储的, 1个bit表示正负符号(符号位), 7个bit表示精度(指数位), 23个bit表示有效数字.上面的数字就是5个有效数字, 指数为1, 精度也就是为1. 也就说按照小数点后面是0, 小数点前面最大有效数字是24位(16777216), 而指数为最大为7位(128), 很明显这个128位要大于24位, 这是为什么呢? 因为小数点后面可以是104个0然后是24个有效数字 有效数字是一个数字中从左第一个不为0的开始向右数, 直到数字结束, 中间的这部分就是有效数字 那么回到正文,刚开始的那个例子是问题出在哪里呢? 答案就在下面的例子里 123456789public class TestFloat &#123; public static void main(String[] args) &#123; long now = 1477911537443l; float f = (float)now; // 0.1477911537443l * 10^13 =&gt; 10101100000011010011001(24位有效数字) 000110011100100011 long time = (long)f; // 截取000110011100100011 =&gt; 10101100000011010011001(有效数字) 000000000000000000 =&gt; 1477911511040 System.out.println(time); // 1477911511040 &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://wangmingco.github.io/categories/Java/"}],"tags":[]},{"title":"LinkedHashMap","slug":"JavaSE/LinkedHashMap","date":"2016-10-26T16:00:00.000Z","updated":"2021-11-18T02:40:42.547Z","comments":true,"path":"2016/10/27/JavaSE/LinkedHashMap/","link":"","permalink":"https://wangmingco.github.io/2016/10/27/JavaSE/LinkedHashMap/","excerpt":"","text":"LinkedHashMap 继承自HashMap, 它维护着一个运行于所有条目的双重链接列表。此链接列表定义了迭代顺序，该迭代顺序通常就是将键插入到映射中的顺序（插入顺序）。 我们从HashMap的putVal()方法开始看 123456789101112131415161718192021222324252627282930313233343536373839404142final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; 在newNode(hash, key, value, null);时调用了LinkedHashMap的linkNodeLast 12345678910private void linkNodeLast(LinkedHashMap.Entry&lt;K,V&gt; p) &#123; LinkedHashMap.Entry&lt;K,V&gt; last = tail; tail = p; if (last == null) head = p; else &#123; p.before = last; last.after = p; &#125;&#125; 这个操作就是将新的Node插入到LinkedHashMap的尾节点. 我们看完插入操作, 再看一下afterNodeAccess(), 这个方法在HashMap的putVal()方法中, 重新插入一个数据时会调用到(还有一些其他的方法也会调用这个方法). 当重新插入数据时, 会尝试afterNodeAccess()调用, 然后改变LinkedHashMap的双向链表, 从而改变整个链表表达的插入顺序. 1234567891011121314151617181920212223242526272829303132333435363738394041void afterNodeAccess(Node&lt;K,V&gt; e) &#123; // move node to last LinkedHashMap.Entry&lt;K,V&gt; last; // 如果被访问的元素是最后一个元素的话, 就不处理, 否则尝试将被访问的元素移动到最后的位置 if (accessOrder &amp;&amp; (last = tail) != e) &#123; LinkedHashMap.Entry&lt;K,V&gt; p = (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after; // 将被访问元素p的后一个node置为null, 因为要将p放到最后面去, 因此它的后面不能再有数据 p.after = null; // 下面俩个if 开始进行对p前后俩个数据进行双向绑定 if (b == null) // 如果p前面没有数据的话, 就将p后面的数据放到首位去, 然后将p放到最后 head = a; else // 如果p前面有数据, 就将p后面的数据和前面的数据连接起来 b.after = a; if (a != null) // 将p前面的数据绑定到p的后面的数据上. a.before = b; else // p后面没有数据, 因为在刚开始的if里已经判断, p不可能是最后一个元素, 但是当只有一个元素时, 可能会出现这种情况 last = b; if (last == null) head = p; else &#123; // 进行置换, 将p放到队列尾 p.before = last; last.after = p; &#125; tail = p; ++modCount; &#125;&#125; 从上面方法的if中我们可以看到,如果accessOrder为true(默认false), 当重新访问数据时, 插入顺序呢是会改变的. 也就是说在调用下列方法时 put replace computeIfAbsent compute merge get被调用的数据会放到队列尾, 因此如果我们将accessOrder置为true, LinkedHashMap可以当做LRU Cache使用 当继承LinkedHashMap, 实现一个LRU Cache的时候, 我们可以重载一下removeEldestEntry(Map.Entry&lt;K,V&gt; eldest)这个方法, 当插入新的数据的时候, 可以灵活地处理过期的数据 写个测试程序测试一下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091import org.junit.Test;import java.util.HashMap;import java.util.LinkedHashMap;import java.util.Map;public class TestLinkedHashMap &#123; @Test public void testHashMap() &#123; Map&lt;String, String&gt; map = new HashMap&lt;&gt;(); for (int i = 0; i &lt; 1000; i++) &#123; map.put(i + &quot;&quot;, &quot;&quot;); &#125; testStep1(&quot;testHashMap&quot;, map); &#125; private Map&lt;String, String&gt; falseAccessOrderMap() &#123; LinkedHashMap&lt;String, String&gt; map = new LinkedHashMap&lt;&gt;(); for (int i = 1; i &lt; 1000; i++) &#123; map.put(i + &quot;&quot;, &quot;&quot;); &#125; return map; &#125; private void testStep1(String module, Map&lt;String, String&gt; map) &#123; int older = 0; for (String string : map.keySet()) &#123; int num = Integer.parseInt(string); if ((older + 1) != num) &#123; System.err.println(module + &quot; : &quot; + (older + 1) + &quot; -&gt; &quot; + num); break; &#125; older = num; &#125; &#125; // 测试 迭代顺序就是将键插入到映射中的顺序（插入顺序） @Test public void falseAccessOrderLinkedHashMap_SaveOrder() &#123; Map&lt;String, String&gt; map = falseAccessOrderMap(); testStep1(&quot;falseAccessOrderLinkedHashMap_SaveOrder&quot;, map); &#125; // 测试 如果在映射中重新插入 键，则插入顺序不受影响 @Test public void falseAccessOrderLinkedHashMap_RePutSaveOrder() &#123; Map&lt;String, String&gt; map = falseAccessOrderMap(); map.put(&quot;123&quot;, &quot;&quot;); testStep1(&quot;falseAccessOrderLinkedHashMap_RePutSaveOrder&quot;, map); &#125; @Test public void falseAccessOrderLinkedHashMap_GetSaveOrder() &#123; Map&lt;String, String&gt; map = falseAccessOrderMap(); map.put(&quot;123&quot;, &quot;&quot;); map.put(&quot;123&quot;, &quot;&quot;); map.put(&quot;123&quot;, &quot;&quot;); testStep1(&quot;falseAccessOrderLinkedHashMap_GetSaveOrder&quot;, map); &#125; private Map&lt;String, String&gt; trueAccessOrderMap() &#123; LinkedHashMap&lt;String, String&gt; map = new LinkedHashMap&lt;&gt;(10, 0.75f, true); for (int i = 1; i &lt; 1000; i++) &#123; map.put(i + &quot;&quot;, &quot;&quot;); &#125; return map; &#125; @Test public void trueAccessOrderLinkedHashMap_SaveOrder() &#123; Map&lt;String, String&gt; map = trueAccessOrderMap(); testStep1(&quot;trueAccessOrderLinkedHashMap_SaveOrder&quot;, map); &#125; @Test public void trueAccessOrderLinkedHashMap_RePutSaveOrder() &#123; Map&lt;String, String&gt; map = trueAccessOrderMap(); map.put(&quot;123&quot;, &quot;&quot;); testStep1(&quot;trueAccessOrderLinkedHashMap_RePutSaveOrder&quot;, map); &#125; @Test public void trueAccessOrderLinkedHashMap_GetSaveOrder() &#123; Map&lt;String, String&gt; map = trueAccessOrderMap(); map.put(&quot;123&quot;, &quot;&quot;); map.put(&quot;123&quot;, &quot;&quot;); map.put(&quot;123&quot;, &quot;&quot;); testStep1(&quot;trueAccessOrderLinkedHashMap_GetSaveOrder&quot;, map); &#125;&#125; 运行一下, 结果果真如此.","categories":[{"name":"Java","slug":"Java","permalink":"https://wangmingco.github.io/categories/Java/"}],"tags":[]},{"title":"一致性hash","slug":"算法/一致性hash","date":"2016-10-23T16:00:00.000Z","updated":"2021-11-18T02:53:43.550Z","comments":true,"path":"2016/10/24/算法/一致性hash/","link":"","permalink":"https://wangmingco.github.io/2016/10/24/%E7%AE%97%E6%B3%95/%E4%B8%80%E8%87%B4%E6%80%A7hash/","excerpt":"","text":"原理 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150import java.util.Map;import java.util.Random;import java.util.TreeMap;import java.util.concurrent.ConcurrentHashMap;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;public class TestConsistentHash &#123; public static void main(String[] args) &#123; Cache.INSTANCE.init(); Random random = new Random(999999999); for (int i = 0; i &lt; 10000; i++) &#123; long number = random.nextLong(); Cache.INSTANCE.insert(number + &quot;&quot;, number + &quot;&quot;); &#125; System.out.println(Cache.INSTANCE); &#125; public static class Cache &#123; public static final Cache INSTANCE = new Cache(); private Integer virtualNodeSize = 50; private Integer serverNodeSize = 10; private static final Integer MIN_HASH = 0; private static final long MAX_HASH = (long)(Math.pow(2,32) - 1); private Integer serverNodeIndex = 0; private static final ExecutorService exec = Executors.newSingleThreadExecutor(); private Map&lt;Long, VirtualNode&gt; virtualNodes = new TreeMap&lt;&gt;(); private Map&lt;Integer, ServerNode&gt; serverNodes = new TreeMap&lt;&gt;(); private Cache() &#123; &#125; private void init() &#123; for (int i = 0; i &lt; serverNodeSize; i++) &#123; serverNodes.put(i, new ServerNode()); &#125; System.out.println(&quot;ServerNode Number : &quot; + serverNodes.size()); long step = MAX_HASH / virtualNodeSize; long hashCode = 0; for (int i = 0; i &lt; virtualNodeSize; i++) &#123; VirtualNode virtualNode = new VirtualNode(); virtualNode.setServerNode(serverNodes.get(serverNodeIndex++)); hashCode += step; virtualNodes.put(hashCode, virtualNode); System.out.println(&quot;Add VirtualNode : &quot; + hashCode); &#125; System.out.println(&quot;VirtualNode Number : &quot; + virtualNodes.size()); &#125; public void addVirtualNode() &#123; exec.submit(() -&gt; &#123; virtualNodes.clear(); ++virtualNodeSize; init(); &#125;); &#125; public void removeVirtualNode() &#123; exec.submit(() -&gt; &#123; virtualNodes.clear(); --virtualNodeSize; init(); &#125;); &#125; public void addServerNode() &#123; exec.submit(() -&gt; &#123; virtualNodes.clear(); serverNodes.clear(); serverNodeIndex++; init(); &#125;); &#125; public void removeServerNode() &#123; exec.submit(() -&gt; &#123; virtualNodes.clear(); serverNodes.clear(); serverNodeIndex--; init(); &#125;); &#125; public void insert(String key, String value) &#123; exec.submit(() -&gt; &#123; int hashCode = key.hashCode(); for (Map.Entry&lt;Long, VirtualNode&gt; entry : virtualNodes.entrySet()) &#123; long hashcode = entry.getKey(); VirtualNode node = entry.getValue(); if (hashCode &gt;= hashcode ) &#123; node.insert(key, value); &#125; &#125; &#125;); &#125; public String toString() &#123; StringBuffer stringBuffer = new StringBuffer(); for (Map.Entry&lt;Integer, ServerNode&gt; entry : serverNodes.entrySet()) &#123; int key1 = entry.getKey(); ServerNode node = entry.getValue(); stringBuffer.append(key1).append(&quot; : &quot;).append(node.map.keySet().size()).append(&quot;\\n&quot;); &#125; return stringBuffer.toString(); &#125; &#125; /** * 虚拟节点 */ private static class VirtualNode &#123; private ServerNode serverNode; public void insert(String key, String value) &#123; serverNode.insert(key, value); &#125; public String get(String key) &#123; return serverNode.get(key); &#125; public void setServerNode(ServerNode serverNode) &#123; this.serverNode = serverNode; &#125; &#125; /** * 代表真实服务器 */ private static class ServerNode &#123; private final Map&lt;String, String&gt; map = new ConcurrentHashMap&lt;&gt;(); public void insert(String key, String value) &#123; map.put(key, value); &#125; public String get(String key) &#123; return map.get(key); &#125; &#125;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://wangmingco.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[]},{"title":"Jackson 笔记","slug":"JavaLibrary/Jackson","date":"2016-10-10T16:00:00.000Z","updated":"2021-11-18T02:47:02.018Z","comments":true,"path":"2016/10/11/JavaLibrary/Jackson/","link":"","permalink":"https://wangmingco.github.io/2016/10/11/JavaLibrary/Jackson/","excerpt":"","text":"Jackson 提供了三种对JSON处理的方式 Data Binding Tree Model Streaming API Data Binding这种方式提供了JSON数据和Java对象之间的无缝转换，而且这种方式是相当便利的. 它内部基于 Streaming API 的JSON 读写系统, 尽管Data Binding 是非常高效地,但是相比纯 streaming/incremental 方式，仍然有一些额外的性能消耗． 序列化1234567891011 @Testpublic void test_Serialization() throws IOException &#123; Obj obj = new Obj(); obj.platform = &quot;qq&quot;; StringWriter stringWriter = new StringWriter(); ObjectMapper objectMapper = new ObjectMapper(); objectMapper.writeValue(stringWriter, obj); System.out.println(stringWriter);&#125; 输出为&#123;&quot;platform&quot;:&quot;qq&quot;&#125; 数据绑定1234567@Testpublic void test_ObjectMapperRead () throws IOException &#123; String jsonStr = &quot;&#123;\\&quot;platform\\&quot;:\\&quot;1\\&quot;&#125;&quot;; ObjectMapper objectMapper = new ObjectMapper(); Obj obj = objectMapper.readValue(jsonStr, Obj.class); System.out.println(obj.platform);&#125; 输出为1 泛型绑定123456789101112@Testpublic void test_Serialization() throws IOException &#123; Map&lt;Integer, String&gt; map = new HashMap&lt;&gt;(); map.put(2016, &quot;10/11&quot;); StringWriter stringWriter = new StringWriter(); ObjectMapper objectMapper = new ObjectMapper(); objectMapper.writeValue(stringWriter, map); Map&lt;Integer, String&gt; newMap = objectMapper.readValue(stringWriter.toString(), new TypeReference&lt;Map&lt;Integer, String&gt;&gt;() &#123;&#125;); System.out.println(newMap.get(2016));&#125; 输出为10/11 数组绑定1234567891011@Test public void test_Binding() throws IOException &#123; String[] array = &#123;&quot;2016&quot;&#125;; StringWriter stringWriter = new StringWriter(); ObjectMapper objectMapper = new ObjectMapper(); objectMapper.writeValue(stringWriter, array); String[] arr = objectMapper.readValue(stringWriter.toString(), String[].class); System.out.println(arr[0]); &#125; 线程安全ObjectMapper被共享出来之后, 只要重新配置共享实例, 那么它就是线程安全的. 也就是不要调用下列方法 enable() disable() configure() 参考 Should I declare Jackson’s ObjectMapper as a static field? Jackson FAQ: Thread-Safety Tree ModelTree Model 和XML 处理方式 非常类似. 1234567891011121314151617181920212223242526272829303132333435363738394041import com.fasterxml.jackson.databind.JsonNode;import com.fasterxml.jackson.databind.ObjectMapper;import org.junit.Test;public class TestTreeModel &#123; @Test public void test_() throws Exception &#123; Obj1 obj1 = new Obj1(); Obj2 obj2 = new Obj2(); Obj3 obj3 = new Obj3(); obj1.obj2 = obj2; obj2.obj3 = obj3; obj3.string = &quot;hello&quot;; ObjectMapper objectMapper = new ObjectMapper(); String str = objectMapper.writeValueAsString(obj1); JsonNode objtree = objectMapper.readTree(str); System.out.println(&quot;get obj2 : &quot; + objtree.get(&quot;obj2&quot;)); System.out.println(&quot;get obj3 : &quot; + objtree.get(&quot;obj3&quot;)); System.out.println(&quot;get string : &quot; + objtree.get(&quot;string&quot;)); System.out.println(&quot;path obj2 : &quot; + objtree.path(&quot;obj2&quot;)); System.out.println(&quot;path obj3 : &quot; + objtree.path(&quot;obj3&quot;)); System.out.println(&quot;path string : &quot; + objtree.path(&quot;string&quot;)); System.out.println(&quot;path string obj2 -&gt; obj3 -&gt; string : &quot; + objtree.path(&quot;obj2&quot;).path(&quot;obj3&quot;).path(&quot;string&quot;)); &#125; private static class Obj1 &#123; public Obj2 obj2; &#125; private static class Obj2 &#123; public Obj3 obj3; &#125; private static class Obj3 &#123; public String string; &#125;&#125; 输出结果为 1234567get obj2 : &#123;&quot;obj3&quot;:&#123;&quot;string&quot;:&quot;hello&quot;&#125;&#125;get obj3 : nullget string : nullpath obj2 : &#123;&quot;obj3&quot;:&#123;&quot;string&quot;:&quot;hello&quot;&#125;&#125;path obj3 : path string : path string obj2 -&gt; obj3 -&gt; string : &quot;hello&quot; 当调用get()方法时, 如果找不到的话, 会返回null, 而path()找不到的话则会返回MissingNode 还有一个方法with(int index)我们没有演示, 这个方法是如果找不到就添加. get()方法还有一个特别有用的地方就是用来处理数组. 12345678910111213141516171819202122import com.fasterxml.jackson.databind.JsonNode;import com.fasterxml.jackson.databind.ObjectMapper;import org.junit.Test;public class TestTreeModel &#123; @Test public void test_() throws Exception &#123; Obj1 obj1 = new Obj1(); ObjectMapper objectMapper = new ObjectMapper(); String str = objectMapper.writeValueAsString(obj1); System.out.println(str); JsonNode tree = objectMapper.readTree(str); System.out.println(tree.get(&quot;strings&quot;).get(1)); &#125; private static class Obj1 &#123; public String[] strings = &#123;&quot;123&quot;, &quot;456&quot;&#125;; &#125;&#125; 结果为 12&#123;&quot;strings&quot;:[&quot;123&quot;,&quot;456&quot;]&#125;&quot;456&quot; Streaming APIStreaming API 是 Jackson处理 JSON最高效地方式. 但是它的易用性却大大地降低了, 我们不能像Data Binding 或者 Tree Model 那样随机访问元素. SerializationFeatureWRAP_ROOT_VALUE是否环绕根元素，默认false，如果为true，则默认以类名作为根元素，也可以通过@JsonRootName来自定义根元素名称 12345678910111213141516171819import com.fasterxml.jackson.databind.ObjectMapper;import com.fasterxml.jackson.databind.SerializationFeature;import org.junit.Test;import java.io.IOException;public class TestDataBinding &#123; @Test public void test_SerializationFeature () throws IOException &#123; ObjectMapper objectMapper = new ObjectMapper(); objectMapper.enable(SerializationFeature.WRAP_ROOT_VALUE); System.out.println( objectMapper.writeValueAsString(new Obj())); &#125; public static class Obj &#123; public String platform = &quot;example&quot;; &#125;&#125; 结果为&#123;&quot;Obj&quot;:&#123;&quot;platform&quot;:&quot;example&quot;&#125;&#125; 如果不开启WRAP_ROOT_VALUE的话, 结果为&#123;&quot;platform&quot;:&quot;example&quot;&#125; INDENT_OUTPUT 是否缩放排列输出 1objectMapper.enable(SerializationFeature.INDENT_OUTPUT); 结果为 123&#123; &quot;platform&quot; : &quot;example&quot;&#125; WRITE_DATES_AS_TIMESTAMPS序列化日期时以timestamps输出 12345678910111213public class TestDataBinding &#123; @Test public void test_SerializationFeature () throws IOException &#123; ObjectMapper objectMapper = new ObjectMapper(); objectMapper.enable(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS); System.out.println( objectMapper.writeValueAsString(new Obj())); &#125; public static class Obj &#123; public Date now = new Date(); &#125;&#125; 结果为 1&#123;&quot;now&quot;:1476179780913&#125; WRITE_CHAR_ARRAYS_AS_JSON_ARRAYS序列化char[]时以json数组输出 ORDER_MAP_ENTRIES_BY_KEYS序列化Map时对key进行排序操作 DeserializationFeatureFAIL_ON_UNKNOWN_PROPERTIES在反序列化时, 如果Java对象中不包含json串的某个数据 属性, 则会报错. 123456789101112131415public class TestDataBinding &#123; @Test public void test_SerializationFeature () throws IOException &#123; ObjectMapper objectMapper = new ObjectMapper(); objectMapper.disable(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES); String str = &quot;&#123;\\&quot;strings1\\&quot;:[\\&quot;123\\&quot;],\\&quot;strings2\\&quot;:[\\&quot;456\\&quot;]&#125;&quot;; objectMapper.readValue(str, Obj.class); &#125; public static class Obj &#123; public String[] strings1 = &#123;&quot;123&quot;&#125;; &#125;&#125; MapperFeatureACCEPT_CASE_INSENSITIVE_PROPERTIES 在反序列化时是否忽略大小写 123456789101112131415161718192021222324252627282930313233343536373839404142434445import com.fasterxml.jackson.databind.MapperFeature;import com.fasterxml.jackson.databind.ObjectMapper;import org.junit.Test;import java.io.IOException;public class TestDataBinding &#123; @Test public void test_SerializationFeature () throws IOException &#123; ObjectMapper objectMapper = new ObjectMapper(); Upper upper = new Upper(); upper.setFirstName(&quot;John&quot;); System.out.println(objectMapper.writeValueAsString(upper)); Lower lower = new Lower(); lower.setLastName(&quot;li&quot;); System.out.println(objectMapper.writeValueAsString(lower)); &#125; @Test public void test_DeserializationFeature () throws IOException &#123; ObjectMapper objectMapper = new ObjectMapper(); objectMapper.enable(MapperFeature.ACCEPT_CASE_INSENSITIVE_PROPERTIES); Upper obj1 = objectMapper.readValue(&quot;&#123;\\&quot;firstName\\&quot;:\\&quot;John\\&quot;&#125;&quot;, Upper.class); System.out.println(obj1.getFirstName()); Upper obj2 = objectMapper.readValue(&quot;&#123;\\&quot;FirstName\\&quot;:\\&quot;John\\&quot;&#125;&quot;, Upper.class); System.out.println(obj2.getFirstName()); &#125;&#125;class Upper &#123; private String FirstName; public String getFirstName() &#123;return FirstName;&#125; public void setFirstName(String firstName) &#123;FirstName = firstName;&#125;&#125;class Lower &#123; private String lastName; public String getLastName() &#123;return lastName;&#125; public void setLastName(String lastName) &#123;this.lastName = lastName;&#125;&#125; 在test_SerializationFeature()这个测试中, 我们可以通过结果看到, Upper的FirstName在JSON串 中成了firstName. 当反序列化得时候, 如果不指定ACCEPT_CASE_INSENSITIVE_PROPERTIES, 那么当JSON串中的FirstName为大写的时候, 是没办法序列化出来的. 注解JsonPropertyjackson 默认是根据Getter来进行注值反序列化的, 但是有时候为了节省存储空间, 字段名远小于Getter名称, 这样就造成了字段名和方法名不一致, 此时就可以利用JsonProperty注解重命名来解决这个问题 1234567891011121314151617181920212223242526272829303132333435import com.fasterxml.jackson.annotation.JsonProperty;import com.fasterxml.jackson.databind.MapperFeature;import com.fasterxml.jackson.databind.ObjectMapper;import org.junit.Test;import java.io.IOException;public class TestDataBinding &#123; @Test public void test_Deferent () throws IOException &#123; ObjectMapper objectMapper = new ObjectMapper(); objectMapper.enable(MapperFeature.ACCEPT_CASE_INSENSITIVE_PROPERTIES); Different different = new Different(); different.setMiddle(&quot;Nice&quot;); System.out.println(objectMapper.writeValueAsString(different)); Different obj2 = objectMapper.readValue(&quot;&#123;\\&quot;middle\\&quot;:\\&quot;Nice\\&quot;&#125;&quot;, Different.class); System.out.println(obj2.getMiddle()); Different obj3 = objectMapper.readValue(&quot;&#123;\\&quot;Mid\\&quot;:\\&quot;Nice\\&quot;&#125;&quot;, Different.class); System.out.println(obj3.getMiddle()); Different obj4 = objectMapper.readValue(&quot;&#123;\\&quot;mid\\&quot;:\\&quot;Nice\\&quot;&#125;&quot;, Different.class); System.out.println(obj4.getMiddle()); &#125;&#125;class Different &#123; @JsonProperty(&quot;mid&quot;) private String Mid; public String getMiddle() &#123;return Mid;&#125; public void setMiddle(String middle) &#123;this.Mid = middle;&#125;&#125; 说到这里就需要点出一个坑了 1234567891011121314151617181920212223242526272829303132333435363738394041import com.alibaba.fastjson.JSON;import com.fasterxml.jackson.databind.ObjectMapper;import com.google.gson.Gson;import java.io.IOException;public class TestPrivate &#123; public static void main(String[] args) throws IOException &#123; ObjectMapper objectMapper = new ObjectMapper(); SimpleId simpleId = new SimpleId(); simpleId.setString(&quot;simple Id&quot;); String json = objectMapper.writeValueAsString(simpleId); System.out.println(&quot;Jsckson ---&gt; &quot; + json); Gson gson = new Gson(); json = gson.toJson(simpleId); System.out.println(&quot;Gson ---&gt; &quot; + json); json = JSON.toJSONString(simpleId); System.out.println(&quot;FastJson ---&gt; &quot; + json); &#125; public static class SimpleId &#123; private String stringId; private String stringName = &quot;empty name&quot;; public String getString() &#123; return stringId; &#125; public void setString(String string) &#123; this.stringId = string; &#125; public String getString1() &#123; return &quot;123456&quot;; &#125; &#125;&#125; 结果为 123Jsckson ---&gt; &#123;&quot;string&quot;:&quot;simple Id&quot;,&quot;string1&quot;:&quot;123456&quot;&#125;Gson ---&gt; &#123;&quot;stringId&quot;:&quot;simple Id&quot;,&quot;stringName&quot;:&quot;empty name&quot;&#125;FastJson ---&gt; &#123;&quot;string&quot;:&quot;simple Id&quot;,&quot;string1&quot;:&quot;123456&quot;&#125; 有时候我们需要Gson这种输出结果, 即不使用Getter, 而是使用filed进行序列化, 怎么办呢？我们可以使用 @JsonAutoDetect(fieldVisibility = Visibility.ANY, getterVisibility = Visibility.NONE, setterVisibility = Visibility.NONE), 但是对于有时候我们并不想在每个类上面都加一个这样的注解, 配置一些ObjectMapper就可以了 123456ObjectMapper objectMapper = new ObjectMapper();objectMapper.setVisibility(objectMapper.getSerializationConfig().getDefaultVisibilityChecker() .withFieldVisibility(JsonAutoDetect.Visibility.ANY) .withGetterVisibility(JsonAutoDetect.Visibility.NONE) .withSetterVisibility(JsonAutoDetect.Visibility.NONE) .withCreatorVisibility(JsonAutoDetect.Visibility.NONE)); 这样结果为 123Jsckson ---&gt; &#123;&quot;stringId&quot;:&quot;simple Id&quot;,&quot;stringName&quot;:&quot;empty name&quot;&#125;Gson ---&gt; &#123;&quot;stringId&quot;:&quot;simple Id&quot;,&quot;stringName&quot;:&quot;empty name&quot;&#125;FastJson ---&gt; &#123;&quot;string&quot;:&quot;simple Id&quot;,&quot;string1&quot;:&quot;123456&quot;&#125; JsonInclude指定在序列化时, 可以输出哪些值. 例如只输出非默认值(包含类型默认值和初始化默认值) 123456789101112131415161718192021import com.fasterxml.jackson.annotation.JsonInclude;import com.fasterxml.jackson.core.JsonProcessingException;import com.fasterxml.jackson.databind.ObjectMapper;import org.junit.Test;public class TestDefault &#123; @Test public void test_() throws JsonProcessingException &#123; ObjectMapper objectMapper = new ObjectMapper(); Foo foo = new Foo(); foo.string1 = &quot;123&quot;; System.out.println(objectMapper.writeValueAsString(foo)); &#125;&#125;@JsonInclude(JsonInclude.Include.NON_DEFAULT)class Foo &#123; public String string1; public String string2 = &quot;xxx&quot;; public String string3;&#125; JsonSerialize实现浮点数只保留俩位 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import com.fasterxml.jackson.core.JsonGenerator;import com.fasterxml.jackson.core.JsonProcessingException;import com.fasterxml.jackson.databind.JsonSerializer;import com.fasterxml.jackson.databind.ObjectMapper;import com.fasterxml.jackson.databind.SerializerProvider;import com.fasterxml.jackson.databind.annotation.JsonSerialize;import org.junit.Test;import java.io.IOException;import java.text.DecimalFormat;public class TestDouble &#123; @Test public void test_() throws JsonProcessingException &#123; DoubleObject doubleObject = new DoubleObject(); doubleObject.aDouble = 1.101010101010101; doubleObject.aFloat = 1.101010101010101f; ObjectMapper objectMapper = new ObjectMapper(); String string = objectMapper.writeValueAsString(doubleObject); System.out.println(string); &#125; public static class CustomDoubleSerializer extends JsonSerializer&lt;Number&gt; &#123; @Override public void serialize(Number value, JsonGenerator jgen, SerializerProvider provider) throws IOException &#123; if (null == value) &#123; jgen.writeNull(); &#125; else if (value instanceof Double || value instanceof Float)&#123; final String pattern = &quot;.##&quot;; final DecimalFormat myFormatter = new DecimalFormat(pattern); final String output = myFormatter.format(value); jgen.writeNumber(output); &#125; &#125; &#125; public static class DoubleObject &#123; @JsonSerialize(using = CustomDoubleSerializer.class) private double aDouble; @JsonSerialize(using = CustomDoubleSerializer.class) private float aFloat; public double getaDouble() &#123;return aDouble;&#125; public void setaDouble(double aDouble) &#123;this.aDouble = aDouble;&#125; public float getaFloat() &#123;return aFloat;&#125; public void setaFloat(float aFloat) &#123;this.aFloat = aFloat;&#125; &#125;&#125; module可以通过module来自定义实现 序列化和反序列机制. 下面的例子中就是演示对Double类型的序列化时保留浮点数位数的实现 注意 如果注解和自定义序列化重复时, 那么注解的设置会覆盖自定义序列化机制. 而且对于原生类型来说, 是区分原生类型和包装类型的 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566import com.fasterxml.jackson.core.JsonGenerator;import com.fasterxml.jackson.core.JsonProcessingException;import com.fasterxml.jackson.databind.JsonSerializer;import com.fasterxml.jackson.databind.ObjectMapper;import com.fasterxml.jackson.databind.SerializerProvider;import com.fasterxml.jackson.databind.annotation.JsonSerialize;import com.fasterxml.jackson.databind.module.SimpleModule;import java.io.IOException;import java.text.DecimalFormat;public class TestModule &#123; private static final ObjectMapper objectMapper; static &#123; objectMapper = new ObjectMapper(); SimpleModule simpleModule = new SimpleModule(); simpleModule.addSerializer(Double.class, new CustomFiveDoubleSerializer()); simpleModule.addSerializer(double.class, new CustomFiveDoubleSerializer()); objectMapper.registerModule(simpleModule); &#125; public static class CustomFiveDoubleSerializer extends JsonSerializer&lt;Number&gt; &#123; @Override public void serialize(Number value, JsonGenerator jgen, SerializerProvider provider) throws IOException &#123; if (null == value) &#123; jgen.writeNull(); &#125; else if (value instanceof Double || value instanceof Float)&#123; final String pattern = &quot;.#####&quot;; final DecimalFormat myFormatter = new DecimalFormat(pattern); final String output = myFormatter.format(value); jgen.writeNumber(output); &#125; &#125; &#125; public static class CustomOneDoubleSerializer extends JsonSerializer&lt;Number&gt; &#123; @Override public void serialize(Number value, JsonGenerator jgen, SerializerProvider provider) throws IOException &#123; if (null == value) &#123; jgen.writeNull(); &#125; else if (value instanceof Double || value instanceof Float)&#123; final String pattern = &quot;.#&quot;; final DecimalFormat myFormatter = new DecimalFormat(pattern); final String output = myFormatter.format(value); jgen.writeNumber(output); &#125; &#125; &#125; public static void main(String[] args) throws JsonProcessingException &#123; Obj obj = new Obj(); obj.aDouble1 = 1.111111111111; obj.aDouble2 = 1.111111111111; System.out.println(objectMapper.writeValueAsString(obj)); &#125; public static class Obj &#123; public Double aDouble1; @JsonSerialize(using = CustomOneDoubleSerializer.class) public Double aDouble2; &#125;&#125;","categories":[{"name":"Java 类库","slug":"Java-类库","permalink":"https://wangmingco.github.io/categories/Java-%E7%B1%BB%E5%BA%93/"}],"tags":[{"name":"Jackson","slug":"Jackson","permalink":"https://wangmingco.github.io/tags/Jackson/"}]},{"title":"Java 字符串优化","slug":"JavaSE/Java String","date":"2016-09-25T16:00:00.000Z","updated":"2021-11-18T02:39:46.348Z","comments":true,"path":"2016/09/26/JavaSE/Java String/","link":"","permalink":"https://wangmingco.github.io/2016/09/26/JavaSE/Java%20String/","excerpt":"","text":"今天review同事写的一段代码, 在枚举中动态生成字符串key的时候, 使用字符串常量进行拼接, 虽然感觉这么写会有一定的GC性能消耗, 但是具体原因有点忘记了, 今天就重新写段测试代码,进行测试一下. 当使用字符串(String)的时候, Java编译器会给我们自动的做一些优化编译的工作. 下面我们分别用三段代码, 从GC和编译俩个角度看看Java是如何给我们优化的. 首先呢,我们使用-XX:+PrintHeapAtGC -Xmx10M -Xms10M这个参数分别运行以下三段代码 首先看一下TestCombine1 123456789public class TestCombine1 &#123; private static final String str1 = new String(&quot;123456789123456789123456789123456789123456789123456789123456789123456789123456789123456789&quot;); public static void main(String[] args) &#123; for (int i = 0; i &lt; 1000000; i++) &#123; String string1 = &quot;string&quot; + str1; &#125; &#125;&#125; 运行结果为 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758&#123;Heap before GC invocations=1 (full 0): PSYoungGen total 2560K, used 2048K [0x00000000ffd00000, 0x0000000100000000, 0x0000000100000000) eden space 2048K, 100% used [0x00000000ffd00000,0x00000000fff00000,0x00000000fff00000) from space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000) to space 512K, 0% used [0x00000000fff00000,0x00000000fff00000,0x00000000fff80000) ParOldGen total 7168K, used 0K [0x00000000ff600000, 0x00000000ffd00000, 0x00000000ffd00000) object space 7168K, 0% used [0x00000000ff600000,0x00000000ff600000,0x00000000ffd00000) Metaspace used 2754K, capacity 4480K, committed 4480K, reserved 1056768K class space used 296K, capacity 384K, committed 384K, reserved 1048576KHeap after GC invocations=1 (full 0): PSYoungGen total 2560K, used 488K [0x00000000ffd00000, 0x0000000100000000, 0x0000000100000000) eden space 2048K, 0% used [0x00000000ffd00000,0x00000000ffd00000,0x00000000fff00000) from space 512K, 95% used [0x00000000fff00000,0x00000000fff7a020,0x00000000fff80000) to space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000) ParOldGen total 7168K, used 530K [0x00000000ff600000, 0x00000000ffd00000, 0x00000000ffd00000) object space 7168K, 7% used [0x00000000ff600000,0x00000000ff684ac0,0x00000000ffd00000) Metaspace used 2754K, capacity 4480K, committed 4480K, reserved 1056768K class space used 296K, capacity 384K, committed 384K, reserved 1048576K&#125;&#123;Heap before GC invocations=2 (full 0): PSYoungGen total 2560K, used 2536K [0x00000000ffd00000, 0x0000000100000000, 0x0000000100000000) eden space 2048K, 100% used [0x00000000ffd00000,0x00000000fff00000,0x00000000fff00000) from space 512K, 95% used [0x00000000fff00000,0x00000000fff7a020,0x00000000fff80000) to space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000) ParOldGen total 7168K, used 530K [0x00000000ff600000, 0x00000000ffd00000, 0x00000000ffd00000) object space 7168K, 7% used [0x00000000ff600000,0x00000000ff684ac0,0x00000000ffd00000) Metaspace used 2969K, capacity 4490K, committed 4864K, reserved 1056768K class space used 319K, capacity 386K, committed 512K, reserved 1048576KHeap after GC invocations=2 (full 0): PSYoungGen total 2560K, used 504K [0x00000000ffd00000, 0x0000000100000000, 0x0000000100000000) eden space 2048K, 0% used [0x00000000ffd00000,0x00000000ffd00000,0x00000000fff00000) from space 512K, 98% used [0x00000000fff80000,0x00000000ffffe010,0x0000000100000000) to space 512K, 0% used [0x00000000fff00000,0x00000000fff00000,0x00000000fff80000) ParOldGen total 7168K, used 581K [0x00000000ff600000, 0x00000000ffd00000, 0x00000000ffd00000) object space 7168K, 8% used [0x00000000ff600000,0x00000000ff691670,0x00000000ffd00000) Metaspace used 2969K, capacity 4490K, committed 4864K, reserved 1056768K class space used 319K, capacity 386K, committed 512K, reserved 1048576K&#125;...&#123;Heap before GC invocations=38 (full 0): PSYoungGen total 2560K, used 2080K [0x00000000ffd00000, 0x0000000100000000, 0x0000000100000000) eden space 2048K, 100% used [0x00000000ffd00000,0x00000000fff00000,0x00000000fff00000) from space 512K, 6% used [0x00000000fff00000,0x00000000fff08000,0x00000000fff80000) to space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000) ParOldGen total 7168K, used 1212K [0x00000000ff600000, 0x00000000ffd00000, 0x00000000ffd00000) object space 7168K, 16% used [0x00000000ff600000,0x00000000ff72f050,0x00000000ffd00000) Metaspace used 3236K, capacity 4494K, committed 4864K, reserved 1056768K class space used 351K, capacity 386K, committed 512K, reserved 1048576KHeap after GC invocations=38 (full 0): PSYoungGen total 2560K, used 32K [0x00000000ffd00000, 0x0000000100000000, 0x0000000100000000) eden space 2048K, 0% used [0x00000000ffd00000,0x00000000ffd00000,0x00000000fff00000) from space 512K, 6% used [0x00000000fff80000,0x00000000fff88000,0x0000000100000000) to space 512K, 0% used [0x00000000fff00000,0x00000000fff00000,0x00000000fff80000) ParOldGen total 7168K, used 1212K [0x00000000ff600000, 0x00000000ffd00000, 0x00000000ffd00000) object space 7168K, 16% used [0x00000000ff600000,0x00000000ff72f050,0x00000000ffd00000) Metaspace used 3236K, capacity 4494K, committed 4864K, reserved 1056768K class space used 351K, capacity 386K, committed 512K, reserved 1048576K&#125; 我们看到一共GC了38次. 接下来看一下TestCombine2 123456789101112public class TestCombine2 &#123; public static void main(String[] args) &#123; for (int i = 0; i &lt; 100000; i++) &#123; String string3 = &quot;string&quot; + getFieldConstant(); &#125; &#125; public static String getFieldConstant() &#123; return &quot;123456789123456789123456789123456789123456789123456789123456789123456789123456789123456789&quot;; &#125;&#125; 运行结果 123456789101112131415161718192021222324252627282930313233343536373839&#123;Heap before GC invocations=1 (full 0): PSYoungGen total 2560K, used 2048K [0x00000000ffd00000, 0x0000000100000000, 0x0000000100000000) eden space 2048K, 100% used [0x00000000ffd00000,0x00000000fff00000,0x00000000fff00000) from space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000) to space 512K, 0% used [0x00000000fff00000,0x00000000fff00000,0x00000000fff80000) ParOldGen total 7168K, used 0K [0x00000000ff600000, 0x00000000ffd00000, 0x00000000ffd00000) object space 7168K, 0% used [0x00000000ff600000,0x00000000ff600000,0x00000000ffd00000) Metaspace used 2752K, capacity 4480K, committed 4480K, reserved 1056768K class space used 296K, capacity 384K, committed 384K, reserved 1048576KHeap after GC invocations=1 (full 0): PSYoungGen total 2560K, used 504K [0x00000000ffd00000, 0x0000000100000000, 0x0000000100000000) eden space 2048K, 0% used [0x00000000ffd00000,0x00000000ffd00000,0x00000000fff00000) from space 512K, 98% used [0x00000000fff00000,0x00000000fff7e010,0x00000000fff80000) to space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000) ParOldGen total 7168K, used 489K [0x00000000ff600000, 0x00000000ffd00000, 0x00000000ffd00000) object space 7168K, 6% used [0x00000000ff600000,0x00000000ff67a598,0x00000000ffd00000) Metaspace used 2752K, capacity 4480K, committed 4480K, reserved 1056768K class space used 296K, capacity 384K, committed 384K, reserved 1048576K&#125;...&#123;Heap before GC invocations=38 (full 0): PSYoungGen total 2560K, used 2080K [0x00000000ffd00000, 0x0000000100000000, 0x0000000100000000) eden space 2048K, 100% used [0x00000000ffd00000,0x00000000fff00000,0x00000000fff00000) from space 512K, 6% used [0x00000000fff00000,0x00000000fff08000,0x00000000fff80000) to space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000) ParOldGen total 7168K, used 1317K [0x00000000ff600000, 0x00000000ffd00000, 0x00000000ffd00000) object space 7168K, 18% used [0x00000000ff600000,0x00000000ff749738,0x00000000ffd00000) Metaspace used 3234K, capacity 4494K, committed 4864K, reserved 1056768K class space used 351K, capacity 386K, committed 512K, reserved 1048576KHeap after GC invocations=38 (full 0): PSYoungGen total 2560K, used 32K [0x00000000ffd00000, 0x0000000100000000, 0x0000000100000000) eden space 2048K, 0% used [0x00000000ffd00000,0x00000000ffd00000,0x00000000fff00000) from space 512K, 6% used [0x00000000fff80000,0x00000000fff88000,0x0000000100000000) to space 512K, 0% used [0x00000000fff00000,0x00000000fff00000,0x00000000fff80000) ParOldGen total 7168K, used 1317K [0x00000000ff600000, 0x00000000ffd00000, 0x00000000ffd00000) object space 7168K, 18% used [0x00000000ff600000,0x00000000ff749738,0x00000000ffd00000) Metaspace used 3234K, capacity 4494K, committed 4864K, reserved 1056768K class space used 351K, capacity 386K, committed 512K, reserved 1048576K&#125; 也GC了38次 接下来看一下TestCombine3 123456789public class TestCombine3 &#123; private static final String str2 = &quot;123456789123456789123456789123456789123456789123456789123456789123456789123456789123456789&quot;; public static void main(String[] args) &#123; for (int i = 0; i &lt; 1000000; i++) &#123; String string2 = &quot;string&quot; + str2; &#125; &#125;&#125; 运行结果 1234567891011121314151617181920212223242526272829303132333435363738&#123;Heap before GC invocations=1 (full 0): PSYoungGen total 2560K, used 2048K [0x00000000ffd00000, 0x0000000100000000, 0x0000000100000000) eden space 2048K, 100% used [0x00000000ffd00000,0x00000000fff00000,0x00000000fff00000) from space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000) to space 512K, 0% used [0x00000000fff00000,0x00000000fff00000,0x00000000fff80000) ParOldGen total 7168K, used 0K [0x00000000ff600000, 0x00000000ffd00000, 0x00000000ffd00000) object space 7168K, 0% used [0x00000000ff600000,0x00000000ff600000,0x00000000ffd00000) Metaspace used 2753K, capacity 4480K, committed 4480K, reserved 1056768K class space used 296K, capacity 384K, committed 384K, reserved 1048576KHeap after GC invocations=1 (full 0): PSYoungGen total 2560K, used 504K [0x00000000ffd00000, 0x0000000100000000, 0x0000000100000000) eden space 2048K, 0% used [0x00000000ffd00000,0x00000000ffd00000,0x00000000fff00000) from space 512K, 98% used [0x00000000fff00000,0x00000000fff7e030,0x00000000fff80000) to space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000) ParOldGen total 7168K, used 435K [0x00000000ff600000, 0x00000000ffd00000, 0x00000000ffd00000) object space 7168K, 6% used [0x00000000ff600000,0x00000000ff66ccc0,0x00000000ffd00000) Metaspace used 2753K, capacity 4480K, committed 4480K, reserved 1056768K class space used 296K, capacity 384K, committed 384K, reserved 1048576K&#125;&#123;Heap before GC invocations=2 (full 0): PSYoungGen total 2560K, used 2552K [0x00000000ffd00000, 0x0000000100000000, 0x0000000100000000) eden space 2048K, 100% used [0x00000000ffd00000,0x00000000fff00000,0x00000000fff00000) from space 512K, 98% used [0x00000000fff00000,0x00000000fff7e030,0x00000000fff80000) to space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000) ParOldGen total 7168K, used 435K [0x00000000ff600000, 0x00000000ffd00000, 0x00000000ffd00000) object space 7168K, 6% used [0x00000000ff600000,0x00000000ff66ccc0,0x00000000ffd00000) Metaspace used 2970K, capacity 4490K, committed 4864K, reserved 1056768K class space used 319K, capacity 386K, committed 512K, reserved 1048576KHeap after GC invocations=2 (full 0): PSYoungGen total 2560K, used 488K [0x00000000ffd00000, 0x0000000100000000, 0x0000000100000000) eden space 2048K, 0% used [0x00000000ffd00000,0x00000000ffd00000,0x00000000fff00000) from space 512K, 95% used [0x00000000fff80000,0x00000000ffffa020,0x0000000100000000) to space 512K, 0% used [0x00000000fff00000,0x00000000fff00000,0x00000000fff80000) ParOldGen total 7168K, used 570K [0x00000000ff600000, 0x00000000ffd00000, 0x00000000ffd00000) object space 7168K, 7% used [0x00000000ff600000,0x00000000ff68e880,0x00000000ffd00000) Metaspace used 2970K, capacity 4490K, committed 4864K, reserved 1056768K class space used 319K, capacity 386K, committed 512K, reserved 1048576K&#125; 一共就GC了俩次, 为什么结果是这样的呢？我们使用javap分析一下(限于篇幅, 我们只看最关键的部分). 首先看TestCombine1反编译之后的源码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061javap -v TestCombine1...Constant pool: #1 = Methodref #13.#33 // java/lang/Object.&quot;&lt;init&gt;&quot;:()V #2 = Integer 100000 #3 = Class #34 // java/lang/StringBuilder #4 = Methodref #3.#33 // java/lang/StringBuilder.&quot;&lt;init&gt;&quot;:()V #5 = String #35 // string #6 = Methodref #3.#36 // java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; #7 = Fieldref #12.#37 // testString/TestCombine1.str1:Ljava/lang/String; #8 = Methodref #3.#38 // java/lang/StringBuilder.toString:()Ljava/lang/String; #9 = Class #39 // java/lang/String #10 = String #40 // 123456789123456789123456789123456789123456789123456789123456789123456789123456789123456789 #11 = Methodref #9.#41 // java/lang/String.&quot;&lt;init&gt;&quot;:(Ljava/lang/String;)V #12 = Class #42 // testString/TestCombine1 #13 = Class #43 // java/lang/Object #14 = Utf8 str1 #15 = Utf8 Ljava/lang/String;... #33 = NameAndType #16:#17 // &quot;&lt;init&gt;&quot;:()V #34 = Utf8 java/lang/StringBuilder #35 = Utf8 string #36 = NameAndType #44:#45 // append:(Ljava/lang/String;)Ljava/lang/StringBuilder; #37 = NameAndType #14:#15 // str1:Ljava/lang/String; #38 = NameAndType #46:#47 // toString:()Ljava/lang/String; #39 = Utf8 java/lang/String #40 = Utf8 123456789123456789123456789123456789123456789123456789123456789123456789123456789123456789 #41 = NameAndType #16:#48 // &quot;&lt;init&gt;&quot;:(Ljava/lang/String;)V #42 = Utf8 testString/TestCombine1 #43 = Utf8 java/lang/Object #44 = Utf8 append #45 = Utf8 (Ljava/lang/String;)Ljava/lang/StringBuilder; #46 = Utf8 toString #47 = Utf8 ()Ljava/lang/String; #48 = Utf8 (Ljava/lang/String;)V&#123;... public static void main(java.lang.String[]); descriptor: ([Ljava/lang/String;)V flags: ACC_PUBLIC, ACC_STATIC Code: stack=2, locals=3, args_size=1 0: iconst_0 1: istore_1 2: iload_1 3: ldc #2 // int 100000 5: if_icmpge 36 8: new #3 // class java/lang/StringBuilder 11: dup 12: invokespecial #4 // Method java/lang/StringBuilder.&quot;&lt;init&gt;&quot;:()V 15: ldc #5 // String string 17: invokevirtual #6 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 20: getstatic #7 // Field str1:Ljava/lang/String; 23: invokevirtual #6 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 26: invokevirtual #8 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 29: astore_2 30: iinc 1, 1 33: goto 2 36: return...SourceFile: &quot;TestCombine1.java&quot; 通过看main方法, 我们可以看出, 是将&quot;string&quot;字符串常量和 str1这个静态常量通过StringBuilder进行拼接得到的string1. 所以不断产生StringBuilder对象,就不断地进行GC了 然后看TestCombine2反编译之后的源码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859ζ javap -v TestCombine2...Constant pool: #1 = Methodref #11.#30 // java/lang/Object.&quot;&lt;init&gt;&quot;:()V #2 = Integer 100000 #3 = Class #31 // java/lang/StringBuilder #4 = Methodref #3.#30 // java/lang/StringBuilder.&quot;&lt;init&gt;&quot;:()V #5 = String #32 // string #6 = Methodref #3.#33 // java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; #7 = Methodref #10.#34 // testString/TestCombine2.getFieldConstant:()Ljava/lang/String; #8 = Methodref #3.#35 // java/lang/StringBuilder.toString:()Ljava/lang/String; #9 = String #36 // 123456789123456789123456789123456789123456789123456789123456789123456789123456789123456789 #10 = Class #37 // testString/TestCombine2 #11 = Class #38 // java/lang/Object #12 = Utf8 &lt;init&gt; #13 = Utf8 ()V... #26 = Utf8 getFieldConstant #27 = Utf8 ()Ljava/lang/String; #28 = Utf8 SourceFile #29 = Utf8 TestCombine2.java #30 = NameAndType #12:#13 // &quot;&lt;init&gt;&quot;:()V #31 = Utf8 java/lang/StringBuilder #32 = Utf8 string #33 = NameAndType #39:#40 // append:(Ljava/lang/String;)Ljava/lang/StringBuilder; #34 = NameAndType #26:#27 // getFieldConstant:()Ljava/lang/String; #35 = NameAndType #41:#27 // toString:()Ljava/lang/String; #36 = Utf8 123456789123456789123456789123456789123456789123456789123456789123456789123456789123456789 #37 = Utf8 testString/TestCombine2 #38 = Utf8 java/lang/Object #39 = Utf8 append #40 = Utf8 (Ljava/lang/String;)Ljava/lang/StringBuilder; #41 = Utf8 toString&#123;... public static void main(java.lang.String[]); descriptor: ([Ljava/lang/String;)V flags: ACC_PUBLIC, ACC_STATIC Code: stack=2, locals=3, args_size=1 0: iconst_0 1: istore_1 2: iload_1 3: ldc #2 // int 100000 5: if_icmpge 36 8: new #3 // class java/lang/StringBuilder 11: dup 12: invokespecial #4 // Method java/lang/StringBuilder.&quot;&lt;init&gt;&quot;:()V 15: ldc #5 // String string 17: invokevirtual #6 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 20: invokestatic #7 // Method getFieldConstant:()Ljava/lang/String; 23: invokevirtual #6 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 26: invokevirtual #8 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 29: astore_2 30: iinc 1, 1 33: goto 2 36: return...SourceFile: &quot;TestCombine2.java&quot; 和TestCombine1类似, 在mian方法中， 也是使用StringBuilder进行拼接处理的 最后看下TestCombine3反编译之后的源码 1234567891011121314151617181920212223242526272829303132333435363738ζ javap -v TestCombine3...Constant pool: #1 = Methodref #5.#26 // java/lang/Object.&quot;&lt;init&gt;&quot;:()V #2 = Integer 1000000 #3 = Class #27 // testString/TestCombine3 #4 = String #28 // string123456789123456789123456789123456789123456789123456789123456789123456789123456789123456789 #5 = Class #29 // java/lang/Object #6 = Utf8 str2 #7 = Utf8 Ljava/lang/String; #8 = Utf8 ConstantValue #9 = String #30 // 123456789123456789123456789123456789123456789123456789123456789123456789123456789123456789... #26 = NameAndType #10:#11 // &quot;&lt;init&gt;&quot;:()V #27 = Utf8 testString/TestCombine3 #28 = Utf8 string123456789123456789123456789123456789123456789123456789123456789123456789123456789123456789 #29 = Utf8 java/lang/Object #30 = Utf8 123456789123456789123456789123456789123456789123456789123456789123456789123456789123456789&#123;... public static void main(java.lang.String[]); descriptor: ([Ljava/lang/String;)V flags: ACC_PUBLIC, ACC_STATIC Code: stack=2, locals=3, args_size=1 0: iconst_0 1: istore_1 2: iload_1 3: ldc #2 // int 1000000 5: if_icmpge 17 8: ldc #4 // String string123456789123456789123456789123456789123456789123456789123456789123456789123456789123456789 10: astore_2 11: iinc 1, 1 14: goto 2 17: return...&#125;SourceFile: &quot;TestCombine3.java&quot; 我们看 #4 = String #28 // string123456789123456789123456789123456789123456789123456789123456789123456789123456789123456789这一行, Java编译器已经将String string2 = &quot;string&quot; + str2;这俩个字符串字面量常量优化成了一个字符串字面量常量. 从上面的分析中我们可以得到, 在Java编译器进行优化的话, 只有当字符串字面量进行拼接的时候, 才会对其进行优化.","categories":[{"name":"Java","slug":"Java","permalink":"https://wangmingco.github.io/categories/Java/"}],"tags":[]},{"title":"wait sleep 不同","slug":"JavaSE/并发 wait sleep","date":"2016-09-22T16:00:00.000Z","updated":"2021-11-18T02:38:28.136Z","comments":true,"path":"2016/09/23/JavaSE/并发 wait sleep/","link":"","permalink":"https://wangmingco.github.io/2016/09/23/JavaSE/%E5%B9%B6%E5%8F%91%20wait%20sleep/","excerpt":"","text":"wait和sleep都可以停止线程的运行,但是这俩点有什么不一样呢？当在加锁的代码中 wait 会释放锁 sleep 不会释放锁 当进入wait或者sleep之后,线程退出CPU占用, 操作系统都不会再给这个线程分配时间片 先看wait的例子 1234567891011121314151617181920212223public class TestLock &#123; private static final Object lock = new Object(); public static void main(String[] args) &#123; ThreadUtil.printThreadState(&quot;thread1&quot;, &quot;thread2&quot;); Runnable runnable = () -&gt; &#123; synchronized (lock) &#123; System.out.println(Thread.currentThread().getName() + &quot; Sleep&quot;); try &#123; lock.wait(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + &quot; Sleep Finshed&quot;); &#125; &#125;; Thread thread1 = new Thread(runnable, &quot;thread1&quot;); Thread thread2 = new Thread(runnable, &quot;thread2&quot;); thread1.start(); thread2.start(); &#125;&#125; 结果为 12345678thread1 Sleepthread2 Sleep2016-09-23T15:15:31.629 thread2 -&gt; TIMED_WAITING2016-09-23T15:15:31.630 thread1 -&gt; TIMED_WAITING2016-09-23T15:15:32.529 thread2 -&gt; TIMED_WAITING2016-09-23T15:15:32.529 thread1 -&gt; TIMED_WAITINGthread1 Sleep Finshedthread2 Sleep Finshed 我们看到当线程1 wait之后,线程2也进入了锁中 然后我们将lock.wait(3000);改为TimeUnit.SECONDS.sleep(3); 1234567891011121314151617181920212223242526import java.util.concurrent.TimeUnit;public class TestLock &#123; private static final Object lock = new Object(); public static void main(String[] args) &#123; ThreadUtil.printThreadState(&quot;thread1&quot;, &quot;thread2&quot;); Runnable runnable = () -&gt; &#123; synchronized (lock) &#123; System.out.println(Thread.currentThread().getName() + &quot; Sleep&quot;); try &#123; TimeUnit.SECONDS.sleep(3); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + &quot; Sleep Finshed&quot;); &#125; &#125;; Thread thread1 = new Thread(runnable, &quot;thread1&quot;); Thread thread2 = new Thread(runnable, &quot;thread2&quot;); thread1.start(); thread2.start(); &#125;&#125; 结果为 12345678910111213thread1 Sleep2016-09-23T15:17:52.488 thread2 -&gt; BLOCKED2016-09-23T15:17:52.488 thread1 -&gt; TIMED_WAITING2016-09-23T15:17:53.462 thread2 -&gt; BLOCKED2016-09-23T15:17:53.462 thread1 -&gt; TIMED_WAITING2016-09-23T15:17:54.463 thread2 -&gt; BLOCKED2016-09-23T15:17:54.463 thread1 -&gt; TIMED_WAITINGthread1 Sleep Finshedthread2 Sleep2016-09-23T15:17:55.464 thread2 -&gt; TIMED_WAITING2016-09-23T15:17:56.465 thread2 -&gt; TIMED_WAITING2016-09-23T15:17:57.466 thread2 -&gt; TIMED_WAITINGthread2 Sleep Finshed 我们看到只有当线程1执行完之后线程才继续执行 在上面的例子中用到的输出线程状态信息的工具类 1234567891011121314151617181920212223import java.time.LocalDateTime;public class ThreadUtil &#123; public static void printThreadState(String... filter) &#123; Thread print = new Thread(() -&gt; &#123; long now = System.currentTimeMillis(); while (true) &#123; if (System.currentTimeMillis() - now &gt; 1000) &#123; now = System.currentTimeMillis(); Thread.getAllStackTraces().forEach((key, thread) -&gt; &#123; for (int i = 0; i &lt; filter.length; i++) &#123; if (key.getName().equals(filter[i])) &#123; System.out.println(LocalDateTime.now() + &quot; &quot; +key.getName() + &quot; -&gt; &quot; + key.getState()); &#125; &#125; &#125;); &#125; &#125; &#125;, &quot;Print&quot;); print.start(); &#125;&#125; 线程中断Java 提供了中断机制,可以使用中断来结束一个线程.(使用中断来结束一个线程,要求线程检查它是否被中断了,然后决定是否响应这个中断请求. 线程允许忽略中断并继续执行(将if语句注掉就可忽略中断请求)) 12345678910111213141516171819202122232425import java.util.concurrent.TimeUnit;public class Main &#123; public static void main(String[] args) &#123; Thread thread = new Thread(() -&gt; &#123; while(true) &#123; if (Thread.interrupted()) &#123; System.out.println(&quot;interrupt &quot; + System.currentTimeMillis()); break; &#125; &#125; &#125;); thread.start(); try &#123; TimeUnit.SECONDS.sleep(5); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;Begin interrupt&quot;); thread.interrupt(); &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://wangmingco.github.io/categories/Java/"}],"tags":[]},{"title":"Java ThreadPoolExecutor","slug":"JavaSE/并发 ThreadPoolExecutor","date":"2016-09-18T16:00:00.000Z","updated":"2021-11-18T02:39:38.968Z","comments":true,"path":"2016/09/19/JavaSE/并发 ThreadPoolExecutor/","link":"","permalink":"https://wangmingco.github.io/2016/09/19/JavaSE/%E5%B9%B6%E5%8F%91%20ThreadPoolExecutor/","excerpt":"","text":"一直受困于ThreadPoolExecutor的内部实现, 今天就拿出点时间解决几点自己的疑问 ThreadPoolExecutor是如何重复利用线程资源的 ThreadPoolExecutor reject 策略 线程资源管理首先拿出一段运行代码 123456public class TestPool &#123; public static void main(String[] args) &#123; ExecutorService pool = Executors.newFixedThreadPool(5); pool.execute(() -&gt; System.out.println(&quot;task is running&quot;)); &#125;&#125; 我们从构造函数入手 123456789101112131415161718192021222324252627public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;&#125; 我们看到了在构造函数中, 只是进行了初始化的操作, 并没有运行任何逻辑代码, 那么下来我们从execute(Runnable )这个方法入手 12345678910111213141516171819202122232425262728293031323334353637public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); /* * 分三步执行 * 1. 现在的线程池的线程数量小于corePoolSize值, 则创建一个新的线程, 用新的线程执行command. * 在调用addWorker()时会自动检测runState和workerCount, 如果发现添加失败的话, 会返回false. * 2. 如果能将command成功地加入到任务队列里, 在接下来的执行中无论是否新建工作线程都要进行对线程池状态 * 进行Double check, 因为 existing ones died since last checking 或者线程池恰巧在这时关闭了. * So we recheck state and if necessary roll back the enqueuing if stopped, or start a new thread if there are none. * 3. 如果不能将command入列到任务队列的话,就尝试启动一个新的线程来运行它. 如果仍然失败就需要reject任务了. */ int c = ctl.get(); // 第一步 ： // 计算线程池中运行的线程数量, 如果当前运行的线程数量小于corePoolSize, 就增加一个worker. if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; // 因为在addWorker时会改变ctl的值, 因此重新获取一下 c = ctl.get(); &#125; // 第二步: // 工作线程已经达到corePoolSize数量或者添加worker失败, 将command加入到任务队列里面去 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); // 如果线程池不再处于运行状态且能成功从任务队列里将删除删除掉, 就reject任务 if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); // 如果worker数量为0的话，就新建一个worker, 执行刚刚添加到任务队列里的任务 else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; // 第三步: // 如果任务队列已经满了, 则尝试新建一个worker用来执行command else if (!addWorker(command, false)) reject(command); &#125; 这个方法的重点一个是addWorker()它会启动一个新的线程, 如果指定了first task(addWorker(command, true)), 那么新的worker线程就从first task开始执行.如果没有指定的话(addWorker(null, false)), 就从任务队列里取出任务依次执行. 另一个重点是workQueue.offer(command)通过这个方法向任务队列里添加任务, 然后在Worker的runWorker()里依次执行任务. 下来我们看一下addWorker()方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172private boolean addWorker(Runnable firstTask, boolean core) &#123; // 下面整个循环都是为了 改变ctl中工作线程worker的数量. retry: for (;;) &#123; int c = ctl.get(); // 计算线程池状态. int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty()) ) // 当线程池处于非运行状态, return false; // 开始增加ctl中的线程数量 for (;;) &#123; int wc = workerCountOf(c); if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl // 如果线程池的状态发生了改变则继续执行retry循环, 进行Check if queue empty only if necessary 检测. // 没有线程池状态没有发生变化的话, 则继续执行ctl数量增加操作 if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; // ok,到现在ctl中的worker数量已经改变完成, 开始真正的创建worker boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; w = new Worker(firstTask); final Thread t = w.thread; if (t != null) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int rs = runStateOf(ctl.get()); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); workers.add(w); int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; if (workerAdded) &#123; t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) addWorkerFailed(w); &#125; return workerStarted; &#125; 根据线程池的当前状态和指定的bound 检查新的worker能否添加.如果新的worker能被添加的话, 就会创建出一个新的worker, 同时增加worker count的数量。然后在这个新的worker运行firstTask 如果线程池是停止状态或者准备停止的话, 这个方法会返回一个false.如果ThreadFactory创建线程失败的话,也会返回一个false.当创建线程失败时,不管是ThreadFactory返回null还是产生错误(一般是在Thread.start()时抛出OutOfMemoryError), 我们将执行回滚操作 当新创建一个线程时, firstTask会成为它第一个执行的任务。当线程池线程数量小于corePoolSize或者队列满的时候, 创建出的worker内部会自动创建一个first task ，忽略掉从任务队列中出列的任务. 我们需要着重看一下t.start();方法, 这个方法是开始运行Worker对象里的thread线程对象(其本身也是Worker类型). 最终也是执行到Worker的runWorker()方法. 12345678910111213141516171819202122232425262728293031323334353637final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try &#123; // 如果first task不为空的话就先执行first task, 否则就从任务队列中取出task执行 while (task != null || (task = getTask()) != null) &#123; w.lock(); // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; beforeExecute(wt, task); Throwable thrown = null; try &#123; task.run(); &#125; catch (RuntimeException x) &#123; &#125; finally &#123; afterExecute(task, thrown); &#125; &#125; finally &#123; task = null; w.completedTasks++; w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; processWorkerExit(w, completedAbruptly); &#125; &#125; 看到这里我们可以看出, ThreadPoolExecutor其内部也是通过while来不断轮训任务队列, 执行任务的task.run();方法, 不开启新线程的方式, 来达到线程资源管理的目的. 那么任务执行完之后, 线程就被干掉了吗? 我们重点看processWorkerExit(w, completedAbruptly);这个方法 1234567891011121314151617181920212223242526272829private void processWorkerExit(Worker w, boolean completedAbruptly) &#123; if (completedAbruptly) // If abrupt, then workerCount wasn&#x27;t adjusted decrementWorkerCount(); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; completedTaskCount += w.completedTasks; // 将刚刚干完活的线程从worker队列中干掉 workers.remove(w); &#125; finally &#123; mainLock.unlock(); &#125; tryTerminate(); int c = ctl.get(); if (runStateLessThan(c, STOP)) &#123; // 如果线程池还能执行任务队列里的任务(Runnable, SHUTDOWN状态),就继续执行任务 if (!completedAbruptly) &#123; int min = allowCoreThreadTimeOut ? 0 : corePoolSize; if (min == 0 &amp;&amp; ! workQueue.isEmpty()) min = 1; if (workerCountOf(c) &gt;= min) return; // replacement not needed &#125; addWorker(null, false); &#125; &#125; 线程池状态从上面的分析, 我们看到了很多这种代码 12workerCountOf(c)isRunning(c) 看到这里可能会有很多疑问, 贴一下ThreadPoolExecutor部分内部成员 123456789101112131415private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); private static final int COUNT_BITS = Integer.SIZE - 3; private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1; // runState is stored in the high-order bits private static final int RUNNING = -1 &lt;&lt; COUNT_BITS; private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS; private static final int STOP = 1 &lt;&lt; COUNT_BITS; private static final int TIDYING = 2 &lt;&lt; COUNT_BITS; private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; // Packing and unpacking ctl private static int runStateOf(int c) &#123; return c &amp; ~CAPACITY; &#125; private static int workerCountOf(int c) &#123; return c &amp; CAPACITY; &#125; private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125; ctl 内部封装了俩个关键性的字段 workerCount, 工作的线程数 runState, 线程池状态为了将这俩个值都存储进ctl里，workerCount的最大值是500万左右((1 &lt;&lt; (Integer.SIZE - 3)) - 1),而不是2亿(queue的最大值是Integer的最大值)。 如果将来需要更高的任务量的话,可以采用AtomLong作为ctl的类型，但是现在采用int可以带来更快的运行速度和更简单 下面的几个值表示了整个线程池的运行状态 RUNNING: Accept new tasks and process queued tasks SHUTDOWN: Don’t accept new tasks, but process queued tasks STOP: Don’t accept new tasks, don’t process queued tasks, and interrupt in-progress tasks TIDYING: All tasks have terminated, workerCount is zero, the thread transitioning to state TIDYING will run the terminated() hook method TERMINATED: terminated() has completed 随着线程池运行, 上面几个状态是依次递增的, 但是在整个线程池生命周期中不一定会达到每个状态.线程池的状态转换过程如下: RUNNING -&gt; SHUTDOWN On invocation of shutdown(), perhaps implicitly in finalize() (RUNNING or SHUTDOWN) -&gt; STOP On invocation of shutdownNow() SHUTDOWN -&gt; TIDYING When both queue and pool are empty STOP -&gt; TIDYING When pool is empty TIDYING -&gt; TERMINATED When the terminated() hook method has completed","categories":[{"name":"Java","slug":"Java","permalink":"https://wangmingco.github.io/categories/Java/"}],"tags":[]},{"title":"LinkedBlockingQueue","slug":"JavaSE/LinkedBlockingQueue","date":"2016-09-07T16:00:00.000Z","updated":"2021-11-18T02:43:25.181Z","comments":true,"path":"2016/09/08/JavaSE/LinkedBlockingQueue/","link":"","permalink":"https://wangmingco.github.io/2016/09/08/JavaSE/LinkedBlockingQueue/","excerpt":"","text":"LinkedBlockingQueue 是基于双锁队列算法(锁实现使用ReentrantLock)实现的阻塞式先进先出(FIFO)的链表式队列. 其默认的链表大小是Interger的最大值,也就是说只要内存hold住,可以在LinkedBlockingQueue入列2亿多个数据. 双锁指的是LinkedBlockingQueue内部使用了俩个ReentrantLock ReentrantLock takeLock : 用于操作队列头, 取出队头元素 12345678910111213141516171819202122232425262728293031323334 public E take() throws InterruptedException &#123; E x; int c = -1; final AtomicInteger count = this.count; final ReentrantLock takeLock = this.takeLock; takeLock.lockInterruptibly(); try &#123; while (count.get() == 0) &#123; notEmpty.await(); &#125; x = dequeue(); c = count.getAndDecrement(); if (c &gt; 1) notEmpty.signal(); &#125; finally &#123; takeLock.unlock(); &#125; // 由于count是先get后Decrement的, 因此现在的count &lt; capacity, 通知阻塞的线程可以添加数据了 if (c == capacity) signalNotFull(); return x; &#125;private E dequeue() &#123; // assert takeLock.isHeldByCurrentThread(); // assert head.item == null; Node&lt;E&gt; h = head; Node&lt;E&gt; first = h.next; h.next = h; // help GC head = first; E x = first.item; first.item = null; return x; &#125; ReentrantLock putLock : 用于操作队列尾, 向队尾添加元素 1234567891011121314151617181920212223242526272829 public void put(E e) throws InterruptedException &#123; if (e == null) throw new NullPointerException(); // Note: convention in all put/take/etc is to preset local var // holding count negative to indicate failure unless set. int c = -1; Node&lt;E&gt; node = new Node&lt;E&gt;(e); final ReentrantLock putLock = this.putLock; final AtomicInteger count = this.count; putLock.lockInterruptibly(); try &#123; while (count.get() == capacity) &#123; notFull.await(); &#125; enqueue(node); c = count.getAndIncrement(); if (c + 1 &lt; capacity) notFull.signal(); &#125; finally &#123; putLock.unlock(); &#125; if (c == 0) signalNotEmpty(); &#125; private void enqueue(Node&lt;E&gt; node) &#123; // assert putLock.isHeldByCurrentThread(); // assert last.next == null; last = last.next = node; &#125; 通过双锁分别操作队列头和队列尾就实现了了一个高效地读写分离的并发安全链表队列 刚才我们只是从宏观上看了一下LinkedBlockingQueue. 下面我们从细节上分析一下. LinkedBlockingQueue有俩个入列方式, 分别是put和offer, 在上面中我们看到了put的实现. 它内部使用了一个notEmpty的Condition, 使用这个是为了当队列已经满了的时候, 就将添加元素的线程阻塞住。接着我们看一下take()方法, 它的最后有一个signalNotFull(), 就是由它来通知阻塞线程来添加数据的. 而offer()实现就没有阻塞行为 1234567891011121314151617181920212223public boolean offer(E e) &#123; if (e == null) throw new NullPointerException(); final AtomicInteger count = this.count; if (count.get() == capacity) return false; int c = -1; Node&lt;E&gt; node = new Node&lt;E&gt;(e); final ReentrantLock putLock = this.putLock; putLock.lock(); try &#123; if (count.get() &lt; capacity) &#123; enqueue(node); c = count.getAndIncrement(); if (c + 1 &lt; capacity) notFull.signal(); &#125; &#125; finally &#123; putLock.unlock(); &#125; if (c == 0) signalNotEmpty(); return c &gt;= 0;&#125; 在offer()实现中,如果添加成功就返回true, 添加失败(没有进行添加操作)就返回false, 它并不会阻塞住调用者. 看完入列, 我们再看一下出列操作. 刚开始给出的一段代码就是一段出列代码take()方法. take()方法内部也使用了一个名为notEmpty的Condition, 如果当前队列为空的话, 就一直阻塞住进行出列操作的线程, 由put()的signalNotEmpty()来通知当前阻塞的线程可以出列操作了(但是为什么要判断为0呢？？想不明白). 大概琢磨一下就能理清LinkedBlockingQueue的工作流程. 但是仍然遗留了俩个比较大的疑问. LinkedBlockingQueue的内部链表是由双锁保证线程安全的,那么当俩个线程分别操作队列头和队列尾的时候,如果恰巧是同一个元素,会不会发生问题 是如何保证LinkedBlockingQueue的内部计数器count(AtomicInteger)的线程安全的? 对于第一个问题, 我画了一张入列和出列的流程图:从图中我们可以看到, 在初始化LinkedBlockingQueue实例的时候,其内部就有了一个Node, first和last都指向这个Node. 当入列一个元素的时候,last指针后移, 而first指针位置不变(参考enqueue(Node&lt;E&gt; node)和dequeue()方法)。其实这个时候实际的第一个Node为A, 而在逻辑上来讲第一个Node为B(因为第一个数据是存储在了B里), 出列的时候, 是删除队列的第一个实际位置(A)的Node,取出的是第二个实际位置(B)的数据,此时第三个实际位置就变成了第一个逻辑位置. 对于第二个问题,在put()方法中是这么描述的 12345678/* * Note that count is used in wait guard even though it is * not protected by lock. This works because count can * only decrease at this point (all other puts are shut * out by lock), and we (or some other waiting put) are * signalled if it ever changes from capacity. Similarly * for all other uses of count in other wait guards. */ 在入列的操作中count只会增加, 在出列的过程中count只会减少. 而入列只是向上做边界检查, 出列只是向下做边界检查, 因此只要保证了count是原子的, 哪怕出现了数据不一致的情况也不会出现队列的大小超过最大值或者小于0的情况.","categories":[{"name":"Java","slug":"Java","permalink":"https://wangmingco.github.io/categories/Java/"}],"tags":[]},{"title":"HotSpot Dynamic Attach Mechanism 简析","slug":"jvm/Attatch API","date":"2016-08-28T16:00:00.000Z","updated":"2021-11-18T02:43:26.782Z","comments":true,"path":"2016/08/29/jvm/Attatch API/","link":"","permalink":"https://wangmingco.github.io/2016/08/29/jvm/Attatch%20API/","excerpt":"","text":"在 在VirtualMachine javadoc中给了我们一个示范用例 12345678910111213141516// attach to target VMVirtualMachine vm = VirtualMachine.attach(&quot;2177&quot;);// get system properties in target VMProperties props = vm.getSystemProperties();// construct path to management agentString home = props.getProperty(&quot;java.home&quot;);String agent = home + File.separator + &quot;lib&quot; + File.separator + &quot;management-agent.jar&quot;;// load agent into target VMvm.loadAgent(agent, &quot;com.sun.management.jmxremote.port=5000&quot;);// detachvm.detach(); 如果要引用 在VirtualMachine的话, 我们需要在classpath上添加tools.jar文件。注意在Windows和Linux上的tools.jar文件实现是不同的, 需要在不同的平台上依赖不同的文件. Attach API 相关实现可以在openjdk中找到 VirtualMachine : openjdk\\jdk\\src\\share\\classes\\com\\sun\\tools\\attach AttachProvider : openjdk\\jdk\\src\\share\\classes\\com\\sun\\tools\\attach\\spi HotSpotAttachProvider : openjdk\\jdk\\src\\share\\classes\\sun\\tools\\attach HotSpotVirtualMachine : openjdk\\jdk\\src\\share\\classes\\sun\\tools\\attach LinuxVirtualMachine : openjdk\\jdk\\src\\solaris\\classes\\sun\\tools\\attach LinuxAttachProvider : openjdk\\jdk\\src\\solaris\\classes\\sun\\tools\\attach jvmstat : openjdk\\jdk\\src\\share\\classes\\sun\\jvmstat Attach API 主要就是依赖上面的几个文件实现的 从HotSpot Dynamic Attach Mechanism这篇介绍中我们可以看到Attach API的实现概要. HotSpot Dynamic Attach Mechanism这个工具是用于Attach到另一个运行Java代码的进程, 目标Java进程会开启一个JVM TI代理或者一个java.lang.instrument代理. 而Sun公司(Hotspot VM)对其还有一些额外的功能实现(HotSpotVirtualMachine中实现) dump堆内存 显示加载进目标虚拟机的class的实例数量. 可以选择是全部的实例数量还是仅仅显示存活下来的实例数量. 当JVM第一次收到attach请求的时候, 它会创建一个attach listener线程. 在不同的系统上, 请求的发送方式也不一样(参考LinuxVirtualMachine). 例如在Linux或者Solaris系统上, attach 客户端会创建一个.attach_pid(pid)文件, 然后向目标虚拟机发送一个SIGQUIT信号. 目标虚拟机会根据.attach_pid(pid)文件与否运行attach listener线程. 在Linux系统上客户端是通过socket与attach listener线程进行交互的. 当attach成功之后, 会在/tmp目录下生成一个.java_pid&lt;pid&gt;的文件生成. 这个文件的生成目录是不可修改的, 而且一旦文件生成之后, 不可以删掉再尝试重新生成. 我们看一下LinuxVirtualMachine 的attach 过程 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110LinuxVirtualMachine(AttachProvider provider, String vmid) throws AttachNotSupportedException, IOException &#123; super(provider, vmid); // This provider only understands pids int pid; try &#123; pid = Integer.parseInt(vmid); &#125; catch (NumberFormatException x) &#123; throw new AttachNotSupportedException(&quot;Invalid process identifier&quot;); &#125; // 尝试搜索 socket file. 如果找不到的话就向目标虚拟机发送QUIT信号, 让目标虚拟机开启 attach mechanism. // 然后继续尝试搜索 socket file. // target VM会创建这个文件, 这个是因为Unix domain socket本身的实现机制需要去创建一个文件, 通过这个文件来进行IPC // Find the socket file. If not found then we attempt to start the // attach mechanism in the target VM by sending it a QUIT signal. // Then we attempt to find the socket file again. path = findSocketFile(pid); if (path == null) &#123; // 创建 .attach_pid&lt;pid&gt; 文件, 触发Attach Listener线程的创建,因为SIGQUIT信号不是只有这里发送， // 通过这个文件来告诉target VM，有attach请求过来了。 File f = createAttachFile(pid); try &#123; // On LinuxThreads each thread is a process and we don&#x27;t have the // pid of the VMThread which has SIGQUIT unblocked. To workaround // this we get the pid of the &quot;manager thread&quot; that is created // by the first call to pthread_create. This is parent of all // threads (except the initial thread). if (isLinuxThreads) &#123; int mpid; try &#123; mpid = getLinuxThreadsManager(pid); &#125; catch (IOException x) &#123; throw new AttachNotSupportedException(x.getMessage()); &#125; assert(mpid &gt;= 1); sendQuitToChildrenOf(mpid); &#125; else &#123; sendQuitTo(pid); &#125; // 默认等待5秒钟, 等待目标虚拟机 attach mechanism 启动完成 // 启动完成之后会创建一个 .java_pid&lt;pid&gt; 文件, 该文件会赋值给 path 变量 // give the target VM time to start the attach mechanism int i = 0; long delay = 200; int retries = (int)(attachTimeout() / delay); do &#123; try &#123; Thread.sleep(delay); &#125; catch (InterruptedException x) &#123; &#125; path = findSocketFile(pid); i++; &#125; while (i &lt;= retries &amp;&amp; path == null); if (path == null) &#123; throw new AttachNotSupportedException( &quot;Unable to open socket file: target process not responding &quot; + &quot;or HotSpot VM not loaded&quot;); &#125; &#125; finally &#123; f.delete(); &#125; &#125; // Check that the file owner/permission to avoid attaching to // bogus process checkPermissions(path); // Check that we can connect to the process // - this ensures we throw the permission denied error now rather than // later when we attempt to enqueue a command. int s = socket(); try &#123; connect(s, path); &#125; finally &#123; close(s); &#125; &#125; // Return the socket file for the given process. private String findSocketFile(int pid) &#123; File f = new File(tmpdir, &quot;.java_pid&quot; + pid); if (!f.exists()) &#123; return null; &#125; return f.getPath(); &#125; // 在 Solaris/Linux 系统中开启 attach mechanism 的一个非常简单的方式是使用握手的方式. 通过在目标虚拟机的工作目录 // (或者tmp目录下) 创建一个.attach_pid&lt;pid&gt; 文件 , 然后目标虚拟机的 SIGQUIT 信号处理器通过不断地查询这个文件是否存在 // 来决定是否开启 attach mechanism . // // On Solaris/Linux a simple handshake is used to start the attach mechanism // if not already started. The client creates a .attach_pid&lt;pid&gt; file in the // target VM&#x27;s working directory (or temp directory), and the SIGQUIT handler // checks for the file. private File createAttachFile(int pid) throws IOException &#123; String fn = &quot;.attach_pid&quot; + pid; String path = &quot;/proc/&quot; + pid + &quot;/cwd/&quot; + fn; File f = new File(path); try &#123; f.createNewFile(); &#125; catch (IOException x) &#123; f = new File(tmpdir, fn); f.createNewFile(); &#125; return f; &#125; 从以上分析我们可以看出, Attach API 是客户端通过本地socket与目标jvm进行通信的, 具体的功能实现都是在目标JVM里实现的.","categories":[{"name":"JVM","slug":"JVM","permalink":"https://wangmingco.github.io/categories/JVM/"}],"tags":[]},{"title":"Java ClassPath 的秘密","slug":"JavaSE/Java ClassPath 的秘密","date":"2016-08-25T16:00:00.000Z","updated":"2021-11-18T02:39:42.550Z","comments":true,"path":"2016/08/26/JavaSE/Java ClassPath 的秘密/","link":"","permalink":"https://wangmingco.github.io/2016/08/26/JavaSE/Java%20ClassPath%20%E7%9A%84%E7%A7%98%E5%AF%86/","excerpt":"","text":"写了一段简单的测试代码 12345678import com.alibaba.fastjson.JSONObject;import java.util.concurrent.TimeUnit;public class Test &#123; public static void main(String[] args) throws InterruptedException &#123; JSONObject json = new JSONObject(); TimeUnit.HOURS.sleep(1); &#125;&#125; 然后分别执行 1234567891011121314151617181920212223242526272829303132333435[root@root wangming]# javac -cp ./* Test.javajavac: invalid flag: ./Test.classUsage: javac &lt;options&gt; &lt;source files&gt;use -help for a list of possible options[root@root wangming]# javac -cp . Test.javaTest.java:2: error: package com.alibaba.fastjson does not existimport com.alibaba.fastjson.JSONObject; ^Test.java:9: error: cannot find symbol JSONObject json = new JSONObject(); ^ symbol: class JSONObject location: class TestTest.java:9: error: cannot find symbol JSONObject json = new JSONObject(); ^ symbol: class JSONObject location: class Test3 errors[root@root wangming]# javac -cp .:./ Test.javaTest.java:2: error: package com.alibaba.fastjson does not existimport com.alibaba.fastjson.JSONObject; ^Test.java:9: error: cannot find symbol JSONObject json = new JSONObject(); ^ symbol: class JSONObject location: class TestTest.java:9: error: cannot find symbol JSONObject json = new JSONObject(); ^ symbol: class JSONObject location: class Test3 errors[root@root wangming]# javac -cp .:./* Test.java 在Setting the class path这篇文章中, 说classpath 可以是以下三种形式 jar包(.jar结尾的文件) 里面包含了class文件 zip包(.zip结尾的文件) 里面包含了class文件 目录(文件夹) 如果class文件里有package, 那么目录里一定要有和package相应的目录结构 如果一个classpath中包含了通配符(*), 那么Java就不会在这个目录下搜索class文件了. 例如lib/*, 如果classpath是这个, 那么classpath就只会在lib目录下搜索jar文件, 然后从jar文件中去加载class, 如果想要在lib目录下既搜索jar文件也搜索class文件的话, 那么可以写成lib:lib/*或者lib/*:lib. 还有一点很重要的是, 如果lib目录下有子目录的话lib/jetty的话, Java是不会进行递归搜索子目录的。 说到这里, Java为什么不会在lib/*下搜索class文件呢？是这样的, 如果lib目录下有a.jar和b.jar, 其实现在的lib/*就被替换成了lib/a.jar:lib/b.jar. 我们可以在Java的系统变量里看到这个结果. 看到这,我们应该就推断出上面错误的原因了, .只会搜索class文件但是不会搜索jar, 而*通配符则自动帮我换成了jar文件的classpath的替换. 安装上JDK后, 系统会自动设置一个CLASSPATH的环境变量(.:/home/jdk1.8/lib/dt.jar:/home/jdk1.8/lib/tools.jar), 但是当运行Java命令, 指定-cp的时候,会覆盖掉这个classpath, 所以在新的classpath上一定要指定. classpath适用于下列工具JDK Tools and Utilities How Classes are Found","categories":[{"name":"Java","slug":"Java","permalink":"https://wangmingco.github.io/categories/Java/"}],"tags":[]},{"title":"hsperfdata","slug":"jvm/hsperfdata","date":"2016-08-21T16:00:00.000Z","updated":"2021-11-18T02:41:45.938Z","comments":true,"path":"2016/08/22/jvm/hsperfdata/","link":"","permalink":"https://wangmingco.github.io/2016/08/22/jvm/hsperfdata/","excerpt":"","text":"Hotspot出于性能测试和排查问题的目的而提供了jvmstat 工具. 我们可以使用JVM参数-XX:+UsePerfData来决定是否开启这个功能. 因此jvm运行时会生成一个目录hsperfdata_$USER($USER是启动java进程的用户,在linux中默认是/tmp),目录下会有些java 进程的 pid文件. 文件内部存储的是jvmstat统计的jvm进程的相关信息. jvmstat源码参考openjdk\\jdk\\src\\share\\classes\\sun\\jvmstat 当我们将/tmp/hsperfdata目录下的某个进程文件删除之后, 相应的进程也就消失了, 经过测试即使Java进程里已经注册了钩子程序, 但是钩子程序也不会执行, 进程就直接消失了. 而且进程消失之后, 这个文件也就没有了. PerfData 相关的JVM选项 -XX:+UsePerfData 用于设置是否开启统计.(默认值为true, 开启) -XX:+PerfDataSaveToFile 在系统退出时是否将PerfData 内存数据保存到hsperfdata_ 文件(默认为false, 不开启). 注意这个数据是保存到Java进程当前的工作目录, 而不是/tmp下 PerfDataSamplingInterval 统计采样间隔(单位毫秒, 默认是50毫秒) PerfDisableSharedMem 是否将标准内存的性能数据进行存储(默认为false, 不存储) PerfDataMemorySize 性能统计数据可存储大小. 总是对操作系统内存页的大小进行取整(默认是32k)。 因为在内存中保存的是32k的数据, 因此存储到文件之后, 文件的大小也固定在32k. 我们可以使用jdk提供的一些工具来读取这个目录下的JVM进程信息统计文件, 例如 jstat读取/tmp/hsperfdata_username/目录下的文件查看虚拟机老年代的情况 123[root@root wangming]# jstat -gcold file:///tmp/hsperfdata_username/2332 MC MU CCSC CCSU OC OU YGC FGC FGCT GCT 26112.0 25379.2 3840.0 3719.1 164864.0 18007.6 495 1 0.102 2.377 HotSpot Jvmstat Performance Counters","categories":[{"name":"JVM","slug":"JVM","permalink":"https://wangmingco.github.io/categories/JVM/"}],"tags":[]},{"title":"当Jedis 遇上 Lambda","slug":"JavaLibrary/jedis lambda","date":"2016-07-28T16:00:00.000Z","updated":"2021-11-18T02:47:28.936Z","comments":true,"path":"2016/07/29/JavaLibrary/jedis lambda/","link":"","permalink":"https://wangmingco.github.io/2016/07/29/JavaLibrary/jedis%20lambda/","excerpt":"","text":"一直苦恼于使用Jedis时要时时牢记关闭资源这个操作, 当Lambda出现后, 这种苦恼终于可以远离而去了 1234567891011121314151617181920212223242526272829303132333435import redis.clients.jedis.Jedis;import redis.clients.jedis.JedisPool;import redis.clients.jedis.JedisPoolConfig;public class Medis &#123; private final JedisPool jedisPool; public Medis() &#123; JedisPoolConfig config = new JedisPoolConfig(); jedisPool = new JedisPool(config, &quot;192.168.15.20&quot;, 6379, 10000, &quot;xpec@2015&quot;); &#125; public void consumer(NonResultOperator consumer) &#123; try(Jedis jedis = jedisPool.getResource()) &#123; consumer.accept(jedis); &#125; &#125; public &lt;U&gt; U accept(ResultOperator consumer) &#123; try(Jedis jedis = jedisPool.getResource()) &#123; return (U) consumer.accept(jedis); &#125; &#125;&#125;@FunctionalInterfaceinterface ResultOperator &#123; Object accept(redis.clients.jedis.Jedis t);&#125;@FunctionalInterfaceinterface NonResultOperator &#123; void accept(redis.clients.jedis.Jedis t);&#125; 写一个测试类 1234567891011public class MedisTest &#123; @Test public void test() &#123; Medis medis = new Medis(); medis.consumer(jedis -&gt; jedis.set(&quot;123&quot;, &quot;456&quot;)); String result = medis.accept(jedis -&gt; jedis.get(&quot;123&quot;)); System.out.println(result); &#125;&#125; 结果为 1456","categories":[{"name":"Jedis","slug":"Jedis","permalink":"https://wangmingco.github.io/categories/Jedis/"}],"tags":[]},{"title":"Jetty 嵌入模式","slug":"JavaLibrary/Jetty","date":"2016-07-24T16:00:00.000Z","updated":"2021-11-18T02:47:53.169Z","comments":true,"path":"2016/07/25/JavaLibrary/Jetty/","link":"","permalink":"https://wangmingco.github.io/2016/07/25/JavaLibrary/Jetty/","excerpt":"","text":"添加依赖 123456&lt;!-- https://mvnrepository.com/artifact/org.eclipse.jetty/jetty-server --&gt;&lt;dependency&gt; &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt; &lt;artifactId&gt;jetty-server&lt;/artifactId&gt; &lt;version&gt;9.4.0.M0&lt;/version&gt;&lt;/dependency&gt; HandlerCollection ：维持一个handlers 集合, 然后按顺序依次调用每个handler(注意这个里的handler不管发生什么情况都会执行一遍, 这通常可以作为一个切面用于统计和记日志). HandlerList：同样维持一个handlers 集合,也是按顺序调用每个handler.但是当有异常抛出, 或者有response返回, 或者 request.isHandled()被设为true. HandlerWrapper：继承自HandlerWrapper的类可以以面向切面编程的方式将handler通过链式的形式组合在一起.例如一个标准的web应用程序就实现了一个这样的规则, 他将context,session,security,servlet的handler以链式的方式组合在一起. 文件服务器通过ResourceHandler 指定了资源路径，并且允许列出目录和文件. 下面的例子中就是直接将ResourceHandler映射到根目录/下, 即通过http://localhost:8080/就可以在浏览器上看到所有的文件列表 1234567891011121314151617181920212223242526272829303132333435363738import org.eclipse.jetty.server.Server;import org.eclipse.jetty.server.handler.ContextHandler;import org.eclipse.jetty.server.handler.HandlerList;import org.eclipse.jetty.server.handler.ResourceHandler;import org.eclipse.jetty.server.handler.gzip.GzipHandler;public class Main &#123; public static void main(String[] args) throws Exception &#123; Server server = new Server(8080); ResourceHandler fileResourceHandler = new ResourceHandler(); fileResourceHandler.setDirectoriesListed(true); fileResourceHandler.setResourceBase(&quot;D:\\\\repository&quot;); GzipHandler gzip = new GzipHandler(); server.setHandler(gzip); ContextHandler fileContext = new ContextHandler(&quot;/files&quot;); fileContext.setHandler(fileResourceHandler); ResourceHandler indexResourceHandler = new ResourceHandler(); indexResourceHandler.setDirectoriesListed(true); indexResourceHandler.setWelcomeFiles(new String[]&#123;&quot;index.html&quot;&#125;); indexResourceHandler.setResourceBase(&quot;.&quot;); ContextHandler indexContextHandler = new ContextHandler(&quot;/&quot;); indexContextHandler.setHandler(indexResourceHandler); HandlerList handlerList = new HandlerList(); handlerList.addHandler(fileContext); handlerList.addHandler(indexContextHandler); server.setHandler(handlerList); server.start(); server.join(); &#125;&#125; 还可以使用ContextHandler将ResourceHandler映射到其他路径上. ContextHandlerContextHandler实现自ScopedHandler. ContextHandler实现的功能是将Http请求路径映射到某个具体处理业务逻辑的Handler上. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859import org.eclipse.jetty.server.Handler;import org.eclipse.jetty.server.Request;import org.eclipse.jetty.server.Server;import org.eclipse.jetty.server.handler.AbstractHandler;import org.eclipse.jetty.server.handler.ContextHandler;import org.eclipse.jetty.server.handler.ContextHandlerCollection;import javax.servlet.ServletException;import javax.servlet.ServletOutputStream;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;public class ManyContexts &#123; public static void main(String[] args) throws Exception &#123; Server server = new Server(8080); // 可以在ContextHandler的构造函数中设置URI映射,但是setContextPath()会覆盖构造函数中的映射 ContextHandler rootContext = new ContextHandler(&quot;/&quot;); rootContext.setContextPath(&quot;/root&quot;); rootContext.setHandler(new HelloHandler(&quot;Root Hello&quot;)); ContextHandler contextFR = new ContextHandler(&quot;/fr&quot;); contextFR.setHandler(new HelloHandler(&quot;Bonjoir&quot;)); ContextHandler contextV = new ContextHandler(&quot;/&quot;); contextV.setVirtualHosts(new String[] &#123; &quot;127.0.0.2&quot; &#125;); contextV.setHandler(new HelloHandler(&quot;Virtual Hello&quot;)); ContextHandler resourceBaseHandler = new ContextHandler(&quot;/resources&quot;); // 设置web内容的路径, 即请求web资源时(Html, js, css文件等)的根路径 resourceBaseHandler.setResourceBase(&quot;/&quot;); resourceBaseHandler.setHandler(new HelloHandler(&quot;Resource Hello&quot;)); ContextHandlerCollection contexts = new ContextHandlerCollection(); contexts.setHandlers(new Handler[] &#123; rootContext, contextFR, contextV, resourceBaseHandler&#125;); server.setHandler(contexts); server.start(); server.join(); &#125; public static class HelloHandler extends AbstractHandler &#123; private String path; public HelloHandler(String path) &#123; this.path = path; &#125; @Override public void handle(String target, Request baseRequest, HttpServletRequest request, HttpServletResponse response) throws IOException, ServletException &#123; ServletOutputStream out = response.getOutputStream(); out.print(path); out.flush(); response.setStatus(200); &#125; &#125;&#125; 我们看一下测试结果 123456789ζ curl http://192.168.10.220:8080/Root Hello% # wangming@OA1503P0256: ~ (16:55:48)ζ curl http://192.168.10.220:8080/fr# wangming@OA1503P0256: ~ (16:55:55)ζ curl http://192.168.10.220:8080/it# wangming@OA1503P0256: ~ (16:56:07)ζ curl 127.0.0.2:8080/Virtual HelloRoot Hello% ServletsServlet是一种标准的处理HTTP请求逻辑的方式. Servlet和Jetty Handler非常像, 但是Servlet得request对象是不可变的.Jetty的ServletHandler采用将请求映射到一个标准路径上. 12345678910111213141516171819202122232425262728293031323334import java.io.IOException;import javax.servlet.ServletException;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import org.eclipse.jetty.server.Server;import org.eclipse.jetty.servlet.ServletHandler;public class MinimalServlets &#123; public static void main(String[] args) throws Exception &#123; Server server = new Server(8080); ServletHandler handler = new ServletHandler(); server.setHandler(handler); // 下面我们配置一个原生的Servlet, 还有其他的Servlet(例如通过web.xml或者@WebServlet注解生成的)可配置 handler.addServletWithMapping(HelloServlet.class, &quot;/*&quot;); server.start(); server.join(); &#125; public static class HelloServlet extends HttpServlet &#123; @Override protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; response.setContentType(&quot;text/html&quot;); response.setStatus(HttpServletResponse.SC_OK); response.getWriter().println(&quot;&lt;h1&gt;Hello from HelloServlet&lt;/h1&gt;&quot;); &#125; &#125;&#125; ServletContextHandler在上面的Servlets中我们看到每个Servlet都对应一个完整的URI地址映射, 但是如果我们想在某个特定的URI下, 增加子映射怎么办呢？这就用到了ServletContextHandler 123456789101112131415161718192021222324252627282930import org.eclipse.jetty.server.Server;import org.eclipse.jetty.servlet.ServletContextHandler;import javax.servlet.ServletException;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;public class ServletContextHandlerTest &#123; public static void main(String[] args) throws Exception &#123; Server server = new Server(8080); ServletContextHandler servletContextHandler = new ServletContextHandler(ServletContextHandler.SESSIONS); servletContextHandler.setContextPath(&quot;/servlet&quot;); servletContextHandler.addServlet(HelloServlet.class, &quot;/abc&quot;); server.setHandler(servletContextHandler); server.start(); server.join(); &#125; public static class HelloServlet extends HttpServlet &#123; @Override protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; response.setContentType(&quot;text/html&quot;); response.setStatus(HttpServletResponse.SC_OK); response.getWriter().println(&quot;&lt;h1&gt;Hello from HelloServlet&lt;/h1&gt;&quot;); &#125; &#125;&#125; Connectors当创建N个connectors应用时, 一般我们会将通用的配置首先提取出来, 使用一个配置类配置这些通用配置. 然后在其他具体Connectors配置时将这个配置传递到具体配置类中, 这样一来就形成了一个链式配置形式. 首先生成一个keystore文件 1234567891011121314151617D:\\ssl&gt;keytool -genkey -alias wm -keyalg RSA -keysize 1024 -keypass 123456 -validity 365 -keystore D:\\ssl\\wm.keystore -storepass 123456您的名字与姓氏是什么? [Unknown]: wm您的组织单位名称是什么? [Unknown]: wm您的组织名称是什么? [Unknown]: wm您所在的城市或区域名称是什么? [Unknown]: bj您所在的省/市/自治区名称是什么? [Unknown]: bj该单位的双字母国家/地区代码是什么? [Unknown]: cnCN=wm, OU=wm, O=wm, L=bj, ST=bj, C=cn是否正确? [否]: yD:\\ssl&gt; 然后看一下服务器代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071import javax.servlet.ServletException;import javax.servlet.http.HttpServlet;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.File;import java.io.FileNotFoundException;import java.io.IOException;public class ManyConnectors &#123; public static void main(String[] args) throws Exception &#123; // 加载ssl需要的keystore File keystoreFile = new File(&quot;D:\\\\ssl\\\\wm.keystore&quot;); if (!keystoreFile.exists()) &#123; throw new FileNotFoundException(keystoreFile.getAbsolutePath()); &#125; // 开启一个JettyServer,但是此时我们并不设置端口,在Connectors里设置端口 Server server = new Server(); // 一个通用的HTTP配置. 使用HttpConfiguration进行对HTTP和HTTPS进行设置. HTTP默认的scheme是http,HTTPS默认的scheme是https HttpConfiguration httpConfig = new HttpConfiguration(); httpConfig.setSecureScheme(&quot;https&quot;); httpConfig.setSecurePort(8443); httpConfig.setOutputBufferSize(32768); // 构建一个HTTP Connectors ServerConnector http = new ServerConnector(server, new HttpConnectionFactory(httpConfig)); http.setPort(8080); http.setIdleTimeout(30000); // 根据SSL证书生成ssl信息 SslContextFactory sslContextFactory = new SslContextFactory(); sslContextFactory.setKeyStorePath(keystoreFile.getAbsolutePath()); sslContextFactory.setKeyStorePassword(&quot;123456&quot;); sslContextFactory.setKeyManagerPassword(&quot;123456&quot;); // 现在为HTTP Connectors创建一个http配置对象, 这个对象是必须的, 我们不能在http Connectors里复用httpConfig对象, // 即便是将httpConfig对象作为参数进行构建，它的内部也是对它的一个克隆而已 HttpConfiguration httpsConfig = new HttpConfiguration(httpConfig); // SecureRequestCustomizer用于处理从Jetty接手的https连接 SecureRequestCustomizer src = new SecureRequestCustomizer(); src.setStsMaxAge(2000); src.setStsIncludeSubDomains(true); httpsConfig.addCustomizer(src); ServerConnector https = new ServerConnector(server, new SslConnectionFactory(sslContextFactory, HttpVersion.HTTP_1_1.asString()), new HttpConnectionFactory(httpsConfig)); https.setPort(8443); https.setIdleTimeout(500000); server.setConnectors(new Connector[] &#123; http, https &#125;); ServletHandler handler = new ServletHandler(); handler.addServletWithMapping(HelloServlet.class, &quot;/*&quot;); server.setHandler(handler); server.start(); server.join(); &#125; public static class HelloServlet extends HttpServlet &#123; @Override protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; response.setContentType(&quot;text/html&quot;); response.setStatus(HttpServletResponse.SC_OK); response.getWriter().println(&quot;&lt;h1&gt;Hello from HelloServlet&lt;/h1&gt;&quot;); &#125; &#125;&#125; 我们使用JMeter模拟客户端进行访问 JMX服务器开启JMX 1234567891011121314151617181920212223242526import java.lang.management.ManagementFactory;import javax.management.remote.JMXServiceURL;import org.eclipse.jetty.jmx.ConnectorServer;import org.eclipse.jetty.jmx.MBeanContainer;import org.eclipse.jetty.server.Server;public class ServerWithJMX &#123; public static void main(String[] args) throws Exception &#123; // === jetty-jmx.xml === MBeanContainer mbContainer = new MBeanContainer(ManagementFactory.getPlatformMBeanServer()); Server server = new Server(8080); server.addBean(mbContainer); ConnectorServer jmx = new ConnectorServer( new JMXServiceURL(&quot;rmi&quot;, null, 1999, &quot;/jndi/rmi://localhost:1999/jmxrmi&quot;), &quot;org.eclipse.jetty.jmx:name=rmiconnectorserver&quot;); server.addBean(jmx); server.start(); server.dumpStdErr(); server.join(); &#125;&#125;","categories":[{"name":"Java 网络库","slug":"Java-网络库","permalink":"https://wangmingco.github.io/categories/Java-%E7%BD%91%E7%BB%9C%E5%BA%93/"}],"tags":[{"name":"Jetty","slug":"Jetty","permalink":"https://wangmingco.github.io/tags/Jetty/"}]},{"title":"动态方法调用","slug":"jvm/动态方法调用","date":"2016-07-23T16:00:00.000Z","updated":"2021-11-18T02:40:48.202Z","comments":true,"path":"2016/07/24/jvm/动态方法调用/","link":"","permalink":"https://wangmingco.github.io/2016/07/24/jvm/%E5%8A%A8%E6%80%81%E6%96%B9%E6%B3%95%E8%B0%83%E7%94%A8/","excerpt":"","text":"java7增加了一个invokedynamic的指令，这个命令是为了更好地支持JVM平台上的动态语言和lambda表达式。在给出一个使用示例时，我们先看四个概念 方法句柄(MethodHandle)：这个很像一个方法的代理，通过它就可以调用一个方法。（class文件常量池中的CONSTANT_MethodHandle就是方法句柄） 调用点(CallSite)：这个是对方法句柄的一个封装，通过在变调用点上设置不同的方法句柄就可以调用不同的方法 启动方法(BootstrapMethods)：通过启动方法可以获得调用点 方法类型(MethodType)：主要用于设置方法的参数和返回值 下面我们看一下方法句柄的使用 123456789101112131415161718192021222324252627282930import java.lang.invoke.MethodHandle;import java.lang.invoke.MethodHandles;import java.lang.invoke.MethodType;import java.time.LocalDateTime;public class TestMethodHandler &#123; public static void main(String[] args) throws Throwable &#123; // specify method&#x27;s parameter and return types MethodType methodType = MethodType.methodType(void.class); // invoke static method MethodHandle printHelloWorld = MethodHandles.lookup().findStatic(TestMethodHandler.class, &quot;printHelloWorld&quot;, methodType); printHelloWorld.invoke(); // invoke instance method TestMethodHandler testMethodHandler = new TestMethodHandler(); MethodHandle printTime = MethodHandles.lookup().findVirtual(TestMethodHandler.class, &quot;printTime&quot;, methodType).bindTo(testMethodHandler); printTime.invoke(); &#125; public static void printHelloWorld() &#123; System.out.println(&quot;Hello World!&quot;); &#125; public void printTime() &#123; System.out.println(LocalDateTime.now().toString()); &#125;&#125; 结果为 12Hello World!2016-07-24T01:05:31.010 下面我们依次看一下上面的例子中使用的方法 findStatic(): 查找一个static方法，然后使用invokestatic进行函数调用 findVirtual(): 查找一个虚方法，使用invokevirtual指令进行函数调用 findSpecial(): 查找私有方法或者父类的方法，使用invokespecial指令进行调用 findConstructor():查找构造器方法 下面我们接着看一下调用点，调用点一共分为3种 常量调用点 可变调用点 易变调用点 我们接着看一下常量调用点的示例 1234567891011121314151617181920212223242526272829import java.lang.invoke.*;import java.time.LocalDateTime;public class TestCallSite &#123; public static void main(String[] args) throws Throwable &#123; // specify method&#x27;s parameter and return types MethodType methodType = MethodType.methodType(void.class); // invoke static method MethodHandle printHelloWorld = MethodHandles.lookup().findStatic(TestCallSite.class, &quot;printHelloWorld&quot;, methodType); CallSite callSite = new ConstantCallSite(printHelloWorld); MethodHandle invoker = callSite.dynamicInvoker(); invoker.invoke(); MethodHandle printTime = MethodHandles.lookup().findStatic(TestCallSite.class, &quot;printTime&quot;, methodType); callSite.setTarget(printTime); invoker.invoke(); &#125; public static void printHelloWorld() &#123; System.out.println(&quot;Hello World!&quot;); &#125; public static void printTime() &#123; System.out.println(LocalDateTime.now().toString()); &#125;&#125; 结果为 123456789Exception in thread &quot;main&quot; java.lang.UnsupportedOperationException at java.lang.invoke.ConstantCallSite.setTarget(ConstantCallSite.java:106) at TestCallSite.main(TestCallSite.java:18) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:147)Hello World! 首先我们发现，当再一个常量调用点上进行重置target的时候，产生了一个异常，那么我们使用可变调用点试试呢？ 1234567891011121314151617181920212223242526272829import java.lang.invoke.*;import java.time.LocalDateTime;public class TestCallSite &#123; public static void main(String[] args) throws Throwable &#123; // specify method&#x27;s parameter and return types MethodType methodType = MethodType.methodType(void.class); // invoke static method MethodHandle printHelloWorld = MethodHandles.lookup().findStatic(TestCallSite.class, &quot;printHelloWorld&quot;, methodType); CallSite callSite = new MutableCallSite(printHelloWorld); MethodHandle invoker = callSite.dynamicInvoker(); invoker.invoke(); MethodHandle printTime = MethodHandles.lookup().findStatic(TestCallSite.class, &quot;printTime&quot;, methodType); callSite.setTarget(printTime); invoker.invoke(); &#125; public static void printHelloWorld() &#123; System.out.println(&quot;Hello World!&quot;); &#125; public static void printTime() &#123; System.out.println(LocalDateTime.now().toString()); &#125;&#125; 结果为 12Hello World!2016-07-24T01:18:02.905","categories":[{"name":"JVM","slug":"JVM","permalink":"https://wangmingco.github.io/categories/JVM/"}],"tags":[]},{"title":"java8 排序","slug":"JavaSE/Java8 排序","date":"2016-07-11T16:00:00.000Z","updated":"2021-11-18T02:43:23.318Z","comments":true,"path":"2016/07/12/JavaSE/Java8 排序/","link":"","permalink":"https://wangmingco.github.io/2016/07/12/JavaSE/Java8%20%E6%8E%92%E5%BA%8F/","excerpt":"","text":"示例在这里我们主要看一下Java8提供的Comparator实现的快捷排序. 首先写一个工具类 123456789101112131415161718192021222324252627282930313233343536class CompareObject &#123; public int tall; public int age; public String name; public CompareObject(int tall, int age, String name) &#123; this.tall = tall; this.age = age; this.name = name; &#125; public int getTall() &#123;return tall;&#125; public int getAge() &#123;return age;&#125; public String getName() &#123;return name;&#125; public static List&lt;CompareObject&gt; getList() &#123; CompareObject co1 = new CompareObject(160, 15, &quot;张华&quot;); CompareObject co2 = new CompareObject(160, 19, &quot;徐来&quot;); CompareObject co3 = new CompareObject(160, 16, &quot;张德建&quot;); CompareObject co4 = new CompareObject(170, 18, &quot;李子栋&quot;); CompareObject co5 = new CompareObject(170, 18, &quot;玛丽凯乐&quot;); CompareObject co6 = new CompareObject(180, 18, &quot;王义海&quot;); CompareObject co7 = new CompareObject(180, 19, &quot;赵同利&quot;); CompareObject co8 = new CompareObject(180, 19, &quot;刘丽&quot;); List&lt;CompareObject&gt; list = new ArrayList&lt;&gt;(); list.add(co1); list.add(co2); list.add(co3); list.add(co4); list.add(co5); list.add(co6); list.add(co7); list.add(co8); return list; &#125;&#125; 我们首先看一个最普通的排序 12345678910public class TestSort &#123; public static void main(String[] args) &#123; List&lt;CompareObject&gt; list = CompareObject.getList(); list.stream().sorted(Comparator.comparing(CompareObject::getTall) .thenComparing(CompareObject::getAge) .thenComparing(CompareObject::getName)) .forEach(co -&gt; System.out.println(co.getTall() + &quot; &quot; + co.getAge() + &quot; &quot; + co.getName())); &#125;&#125; 结果为 12345678160 15 张华160 16 张德建160 19 徐来170 18 李子栋170 18 玛丽凯乐180 18 王义海180 19 刘丽180 19 赵同利 下面我们看一下它的倒序 12345678910public class TestSort &#123; public static void main(String[] args) &#123; List&lt;CompareObject&gt; list = CompareObject.getList(); list.stream().sorted(Comparator.comparing(CompareObject::getTall).reversed() .thenComparing(CompareObject::getAge) .thenComparing(CompareObject::getName)) .forEach(co -&gt; System.out.println(co.getTall() + &quot; &quot; + co.getAge() + &quot; &quot; + co.getName())); &#125;&#125; 结果为 12345678180 18 王义海180 19 刘丽180 19 赵同利170 18 李子栋170 18 玛丽凯乐160 15 张华160 16 张德建160 19 徐来 然们将其作用在第二个comparing上 12345678910public class TestSort &#123; public static void main(String[] args) &#123; List&lt;CompareObject&gt; list = CompareObject.getList(); list.stream().sorted(Comparator.comparing(CompareObject::getTall) .thenComparing(CompareObject::getAge).reversed() .thenComparing(CompareObject::getName)) .forEach(co -&gt; System.out.println(co.getTall() + &quot; &quot; + co.getAge() + &quot; &quot; + co.getName())); &#125;&#125; 结果为 12345678180 19 刘丽180 19 赵同利180 18 王义海170 18 李子栋170 18 玛丽凯乐160 19 徐来160 16 张德建160 15 张华 然们将其作用在第三个comparing上 12345678910public class TestSort &#123; public static void main(String[] args) &#123; List&lt;CompareObject&gt; list = CompareObject.getList(); list.stream().sorted(Comparator.comparing(CompareObject::getTall) .thenComparing(CompareObject::getAge) .thenComparing(CompareObject::getName).reversed()) .forEach(co -&gt; System.out.println(co.getTall() + &quot; &quot; + co.getAge() + &quot; &quot; + co.getName())); &#125;&#125; 结果为 12345678180 19 赵同利180 19 刘丽180 18 王义海170 18 玛丽凯乐170 18 李子栋160 19 徐来160 16 张德建160 15 张华 通关上面的现象我们可以得出, 放在后面的reversed()会将前面的都执行倒序操作. 那么如果只想对某个键进行倒序, 其他都正序要如何操作呢？ 12345678910public class TestClassForName &#123; public static void main(String[] args) throws InterruptedException, ClassNotFoundException &#123; List&lt;CompareObject&gt; list = CompareObject.getList(); list.stream().sorted(Comparator.comparing(CompareObject::getTall) .thenComparing(CompareObject::getAge, Comparator.reverseOrder()) .thenComparing(CompareObject::getName)) .forEach(co -&gt; System.out.println(co.getTall() + &quot; &quot; + co.getAge() + &quot; &quot; + co.getName())); &#125;&#125; 输出结果为 12345678160 19 徐来160 16 张德建160 15 张华170 18 李子栋170 18 玛丽凯乐180 19 刘丽180 19 赵同利180 18 王义海 我们看到年龄已经降序排序了 TimSort异常今天项目中跑出了一段排序的异常代码 1234567891011121314java.lang.IllegalArgumentException: Comparison method violates its general contract! at java.util.TimSort.mergeLo(TimSort.java:777) at java.util.TimSort.mergeAt(TimSort.java:514) at java.util.TimSort.mergeCollapse(TimSort.java:441) at java.util.TimSort.sort(TimSort.java:245) at java.util.Arrays.sort(Arrays.java:1512) at java.util.ArrayList.sort(ArrayList.java:1454) at java.util.stream.SortedOps$RefSortingSink.end(SortedOps.java:387) at java.util.stream.Sink$ChainedReference.end(Sink.java:258) at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482) at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) 通过百度得知, 这是因为JDK升级到7的时候内置的排序算法由归并排序替换成了TimeSort算法. 然后打开JDK API看一下它现在的描述 123456789101112131415161718192021int compare(T o1, T o2)Compares its two arguments for order. Returns a negative integer, zero, or a positive integer as the first argument is less than, equal to, or greater than the second.In the foregoing description, the notation sgn(expression) designates the mathematical signum function, which is defined to return one of -1, 0, or 1 according to whether the value of expression is negative, zero or positive.The implementor must ensure that sgn(compare(x, y)) == -sgn(compare(y, x)) for all x and y. (This implies that compare(x, y) must throw an exception if and only if compare(y, x) throws an exception.)The implementor must also ensure that the relation is transitive: ((compare(x, y)&gt;0) &amp;&amp; (compare(y, z)&gt;0)) implies compare(x, z)&gt;0.Finally, the implementor must ensure that compare(x, y)==0 implies that sgn(compare(x, z))==sgn(compare(y, z)) for all z.It is generally the case, but not strictly required that (compare(x, y)==0) == (x.equals(y)). Generally speaking, any comparator that violates this condition should clearly indicate this fact. The recommended language is &quot;Note: this comparator imposes orderings that are inconsistent with equals.&quot;Parameters:o1 - the first object to be compared.o2 - the second object to be compared.Returns:a negative integer, zero, or a positive integer as the first argument is less than, equal to, or greater than the second.Throws:NullPointerException - if an argument is null and this comparator does not permit null argumentsClassCastException - if the arguments&#x27; types prevent them from being compared by this comparator. 通过这个描述我们可以看出compare函数是对o1和o2进行对比，如果o1&lt;o2则返回负数, o1==o2返回0, o1&gt;o2返回正数. 在第二段中又描述到，sgn(expression)函数（数学上的符号函数, 取出一个数字的符号）定义了在上文中的正数要返回1，负数要返回-1，0则返回0. 接着说到，如果要实现这个函数则必须保证三点 在所有的x和y下，sgn(compare(x, y)) == -sgn(compare(y, x)). 这意味着当且仅当compare(y, x)抛出异常的话,则compare(x, y)也必须抛出一个异常. 还必须要保证传递性, ((compare(x, y)&gt;0) &amp;&amp; (compare(y, z)&gt;0))则必须compare(x, z)&gt;0. 最后还需要保证当compare(x, y)==0时则对于所有的z要sgn(compare(x, z))==sgn(compare(y, z)). 最后阐述的是对equals()函数, compare函数并不严格要求要确保(compare(x, y)==0) == (x.equals(y)). 看了这么多, 那么那个bug是怎么发生的呢？","categories":[{"name":"Java","slug":"Java","permalink":"https://wangmingco.github.io/categories/Java/"}],"tags":[]},{"title":"基于递归实现的二叉树","slug":"算法/基于递归实现的二叉树","date":"2016-06-17T16:00:00.000Z","updated":"2021-11-18T02:53:37.431Z","comments":true,"path":"2016/06/18/算法/基于递归实现的二叉树/","link":"","permalink":"https://wangmingco.github.io/2016/06/18/%E7%AE%97%E6%B3%95/%E5%9F%BA%E4%BA%8E%E9%80%92%E5%BD%92%E5%AE%9E%E7%8E%B0%E7%9A%84%E4%BA%8C%E5%8F%89%E6%A0%91/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149#-*- coding=utf-8 -*-class Node: key = 0 value = 0 left = 0 right = 0 size = 0class BST: root = Node def size(self): return self.size(self.root) def size(self, node): return node.size def get(self, key): return self.get(self.root, key) def get(self, node, key): if node == None: return if key &lt; node.key: return self.get(node.left, key) elif key &gt; node.key: return self.get(node.right, key) return node.value def put(self, key, value): return self.put(self.root, key, value) def put(self, node, key, value): if key &lt; node.key: self.put(node.left, key, value) elif key &gt; node.key: self.put(node.right, key, value) node.value = value node.size = self.size(node.left) + self.size(node.right) + 1 return node def max(self): return self.max(self.root) def max(self, node): if node.right == None: return node return self.max(node.right) def min(self): return self.min(self.root) def min(self, node): if node.left == None: return node return self.min(node.left) def floor(self, key): return self.floor(self.root, key) def floor(self, node, key): if key == node.key: return node if key &lt; node.key: return self.floor(node.left, key) if node.right == None: return node nextNode = self.floor(node.right, key) if nextNode == None: return node return nextNode def ceiling(self): pass def select(self, rank): return self.select(self.root, rank) def select(self, node, rank): size = self.size(node.left) if size &gt; rank: return self.select(node.left, rank) elif size &lt; rank: return self.select(node.right, rank - size -1) else: return rank def rank(self, key): return self.rank(self.root, key) def rank(self, node, key): if node.key &lt; key: return self.rank(node.left, key) elif node.key &gt; key: return 1 + self.size(node.left) + self.rank(node.right, key) else: return self.size(node.left) def deleteMin(self): return self.deleteMin(self.root) def deleteMin(self, node): if node.left == None: return node.right node.left = self.deleteMin(node.left) node.size = self.size(node.left) + self.size(node.right) + 1 return node def delete(self, key): return self.delete(self.root, key) def delete(self, node, key): if key &lt; node.key: node.left = self.delete(node.left, key) elif key &gt; node.key: node.right = self.delete(node.right, key) else: if node.right == None: return node.left if node.left == None: return node.right tmpNode = node node = self.min(tmpNode.right) node.right = self.deleteMin(tmpNode.right) node.left = tmpNode.left node.size = self.size(node.left) + self.size(node.right) + 1 return node def keys(self): queue = [] self.keys(self.root, queue, self.min(), self.max()) return queue def keys(self, node, queue, lo, hi): if lo &lt; node.key: self.keys(node.left, queue, lo, hi) if lo &lt;= node.key &amp; lo &gt;= node.key: queue.append(node.key) if lo &gt; node.right: self.keys(node.right, queue, lo, hi)","categories":[{"name":"算法","slug":"算法","permalink":"https://wangmingco.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[]},{"title":"ReflectASM 性能测试","slug":"JavaLibrary/ReflectASM 性能测试","date":"2016-06-13T16:00:00.000Z","updated":"2021-11-18T02:50:11.663Z","comments":true,"path":"2016/06/14/JavaLibrary/ReflectASM 性能测试/","link":"","permalink":"https://wangmingco.github.io/2016/06/14/JavaLibrary/ReflectASM%20%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/","excerpt":"","text":"我们采用JMH测试ReflectASM 官网给出的几个示例的吞吐量. 我们的测试代码为 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768package testASM;import com.esotericsoftware.reflectasm.ConstructorAccess;import com.esotericsoftware.reflectasm.FieldAccess;import com.esotericsoftware.reflectasm.MethodAccess;import org.openjdk.jmh.annotations.*;import org.openjdk.jmh.runner.Runner;import org.openjdk.jmh.runner.RunnerException;import org.openjdk.jmh.runner.options.Options;import org.openjdk.jmh.runner.options.OptionsBuilder;import java.util.concurrent.TimeUnit;@State(Scope.Thread)@BenchmarkMode(Mode.AverageTime)@OutputTimeUnit(TimeUnit.NANOSECONDS)public class TestRelectASM &#123; public static void main(String[] args) throws RunnerException &#123; Options opt = new OptionsBuilder() .include(TestRelectASM.class.getSimpleName()) .warmupIterations(5) .measurementIterations(5) .forks(1) .build(); new Runner(opt).run(); &#125; @BenchmarkMode(Mode.Throughput) @OutputTimeUnit(TimeUnit.SECONDS) @Benchmark public void measureMethodAccess() &#123; SomeClass someObject = new SomeClass(); MethodAccess access = MethodAccess.get(SomeClass.class); access.invoke(someObject, &quot;setName&quot;, &quot;Awesome McLovin&quot;); String name = (String)access.invoke(someObject, &quot;getName&quot;); &#125; @BenchmarkMode(Mode.Throughput) @OutputTimeUnit(TimeUnit.SECONDS) @Benchmark public void measureFieldAccess() &#123; SomeClass someObject = new SomeClass(); FieldAccess access = FieldAccess.get(SomeClass.class); access.set(someObject, &quot;age&quot;, 18); Integer age = (Integer)access.get(someObject, &quot;age&quot;); &#125; @BenchmarkMode(Mode.Throughput) @OutputTimeUnit(TimeUnit.SECONDS) @Benchmark public void measureConstructorAccess() &#123; ConstructorAccess&lt;SomeClass&gt; access = ConstructorAccess.get(SomeClass.class); SomeClass someObject = access.newInstance(); &#125;&#125;class SomeClass &#123; public int age; private String name; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125;&#125; 测试结果为 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687# Warmup: 5 iterations, 1 s each# Measurement: 5 iterations, 1 s each# Timeout: 10 min per iteration# Threads: 1 thread, will synchronize iterations# Benchmark mode: Throughput, ops/time# Benchmark: testASM.TestRelectASM.measureConstructorAccess# Run progress: 0.00% complete, ETA 00:00:30# Fork: 1 of 1# Warmup Iteration 1: 146112.555 ops/s# Warmup Iteration 2: 399173.011 ops/s# Warmup Iteration 3: 452136.048 ops/s# Warmup Iteration 4: 450102.353 ops/s# Warmup Iteration 5: 446112.781 ops/sIteration 1: 454817.511 ops/sIteration 2: 444272.121 ops/sIteration 3: 454354.750 ops/sIteration 4: 449983.056 ops/sIteration 5: 446149.202 ops/sResult &quot;measureConstructorAccess&quot;: 449915.328 ±(99.9%) 18242.255 ops/s [Average] (min, avg, max) = (444272.121, 449915.328, 454817.511), stdev = 4737.456 CI (99.9%): [431673.074, 468157.583] (assumes normal distribution)# Warmup: 5 iterations, 1 s each# Measurement: 5 iterations, 1 s each# Timeout: 10 min per iteration# Threads: 1 thread, will synchronize iterations# Benchmark mode: Throughput, ops/time# Benchmark: testASM.TestRelectASM.measureFieldAccess# Run progress: 33.33% complete, ETA 00:00:21# Fork: 1 of 1# Warmup Iteration 1: 483272.367 ops/s# Warmup Iteration 2: 638769.340 ops/s# Warmup Iteration 3: 643087.589 ops/s# Warmup Iteration 4: 654921.986 ops/s# Warmup Iteration 5: 646076.594 ops/sIteration 1: 657034.718 ops/sIteration 2: 651774.971 ops/sIteration 3: 648118.383 ops/sIteration 4: 647813.662 ops/sIteration 5: 654691.279 ops/sResult &quot;measureFieldAccess&quot;: 651886.603 ±(99.9%) 15542.738 ops/s [Average] (min, avg, max) = (647813.662, 651886.603, 657034.718), stdev = 4036.400 CI (99.9%): [636343.865, 667429.341] (assumes normal distribution)# Warmup: 5 iterations, 1 s each# Measurement: 5 iterations, 1 s each# Timeout: 10 min per iteration# Threads: 1 thread, will synchronize iterations# Benchmark mode: Throughput, ops/time# Benchmark: testASM.TestRelectASM.measureMethodAccess# Run progress: 66.67% complete, ETA 00:00:10# Fork: 1 of 1# Warmup Iteration 1: 432894.585 ops/s# Warmup Iteration 2: 621680.095 ops/s# Warmup Iteration 3: 618783.228 ops/s# Warmup Iteration 4: 624738.576 ops/s# Warmup Iteration 5: 611762.568 ops/sIteration 1: 625825.844 ops/sIteration 2: 621933.920 ops/sIteration 3: 644088.779 ops/sIteration 4: 644729.889 ops/sIteration 5: 615383.465 ops/sResult &quot;measureMethodAccess&quot;: 630392.379 ±(99.9%) 51331.476 ops/s [Average] (min, avg, max) = (615383.465, 630392.379, 644729.889), stdev = 13330.621 CI (99.9%): [579060.904, 681723.855] (assumes normal distribution)# Run complete. Total time: 00:00:31Benchmark Mode Cnt Score Error UnitstestASM.TestRelectASM.measureConstructorAccess thrpt 5 449915.328 ± 18242.255 ops/stestASM.TestRelectASM.measureFieldAccess thrpt 5 651886.603 ± 15542.738 ops/stestASM.TestRelectASM.measureMethodAccess thrpt 5 630392.379 ± 51331.476 ops/s 接下来我们看一下JDK原生反射的性能 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283package testASM;import org.openjdk.jmh.annotations.*;import org.openjdk.jmh.runner.Runner;import org.openjdk.jmh.runner.RunnerException;import org.openjdk.jmh.runner.options.Options;import org.openjdk.jmh.runner.options.OptionsBuilder;import java.lang.reflect.Constructor;import java.lang.reflect.Field;import java.lang.reflect.InvocationTargetException;import java.lang.reflect.Method;import java.util.concurrent.TimeUnit;@State(Scope.Thread)@BenchmarkMode(Mode.AverageTime)@OutputTimeUnit(TimeUnit.NANOSECONDS)public class TestJDKReflect &#123; public static void main(String[] args) throws RunnerException &#123; Options opt = new OptionsBuilder() .include(TestRelectASM.class.getSimpleName()) .warmupIterations(5) .measurementIterations(5) .forks(1) .build(); new Runner(opt).run(); &#125; @BenchmarkMode(Mode.Throughput) @OutputTimeUnit(TimeUnit.SECONDS) @Benchmark public void measureMethodAccess() &#123; SomeClass someObject = new SomeClass(); try &#123; Method setNameMethod = SomeClass.class.getMethod(&quot;setName&quot;); setNameMethod.invoke(someObject, &quot;Awesome McLovin&quot;); Method getNameMethod = SomeClass.class.getMethod(&quot;getName&quot;); String name = (String)getNameMethod.invoke(someObject); &#125; catch (NoSuchMethodException e) &#123; e.printStackTrace(); &#125; catch (InvocationTargetException e) &#123; e.printStackTrace(); &#125; catch (IllegalAccessException e) &#123; e.printStackTrace(); &#125; &#125; @BenchmarkMode(Mode.Throughput) @OutputTimeUnit(TimeUnit.SECONDS) @Benchmark public void measureFieldAccess() &#123; SomeClass someObject = new SomeClass(); try &#123; Field ageField = SomeClass.class.getField(&quot;age&quot;); ageField.set(someObject, 18); Integer age = (Integer)ageField.get(someObject); &#125; catch (NoSuchFieldException e) &#123; e.printStackTrace(); &#125; catch (IllegalAccessException e) &#123; e.printStackTrace(); &#125; &#125; @BenchmarkMode(Mode.Throughput) @OutputTimeUnit(TimeUnit.SECONDS) @Benchmark public void measureConstructorAccess() &#123; try &#123; Constructor&lt;SomeClass&gt; con = SomeClass.class.getConstructor(); SomeClass newInstance = con.newInstance(); &#125; catch (NoSuchMethodException e) &#123; e.printStackTrace(); &#125; catch (IllegalAccessException e) &#123; e.printStackTrace(); &#125; catch (InstantiationException e) &#123; e.printStackTrace(); &#125; catch (InvocationTargetException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 测试结果为 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788# Warmup: 5 iterations, 1 s each# Measurement: 5 iterations, 1 s each# Timeout: 10 min per iteration# Threads: 1 thread, will synchronize iterations# Benchmark mode: Throughput, ops/time# Benchmark: testASM.TestRelectASM.measureConstructorAccess# Run progress: 0.00% complete, ETA 00:00:30# Fork: 1 of 1# Warmup Iteration 1: 272071.065 ops/s# Warmup Iteration 2: 589448.060 ops/s# Warmup Iteration 3: 583306.327 ops/s# Warmup Iteration 4: 559099.151 ops/s# Warmup Iteration 5: 546514.262 ops/sIteration 1: 603711.245 ops/sIteration 2: 582218.187 ops/sIteration 3: 561487.624 ops/sIteration 4: 582646.831 ops/sIteration 5: 612259.454 ops/sResult &quot;measureConstructorAccess&quot;: 588464.668 ±(99.9%) 76995.468 ops/s [Average] (min, avg, max) = (561487.624, 588464.668, 612259.454), stdev = 19995.478 CI (99.9%): [511469.200, 665460.136] (assumes normal distribution)# Warmup: 5 iterations, 1 s each# Measurement: 5 iterations, 1 s each# Timeout: 10 min per iteration# Threads: 1 thread, will synchronize iterations# Benchmark mode: Throughput, ops/time# Benchmark: testASM.TestRelectASM.measureFieldAccess# Run progress: 33.33% complete, ETA 00:00:21# Fork: 1 of 1# Warmup Iteration 1: 407799.239 ops/s# Warmup Iteration 2: 599419.421 ops/s# Warmup Iteration 3: 624838.592 ops/s# Warmup Iteration 4: 636293.822 ops/s# Warmup Iteration 5: 623880.225 ops/sIteration 1: 600361.584 ops/sIteration 2: 642029.016 ops/sIteration 3: 613483.428 ops/sIteration 4: 645823.284 ops/sIteration 5: 632346.098 ops/sResult &quot;measureFieldAccess&quot;: 626808.682 ±(99.9%) 74589.468 ops/s [Average] (min, avg, max) = (600361.584, 626808.682, 645823.284), stdev = 19370.648 CI (99.9%): [552219.214, 701398.150] (assumes normal distribution)# Warmup: 5 iterations, 1 s each# Measurement: 5 iterations, 1 s each# Timeout: 10 min per iteration# Threads: 1 thread, will synchronize iterations# Benchmark mode: Throughput, ops/time# Benchmark: testASM.TestRelectASM.measureMethodAccess# Run progress: 66.67% complete, ETA 00:00:10# Fork: 1 of 1# Warmup Iteration 1: 397028.204 ops/s# Warmup Iteration 2: 602683.986 ops/s# Warmup Iteration 3: 576226.708 ops/s# Warmup Iteration 4: 602674.109 ops/s# Warmup Iteration 5: 591631.635 ops/sIteration 1: 607990.169 ops/sIteration 2: 586306.494 ops/sIteration 3: 606049.775 ops/sIteration 4: 583441.620 ops/sIteration 5: 577363.527 ops/sResult &quot;measureMethodAccess&quot;: 592230.317 ±(99.9%) 53519.265 ops/s [Average] (min, avg, max) = (577363.527, 592230.317, 607990.169), stdev = 13898.783 CI (99.9%): [538711.052, 645749.582] (assumes normal distribution)# Run complete. Total time: 00:00:31Benchmark Mode Cnt Score Error UnitstestASM.TestRelectASM.measureConstructorAccess thrpt 5 588464.668 ± 76995.468 ops/stestASM.TestRelectASM.measureFieldAccess thrpt 5 626808.682 ± 74589.468 ops/stestASM.TestRelectASM.measureMethodAccess thrpt 5 592230.317 ± 53519.265 ops/s","categories":[{"name":"Java 类库","slug":"Java-类库","permalink":"https://wangmingco.github.io/categories/Java-%E7%B1%BB%E5%BA%93/"}],"tags":[{"name":"ReflectASM","slug":"ReflectASM","permalink":"https://wangmingco.github.io/tags/ReflectASM/"}]},{"title":"Integer Parse ValueOf","slug":"JavaSE/Java Integer Parse String","date":"2016-06-12T16:00:00.000Z","updated":"2021-11-18T02:39:45.414Z","comments":true,"path":"2016/06/13/JavaSE/Java Integer Parse String/","link":"","permalink":"https://wangmingco.github.io/2016/06/13/JavaSE/Java%20Integer%20Parse%20String/","excerpt":"","text":"今天使用FindBugs检查项目时，发现有这样一个提示 12Boxing/unboxing to parse a primitiveA boxed primitive is created from a String, just to extract the unboxed primitive value. It is more efficient to just call the static parseXXX method. 这句话的意思是说，我们正在讲一个String解析成一个boxed的原生类型，也就是Integer，Long这些等等，但是我们只需要将String解析成unboxed原生类型即可，也就是int，long这种。最后它推荐使用parseXXX()这样的静态方法. 于是很好奇parseXXX()和valueOf()有啥不同呢？打开源码看一看 12345678public static Integer valueOf(String s) throws NumberFormatException &#123; return Integer.valueOf(parseInt(s, 10)); &#125;public static Integer valueOf(int i) &#123; if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i);&#125; 我们看到valueOf()内部也是调用了parseInt()方法. 从下面的valueOf()方法可以看出, parseInt()返回的是一个unboxed的原生类型数据. 因此在上面的场景中会有那样的提示. 但是看到这里还不算完, 看到这让我想起了一个以前碰到的面试题 12345678910111213141516171819public class TestIntegerValueOf &#123; public static void main(String[] args) &#123; Integer i1 = 1; Integer i2 = 1; System.out.println(i1 == i2); Integer i3 = 200; Integer i4 = 200; System.out.println(i3 == i4); Integer i5 = Integer.valueOf(100); Integer i6 = Integer.valueOf(100); System.out.println(i5 == i6); Integer i7 = Integer.valueOf(200); Integer i8 = Integer.valueOf(200); System.out.println(i7 == i8); &#125;&#125; 结果为 1234truefalsetruefalse 我们看到在讲int强转为Interger的时候, 也是valueOf()的逻辑 除了Integer之外, 还有哪些基本原生类型是这样子的呢？先看看long 1234567public static Long valueOf(long l) &#123; final int offset = 128; if (l &gt;= -128 &amp;&amp; l &lt;= 127) &#123; // will cache return LongCache.cache[(int)l + offset]; &#125; return new Long(l);&#125; 接下来是Short 12345678public static Short valueOf(short s) &#123; final int offset = 128; int sAsInt = s; if (sAsInt &gt;= -128 &amp;&amp; sAsInt &lt;= 127) &#123; // must cache return ShortCache.cache[sAsInt + offset]; &#125; return new Short(s);&#125; 接下来是Byte 1234public static Byte valueOf(byte b) &#123; final int offset = 128; return ByteCache.cache[(int)b + offset];&#125; 接下来是Char 123456public static Character valueOf(char c) &#123; if (c &lt;= 127) &#123; // must cache return CharacterCache.cache[(int)c]; &#125; return new Character(c);&#125; 接下来是Float 123public static Float valueOf(float f) &#123; return new Float(f);&#125; 接下来是Double 123public static Double valueOf(double d) &#123; return new Double(d);&#125; 我们看到除了浮点型之外，都采用了缓存的原理。虽然我们从源码中看到了结果，可是求个心安，我们还是要写代码测试一下 123456789101112131415161718192021222324252627public class Test &#123; public static void main(String[] args) &#123; Short s_1 = 100; Short s_2 = 100; System.out.println(s_1 == s_2); Long l_1 = 100l; Long l_2 = 100l; System.out.println(l_1 == l_2); Character c_1 = 100; Character c_2 = 100; System.out.println(c_1 == c_2); Short s1 = 200; Short s2 = 200; System.out.println(s1 == s2); Long l1 = 200l; Long l2 = 200l; System.out.println(l1 == l2); Character c1 = 200; Character c2 = 200; System.out.println(c1 == c2); &#125;&#125; 结果为 123456truetruetruefalsefalsefalse 好了，这下世界安静了 后来在项目中发现有使用Gson转换中也会发生这种情况, 写个代码测试一下 12345678910111213141516public class TestIntegerValueOf &#123; public static void main(String[] args) &#123; Obj obj = new Obj(); obj.integer = 200; Gson gson = new Gson(); String str = gson.toJson(obj); System.out.println(str); Obj newObj1 = gson.fromJson(str, Obj.class); Obj newObj2 = gson.fromJson(str, Obj.class); System.out.println(newObj1.integer == newObj2.integer); &#125; private static class Obj &#123; public Integer integer; &#125;&#125; 输出结果为 12&#123;&quot;integer&quot;:200&#125;false 看来在Gson中不是使用强转就是使用的valueOf()","categories":[{"name":"Java","slug":"Java","permalink":"https://wangmingco.github.io/categories/Java/"}],"tags":[]},{"title":"希尔排序","slug":"算法/希尔排序","date":"2016-06-09T16:00:00.000Z","updated":"2021-11-18T02:53:41.632Z","comments":true,"path":"2016/06/10/算法/希尔排序/","link":"","permalink":"https://wangmingco.github.io/2016/06/10/%E7%AE%97%E6%B3%95/%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F/","excerpt":"","text":"希尔排序是一种基于插入排序的算法. 插入排序的递增序列是1, 每次向前插入的时候都是和相邻的数组元素比较. 而希尔排序的递增是不固定的, 一般我们是选择一个算法, 算出递增. 希尔排序的思想是在间隔任意值h之间的数字是有序的, 这样的数组称为h有序数组. h有序数组是由h个互相独立的有序数组组成的一个大数组. 1234567891011121314151617181920212223#-*- coding=utf-8 -*-data = [8, 7, 6, 5, 4, 3, 2, 1]print datah = 1while h &lt; len(data)/3: h = 3*h + 1def sort(): global h while h &gt; 0: for i in range(0, len(data)): for j in range(i, 0, -h): pre = j - h if data[j] &lt; data[pre]: tmp = data[pre] data[pre] = data[j] data[j] = tmp print str(h) + &quot;: &quot; + str(data[j - h]) + &quot; compore &quot; + str(data[j]) + &quot; -&gt; &quot; + str(data) h = h / 3sort() 运算结果为 123456789101112131415161718192021222324252627282930313233343536373839[8, 7, 6, 5, 4, 3, 2, 1]4: 3 compore 7 -&gt; [8, 7, 6, 5, 4, 3, 2, 1]4: 2 compore 6 -&gt; [8, 7, 6, 5, 4, 3, 2, 1]4: 1 compore 5 -&gt; [8, 7, 6, 5, 4, 3, 2, 1]4: 4 compore 8 -&gt; [4, 7, 6, 5, 8, 3, 2, 1]4: 3 compore 7 -&gt; [4, 3, 6, 5, 8, 7, 2, 1]4: 3 compore 7 -&gt; [4, 7, 6, 5, 8, 3, 2, 1]4: 2 compore 6 -&gt; [4, 7, 2, 5, 8, 3, 6, 1]4: 2 compore 6 -&gt; [4, 7, 6, 5, 8, 3, 2, 1]4: 1 compore 5 -&gt; [4, 7, 6, 1, 8, 3, 2, 5]4: 1 compore 5 -&gt; [4, 7, 6, 5, 8, 3, 2, 1]1: 4 compore 7 -&gt; [4, 7, 6, 5, 8, 3, 2, 1]1: 6 compore 7 -&gt; [4, 6, 7, 5, 8, 3, 2, 1]1: 4 compore 6 -&gt; [4, 6, 7, 5, 8, 3, 2, 1]1: 5 compore 7 -&gt; [4, 6, 5, 7, 8, 3, 2, 1]1: 5 compore 6 -&gt; [4, 5, 6, 7, 8, 3, 2, 1]1: 4 compore 5 -&gt; [4, 5, 6, 7, 8, 3, 2, 1]1: 7 compore 8 -&gt; [4, 5, 6, 7, 8, 3, 2, 1]1: 6 compore 7 -&gt; [4, 5, 6, 7, 8, 3, 2, 1]1: 5 compore 6 -&gt; [4, 5, 6, 7, 8, 3, 2, 1]1: 4 compore 5 -&gt; [4, 5, 6, 7, 8, 3, 2, 1]1: 3 compore 8 -&gt; [4, 5, 6, 7, 3, 8, 2, 1]1: 3 compore 7 -&gt; [4, 5, 6, 3, 7, 8, 2, 1]1: 3 compore 6 -&gt; [4, 5, 3, 6, 7, 8, 2, 1]1: 3 compore 5 -&gt; [4, 3, 5, 6, 7, 8, 2, 1]1: 3 compore 4 -&gt; [3, 4, 5, 6, 7, 8, 2, 1]1: 2 compore 8 -&gt; [3, 4, 5, 6, 7, 2, 8, 1]1: 2 compore 7 -&gt; [3, 4, 5, 6, 2, 7, 8, 1]1: 2 compore 6 -&gt; [3, 4, 5, 2, 6, 7, 8, 1]1: 2 compore 5 -&gt; [3, 4, 2, 5, 6, 7, 8, 1]1: 2 compore 4 -&gt; [3, 2, 4, 5, 6, 7, 8, 1]1: 2 compore 3 -&gt; [2, 3, 4, 5, 6, 7, 8, 1]1: 1 compore 8 -&gt; [2, 3, 4, 5, 6, 7, 1, 8]1: 1 compore 7 -&gt; [2, 3, 4, 5, 6, 1, 7, 8]1: 1 compore 6 -&gt; [2, 3, 4, 5, 1, 6, 7, 8]1: 1 compore 5 -&gt; [2, 3, 4, 1, 5, 6, 7, 8]1: 1 compore 4 -&gt; [2, 3, 1, 4, 5, 6, 7, 8]1: 1 compore 3 -&gt; [2, 1, 3, 4, 5, 6, 7, 8]1: 1 compore 2 -&gt; [1, 2, 3, 4, 5, 6, 7, 8]","categories":[{"name":"算法","slug":"算法","permalink":"https://wangmingco.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[]},{"title":"选择排序","slug":"算法/选择排序","date":"2016-06-09T16:00:00.000Z","updated":"2021-11-18T02:53:42.649Z","comments":true,"path":"2016/06/10/算法/选择排序/","link":"","permalink":"https://wangmingco.github.io/2016/06/10/%E7%AE%97%E6%B3%95/%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F/","excerpt":"","text":"假设我们有这样的一个数组 [10, 2, 5, 3, 6, 4]. 在选择排序算法时, 会进行如下操作 10 与 2, 5, 3, 6, 4进行比较, 找到最小的值放到左边. 因此第一轮排序之后结果为 [2, 10, 5, 3, 6, 4] 10 与 5, 3, 6, 4进行比较, 找到最小的值放到左边. 因此第二轮排序之后结果为 [2, 3, 5, 10, 6, 4] 5 与 10, 6, 4进行比较, 找到最小的值放到左边. 因此第二轮排序之后结果为 [2, 3, 4, 10, 6, 5] …以此类推 我们看一下选择排序的实现 123456789101112131415161718#-*- coding=utf-8 -*-data = [5, 4, 3, 2, 1]print datadef sort(): for i in range(0, len(data)): min = i for j in range(i, len(data)): if data[j] &lt; data[min]: min = j tmp = data[i] data[i] = data[min] data[min] = tmp print str(data[i]) + &quot; compore &quot; + str(data[j]) + &quot; -&gt; &quot; + str(data)sort() 结果为 123456[5, 4, 3, 2, 1]1 compore 5 -&gt; [1, 4, 3, 2, 5]2 compore 5 -&gt; [1, 2, 3, 4, 5]3 compore 5 -&gt; [1, 2, 3, 4, 5]4 compore 5 -&gt; [1, 2, 3, 4, 5]5 compore 5 -&gt; [1, 2, 3, 4, 5] 选择排序的运行时间和输入没有关系. 因为在排序的过程中, 每一个位置的数字都会跟后边的数字比较一遍.所以哪怕数组是排序好的, 仍然会进行比较. 那么选择排序会比较多少次呢? 答案是(N + (N - 1) + (N - 2) ... 1) = N^2/2. 相关网站 visualgo Sorting Algorithm","categories":[{"name":"算法","slug":"算法","permalink":"https://wangmingco.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[]},{"title":"冒泡排序","slug":"算法/冒泡排序","date":"2016-06-08T16:00:00.000Z","updated":"2021-11-18T02:53:40.515Z","comments":true,"path":"2016/06/09/算法/冒泡排序/","link":"","permalink":"https://wangmingco.github.io/2016/06/09/%E7%AE%97%E6%B3%95/%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F/","excerpt":"","text":"12345678910111213141516#-*- coding=utf-8 -*-data = [5, 4, 3, 2, 1]print datadef sort(): for i in range(0, len(data)): for j in range(i, 0, -1): pre = j - 1 if data[j] &lt; data[pre]: tmp = data[pre] data[pre] = data[j] data[j] = tmp print str(data[pre]) + &quot; compore &quot; + str(data[j]) + &quot; -&gt; &quot; + str(data)sort() 结果为 1234567891011[5, 4, 3, 2, 1]4 compore 5 -&gt; [4, 5, 3, 2, 1]3 compore 5 -&gt; [4, 3, 5, 2, 1]3 compore 4 -&gt; [3, 4, 5, 2, 1]2 compore 5 -&gt; [3, 4, 2, 5, 1]2 compore 4 -&gt; [3, 2, 4, 5, 1]2 compore 3 -&gt; [2, 3, 4, 5, 1]1 compore 5 -&gt; [2, 3, 4, 1, 5]1 compore 4 -&gt; [2, 3, 1, 4, 5]1 compore 3 -&gt; [2, 1, 3, 4, 5]1 compore 2 -&gt; [1, 2, 3, 4, 5]","categories":[{"name":"算法","slug":"算法","permalink":"https://wangmingco.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[]},{"title":"插入排序","slug":"算法/插入排序","date":"2016-06-08T16:00:00.000Z","updated":"2021-11-18T02:53:35.548Z","comments":true,"path":"2016/06/09/算法/插入排序/","link":"","permalink":"https://wangmingco.github.io/2016/06/09/%E7%AE%97%E6%B3%95/%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F/","excerpt":"","text":"插入排序和选择排序类似, 也是在每个数组元素左边的数据都是有序的, 但是不确定他们的最终位置在哪里. 都是排序完的结果都是升序, 但是选择排序是将每个数据向后比较, 上次的比较和交换结果对下次的比较交换并没有什么影响. 而插入排序就不一样了, 插入排序是向前比较, 而它前面的数据是已经排序好了的. 因此插入排序的结果是受数据输入的影响的.如果输入的数据是一个已经排序好的数组, 那么插入排序的时间复杂度仅仅是O(N). 更多关于性能方面的介绍我会在最后给出, 下面我们看一个实现, 以及对一组简单数据排序后的结果: 12345678910111213141516#-*- coding=utf-8 -*-data = [10, 2, 5, 3, 6, 4]print datadef sort(): for i in range(0, len(data)): for j in range(i, 0, -1): if data[j] &lt; data[j - 1]: tmp = data[j - 1] data[j - 1] = data[j] data[j] = tmp sort() 结果为 12345678910111213141516[10, 2, 5, 3, 6, 4]2 compore 10 -&gt; [2, 10, 5, 3, 6, 4]5 compore 10 -&gt; [2, 5, 10, 3, 6, 4]2 compore 5 -&gt; [2, 5, 10, 3, 6, 4]3 compore 10 -&gt; [2, 5, 3, 10, 6, 4]3 compore 5 -&gt; [2, 3, 5, 10, 6, 4]2 compore 3 -&gt; [2, 3, 5, 10, 6, 4]6 compore 10 -&gt; [2, 3, 5, 6, 10, 4]5 compore 6 -&gt; [2, 3, 5, 6, 10, 4]3 compore 5 -&gt; [2, 3, 5, 6, 10, 4]2 compore 3 -&gt; [2, 3, 5, 6, 10, 4]4 compore 10 -&gt; [2, 3, 5, 6, 4, 10]4 compore 6 -&gt; [2, 3, 5, 4, 6, 10]4 compore 5 -&gt; [2, 3, 4, 5, 6, 10]3 compore 4 -&gt; [2, 3, 4, 5, 6, 10]2 compore 3 -&gt; [2, 3, 4, 5, 6, 10]","categories":[{"name":"算法","slug":"算法","permalink":"https://wangmingco.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[]},{"title":"ThreadLocal 实战","slug":"JavaSE/Java  ThreadLocal","date":"2016-06-06T16:00:00.000Z","updated":"2021-11-18T02:39:49.265Z","comments":true,"path":"2016/06/07/JavaSE/Java  ThreadLocal/","link":"","permalink":"https://wangmingco.github.io/2016/06/07/JavaSE/Java%20%20ThreadLocal/","excerpt":"","text":"应用项目中使用了java.text.SimpleDateFormat, 但是却将其声明为static. 在Oracle的Java API文档中是这样说明的 123SynchronizationDate formats are not synchronized. It is recommended to create separate format instances for each thread. If multiple threads access a format concurrently, it must be synchronized externally. Date对象的format操作并不是同步进行的. 我们应该为每个线程都创建一个SimpleDateFormat对象, 或者为format操作进行加锁处理. 那么ThreadLocal就可以成为这种场景下的替代方案. 我们看一下替换后的代码 12345678910111213141516171819202122232425262728import java.util.concurrent.TimeUnit;import java.util.concurrent.atomic.AtomicInteger;public class Test &#123; private static ThreadLocal&lt;byte[]&gt; simpleDateFormatThreadLocal = new ThreadLocal&lt;&gt;(); private static AtomicInteger count = new AtomicInteger(); public static void main(String[] args) throws InterruptedException &#123; for (int j = 0; j &lt; 5; j++) &#123; for (int i = 0; i &lt; 50; i++) &#123; Thread thread = new Thread(() -&gt; &#123; byte[] bytes = simpleDateFormatThreadLocal.get(); if (bytes == null) &#123; bytes = new byte[1024 * 1024 * 3]; simpleDateFormatThreadLocal.set(bytes); count.incrementAndGet(); &#125; &#125;); thread.start(); thread.join(); &#125; System.out.println(&quot;Active Thread Count : &quot; + Thread.activeCount()); TimeUnit.MILLISECONDS.sleep(50); &#125; System.out.println(&quot;set count ; &quot; + count); &#125;&#125; 我们看到了ThreadLocal的使用很简单, 首先是分配一个ThreadLocal对象, 然后接下来就通关get, set进行操作就ok了 原理ThreadLocal的实现是这样子的, 每个Thread对象内部有一个ThreadLocal.ThreadLocalMap实例 123public class Thread implements Runnable &#123; ThreadLocal.ThreadLocalMap threadLocals = null;&#125; 而ThreadLocal.ThreadLocalMap里有一个Entry数组用于实际存储数据, 也就是说ThreadLocal本身是不存储数据的 12345678910111213static class ThreadLocalMap &#123; static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125; private Entry[] table;&#125; 通过下面ThreadLocal方法实现我们可以看到每个和线程相关的数据最终都是保存到了各自的线程对象ThreadLocal.ThreadLocalMap实例里, 然后使用ThreadLocal作为key存储. 12345678910111213141516171819202122232425262728public class ThreadLocal&lt;T&gt; &#123; public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; &#125; &#125; return setInitialValue(); &#125; ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals; &#125; private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; int i = key.threadLocalHashCode &amp; (table.length - 1); Entry e = table[i]; if (e != null &amp;&amp; e.get() == key) return e; else return getEntryAfterMiss(key, i, e); &#125;&#125; 内存溢出上面我们说了一下应用和原理, 但是见网上有人说内存泄漏的问题, 关键在于 12345678static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125;&#125; Entry是一个弱引用类型(Java 引用类型). 当GC的时候, 如果weakReference的引用没有被强依赖的话, 则势必会被回收掉, 但是在ThreadLocal的时候则不然, 因为我们会一直保留ThreadLocal作为强引用依赖, 那么ThreadLocal则会一直被引用着, GC也不会回收它, Entry里面的value也就一直是可用的. 并不会发生ThreadLocal实例被回收, 而Entry里面value一直保存下来, 发生内存泄漏的情况. 第一个应用中就是我实际代码中使用的示例, 下面我使用-Xmx10M -Xms10M -XX:+PrintGC这几个JVM参数测试一下上面程序的内存泄漏问题, 结果为 1234567891011121314151617181920212223242526272829303132333435363738[GC (Allocation Failure) 2048K-&gt;905K(9728K), 0.0061875 secs][GC (Allocation Failure) 7854K-&gt;7113K(9728K), 0.0011924 secs][GC (Allocation Failure) 7113K-&gt;7129K(9728K), 0.0031599 secs][Full GC (Allocation Failure) 7129K-&gt;873K(9728K), 0.0409086 secs][GC (Allocation Failure) 7140K-&gt;7081K(9728K), 0.0311850 secs][Full GC (Ergonomics) 7081K-&gt;1024K(9728K), 0.0355878 secs][GC (Allocation Failure) 4150K-&gt;4128K(9728K), 0.0130218 secs][GC (Allocation Failure) 4128K-&gt;4128K(8704K), 0.0009429 secs][Full GC (Allocation Failure) 4128K-&gt;872K(8704K), 0.0158858 secs][GC (Allocation Failure) 7057K-&gt;7112K(9216K), 0.0064885 secs][Full GC (Ergonomics) 7112K-&gt;872K(9216K), 0.0088626 secs][GC (Allocation Failure) 7057K-&gt;7112K(9216K), 0.0037829 secs][Full GC (Ergonomics) 7112K-&gt;872K(9216K), 0.0174345 secs][GC (Allocation Failure) 7057K-&gt;7048K(9216K), 0.0180387 secs][Full GC (Ergonomics) 7048K-&gt;872K(9216K), 0.0508169 secs][GC (Allocation Failure) 7057K-&gt;7080K(9216K), 0.0088642 secs][Full GC (Ergonomics) 7080K-&gt;872K(9216K), 0.0328227 secs]Active Thread Count : 2......[Full GC (Ergonomics) 7050K-&gt;874K(9728K), 0.0055843 secs][GC (Allocation Failure) 7100K-&gt;7050K(9728K), 0.0002894 secs][Full GC (Ergonomics) 7050K-&gt;874K(9728K), 0.0209747 secs][GC (Allocation Failure) 7100K-&gt;7114K(9728K), 0.0002878 secs][Full GC (Ergonomics) 7114K-&gt;874K(9728K), 0.0034925 secs][GC (Allocation Failure) 7100K-&gt;7082K(9728K), 0.0003256 secs][Full GC (Ergonomics) 7082K-&gt;874K(9728K), 0.0057511 secs][GC (Allocation Failure) 7100K-&gt;7082K(9728K), 0.0003378 secs][Full GC (Ergonomics) 7082K-&gt;874K(9728K), 0.0037080 secs][GC (Allocation Failure) 7100K-&gt;7050K(9728K), 0.0001761 secs][Full GC (Ergonomics) 7050K-&gt;874K(9728K), 0.0040176 secs][GC (Allocation Failure) 7120K-&gt;7050K(9728K), 0.0005024 secs][Full GC (Ergonomics) 7050K-&gt;874K(9728K), 0.0051379 secs][GC (Allocation Failure) 7100K-&gt;7082K(9728K), 0.0021276 secs][Full GC (Ergonomics) 7082K-&gt;874K(9728K), 0.0060047 secs]Active Thread Count : 2set count ; 250 由于篇幅的原因, 我并没有将全部的日志输出, 但是通过上面的日志我们还是可以看出, 程序一共分配了250次内存, 每次分配给ThreadLocal里面的数据都被回收掉了, 因此对ThreadLocal的一个简单应用, 只要我们写的线程代码没有问题, 我们并不需要对内存泄漏担心太多.","categories":[{"name":"Java","slug":"Java","permalink":"https://wangmingco.github.io/categories/Java/"}],"tags":[]},{"title":"Mysql JSON 支持","slug":"数据库/Mysql JSON Data Type","date":"2016-05-16T16:00:00.000Z","updated":"2021-11-18T02:53:48.233Z","comments":true,"path":"2016/05/17/数据库/Mysql JSON Data Type/","link":"","permalink":"https://wangmingco.github.io/2016/05/17/%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql%20JSON%20Data%20Type/","excerpt":"","text":"官方文档学习 在MySQL5.7版本中增加了对JSON的支持. 在SQL中进行JSON字段操作时都是通过使用函数完成的 创建JSON字段在Mysql中, JSON是通过字符串进行存储的. 下面的例子演示了创建JSON类型字段的表, 以及插入一个JSON串和插入一个非法的JSON串 12345678mysql&gt; CREATE TABLE t1 (jdoc JSON);Query OK, 0 rows affected (0.20 sec)mysql&gt; INSERT INTO t1 VALUES(&#x27;&#123;&quot;key1&quot;: &quot;value1&quot;, &quot;key2&quot;: &quot;value2&quot;&#125;&#x27;);Query OK, 1 row affected (0.01 sec)mysql&gt; INSERT INTO t1 VALUES(&#x27;[1, 2,&#x27;);ERROR 3140 (22032) at line 2: Invalid JSON text: &quot;Invalid value.&quot; at position 6 in value (or column) &#x27;[1, 2,&#x27;. at position N是从0 开始计算的 搜索我们可以在JSON文档中通过JSON_EXTRACT()函数指定path来搜索出一个值. 在相关方法中使用表达式可以提取数据,或者修改JSON文档 以及进行其他的操作. 例如下面的操作就是从JSON文档中提取key为name的值. 123456mysql&gt; SELECT JSON_EXTRACT(&#x27;&#123;&quot;id&quot;: 14, &quot;name&quot;: &quot;Aztalan&quot;&#125;&#x27;, &#x27;$.name&#x27;);+---------------------------------------------------------+| JSON_EXTRACT(&#x27;&#123;&quot;id&quot;: 14, &quot;name&quot;: &quot;Aztalan&quot;&#125;&#x27;, &#x27;$.name&#x27;) |+---------------------------------------------------------+| &quot;Aztalan&quot; |+---------------------------------------------------------+ 在Mysql中, 可以使用$加后缀的方式表示一个JSON文档. $后可以跟一个选择符来索引到JSON文档中任意的位置元素: $&quot;key&quot; 表示在JSON文档中, key所对应的值. 注意key必须使用&quot;&quot;括起来. [N] 表示JSON数组文档中第N个位置的值(从0开始). Paths 可以包含 *或者** 通配符. .[*] 找到JSON对象中所有的成员值 [*] 找到JSON数组中所有的成员值 prefix**suffix 匹配所有的以prefix开头, 以suffix结尾的path. 下面我们创建出三个元素的数组, 然后假设 $ 指向这个数组: 1[3, &#123;&quot;a&quot;: [5, 6], &quot;b&quot;: 10&#125;, [99, 100]] 那么: $[0] 求值为 3. $[1] 求值为 {“a”: [5, 6], “b”: 10}. $[2] 求值为[99, 100]. $[3] 求值为 NULL (指向一个不存在的元素). 因为 $[1] 和 $[2] 是非标量的值, 因此我们可以进一步的使用path表达式求出它内嵌的值. 例如: $[1].a 求值为 [5, 6]. $[1].a[1] 求值为 6. $[1].b 求值为 10. $[2][0] 求值为 99. 刚才我们也提到了, path表达式的key必须被&quot;&quot;包含起来, 未被&quot;&quot;包含起来的key会被视为非法的. 1&#123;&quot;a fish&quot;: &quot;shark&quot;, &quot;a bird&quot;: &quot;sparrow&quot;&#125; 这俩个key都包含了一个空格, 因此在path表达式中, 必须使用&quot;&quot;将key包含: $.&quot;a fish&quot; 求值为 shark. $.&quot;a bird&quot; 求值为 to sparrow. 如果在对数组求值时, path中的通配符会求值出多个结果. 123456789101112mysql&gt; SELECT JSON_EXTRACT(&#x27;&#123;&quot;a&quot;: 1, &quot;b&quot;: 2, &quot;c&quot;: [3, 4, 5]&#125;&#x27;, &#x27;$.*&#x27;);+---------------------------------------------------------+| JSON_EXTRACT(&#x27;&#123;&quot;a&quot;: 1, &quot;b&quot;: 2, &quot;c&quot;: [3, 4, 5]&#125;&#x27;, &#x27;$.*&#x27;) |+---------------------------------------------------------+| [1, 2, [3, 4, 5]] |+---------------------------------------------------------+mysql&gt; SELECT JSON_EXTRACT(&#x27;&#123;&quot;a&quot;: 1, &quot;b&quot;: 2, &quot;c&quot;: [3, 4, 5]&#125;&#x27;, &#x27;$.c[*]&#x27;);+------------------------------------------------------------+| JSON_EXTRACT(&#x27;&#123;&quot;a&quot;: 1, &quot;b&quot;: 2, &quot;c&quot;: [3, 4, 5]&#125;&#x27;, &#x27;$.c[*]&#x27;) |+------------------------------------------------------------+| [3, 4, 5] |+------------------------------------------------------------+ 在下面的例子中, $**.b会在多个path($.a.b 和 $.c.b)中进行求值, 然后将求值结果放到一个数组中: 123456mysql&gt; SELECT JSON_EXTRACT(&#x27;&#123;&quot;a&quot;: &#123;&quot;b&quot;: 1&#125;, &quot;c&quot;: &#123;&quot;b&quot;: 2&#125;&#125;&#x27;, &#x27;$**.b&#x27;);+---------------------------------------------------------+| JSON_EXTRACT(&#x27;&#123;&quot;a&quot;: &#123;&quot;b&quot;: 1&#125;, &quot;c&quot;: &#123;&quot;b&quot;: 2&#125;&#125;&#x27;, &#x27;$**.b&#x27;) |+---------------------------------------------------------+| [1, 2] |+---------------------------------------------------------+ 在MySQL 5.7.9 和以后的版本中, 你可以使用column-&gt;path代替方法JSON_EXTRACT(column, path). 更多参考See Section 13.16.3, “Functions That Search JSON Values” 以及 Section 14.1.18.6, “Secondary Indexes and Generated Virtual Columns”. 在一些方法中, 会接受一个JSON文档, 然后对该JSON文档进行一些处理. 例如 JSON_SET() JSON_INSERT() JSON_REPLACE() 插入我们生成一个JSON文档, 然后在下面的操作中使用这个文档: 1mysql&gt; SET @j = &#x27;[&quot;a&quot;, &#123;&quot;b&quot;: [true, false]&#125;, [10, 20]]&#x27;; JSON_SET()会对已经存在的path替换, 不存在的进行添加: 123456mysql&gt; SELECT JSON_SET(@j, &#x27;$[1].b[0]&#x27;, 1, &#x27;$[2][2]&#x27;, 2);+--------------------------------------------+| JSON_SET(@j, &#x27;$[1].b[0]&#x27;, 1, &#x27;$[2][2]&#x27;, 2) |+--------------------------------------------+| [&quot;a&quot;, &#123;&quot;b&quot;: [1, false]&#125;, [10, 20, 2]] |+--------------------------------------------+ 在上例中$[1].b[0]选择了一个已经存在的value，然后它被替换成了1. 但是$[2][2] 并不存在, 所以就在$[2][2]插入了值2. JSON_INSERT()向JSON文档中插入新的值, 但是如果path已经存在, 则会归一化处理, 不会覆盖原有的值: 123456mysql&gt; SELECT JSON_INSERT(@j, &#x27;$[1].b[0]&#x27;, 1, &#x27;$[2][2]&#x27;, 2);+-----------------------------------------------+| JSON_INSERT(@j, &#x27;$[1].b[0]&#x27;, 1, &#x27;$[2][2]&#x27;, 2) |+-----------------------------------------------+| [&quot;a&quot;, &#123;&quot;b&quot;: [true, false]&#125;, [10, 20, 2]] |+-----------------------------------------------+ 修改JSON_REPLACE()执行替换操作, 但是如果path不存在的话, 不会进行插入操作: 123456mysql&gt; SELECT JSON_REPLACE(@j, &#x27;$[1].b[0]&#x27;, 1, &#x27;$[2][2]&#x27;, 2);+------------------------------------------------+| JSON_REPLACE(@j, &#x27;$[1].b[0]&#x27;, 1, &#x27;$[2][2]&#x27;, 2) |+------------------------------------------------+| [&quot;a&quot;, &#123;&quot;b&quot;: [1, false]&#125;, [10, 20]] |+------------------------------------------------+ JSON_SET()也会完成修改值的功能 删除JSON_REMOVE() 接受一个 JSON 文档以及一个或者多个要删除的path. The return value is the original document minus the values selected by paths that exist within the document: 123456mysql&gt; SELECT JSON_REMOVE(@j, &#x27;$[2]&#x27;, &#x27;$[1].b[1]&#x27;, &#x27;$[1].b[1]&#x27;);+---------------------------------------------------+| JSON_REMOVE(@j, &#x27;$[2]&#x27;, &#x27;$[1].b[1]&#x27;, &#x27;$[1].b[1]&#x27;) |+---------------------------------------------------+| [&quot;a&quot;, &#123;&quot;b&quot;: [true]&#125;] |+---------------------------------------------------+ 这三个path产生了如下的效果 $[2]找到匹配[10, 20]值, 然后将其删除掉. 第一个$[1].b[1]匹配到了false值, 然后将其删除掉. 第二个$[1].b[1]没有匹配到任何值, 因此该操作不会有任何结果. 归一化处理当一个字符串可以解析成一个有效的JSON文档, 它同时也会进行归一化处理. 当JSON中出现重复的Key时, 只会保留最开始的那个Key/Value, 接下来重复出现的都会抛弃掉. 123456mysql&gt; SELECT JSON_OBJECT(&#x27;key1&#x27;, 1, &#x27;key2&#x27;, &#x27;abc&#x27;, &#x27;key1&#x27;, &#x27;def&#x27;);+------------------------------------------------------+| JSON_OBJECT(&#x27;key1&#x27;, 1, &#x27;key2&#x27;, &#x27;abc&#x27;, &#x27;key1&#x27;, &#x27;def&#x27;) |+------------------------------------------------------+| &#123;&quot;key1&quot;: 1, &quot;key2&quot;: &quot;abc&quot;&#125; |+------------------------------------------------------+ Mysql的归一化处理还会对JSON对象的key进行排序处理(以便查找时提供更好的性能). The result of this ordering is subject to change and not guaranteed to be consistent across releases. 另外, key或者value之间的空格会自动的被忽略掉. 同样的, Mysql中创建JSON的方法同样也都做了归一化处理. 当多个数组合并成一个数组时, 数组元素会依次存储进新的数组中, 如下面的JSON_MERGE(): 123456mysql&gt; SELECT JSON_MERGE(&#x27;[1, 2]&#x27;, &#x27;[&quot;a&quot;, &quot;b&quot;]&#x27;, &#x27;[true, false]&#x27;);+-----------------------------------------------------+| JSON_MERGE(&#x27;[1, 2]&#x27;, &#x27;[&quot;a&quot;, &quot;b&quot;]&#x27;, &#x27;[true, false]&#x27;) |+-----------------------------------------------------+| [1, 2, &quot;a&quot;, &quot;b&quot;, true, false] |+-----------------------------------------------------+ 合并多个对象合并到一个对象中的时候, 如果多个对象中都出现了相同的key, 那么相同的key对应的value值会被放到该key对应的数组中. 123456mysql&gt; SELECT JSON_MERGE(&#x27;&#123;&quot;a&quot;: 1, &quot;b&quot;: 2&#125;&#x27;, &#x27;&#123;&quot;c&quot;: 3, &quot;a&quot;: 4&#125;&#x27;);+----------------------------------------------------+| JSON_MERGE(&#x27;&#123;&quot;a&quot;: 1, &quot;b&quot;: 2&#125;&#x27;, &#x27;&#123;&quot;c&quot;: 3, &quot;a&quot;: 4&#125;&#x27;) |+----------------------------------------------------+| &#123;&quot;a&quot;: [1, 4], &quot;b&quot;: 2, &quot;c&quot;: 3&#125; |+----------------------------------------------------+ 当非数组类型的数据出现在要求数组为参数的上下文中时, 非数组类型的数据会自动被包装成数组类型(会自动在数据俩侧添加[]将其括起来). 在下面的例子中, 每一个参数都会被自动包装成([1], [2]), 然后产生一个新的数组. 123456mysql&gt; SELECT JSON_MERGE(&#x27;1&#x27;, &#x27;2&#x27;);+----------------------+| JSON_MERGE(&#x27;1&#x27;, &#x27;2&#x27;) |+----------------------+| [1, 2] |+----------------------+ 当对象和数组进行合并时, 对象会自动的包装成一个数组, 然后将这俩个数组进行合并 123456mysql&gt; SELECT JSON_MERGE(&#x27;[10, 20]&#x27;, &#x27;&#123;&quot;a&quot;: &quot;x&quot;, &quot;b&quot;: &quot;y&quot;&#125;&#x27;);+------------------------------------------------+| JSON_MERGE(&#x27;[10, 20]&#x27;, &#x27;&#123;&quot;a&quot;: &quot;x&quot;, &quot;b&quot;: &quot;y&quot;&#125;&#x27;) |+------------------------------------------------+| [10, 20, &#123;&quot;a&quot;: &quot;x&quot;, &quot;b&quot;: &quot;y&quot;&#125;] |+------------------------------------------------+ 其他在下面我们看一下除了增删改查之外的其他常用函数 JSON_TYPE()JSON_TYPE()方法接受一个JSON串, 然后尝试解析它, 最后返回该JSON的数据类型 1234567891011121314151617mysql&gt; SELECT JSON_TYPE(&#x27;[&quot;a&quot;, &quot;b&quot;, 1]&#x27;);+----------------------------+| JSON_TYPE(&#x27;[&quot;a&quot;, &quot;b&quot;, 1]&#x27;) |+----------------------------+| ARRAY |+----------------------------+mysql&gt; SELECT JSON_TYPE(&#x27;&quot;hello&quot;&#x27;);+----------------------+| JSON_TYPE(&#x27;&quot;hello&quot;&#x27;) |+----------------------+| STRING |+----------------------+mysql&gt; SELECT JSON_TYPE(&#x27;hello&#x27;);ERROR 3146 (22032): Invalid data type for JSON data in argument 1to function json_type; a JSON string or JSON type is required. MySQL 使用utf8mb4编码和utf8mb4_bin集合处理JSON 字符串内容. 其他的编码会被转换成utf8mb4编码. (ascii 和 utf8 编码并不会进行转换, 因为这俩个字符集是utf8mb4的子集.) 创建JSON数组除了使用字面量JSON串之外, Mysql还提供了很多创建JSON串的方法. 例如JSON_ARRAY()`函数接受一个参数列表(个数大于等于0), 然后返回一个JSON字符串数组. 123456mysql&gt; SELECT JSON_ARRAY(&#x27;a&#x27;, 1, NOW());+----------------------------------------+| JSON_ARRAY(&#x27;a&#x27;, 1, NOW()) |+----------------------------------------+| [&quot;a&quot;, 1, &quot;2015-07-27 09:43:47.000000&quot;] |+----------------------------------------+ 创建JSON对象JSON_OBJECT()接受一个key/value形式的参数列表, 返回一个包含那些元素的JSON对象: 123456mysql&gt; SELECT JSON_OBJECT(&#x27;key1&#x27;, 1, &#x27;key2&#x27;, &#x27;abc&#x27;);+---------------------------------------+| JSON_OBJECT(&#x27;key1&#x27;, 1, &#x27;key2&#x27;, &#x27;abc&#x27;) |+---------------------------------------+| &#123;&quot;key1&quot;: 1, &quot;key2&quot;: &quot;abc&quot;&#125; |+---------------------------------------+ 变量赋值也可以将JSON赋给一个用户自定义的变量 1234567mysql&gt; SET @j = JSON_OBJECT(&#x27;key&#x27;, &#x27;value&#x27;);mysql&gt; SELECT @j;+------------------+| @j |+------------------+| &#123;&quot;key&quot;: &quot;value&quot;&#125; |+------------------+ 在上例中, 尽管JSON_OBJECT()方法会返回一个JSON类型对象, 但是当将其赋给一个变量(@j)时, 它就被自动转换成了一个字符串类型. JSON转换成的字符串, 它的编码是utf8mb4, 字符序为utf8mb4_bin: 123456mysql&gt; SELECT CHARSET(@j), COLLATION(@j);+-------------+---------------+| CHARSET(@j) | COLLATION(@j) |+-------------+---------------+| utf8mb4 | utf8mb4_bin |+-------------+---------------+ 因为utf8mb4_bin是一种二进制的字符序, 因此在对比俩个JSON值是区分大小写的. 123456mysql&gt; SELECT JSON_ARRAY(&#x27;x&#x27;) = JSON_ARRAY(&#x27;X&#x27;);+-----------------------------------+| JSON_ARRAY(&#x27;x&#x27;) = JSON_ARRAY(&#x27;X&#x27;) |+-----------------------------------+| 0 |+-----------------------------------+ 字面量区分大小写同样支持JSON的null, true, false等字面量. 因此在引用他们的时候一定要小写. 1234567891011121314mysql&gt; SELECT JSON_VALID(&#x27;null&#x27;), JSON_VALID(&#x27;Null&#x27;), JSON_VALID(&#x27;NULL&#x27;);+--------------------+--------------------+--------------------+| JSON_VALID(&#x27;null&#x27;) | JSON_VALID(&#x27;Null&#x27;) | JSON_VALID(&#x27;NULL&#x27;) |+--------------------+--------------------+--------------------+| 1 | 0 | 0 |+--------------------+--------------------+--------------------+mysql&gt; SELECT CAST(&#x27;null&#x27; AS JSON);+----------------------+| CAST(&#x27;null&#x27; AS JSON) |+----------------------+| null |+----------------------+1 row in set (0.00 sec) 转换123mysql&gt; SELECT CAST(&#x27;NULL&#x27; AS JSON);ERROR 3141 (22032): Invalid JSON text in argument 1 to function cast_as_json:&quot;Invalid value.&quot; at position 0 in &#x27;NULL&#x27;. JSON字面量区分大小写与SQL中的不同. 在SQL中NULL, TRUE, FALSE等字面量可以写成由任意大小写组成: 123456mysql&gt; SELECT ISNULL(null), ISNULL(Null), ISNULL(NULL);+--------------+--------------+--------------+| ISNULL(null) | ISNULL(Null) | ISNULL(NULL) |+--------------+--------------+--------------+| 1 | 1 | 1 |+--------------+--------------+--------------+ 比较和排序JSON文档里面的value可以通过如下操作符进行比较操作 = &lt; &lt;= = &lt;&gt; != &lt;=&gt; 下面的比较操作符和方法并不支持JSON值 BETWEEN IN() GREATEST() LEAST() 刚才列出的比较操作符和方法会将JSON值转换成MySQL原生的numeric或者string类型, 因此他们有一个consistent non-JSON扩展类型. JSON值进行比较时会先根据JSON类型进行比较, 如果类型不同的话, 比较结果就决定于更高优先级的类型. 如果类型一样的话, 则会根据指定类型原则进行比较. 下面列出了JSON类型的优先级, 从高到低进行排序. 我们可以通过JSON_TYPE()来获取某个值得类型. BLOB BIT OPAQUE DATETIME TIME DATE BOOLEAN ARRAY OBJECT STRING INTEGER, DOUBLE NULL如果JSON值拥有相同的优先级的话, 那么不同的类型或根据下面介绍的规则进行比较:","categories":[{"name":"数据库","slug":"数据库","permalink":"https://wangmingco.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://wangmingco.github.io/tags/mysql/"}]},{"title":"CRaSH 安装启动","slug":"JavaLibrary/CRaSH 命令行","date":"2016-05-14T16:00:00.000Z","updated":"2021-11-18T02:46:17.222Z","comments":true,"path":"2016/05/15/JavaLibrary/CRaSH 命令行/","link":"","permalink":"https://wangmingco.github.io/2016/05/15/JavaLibrary/CRaSH%20%E5%91%BD%E4%BB%A4%E8%A1%8C/","excerpt":"","text":"CRaSH 的全名是 Common Reusable SHell . 网上对其介绍是: 基于 Java 发布提供与 JVM 进行交互的 SHELL 环境. 作为入门, 这篇文章介绍一下, 作为单独程序的使用. 我在mac上使用brew安装上里CRaSH, 大家可以根据自己的环境自行安装. 我启动了一个SpringBoot HTTP服务, 然后使用CRaSH连接到这个服务上. 1234567891011121314151617181920import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.EnableAutoConfiguration;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.ResponseBody;@Controller@EnableAutoConfigurationpublic class HTTPServer &#123; @RequestMapping(&quot;/&quot;) @ResponseBody String home() &#123; return &quot;Hello World!&quot;; &#125; public static void main(String[] args) throws Exception &#123; SpringApplication.run(HTTPServer.class, args); &#125;&#125; 然后在命令行找到这个进程id 1234567891011121314151617181920➜ ~ jps -l467488 org.jetbrains.idea.maven.server.RemoteMavenServer696 com.intellij.rt.execution.application.AppMain697 org.jetbrains.jps.cmdline.Launcher845 sun.tools.jps.Jps➜ ~ crash.sh 696 _____ ________ _______ ____ ____ .&#x27; `. | `. .&#x27; `. | | | 1.3.0| | | | | | .-------. | | | | | || |____| | ` .&#x27; | _| | . &#x27;~_ ` | || | | | . `. .~&#x27; | | `~_ `| | || | | | | | | | | | | | | | | `._____.&#x27; |____|____| `.________| `._____.&#x27; |____|____|Follow and support the project on http://www.crashub.orgWelcome to localhost + !It is Sun May 15 10:44:03 CST 2016 now% 最后出现%说明我们已经连接到SpringBoot服务所在的虚拟机里了. 同样的在SpringBoot服务的日志里也有输出 12345678910111213142016-05-15 10:44:00.005 INFO 696 --- [Attach Listener] org.crsh.standalone.Agent : CRaSH agent loaded2016-05-15 10:44:00.007 INFO 696 --- [Attach Listener] org.crsh.standalone.Agent : Spawned CRaSH thread 23 for further processing2016-05-15 10:44:00.097 INFO 696 --- [ Thread-3] org.crsh.standalone.Bootstrap : Configuring property vfs.refresh_period=1 from properties2016-05-15 10:44:00.203 INFO 696 --- [ Thread-3] org.crsh.standalone.Bootstrap : Configuring property ssh.port=2000 from properties2016-05-15 10:44:00.203 INFO 696 --- [ Thread-3] org.crsh.standalone.Bootstrap : Configuring property ssh.auth_timeout=600000 from properties2016-05-15 10:44:00.204 INFO 696 --- [ Thread-3] org.crsh.standalone.Bootstrap : Configuring property ssh.idle_timeout=600000 from properties2016-05-15 10:44:00.204 INFO 696 --- [ Thread-3] org.crsh.standalone.Bootstrap : Configuring property ssh.default_encoding=UTF-8 from properties2016-05-15 10:44:00.204 INFO 696 --- [ Thread-3] org.crsh.standalone.Bootstrap : Configuring property auth=simple from properties2016-05-15 10:44:00.204 INFO 696 --- [ Thread-3] org.crsh.standalone.Bootstrap : Configuring property telnet.port=5000 from properties2016-05-15 10:44:00.204 INFO 696 --- [ Thread-3] org.crsh.standalone.Bootstrap : Configuring property mail.debug=false from properties2016-05-15 10:44:00.205 INFO 696 --- [ Thread-3] org.crsh.standalone.Bootstrap : Configuring property auth.simple.username=admin from properties2016-05-15 10:44:00.205 INFO 696 --- [ Thread-3] org.crsh.standalone.Bootstrap : Configuring property auth.simple.password=admin from properties2016-05-15 10:44:02.111 INFO 696 --- [ Thread-6] net.wimpi.telnetd.net.PortListener : Listening to Port 5,000 with a connectivity queue size of 5.2016-05-15 10:44:02.700 INFO 696 --- [ Thread-3] org.crsh.standalone.Agent : Callback back remote on port 50656 当我们在启动时, 还可以指定一些参数设置 --cmd : 这个选项用于指定, 我们要执行的命令所在的目录. 如果不指定的话, 会默认地从当前classpath下的/crash/commands/进行查找 --conf : 用于指定配置文件所在的目录, 可以指定多个目录 --property : --cmd可选参数, 可以覆盖配置文件中的配置, 示例crash.sh --property crash.telnet.port=3000 下面我们看一下在CRaSH中都可以使用哪些命令 1234567891011121314151617181920212223242526272829% helpTry one of these commands with the -h or --help switch:NAME DESCRIPTIONclockcron manages the cron plugindashboard a monitoring dashboarddate show the current timeegrep search file(s) for lines that match a patternenv display the term envfilter a filter for a stream of maphellojava various java language commandsjdbc JDBC connectionjmx Java Management Extensionsjndi Java Naming and Directory Interfacejpa Java persistance APIjul java.util.logging commandsjvm JVM informationsless opposite of moremail interact with emailsman format and display the on-line manual pagesshell shell related commandsleep sleep for some timesort sort a mapsystem vm system properties commandsthread JVM thread commandshelp provides basic helprepl list the repl or change the current repl CRaSH为我们提供了非常多的命令, 对于命令的具体用法, 大家可以使用jvm --help这样的用法具体看一下. CRaSH还提供了pipline, 我们可以使用|管道符使用多个命令. 具体的命令这篇文章就不再多介绍了, 下面我们看一下如何将CRaSH内嵌到Spring里. 为了简单, 我并没有直接使用CRaSH官网里介绍的那样, 使用xml配置Spring 1234567891011121314151617181920212223import org.crsh.spring.SpringBootstrap;import java.util.Properties;import java.util.concurrent.TimeUnit;public class Main &#123; public static void main(String[] args) throws InterruptedException &#123; SpringBootstrap springBootstrap = new SpringBootstrap(); Properties properties = new Properties(); properties.setProperty(&quot;crash.vfs.refresh_period&quot;, &quot;1&quot;); properties.setProperty(&quot;crash.ssh.port&quot;, &quot;2000&quot;); properties.setProperty(&quot;crash.ssh.idle_timeout&quot;, &quot;3000000&quot;); properties.setProperty(&quot;crash.telnet.port&quot;, &quot;5000&quot;); properties.setProperty(&quot;crash.ssh.auth_timeout&quot;, &quot;300000&quot;); properties.setProperty(&quot;crash.auth&quot;, &quot;simple&quot;); properties.setProperty(&quot;crash.auth.simple.username&quot;, &quot;admin&quot;); properties.setProperty(&quot;crash.auth.simple.password&quot;, &quot;admin&quot;); springBootstrap.setConfig(properties); TimeUnit.DAYS.sleep(1); &#125;&#125; 然后启动一个客户端 123456789101112131415161718➜ ~ telnet localhost 5000Trying ::1...Connected to localhost.Escape character is &#x27;^]&#x27;. _____ ________ _______ ____ ____ .&#x27; `. | `. .&#x27; `. | | | 1.3.0| | | | | | .-------. | | | | | || |____| | ` .&#x27; | _| | . &#x27;~_ ` | || | | | . `. .~&#x27; | | `~_ `| | || | | | | | | | | | | | | | | `._____.&#x27; |____|____| `.________| `._____.&#x27; |____|____|Follow and support the project on http://www.crashub.orgWelcome to localhost + !It is Sun May 15 11:29:56 CST 2016 now% 通过telnet, 我们也成功连接进来了. 这个需要添加的CRaSH的maven依赖有 123456789101112131415161718192021222324252627&lt;!-- http://mvnrepository.com/artifact/org.crashub/crash.shell --&gt;&lt;dependency&gt; &lt;groupId&gt;org.crashub&lt;/groupId&gt; &lt;artifactId&gt;crash.shell&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt;&lt;/dependency&gt;&lt;!-- http://mvnrepository.com/artifact/org.crashub/crash.cli --&gt;&lt;dependency&gt; &lt;groupId&gt;org.crashub&lt;/groupId&gt; &lt;artifactId&gt;crash.cli&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt;&lt;/dependency&gt;&lt;!-- http://mvnrepository.com/artifact/org.crashub/crash.packaging --&gt;&lt;dependency&gt; &lt;groupId&gt;org.crashub&lt;/groupId&gt; &lt;artifactId&gt;crash.packaging&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt;&lt;/dependency&gt;&lt;!-- http://mvnrepository.com/artifact/org.crashub/crash.embed.spring --&gt;&lt;dependency&gt; &lt;groupId&gt;org.crashub&lt;/groupId&gt; &lt;artifactId&gt;crash.embed.spring&lt;/artifactId&gt; &lt;version&gt;1.3.2&lt;/version&gt;&lt;/dependency&gt;","categories":[{"name":"Java 类库","slug":"Java-类库","permalink":"https://wangmingco.github.io/categories/Java-%E7%B1%BB%E5%BA%93/"}],"tags":[{"name":"CRaSH","slug":"CRaSH","permalink":"https://wangmingco.github.io/tags/CRaSH/"}]},{"title":"Log4J2 笔记","slug":"JavaLibrary/log4j2","date":"2016-05-11T16:00:00.000Z","updated":"2021-11-18T02:48:11.455Z","comments":true,"path":"2016/05/12/JavaLibrary/log4j2/","link":"","permalink":"https://wangmingco.github.io/2016/05/12/JavaLibrary/log4j2/","excerpt":"","text":"示例Log4J2会使用ConfigurationFactory从classpath上依次尝试加载下面的配置文件, 一旦找到就停止查找过程 log4j.configurationFil log4j2-test.properties log4j2-test.yaml or log4j2-test.yml log4j2-test.json or log4j2-test.jsn log4j2-test.xml log4j2.properties log4j2.yaml or log4j2.yml log4j2.json or log4j2.jsn log4j2.xml从上面的配置文件,我们可以看到Log4J2支持, JSON, YAML, properties, XML 等四种格式的配置文件. 如果找不到配置文件的话, 就会使用默认的配置 想root logger 关联一个ConsoleAppender (root logger的默认等级是Level.ERROR) ConsoleAppender指定一个PatternLayout, 其格式内容为%d&#123;HH:mm:ss.SSS&#125; [%t] %-5level %logger&#123;36&#125; - %msg%n 官网给出了一个简单的示例 123456789101112131415161718192021222324252627282930313233343536import com.foo.Bar;import org.apache.logging.log4j.Logger;import org.apache.logging.log4j.LogManager; public class MyApp &#123; // Define a static logger variable so that it references the // Logger instance named &quot;MyApp&quot;. private static final Logger logger = LogManager.getLogger(MyApp.class); public static void main(final String... args) &#123; // Set up a simple configuration that logs on the console. logger.trace(&quot;Entering application.&quot;); Bar bar = new Bar(); if (!bar.doIt()) &#123; logger.error(&quot;Didn&#x27;t do it.&quot;); &#125; logger.trace(&quot;Exiting application.&quot;); &#125;&#125;package com.foo;import org.apache.logging.log4j.Logger;import org.apache.logging.log4j.LogManager; public class Bar &#123; static final Logger logger = LogManager.getLogger(Bar.class.getName()); public boolean doIt() &#123; logger.entry(); logger.error(&quot;Did it again!&quot;); return logger.exit(false); &#125;&#125; 配置文件为 12345678910111213&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;Configuration status=&quot;WARN&quot; monitorInterval=&quot;30&quot;&gt; &lt;Appenders&gt; &lt;Console name=&quot;Console&quot; target=&quot;SYSTEM_OUT&quot;&gt; &lt;PatternLayout pattern=&quot;%d&#123;HH:mm:ss.SSS&#125; [%t] %-5level %logger&#123;36&#125; - %msg%n&quot;/&gt; &lt;/Console&gt; &lt;/Appenders&gt; &lt;Loggers&gt; &lt;Root level=&quot;error&quot;&gt; &lt;AppenderRef ref=&quot;Console&quot;/&gt; &lt;/Root&gt; &lt;/Loggers&gt;&lt;/Configuration&gt; 输出结果为 12345617:13:01.540 [main] TRACE MyApp - Entering application.17:13:01.540 [main] TRACE com.foo.Bar - entry17:13:01.540 [main] ERROR com.foo.Bar - Did it again!17:13:01.540 [main] TRACE com.foo.Bar - exit with (false)17:13:01.540 [main] ERROR MyApp - Didn&#x27;t do it.17:13:01.540 [main] TRACE MyApp - Exiting application. 我们在配置里使用了一个monitorInterval属性, 这个属性是用来监控日志文件的, 每隔多少秒刷新一次. 下面我们展示一个只有com.foo.Bar才会trace全部日志, 而其他的日志则只会输出ERROR级别的. 12345678910111213141516&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;Configuration status=&quot;WARN&quot;&gt; &lt;Appenders&gt; &lt;Console name=&quot;Console&quot; target=&quot;SYSTEM_OUT&quot;&gt; &lt;PatternLayout pattern=&quot;%d&#123;HH:mm:ss.SSS&#125; [%t] %-5level %logger&#123;36&#125; - %msg%n&quot;/&gt; &lt;/Console&gt; &lt;/Appenders&gt; &lt;Loggers&gt; &lt;Logger name=&quot;com.foo.Bar&quot; level=&quot;trace&quot; additivity=&quot;false&quot;&gt; &lt;AppenderRef ref=&quot;Console&quot;/&gt; &lt;/Logger&gt; &lt;Root level=&quot;error&quot;&gt; &lt;AppenderRef ref=&quot;Console&quot;/&gt; &lt;/Root&gt; &lt;/Loggers&gt;&lt;/Configuration&gt; 结果为 123417:13:01.540 [main] TRACE com.foo.Bar - entry17:13:01.540 [main] ERROR com.foo.Bar - Did it again!17:13:01.540 [main] TRACE com.foo.Bar - exit (false)17:13:01.540 [main] ERROR MyApp - Didn&#x27;t do it. 需要注意的是,我们在com.foo.Bar这个Logger后面添加了一个additivity=&quot;false&quot;的属性. 关于日志级别我们来测试一下, 我们写一个Java程序 123456789101112public class TestLevel &#123; static final Logger logger = LogManager.getLogger(TestLookups.class.getName()); public static void main(String[] args) &#123; logger.trace(&quot;test&quot;); logger.debug(&quot;test&quot;); logger.info(&quot;test&quot;); logger.warn(&quot;test&quot;); logger.error(&quot;test&quot;); &#125;&#125; log4j2的配置文件为 123456789101112131415&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;Configuration status=&quot;WARN&quot; monitorInterval=&quot;30&quot;&gt; &lt;Appenders&gt; &lt;Console name=&quot;Console&quot; target=&quot;SYSTEM_OUT&quot;&gt; &lt;PatternLayout&gt; &lt;pattern&gt;%d %p %c&#123;1.&#125; [%t] $$&#123;ctx:loginId&#125; %m%n&lt;/pattern&gt; &lt;/PatternLayout&gt; &lt;/Console&gt; &lt;/Appenders&gt; &lt;Loggers&gt; &lt;Root level=&quot;trace&quot;&gt; &lt;AppenderRef ref=&quot;Console&quot;/&gt; &lt;/Root&gt; &lt;/Loggers&gt;&lt;/Configuration&gt; 结果为 123452016-05-12 18:29:55,570 TRACE t.TestLookups [main] $&#123;ctx:loginId&#125; test2016-05-12 18:29:55,571 DEBUG t.TestLookups [main] $&#123;ctx:loginId&#125; test2016-05-12 18:29:55,572 INFO t.TestLookups [main] $&#123;ctx:loginId&#125; test2016-05-12 18:29:55,572 WARN t.TestLookups [main] $&#123;ctx:loginId&#125; test2016-05-12 18:29:55,572 ERROR t.TestLookups [main] $&#123;ctx:loginId&#125; test 级别改为debug后结果为 12342016-05-12 18:30:13,574 DEBUG t.TestLookups [main] $&#123;ctx:loginId&#125; test2016-05-12 18:30:13,575 INFO t.TestLookups [main] $&#123;ctx:loginId&#125; test2016-05-12 18:30:13,575 WARN t.TestLookups [main] $&#123;ctx:loginId&#125; test2016-05-12 18:30:13,575 ERROR t.TestLookups [main] $&#123;ctx:loginId&#125; test 级别改为info后结果为 1232016-05-12 18:30:43,042 INFO t.TestLookups [main] $&#123;ctx:loginId&#125; test2016-05-12 18:30:43,043 WARN t.TestLookups [main] $&#123;ctx:loginId&#125; test2016-05-12 18:30:43,044 ERROR t.TestLookups [main] $&#123;ctx:loginId&#125; test 级别改为warn后结果为 122016-05-12 18:31:18,095 WARN t.TestLookups [main] $&#123;ctx:loginId&#125; test2016-05-12 18:31:18,096 ERROR t.TestLookups [main] $&#123;ctx:loginId&#125; test 级别改为error后结果为 12016-05-12 18:31:43,894 ERROR t.TestLookups [main] $&#123;ctx:loginId&#125; test 如果出现重复日志输出, 多半原因因为, root收集到了子logger反馈的日志, 只需要将子logger设置为additivity=&quot;false&quot;就可以了,例如 123456789101112131415161718&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;Configuration status=&quot;WARN&quot; monitorInterval=&quot;30&quot;&gt; &lt;Appenders&gt; &lt;Console name=&quot;Console&quot; target=&quot;SYSTEM_OUT&quot;&gt; &lt;PatternLayout&gt; &lt;pattern&gt;%d %p %c&#123;1.&#125; [%t] $$&#123;ctx:loginId&#125; %m%n&lt;/pattern&gt; &lt;/PatternLayout&gt; &lt;/Console&gt; &lt;/Appenders&gt; &lt;Loggers&gt; &lt;Logger name=&quot;stdout&quot; level=&quot;info&quot; additivity=&quot;false&quot;&gt; &lt;appender-ref ref=&quot;Console&quot;/&gt; &lt;/Logger&gt; &lt;Root level=&quot;trace&quot;&gt; &lt;AppenderRef ref=&quot;Console&quot;/&gt; &lt;/Root&gt; &lt;/Loggers&gt;&lt;/Configuration&gt; 动态修改日志级别 12345678910111213final LoggerContext ctx = (LoggerContext) LogManager.getContext(false);final Configuration config = ctx.getConfiguration();LoggerConfig loggerConfig = config.getLoggerConfig(logger.getName());LoggerConfig specificConfig = loggerConfig;if (!loggerConfig.getName().equals(logger.getName())) &#123; specificConfig = new LoggerConfig(logger.getName(), level, true); specificConfig.setParent(loggerConfig); config.addLogger(logger.getName(), specificConfig);&#125;specificConfig.setLevel(level);ctx.updateLoggers(); AppenderLog4j2为我们提供了非常多的Appender, 我们就是通过Appender最终将日志输出到磁盘的. Async Console Failover File Flume JDBC JMS Queue JMS Topic JPA Kafka Memory Mapped File NoSQL Output Stream Random Access File Rewrite Rolling File Rolling Random Access File Routing SMTP Socket Syslog ZeroMQ/JeroMQ AsyncAppender首先我们看一下AsyncAppender。 AsyncAppender通过一个单独的线程将LogEvent发送给它内部代理的其他的Appender，业务逻辑线程可以快速返回调用。AsyncAppender内部封装了一个java.util.concurrent.ArrayBlockingQueue用于接收日志事件。在多线程的情况下并不推荐使用这个Appender，因为BlockingQueue对于锁争夺是非常敏感的，在多线程并发写日志的时候，性能会下降。官方推荐使用lock-free Async Loggers 下来我们看一下这个Appender的几个重点参数 blocking：如果设置为tue的话(默认值), 当BlockingQueue满的时候，新的日志文件会一直阻塞, 直到可以入列为止. 如果为false的话, 不能入列的日志会被写到 error appender 里。 bufferSize：队列里的最大日志事件数量(默认是128) errorRef：当没有Appender可用或者写日志发生错误或者队列满的时候，新的日志事件会被写到这个errorRef里。如果不设置的话，那些日志都会丢失123456789101112131415161718&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;Configuration status=&quot;warn&quot; name=&quot;MyApp&quot; packages=&quot;&quot;&gt; &lt;Appenders&gt; &lt;File name=&quot;MyFile&quot; fileName=&quot;logs/app.log&quot;&gt; &lt;PatternLayout&gt; &lt;Pattern&gt;%d %p %c&#123;1.&#125; [%t] %m%n&lt;/Pattern&gt; &lt;/PatternLayout&gt; &lt;/File&gt; &lt;Async name=&quot;Async&quot;&gt; &lt;AppenderRef ref=&quot;MyFile&quot;/&gt; &lt;/Async&gt; &lt;/Appenders&gt; &lt;Loggers&gt; &lt;Root level=&quot;error&quot;&gt; &lt;AppenderRef ref=&quot;Async&quot;/&gt; &lt;/Root&gt; &lt;/Loggers&gt;&lt;/Configuration&gt; MemoryMappedFileAppenderMemoryMappedFileAppender是在2.1的版本是行新增加的。 其通过将指定的文件映射到内存，然后将日志直接写到映射内存里。这个Appender主要依赖于操作系统的虚拟内存将映射内存里的数据同步到磁盘上。相比与传统的通过系统调用方式将数据写到磁盘上，这里只是将数据同步到内存里。速度提升了很多倍。在大多数的操作系统里，memory region实际上映射的是内核区的page cache，这意味着，在用户空间之内就不需要再创建一份数据拷贝了。 但是将一个文件映射到内存里还是有一些消耗的，特别是映射一些特别大的文件(500M以上)，默认的region大小是32M。 和FileAppender和RandomAccessFileAppender很像，MemoryMappedFileAppender使用MemoryMappedFileManager来执行IO操作。 同样的来看几个比较重要的属相 append：新的日志事件是否追加在日志文件末尾（如果不是原先的内容会被刷新掉） regionLength：映射的region的大小，默认是32M。这个值必须在256和1,073,741,824字节之间。 123456789101112131415&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;Configuration status=&quot;warn&quot; name=&quot;MyApp&quot; packages=&quot;&quot;&gt; &lt;Appenders&gt; &lt;MemoryMappedFile name=&quot;MyFile&quot; fileName=&quot;logs/app.log&quot;&gt; &lt;PatternLayout&gt; &lt;Pattern&gt;%d %p %c&#123;1.&#125; [%t] %m%n&lt;/Pattern&gt; &lt;/PatternLayout&gt; &lt;/MemoryMappedFile&gt; &lt;/Appenders&gt; &lt;Loggers&gt; &lt;Root level=&quot;error&quot;&gt; &lt;AppenderRef ref=&quot;MyFile&quot;/&gt; &lt;/Root&gt; &lt;/Loggers&gt;&lt;/Configuration&gt; RandomAccessFileAppenderRandomAccessFileAppender与标准的FileAppender非常像, 只不过RandomAccessFileAppender不能像FileAppender关闭缓冲功能。RandomAccessFileAppender内部使用ByteBuffer 和 RandomAccessFile实现(FileAppender基于BufferedOutputStream) 在官方的测试中RandomAccessFileAppender比开启了缓冲功能的FileAppender的性能提升了20 ~ 200倍. append:新的日志事件是否追加在日志文件末尾（如果不是原先的内容会被刷新掉） immediateFlush: 设置为true的话(默认为true)，每一次写入都会强制执行一次flush, 这种情况下回保证数据肯定被写到磁盘上,但是对性能有消耗. 只有当使用同步logger的时候，每一次写入日志都flush才有意义。这是因为当使用异步logger或者Appender的时候，当events达到固定数量的时候回自动执行flush操作（即使immediateFlush为false,也会执行刷新），使用异步的方式同样保证数据会写入到磁盘而且更高效。 bufferSize：缓冲大小，默认是 262,144 bytes (256 * 1024).123456789101112131415&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;Configuration status=&quot;warn&quot; name=&quot;MyApp&quot; packages=&quot;&quot;&gt; &lt;Appenders&gt; &lt;RandomAccessFile name=&quot;MyFile&quot; fileName=&quot;logs/app.log&quot;&gt; &lt;PatternLayout&gt; &lt;Pattern&gt;%d %p %c&#123;1.&#125; [%t] %m%n&lt;/Pattern&gt; &lt;/PatternLayout&gt; &lt;/RandomAccessFile&gt; &lt;/Appenders&gt; &lt;Loggers&gt; &lt;Root level=&quot;error&quot;&gt; &lt;AppenderRef ref=&quot;MyFile&quot;/&gt; &lt;/Root&gt; &lt;/Loggers&gt;&lt;/Configuration&gt; 异步日志采用异步的方式记录日志首先是AsyncLogger 异步日志通过在单独的线程中记录日志，能快速地返回日志调用。通常来说如果所有的logger都采用异步的方式的话，能获得最好的性能 异步日志内部采用了Disruptor取代了java内部队列。这个特性能获得更高的吞吐量和更低的延迟。 异步日志通过缓存方式，批量将日志输出尽管异步日志有诸多特性，但是有时候仍然是需要采用同步地方式记录日志。我们下来首先看一下异步日志的优点： 更高的吞吐量。异步日志与同步方式相比，它能提供6~68倍的日志输出量。当突然遇到日志洪峰时,采用异步方式能获得更快地日志响应 更低的延迟. 异步日志比同步方式记录日志和采用基于队列实现的异步日志方式都获得了更低的延迟。下面我们再看看异步记录方式的缺点 当在写日志的时候，如果发生了问题或者抛出了异常，使用异步记录方式很难定位问题究竟是出现在哪里。因此在异步日志里推荐配置一个ExceptionHandler，但是哪怕配置了一个handler，仍然有可能出现日志丢失等问题。因为对于日志依赖严重的地方，推荐使用同步方式记录日志 在单核的情况下，异步日志并不能获得更好地性能。当然现在的服务器动辄就是16核，32核，这个情况一般就不考虑了。最后我们看一下如果所有的日志都采用异步方式的配置方式1-DLog4jContextSelector=org.apache.logging.log4j.core.async.AsyncLoggerContextSelector 当我们在java进程的启动脚本里进行了这样的配置后(我们也可以在程序启动后再系统属性里进行设置)，log4j会采用AsyncLoggerContextSelector进行异步日志输出。但是在配置文件里要使用&lt;root&gt;和&lt;logger&gt;,不能使用&lt;asyncRoot&gt;和&lt;asyncLogger&gt;, 因为这种异步的logger是为了在同步异步混合logger的时候使用的。","categories":[{"name":"Java 类库","slug":"Java-类库","permalink":"https://wangmingco.github.io/categories/Java-%E7%B1%BB%E5%BA%93/"}],"tags":[{"name":"Log4J2","slug":"Log4J2","permalink":"https://wangmingco.github.io/tags/Log4J2/"}]},{"title":"Oracle® Solaris Studio","slug":"JavaLibrary/Oracle Solaris Studio","date":"2016-05-10T16:00:00.000Z","updated":"2021-11-18T02:48:53.888Z","comments":true,"path":"2016/05/11/JavaLibrary/Oracle Solaris Studio/","link":"","permalink":"https://wangmingco.github.io/2016/05/11/JavaLibrary/Oracle%20Solaris%20Studio/","excerpt":"","text":"在Centos上安装Oracle® Solaris Studio. 中文教程 首先执行下列命令 12345yum install glibcyum install elfutils-libelf-develyum install zlibyum install libstdc++yum install libgcc 执行完之后, 会将下列依赖包安装完成 123456789101112glibcglibc.i686glibc-develglibc-devel.i686elfutils-libelf-devel elfutils-libelf-devel.i686zlibzlib.i686libstdc++libstdc++.i686libgcclibgcc.i686 在下载界面下载Oracle Linux/ Red Hat Linux - RPM installer on x86 运行命令解压bzcat download_directory/SolarisStudio12.4-linux-x86-rpm.tar.bz2 | /bin/tar -xf - 进行安装./solarisstudio.sh --non-interactive (包含GUI, 也就是我们可以在Linux的桌面上打开Solaris Studio IDE) 验证是否安装成功/opt/oracle/solarisstudio12.4/bin/analyzer -v 安装完成后会显示 123456Configuring the installer...Searching for JVM on the system...Extracting installation data (can take a while, please wait)...Running the installer wizard.../tmp/ossi-c2x_test-20160509142618.silent.log:[2016-05-09 14:26:18.764]: WARNING - Your OS distribution is not supported. The list of supported systems can be found in the Oracle Solaris Studio documentation. While it might be possible to install Oracle Solaris Studio on your system, it might not function properly. 运行analyzer -v显示 12345678analyzer: Oracle Solaris Studio 12.4 Performance Analyzer 12.4 Linux_x64 2014/10/21Java at /usr/java/jdk1.8.0_25/bin/java selected by PATHjava version &quot;1.8.0_25&quot;Java(TM) SE Runtime Environment (build 1.8.0_25-b17)Java HotSpot(TM) 64-Bit Server VM (build 25.25-b02, mixed mode)WARNING: Linux CentOS_6.7 system &quot;c2x_test&quot; is not supported by the Performance tools.Running /usr/java/jdk1.8.0_25/bin/java -version/opt/oracle/solarisstudio12.4/bin/analyzer: ERROR: environment variable DISPLAY is not set 额外事项 卸载程序 /opt/oracle/solarisstudio12.4/uninstall.sh --non-interactive 如果安装时不想要GUI, 只需要在后面加上--libraries-only就好了 设置环境变量 vi /ect/profile 修改 PATH=$PATH:/opt/oracle/solarisstudio12.4/bin/","categories":[{"name":"性能监控","slug":"性能监控","permalink":"https://wangmingco.github.io/categories/%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/"}],"tags":[]},{"title":"Mysql 第二索引和虚拟列","slug":"数据库/Mysql Secondary Indexes and Generated Virtual Columns","date":"2016-05-09T16:00:00.000Z","updated":"2021-11-18T02:53:49.300Z","comments":true,"path":"2016/05/10/数据库/Mysql Secondary Indexes and Generated Virtual Columns/","link":"","permalink":"https://wangmingco.github.io/2016/05/10/%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql%20Secondary%20Indexes%20and%20Generated%20Virtual%20Columns/","excerpt":"","text":"官方文档 Generated Columnsgenerated column是由普通column生成的列. 1234567891011121314CREATE TABLE sum ( num1 int, num2 int, sum int AS (num1 + num2));INSERT INTO sum (num1, num2) VALUES(1,1),(3,4);mysql&gt; SELECT * FROM sum;+-------+-------+--------------------+| num1 | num2 | sum |+-------+-------+--------------------+| 1 | 1 | 2 || 3 | 4 | 7 |+-------+-------+--------------------+ 在上面的实例中我们首先创建了一个sum表，然后插入俩条数据数据 我们发现sum这一列上自动生成一个值 这种自动生成列的语法为为 123col_name data_type [GENERATED ALWAYS] AS (expression) [VIRTUAL | STORED] [UNIQUE [KEY]] [COMMENT comment] [[NOT] NULL] [[PRIMARY] KEY] VIRTUAL: 不存储值到磁盘上 STORED : 将值存储到磁盘上 Secondary Indexes从MySQL5.7.8开始, InnoDB引擎基于自生成(generated virtual columns)的虚拟列支持辅助索引索引(secondary indexes, 并不支持其他索引, 例如簇索引等). secondary indexe可以基于一个, 多个, 组合virtual columns或者非generated virtual columns生成。当基于virtual column的secondary index可以由UNIQUE进行定义. 当基于generated virtual column创建的secondary index, generated column的值就体现在了这个secondary index的记录上. 如果这个索引是一个covering index, generated column值是从索引中已经生成的值进行索引, 而不是再自己计算一遍. covering index 查询时检索所有的column. 在执行INSERT和UPDATE这样的写操作时, 如果用到了基于virtual column的辅助索引时, 那么生成virtual column时会产生额外的性能消耗. 甚至当使用STORED generated columns时, 写操作会带来更多的性能消耗, 还有更多的内存和磁盘消耗. 如果secondary index不是基于virtual column, 当产生读操作时会带来更多的性能消耗, 这是因为virtual column的值每当该column的列被检查时都会计算一次. 当发生回滚或者清除操作时, 被索引过的virtual column已经经过里MVCC-logged, 如此一来就可以以避免再计算一次. logged值的长度是由索引长度限制的, COMPACT和REDUNDANT是767字节, DYNAMIC和COMPRESSED是3072个字节. 在virtual column 上增加或者删除secondary index是一个内置的操作. virtual column 上的secondary index不能成为外键的索引. 同样secondary index的virtual column也不能指向外键, 而且也不能使用如下的语句定义 ON DELETE CASCADE ON DELETE SET NULL ON UPDATE CASCADE ON UPDATE SET NULL. Generated Virtual Column索引JSON Column上JSON columns是不能被直接索引的. 但是我们可以通过创建一个generated column来间接为JSON columns生成一个索引, 如下例: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647mysql&gt; CREATE TABLE jemp ( -&gt; c JSON, -&gt; g INT GENERATED ALWAYS AS (JSON_EXTRACT(c, &#x27;$.id&#x27;)), -&gt; INDEX i (g) -&gt; );Query OK, 0 rows affected (0.28 sec)mysql&gt; INSERT INTO jemp (c) VALUES &gt; (&#x27;&#123;&quot;id&quot;: &quot;1&quot;, &quot;name&quot;: &quot;Fred&quot;&#125;&#x27;), (&#x27;&#123;&quot;id&quot;: &quot;2&quot;, &quot;name&quot;: &quot;Wilma&quot;&#125;&#x27;), &gt; (&#x27;&#123;&quot;id&quot;: &quot;3&quot;, &quot;name&quot;: &quot;Barney&quot;&#125;&#x27;), (&#x27;&#123;&quot;id&quot;: &quot;4&quot;, &quot;name&quot;: &quot;Betty&quot;&#125;&#x27;);Query OK, 4 rows affected (0.04 sec)Records: 4 Duplicates: 0 Warnings: 0mysql&gt; SELECT JSON_UNQUOTE(JSON_EXTRACT(c, &#x27;$.name&#x27;)) AS name &gt; FROM jemp WHERE g &gt; 2;+--------+| name |+--------+| Barney || Betty |+--------+2 rows in set (0.00 sec)mysql&gt; EXPLAIN SELECT JSON_UNQUOTE(JSON_EXTRACT(c, &#x27;$.name&#x27;)) AS name &gt; FROM jemp WHERE g &gt; 2\\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: jemp partitions: NULL type: rangepossible_keys: i key: i key_len: 5 ref: NULL rows: 2 filtered: 100.00 Extra: Using where1 row in set, 1 warning (0.00 sec)mysql&gt; SHOW WARNINGS\\G*************************** 1. row *************************** Level: Note Code: 1003Message: /* select#1 */ select json_unquote(json_extract(`test`.`jemp`.`c`,&#x27;$.name&#x27;))AS `name` from `test`.`jemp` where (`test`.`jemp`.`g` &gt; 2)1 row in set (0.00 sec) 关于上例中创建表的更多信息参考 Section 9.3.9, “Optimizer Use of Generated Column Indexes” 在Mysql 5.7.9以后, 你可以使用-&gt;替代JSON_EXTRACT()作为path访问JSON列. 当你使用EXPLAIN的语句中包含了一个或者多个-&gt;操作符时, 它们会被JSON_EXTRACT()进行替换. 12345678910111213141516171819202122232425mysql&gt; EXPLAIN SELECT c-&gt;&quot;$.name&quot; &gt; FROM jemp WHERE g &gt; 2\\G ORDER BY c-&gt;&quot;$.name&quot;*************************** 1. row *************************** id: 1 select_type: SIMPLE table: jemp partitions: NULL type: rangepossible_keys: i key: i key_len: 5 ref: NULL rows: 2 filtered: 100.00 Extra: Using where; Using filesort1 row in set, 1 warning (0.00 sec)mysql&gt; SHOW WARNINGS\\G*************************** 1. row *************************** Level: Note Code: 1003Message: /* select#1 */ select json_extract(`test`.`jemp`.`c`,&#x27;$.name&#x27;) AS`c-&gt;&quot;$.name&quot;` from `test`.`jemp` where (`test`.`jemp`.`g` &gt; 2) order byjson_extract(`test`.`jemp`.`c`,&#x27;$.name&#x27;) 1 row in set (0.00 sec)","categories":[{"name":"数据库","slug":"数据库","permalink":"https://wangmingco.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://wangmingco.github.io/tags/mysql/"}]},{"title":"JMeter","slug":"JavaLibrary/JMeter","date":"2016-05-08T16:00:00.000Z","updated":"2021-11-18T02:48:04.376Z","comments":true,"path":"2016/05/09/JavaLibrary/JMeter/","link":"","permalink":"https://wangmingco.github.io/2016/05/09/JavaLibrary/JMeter/","excerpt":"","text":"Aggregate report使用JMeter压测服务器登录压力,首先给出几张图看一下我们的配置 最后一张图是概要结果, 测试GameCenter结果.csv 是聚合报告结果 这个是我们要配置的统计结果, 我们只统计了延迟, 耗时以及消息的字节数. 下面我们看一下, JMeter官方对Aggregate report(聚合报告)的说明: 聚合报告为每个不同名的Sampler(注意是不同名的哦)都创建了一个结果记录. 在结果记录中不仅仅统计了请求响应信息, 还提供了对请求的数，最小延迟值，最大延迟值，平均延迟，请求产生的错误比，吞吐量以及每秒吞吐产生的字节数的统计。JMeter在统计时已经考虑了生成消息所消耗的时间. 如果其他的采样器以及定时器在同一个线程中, 那么这将会增加总的时间统计, 从而降低吞吐量. 因此俩个名称不相同的采样器产生的吞吐量加在一起才是总的吞吐量. 在聚合报告中, 计算Median和90% Line值需要消耗额外的内存. JMeter现在将耗时相同的采样都合并到了一起,如此一来可以尽量减少内存占用．然而在某些情况下， 可能还会产生大量消耗内存的情况，因此推荐的方式是使用listener，然后从CSV或者XML文件中重新加载结果进行计算. Label - 统计标签 Samples - 相同名称的标签下采样的次数 Average - 统计数据结果的平均耗时时间 Median - 统计数据中中间的耗时时间, 50%的采样不会超过这个时间. 剩下的则大于等于这个值. 90% Line - 统计结果中90%的不会超过这个时间.剩下的则大于等于这个值. 95% Line - 统计结果中95%的不会超过这个时间.剩下的则大于等于这个值. 99% Line - 统计结果中99%的不会超过这个时间.剩下的则大于等于这个值. Min - 统计结果中最短的耗时时间. Max - 统计结果中最长的耗时时间. Error % - 统计结果中发生错误的百分比. Throughput - 吞吐量是在可以通过second/minute/hour这三种单位进行测量. 通过选择不同的单位可以让结果值最小的可能也是1.0. 当吞吐量被存在CSV 文件时, 吞吐量是通过requests/second表示的, 例如30.0 requests/minute 就被保存为0.5. Kb/sec - The throughput measured in Kilobytes per second Summy Report接下来我们看一下Summy Reportsummary 报告为每个不同名的请求(注意是不同名的哦)都创建了一个结果记录. 这个和聚合报告非常像, 但不同的是它所使用的内存要比聚合报告少. Label - 统计标签 Samples - 相同名称的标签下采样的次数 Average - 该组统计的平均耗时 Min - 该组采样中最短的耗时时间 Max - 该组采样中最长的耗时时间 Std. Dev. - 采样耗时的标准偏差(Standard Deviation ) Error % - 请求发生错误的百分比 Throughput - 吞吐量是在可以通过second/minute/hour这三种单位进行测量. 通过选择不同的单位可以让结果值最小的可能也是1.0. 当吞吐量被存在CSV 文件时, 吞吐量是通过requests/second表示的, 例如30.0 requests/minute 就被保存为0.5. Kb/sec - The throughput measured in Kilobytes per second Avg. Bytes - average size of the sample response in bytes. (in JMeter 2.2 it wrongly showed the value in kB) SSL","categories":[{"name":"Java 类库","slug":"Java-类库","permalink":"https://wangmingco.github.io/categories/Java-%E7%B1%BB%E5%BA%93/"}],"tags":[{"name":"JMeter","slug":"JMeter","permalink":"https://wangmingco.github.io/tags/JMeter/"}]},{"title":"Mysql 客户端","slug":"数据库/Mysql 客户端","date":"2016-05-07T16:00:00.000Z","updated":"2021-11-18T02:53:46.416Z","comments":true,"path":"2016/05/08/数据库/Mysql 客户端/","link":"","permalink":"https://wangmingco.github.io/2016/05/08/%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql%20%E5%AE%A2%E6%88%B7%E7%AB%AF/","excerpt":"","text":"mycliMyCli 是一个 MySQL 命令行工具，支持自动补全和语法高亮 dbv数据库版本控制系统 http://dbv.vizuina.com","categories":[{"name":"数据库","slug":"数据库","permalink":"https://wangmingco.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://wangmingco.github.io/tags/mysql/"}]},{"title":"Java 引用类型","slug":"jvm/Java 引用类型","date":"2016-05-04T16:00:00.000Z","updated":"2021-11-18T02:43:29.549Z","comments":true,"path":"2016/05/05/jvm/Java 引用类型/","link":"","permalink":"https://wangmingco.github.io/2016/05/05/jvm/Java%20%E5%BC%95%E7%94%A8%E7%B1%BB%E5%9E%8B/","excerpt":"","text":"JDK1.2之后,java对引用的概念进行了拓充,将引用分为强引用,软引用,弱引用,虚引用 强引用: 指的是在代码之中普遍存在的,类似Object obj = new Object() 这类的引用,只要强引用还存在,垃圾收集器永远不会回收掉被引用的对象 软引用: 用来描述一些还有用,但是并非重要的对象.对于软引用关联着的对象,在系统将要发生内存溢出之前,将会把这些对象列进回收范围之中并进行第二次回收.如果这次回收还是没有足够的内存,才会抛出内存溢出异常. 弱饮用: 当垃圾收集器工作时,无论是否内存足够,都将回收掉只被若饮用关联的对象 虚引用: 一个对象是否是有虚引用的存在,完全不会对其生成时间构成影响,也无法通过虚引用来取得一个对象实例.为一个对象设置虚引用关联的唯一目的是希望在其被收集器回收时收到一个系统通知. 强引用JVM在GC的时候并不会释放强引用的堆实例, 因此当堆内GC后仍然不能获得足够的空间, 就会发生OOM 1String str = new String(&quot;Hi&quot;); 上面的例子中, 在栈中分配的str指向了堆中分配的String实例, 那么str引用就是这个实例的强引用. 保存在数组和集合中以及Map中的引用都都算是强引用. 软引用JVM在GC时不一定会释放软引用所引用的对象实例, 那什么时候会进行释放呢? 只有当JVM发现堆内存不足时, 才会在GC时将软引用的堆内存释放掉 1234567891011121314151617181920212223242526272829303132333435363738import java.lang.ref.Reference;import java.lang.ref.ReferenceQueue;import java.lang.ref.SoftReference;public class TestSoft &#123; public static void main(String[] args) throws InterruptedException &#123; ReferenceQueue&lt;User&gt; referenceQueue = new ReferenceQueue&lt;&gt;(); User user = new User(); SoftReference&lt;User&gt; softReference = new SoftReference&lt;&gt;(user, referenceQueue); user = null; Thread t = new Thread(() -&gt; &#123; while (true) &#123; Reference&lt;? extends User&gt; ref = referenceQueue.poll(); if (ref != null) &#123; System.out.println(&quot;Changed : &quot; + ref); break; &#125; &#125; &#125;); t.setDaemon(true); t.start(); System.out.println(&quot;Before GC : &quot; + &quot; &quot; + softReference.get()); System.gc(); System.out.println(&quot;After GC : &quot; + softReference.get()); byte[] array = new byte[1024 * 920 * 7]; System.out.println(&quot;Alocate : &quot; + softReference.get()); &#125;&#125;class User &#123; public String name;&#125; 我们指定虚拟机参数-Xmx10M -Xms10M -XX:PrintGC, 运行一下这个程序的结果为: 123456789101112[GC (Allocation Failure) 2048K-&gt;836K(9728K), 0.0023890 secs]Before GC : testRef.User@404b9385[GC (System.gc()) 1145K-&gt;844K(9728K), 0.0013400 secs][Full GC (System.gc()) 844K-&gt;750K(9728K), 0.0085260 secs]After GC : testRef.User@404b9385[GC (Allocation Failure) 788K-&gt;782K(9728K), 0.0003760 secs][GC (Allocation Failure) 782K-&gt;782K(9728K), 0.0002590 secs][Full GC (Allocation Failure) 782K-&gt;750K(9728K), 0.0043290 secs][GC (Allocation Failure) 750K-&gt;750K(9728K), 0.0004580 secs][Full GC (Allocation Failure) 750K-&gt;692K(9728K), 0.0079430 secs]Changed : java.lang.ref.SoftReference@19366529Alocate : null 我们在构建SoftReference实例对象时, 除了添加一个测试对象外, 还添加里一个ReferenceQueue实例对象, 当对象的可达状态发生改变时, SoftReference就会移动到ReferenceQueue队列里. 从最后的Poll 这个输出里我们可以看到, 已经看不到这个对象了. 弱引用弱引用是一种比软饮用更加弱的引用, JVM在GC时只要发现弱引用, 都会对其引用的实例进行回收 123456789101112131415161718192021222324252627282930313233343536373839import java.lang.ref.Reference;import java.lang.ref.ReferenceQueue;import java.lang.ref.SoftReference;import java.lang.ref.WeakReference;public class TestSoft &#123; public static void main(String[] args) throws InterruptedException &#123; ReferenceQueue&lt;User&gt; referenceQueue = new ReferenceQueue&lt;&gt;(); User user = new User(); WeakReference&lt;User&gt; softReference = new WeakReference&lt;&gt;(user, referenceQueue); // 确定没有强引用 user = null; Thread t = new Thread(() -&gt; &#123; while (true) &#123; Reference&lt;? extends User&gt; ref = referenceQueue.poll(); if (ref != null) &#123; System.out.println(&quot;Changed : &quot; + ref); break; &#125; &#125; &#125;); t.setDaemon(true); t.start(); System.out.println(&quot;Before GC : &quot; + &quot; &quot; + softReference.get()); System.gc(); System.out.println(&quot;After GC : &quot; + softReference.get()); byte[] array = new byte[1024 * 920 * 7]; System.out.println(&quot;Alocate : &quot; + softReference.get()); &#125;&#125;class User &#123;&#125; 我们指定虚拟机参数-Xmx10M -Xms10M -XX:+PrintGC, 运行一下这个程序的结果为: 123456789101112[GC (Allocation Failure) 2048K-&gt;800K(9728K), 0.0031060 secs]Before GC : nullChanged : java.lang.ref.WeakReference@175fdc70[GC (System.gc()) 1084K-&gt;824K(9728K), 0.0011480 secs][Full GC (System.gc()) 824K-&gt;748K(9728K), 0.0088060 secs]After GC : null[GC (Allocation Failure) 807K-&gt;812K(9728K), 0.0010100 secs][GC (Allocation Failure) 812K-&gt;844K(9728K), 0.0004150 secs][Full GC (Allocation Failure) 844K-&gt;748K(9728K), 0.0090930 secs][GC (Allocation Failure) 748K-&gt;748K(9728K), 0.0003230 secs][Full GC (Allocation Failure) 748K-&gt;690K(9728K), 0.0082600 secs]Alocate : null 如果WeakReference是保存在一个对象实例里面是什么情况呢？ 1234567891011121314151617181920import java.lang.ref.WeakReference;public class TestSoft &#123; public static void main(String[] args) throws InterruptedException &#123; WeakReferenceCache weakReferenceCache = new WeakReferenceCache(); weakReferenceCache.cache = new WeakReference&lt;&gt;(new User()); System.out.println(&quot;Before GC : &quot; + weakReferenceCache.cache.get()); System.gc(); System.out.println(&quot;After GC : &quot; + weakReferenceCache.cache.get()); byte[] array = new byte[1024 * 920 * 7]; System.out.println(&quot;Alocate GC : &quot; + weakReferenceCache.cache.get()); &#125;&#125;class WeakReferenceCache &#123; public WeakReference&lt;User&gt; cache;&#125;class User &#123;&#125; 同样我们运行一下看一下结果 123Before GC : User@41629346After GC : nullAlocate GC : null 确实是, 每次GC都将其回收掉了 我们再实验一下, 如果将其存进一个列表里 1234567891011121314151617181920212223242526272829303132333435import java.lang.ref.WeakReference;import java.util.ArrayList;import java.util.List;public class TestSoft &#123; public static void main(String[] args) throws InterruptedException &#123; WeakReferenceCache weakReferenceCache = new WeakReferenceCache(); for (int i = 0; i &lt; 10; i++) &#123; WeakReference&lt;User&gt; softReference = new WeakReference&lt;&gt;(new User()); weakReferenceCache.cache.add(softReference); &#125; System.out.println(&quot;Before GC : &quot;); weakReferenceCache.cache.forEach(cache -&gt; &#123; System.out.println(cache.get()); &#125;); System.gc(); System.out.println(&quot;After GC : &quot;); weakReferenceCache.cache.forEach(cache -&gt; &#123; System.out.println(cache.get()); &#125;); byte[] array = new byte[1024 * 920 * 7]; System.out.println(&quot;Alocate GC : &quot;); weakReferenceCache.cache.forEach(cache -&gt; &#123; System.out.println(cache.get()); &#125;); &#125;&#125;class WeakReferenceCache &#123; public List&lt;WeakReference&lt;User&gt;&gt; cache = new ArrayList&lt;&gt;();&#125;class User &#123;&#125; 结果为 123456789101112131415161718192021222324252627282930313233Before GC : User@6433a2User@5910e440User@6267c3bbUser@533ddbaUser@246b179dUser@7a07c5b4User@26a1ab54User@3d646c37User@41cf53f9User@5a10411After GC : nullnullnullnullnullnullnullnullnullnullAlocate GC : nullnullnullnullnullnullnullnullnullnull 即使是存储在数组里也一样被回收掉了 虚引用虚引用是所有引用类型中最弱的一个, 一个被虚引用持有的对象跟没有被持有的效果基本上是一样的. 当我们从虚引用中get时, 总会获得一个空, 那既然如此还为什么要设计出一个这样的引用呢? 因为虚引用必须跟一个引用队列, 我们可以将一些资源性的东西放到虚引用中执行和记录. 1234567891011121314151617181920212223242526272829303132333435import java.lang.ref.*;public class TestSoft &#123; public static void main(String[] args) throws InterruptedException &#123; ReferenceQueue&lt;User&gt; referenceQueue = new ReferenceQueue&lt;&gt;(); User user = new User(); PhantomReference&lt;User&gt; softReference = new PhantomReference&lt;&gt;(user, referenceQueue); user = null; Thread t = new Thread(() -&gt; &#123; while (true) &#123; Reference&lt;? extends User&gt; ref = referenceQueue.poll(); if (ref != null) &#123; System.out.println(&quot;Changed : &quot; + System.currentTimeMillis()); break; &#125; &#125; &#125;); t.setDaemon(true); t.start(); System.out.println(&quot;Before GC : &quot; + System.currentTimeMillis() + &quot; &quot; + softReference.get()); System.gc(); System.out.println(&quot;After GC : &quot; + softReference.get()); byte[] array = new byte[1024 * 920 * 7]; System.out.println(&quot;Alocate : &quot; + softReference.get()); &#125;&#125;class User &#123;&#125; 我们指定虚拟机参数-Xmx30M -Xms30M -XX:+PrintGC, 运行一下这个程序的结果为: 123456Before GC : 1462461362835 null[GC (System.gc()) 2806K-&gt;904K(29696K), 0.0033390 secs][Full GC (System.gc()) 904K-&gt;779K(29696K), 0.0095950 secs]Changed : 1462461362850After GC : nullAlocate : null","categories":[{"name":"JVM","slug":"JVM","permalink":"https://wangmingco.github.io/categories/JVM/"}],"tags":[]},{"title":"ZooKeeper Curator 基本操作","slug":"zookeeper/ZooKeeper Curator 基本操作","date":"2016-04-26T16:00:00.000Z","updated":"2021-11-18T02:43:54.236Z","comments":true,"path":"2016/04/27/zookeeper/ZooKeeper Curator 基本操作/","link":"","permalink":"https://wangmingco.github.io/2016/04/27/zookeeper/ZooKeeper%20Curator%20%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/","excerpt":"","text":"Curator的Framework API为我们操作Zookeeper提供了非常便捷的操作. 它在ZooKeeper API之上为我们增加里许多新的特性, 例如对ZooKeeper集群连接的管理以及重试操作等等. 下面就列举了一些特性: 自动连接管理 Leader 选举 共享锁 路径缓存以及watch 分布式队列(以及分布式Priority队列) 我们根据下面的例子看一下Curator Framework的增删改查操作 123456789101112131415161718192021222324252627282930313233343536import org.apache.curator.framework.CuratorFramework;import org.apache.curator.framework.CuratorFrameworkFactory;import org.apache.curator.retry.ExponentialBackoffRetry;import org.apache.curator.utils.CloseableUtils;import org.apache.zookeeper.CreateMode;public class TestCurator &#123; public static void main(String[] args) throws Exception &#123; CuratorFramework client = null; try &#123; client = CuratorFrameworkFactory.newClient(&quot;0.0.0.0:2181&quot;, new ExponentialBackoffRetry(1000, 3)); client.start(); // 创建一个临时节点, 如果父节点不存在, 则将父节点也创建出来 client.create().creatingParentsIfNeeded().withMode(CreateMode.EPHEMERAL).forPath(&quot;/Servers/LoginServer&quot;); // 查看根节点下的所有节点, 但是不会对子节点进行递归查询 client.getChildren().forPath(&quot;/&quot;).forEach(path -&gt; System.out.println(&quot;Exist : &quot; + path)); // 设置数据 client.setData().forPath(&quot;/Servers/LoginServer&quot;, &quot;192.168.15.15&quot;.getBytes()); // 获取节点数据 System.out.println(&quot;Data : &quot; + client.getData().forPath(&quot;/Servers/LoginServer&quot;)); // 将子节点和父节点一起删除 client.delete().deletingChildrenIfNeeded().forPath(&quot;/Servers&quot;); // 验证最后还有哪些节点存在 client.getChildren().forPath(&quot;/&quot;).forEach(path -&gt; System.out.println(&quot;Exist : &quot; + path)); &#125; finally &#123; CloseableUtils.closeQuietly(client); &#125; &#125;&#125; 结果为 123Exist : ServersExist : zookeeperData : [B@63753b6d 如果要异步执行的话, 只需要调用相关逻辑的background方法就好了 我们使用的是Curator2.x版本 12345678910&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-framework&lt;/artifactId&gt; &lt;version&gt;2.10.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt; &lt;version&gt;2.10.0&lt;/version&gt;&lt;/dependency&gt; 我们应该使用curator-framework, 而不是使用curator-client 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-client&lt;/artifactId&gt; &lt;version&gt;2.10.0&lt;/version&gt;&lt;/dependency&gt; curator-client是对Zookepper官方API的一个简单封装, 如果我们使用curator-client, 还需要自己处理一些底层问题, 例如失败重连等问题 12345678910111213141516RetryLoop retryLoop = client.newRetryLoop();while ( retryLoop.shouldContinue() )&#123; try &#123; // perform your work ... // it&#x27;s important to re\\-get the ZK instance as there may have been an error and the instance was re\\-created ZooKeeper zk = client.getZookeeper(); retryLoop.markComplete(); &#125; catch ( Exception e ) &#123; retryLoop.takeException(e); &#125;&#125; 或者 123456789RetryLoop.callWithRetry(client, new Callable&lt;Void&gt;()&#123; @Override public Void call() throws Exception &#123; // do your work here - it will get retried if needed return null; &#125;&#125;);","categories":[{"name":"ZooKeeper","slug":"ZooKeeper","permalink":"https://wangmingco.github.io/categories/ZooKeeper/"}],"tags":[]},{"title":"ZooKeeper Curator 事件监听","slug":"zookeeper/ZooKeeper Curator 事件监听","date":"2016-04-25T16:00:00.000Z","updated":"2021-11-18T02:43:55.123Z","comments":true,"path":"2016/04/26/zookeeper/ZooKeeper Curator 事件监听/","link":"","permalink":"https://wangmingco.github.io/2016/04/26/zookeeper/ZooKeeper%20Curator%20%E4%BA%8B%E4%BB%B6%E7%9B%91%E5%90%AC/","excerpt":"","text":"监测时检查出已有节点123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135package zk;import java.util.Date;import java.util.concurrent.TimeUnit;import org.apache.curator.framework.CuratorFramework;import org.apache.curator.framework.CuratorFrameworkFactory;import org.apache.curator.framework.recipes.cache.ChildData;import org.apache.curator.framework.recipes.cache.PathChildrenCache;import org.apache.curator.framework.recipes.cache.PathChildrenCacheEvent;import org.apache.curator.framework.recipes.cache.PathChildrenCacheListener;import org.apache.curator.retry.ExponentialBackoffRetry;import org.apache.curator.utils.CloseableUtils;import org.apache.curator.utils.ZKPaths;import org.apache.zookeeper.CreateMode;public class PathCacheExample &#123; public static void main(String[] args) throws InterruptedException &#123; ZKClient zkClient1 = register(&quot;Server1&quot;); TimeUnit.SECONDS.sleep(10); ZKClient zkClient2 = register(&quot;Server2&quot;); ZKClient zkClient3 = register(&quot;Server3&quot;); TimeUnit.SECONDS.sleep(5); zkClient1.closeAllService(); zkClient2.closeAllService(); zkClient3.closeAllService(); &#125; public static ZKClient register(String serverName) throws InterruptedException &#123; ZKClient zkClient = new ZKClient(serverName); Thread thread = new Thread(zkClient); thread.start(); return zkClient; &#125;&#125;class ZKClient implements Runnable &#123; private static final String PATH = &quot;/ServersCache1&quot;; private CuratorFramework client = null; private PathChildrenCache cache = null; private String servername = null; public void closeAllService() &#123; closeCuratorFramework(); closePathChildrenCache(); &#125; public void closeCuratorFramework() &#123; CloseableUtils.closeQuietly(cache); &#125; public void closePathChildrenCache() &#123; CloseableUtils.closeQuietly(client); &#125; public ZKClient(String serverName) &#123; this.servername = serverName; try &#123; client = CuratorFrameworkFactory.newClient(&quot;0.0.0.0:2181&quot;, new ExponentialBackoffRetry(1000, 3)); client.start(); cache = new PathChildrenCache(client, PATH, true); cache.start(); addListener(cache); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; @Override public void run() &#123; create(client, servername, servername); setValue(client, servername, servername); try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; private void addListener(PathChildrenCache cache) &#123; PathChildrenCacheListener listener = (client, event) -&gt; &#123; switch (event.getType()) &#123; case CHILD_ADDED: &#123; printNodeStateChange(&quot;added&quot;, event.getData().getPath()); break; &#125; case CHILD_UPDATED: &#123; printNodeStateChange(&quot;changed&quot;, event.getData().getPath()); break; &#125; case CHILD_REMOVED: &#123; printNodeStateChange(&quot;removed&quot;, event.getData().getPath()); break; &#125; &#125; &#125;; cache.getListenable().addListener(listener); &#125; private void printNodeStateChange(String type, String path) &#123; System.out.println(servername + &quot; Monitor Node &quot; + type + &quot;: &quot; + path + &quot;. &quot; + new Date().toLocaleString()); &#125; private static void remove(CuratorFramework client, String pathName) &#123; String path = ZKPaths.makePath(PATH, pathName); try &#123; client.delete().deletingChildrenIfNeeded().forPath(path); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; private static void create(CuratorFramework client, String pathName, String data) &#123; String path = ZKPaths.makePath(PATH, pathName); try &#123; client.create().creatingParentsIfNeeded().withMode(CreateMode.EPHEMERAL).forPath(path, data.getBytes()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; private static void setValue(CuratorFramework client, String pathName, String data) &#123; String path = ZKPaths.makePath(PATH, pathName); try &#123; client.setData().forPath(path, data.getBytes()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 输出结果为 123456789101112Server1 Monitor Node added: /ServersCache1/Server1. 2016-4-28 18:41:54Server1 Monitor Node added: /ServersCache1/Server2. 2016-4-28 18:42:04Server1 Monitor Node added: /ServersCache1/Server3. 2016-4-28 18:42:04Server3 Monitor Node added: /ServersCache1/Server1. 2016-4-28 18:42:04Server3 Monitor Node added: /ServersCache1/Server2. 2016-4-28 18:42:04Server3 Monitor Node added: /ServersCache1/Server3. 2016-4-28 18:42:04Server2 Monitor Node added: /ServersCache1/Server1. 2016-4-28 18:42:04Server2 Monitor Node added: /ServersCache1/Server2. 2016-4-28 18:42:04Server2 Monitor Node added: /ServersCache1/Server3. 2016-4-28 18:42:04Server3 Monitor Node removed: /ServersCache1/Server1. 2016-4-28 18:42:09Server2 Monitor Node removed: /ServersCache1/Server1. 2016-4-28 18:42:09Server3 Monitor Node removed: /ServersCache1/Server2. 2016-4-28 18:42:09 删除节点监测123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117public class PathCacheExample &#123; public static void main(String[] args) throws InterruptedException &#123; ZKClient zkClient1 = register(&quot;Server1&quot;); TimeUnit.SECONDS.sleep(3); ZKClient zkClient2 = register(&quot;Server2&quot;); ZKClient zkClient3 = register(&quot;Server3&quot;); TimeUnit.SECONDS.sleep(3); &#125; public static ZKClient register(String serverName) throws InterruptedException &#123; ZKClient zkClient = new ZKClient(serverName); Thread thread = new Thread(zkClient); thread.start(); return zkClient; &#125;&#125;class ZKClient implements Runnable &#123; private static final String PATH = &quot;/ServersCache5&quot;; private CuratorFramework client = null; private PathChildrenCache cache = null; private String servername = null; public void closeAllService() &#123; closeCuratorFramework(); closePathChildrenCache(); &#125; public void closeCuratorFramework() &#123; CloseableUtils.closeQuietly(client); &#125; public void closePathChildrenCache() &#123; CloseableUtils.closeQuietly(cache); &#125; public ZKClient(String serverName) &#123; this.servername = serverName; try &#123; client = CuratorFrameworkFactory.newClient(&quot;0.0.0.0:2181&quot;, new ExponentialBackoffRetry(1000, 3)); client.start(); cache = new PathChildrenCache(client, PATH, true); cache.start(); addListener(cache); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; @Override public void run() &#123; create(client, servername, servername); setValue(client, servername, servername); try &#123; TimeUnit.SECONDS.sleep(3); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; remove(client, servername); &#125; private void addListener(PathChildrenCache cache) &#123; PathChildrenCacheListener listener = (client, event) -&gt; &#123; switch (event.getType()) &#123; case CHILD_ADDED: &#123; printNodeStateChange(&quot;added&quot;, event.getData().getPath()); break; &#125; case CHILD_UPDATED: &#123; printNodeStateChange(&quot;changed&quot;, event.getData().getPath()); break; &#125; case CHILD_REMOVED: &#123; printNodeStateChange(&quot;removed&quot;, event.getData().getPath()); break; &#125; &#125; &#125;; cache.getListenable().addListener(listener); &#125; private void printNodeStateChange(String type, String path) &#123; System.out.println(servername + &quot; Monitor Node &quot; + type + &quot;: &quot; + path + &quot;. &quot; + new Date().toLocaleString()); &#125; private static void remove(CuratorFramework client, String pathName) &#123; String path = ZKPaths.makePath(PATH, pathName); try &#123; client.delete().forPath(path); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; private static void create(CuratorFramework client, String pathName, String data) &#123; String path = ZKPaths.makePath(PATH, pathName); try &#123; client.create().creatingParentsIfNeeded().withMode(CreateMode.EPHEMERAL).forPath(path, data.getBytes()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; private static void setValue(CuratorFramework client, String pathName, String data) &#123; String path = ZKPaths.makePath(PATH, pathName); try &#123; client.setData().forPath(path, data.getBytes()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 输出结果为 123456789101112131415161718Server1 Monitor Node added: /ServersCache5/Server1. 2016-4-28 19:33:13Server1 Monitor Node added: /ServersCache5/Server2. 2016-4-28 19:33:16Server2 Monitor Node added: /ServersCache5/Server1. 2016-4-28 19:33:16Server1 Monitor Node added: /ServersCache5/Server3. 2016-4-28 19:33:16Server2 Monitor Node added: /ServersCache5/Server2. 2016-4-28 19:33:16Server2 Monitor Node added: /ServersCache5/Server3. 2016-4-28 19:33:16Server3 Monitor Node added: /ServersCache5/Server1. 2016-4-28 19:33:16Server3 Monitor Node added: /ServersCache5/Server2. 2016-4-28 19:33:16Server3 Monitor Node added: /ServersCache5/Server3. 2016-4-28 19:33:16Server2 Monitor Node removed: /ServersCache5/Server1. 2016-4-28 19:33:16Server1 Monitor Node removed: /ServersCache5/Server1. 2016-4-28 19:33:16Server3 Monitor Node removed: /ServersCache5/Server1. 2016-4-28 19:33:16Server1 Monitor Node removed: /ServersCache5/Server2. 2016-4-28 19:33:19Server3 Monitor Node removed: /ServersCache5/Server2. 2016-4-28 19:33:19Server2 Monitor Node removed: /ServersCache5/Server2. 2016-4-28 19:33:19Server3 Monitor Node removed: /ServersCache5/Server3. 2016-4-28 19:33:19Server1 Monitor Node removed: /ServersCache5/Server3. 2016-4-28 19:33:19Server2 Monitor Node removed: /ServersCache5/Server3. 2016-4-28 19:33:19 客户端网络断开监测123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126public class PathCacheExample &#123; public static void main(String[] args) throws InterruptedException &#123; ZKClient zkClient1 = register(&quot;Server1&quot;); TimeUnit.SECONDS.sleep(3); ZKClient zkClient2 = register(&quot;Server2&quot;); ZKClient zkClient3 = register(&quot;Server3&quot;); TimeUnit.SECONDS.sleep(3); zkClient1.closeCuratorFramework(); TimeUnit.SECONDS.sleep(1); zkClient2.closeCuratorFramework(); TimeUnit.SECONDS.sleep(1); zkClient3.closeCuratorFramework(); TimeUnit.SECONDS.sleep(3); zkClient1.closePathChildrenCache(); zkClient2.closePathChildrenCache(); zkClient3.closePathChildrenCache(); &#125; public static ZKClient register(String serverName) throws InterruptedException &#123; ZKClient zkClient = new ZKClient(serverName); Thread thread = new Thread(zkClient); thread.start(); return zkClient; &#125;&#125;class ZKClient implements Runnable &#123; private static final String PATH = &quot;/ServersCache4&quot;; private CuratorFramework client = null; private PathChildrenCache cache = null; private String servername = null; public void closeAllService() &#123; closeCuratorFramework(); closePathChildrenCache(); &#125; public void closeCuratorFramework() &#123; CloseableUtils.closeQuietly(client); &#125; public void closePathChildrenCache() &#123; CloseableUtils.closeQuietly(cache); &#125; public ZKClient(String serverName) &#123; this.servername = serverName; try &#123; client = CuratorFrameworkFactory.newClient(&quot;0.0.0.0:2181&quot;, new ExponentialBackoffRetry(1000, 3)); client.start(); cache = new PathChildrenCache(client, PATH, true); cache.start(); addListener(cache); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; @Override public void run() &#123; create(client, servername, servername);// remove(client, servername); try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; private void addListener(PathChildrenCache cache) &#123; PathChildrenCacheListener listener = (client, event) -&gt; &#123; switch (event.getType()) &#123; case CHILD_ADDED: &#123; printNodeStateChange(&quot;added&quot;, event.getData().getPath()); break; &#125; case CHILD_UPDATED: &#123; printNodeStateChange(&quot;changed&quot;, event.getData().getPath()); break; &#125; case CHILD_REMOVED: &#123; printNodeStateChange(&quot;removed&quot;, event.getData().getPath()); break; &#125; &#125; &#125;; cache.getListenable().addListener(listener); &#125; private void printNodeStateChange(String type, String path) &#123; System.out.println(servername + &quot; Monitor Node &quot; + type + &quot;: &quot; + path + &quot;. &quot; + new Date().toLocaleString()); &#125; private static void remove(CuratorFramework client, String pathName) &#123; String path = ZKPaths.makePath(PATH, pathName); try &#123; client.delete().deletingChildrenIfNeeded().forPath(path); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; private static void create(CuratorFramework client, String pathName, String data) &#123; String path = ZKPaths.makePath(PATH, pathName); try &#123; client.create().creatingParentsIfNeeded().withMode(CreateMode.EPHEMERAL).forPath(path, data.getBytes()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; private static void setValue(CuratorFramework client, String pathName, String data) &#123; String path = ZKPaths.makePath(PATH, pathName); try &#123; client.setData().forPath(path, data.getBytes()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 结果输出为 123456789101112131415Server1 Monitor Node added: /ServersCache4/Server1. 2016-4-28 19:27:32Server1 Monitor Node added: /ServersCache4/Server2. 2016-4-28 19:27:35Server3 Monitor Node added: /ServersCache4/Server1. 2016-4-28 19:27:35Server1 Monitor Node added: /ServersCache4/Server3. 2016-4-28 19:27:35Server3 Monitor Node added: /ServersCache4/Server2. 2016-4-28 19:27:35Server3 Monitor Node added: /ServersCache4/Server3. 2016-4-28 19:27:35Server2 Monitor Node added: /ServersCache4/Server1. 2016-4-28 19:27:35Server2 Monitor Node added: /ServersCache4/Server2. 2016-4-28 19:27:35Server2 Monitor Node added: /ServersCache4/Server3. 2016-4-28 19:27:35Server2 Monitor Node removed: /ServersCache4/Server1. 2016-4-28 19:27:38Server1 Monitor Node removed: /ServersCache4/Server1. 2016-4-28 19:27:38Server3 Monitor Node removed: /ServersCache4/Server1. 2016-4-28 19:27:38Server2 Monitor Node removed: /ServersCache4/Server2. 2016-4-28 19:27:39Server3 Monitor Node removed: /ServersCache4/Server2. 2016-4-28 19:27:39Server3 Monitor Node removed: /ServersCache4/Server3. 2016-4-28 19:27:40","categories":[{"name":"ZooKeeper","slug":"ZooKeeper","permalink":"https://wangmingco.github.io/categories/ZooKeeper/"}],"tags":[]},{"title":"nginx web服务器","slug":"nginx/nginx web服务器","date":"2016-04-22T16:00:00.000Z","updated":"2021-11-18T02:43:36.283Z","comments":true,"path":"2016/04/23/nginx/nginx web服务器/","link":"","permalink":"https://wangmingco.github.io/2016/04/23/nginx/nginx%20web%E6%9C%8D%E5%8A%A1%E5%99%A8/","excerpt":"","text":"官方文档学习 在Nginx中每个用来处理HTTP请求的virtual server都被称为location. location可以参与请求处理的整个过程. location可以代理一个请求或者直接返回一个文件. 不但如此, 在location中我们还可以修改URI访问路径, 这样我们就可以将该请求指向其他的location或者其他的virtual server. Setting Up Virtual ServersNginx插件配置必须最少包含一个server指令(用于定义虚拟服务器-virtual server). 当Nginx插件处理一个请求时, 它首先会选择处理该请求的虚拟服务器. 一个虚拟服务器定义在http上下文里, 例如: 12345http &#123; server &#123; # Server configuration &#125;&#125; 在http上下文里可以定义多个server指令, 这样一来就可以实现多个虚拟服务器了. 在server指令里通常包含一个listen指令, 通过listen指令来指定监听请求的IP地址和端口号(或者Unix domain socket and path). IPv4 和 IPv6 地址都可进行配置 下面的例子展示了在IP地址127.0.0.1和端口8080上进行网络事件监听 1234server &#123; listen 127.0.0.1:8080; # The rest of server configuration&#125; 如果端口忽略不写的话, Nginx插件会使用标准端口. 还有如果IP地址忽略不填的话, Nginx插件会在所有的IP地址上进行网络事件监听. 如果没有配置listen指令的话, 在超级用户权限下, 标准端口是80/tcp, 默认端口8000/tcp. 如果有多个server指令里配置的IP地址和端口匹配到请求, 那么Nginx插件会根据请求的Host header字段与server_name指令进行匹配. 我们可以将server_name指令配置成一个全名称的地址, 或者使用通配符, 正则表达式. 如果想要使用通配符的话, 可以在地址的开头或者结尾使用*. 12345server &#123; listen 80; server_name example.org www.example.org; ...&#125; 如果有多个server_name指令匹配到Host header, Nginx插件会根据如下顺序进行匹配查找, 直到找到第一个. 名字完全符合 以*开始的, 最符合的名字, 例如*.example.org 以*结束的, 最符合的名字, 例如mail.* 第一个匹配正则表达式的 如果请求中的Host header没有匹配到一个合适的server name, Nginx插件会将该消息路由到默认服上面去. 默认服是在nginx.conf文件里进行配置的. 我们也可以使用default_server参数在listen指令中进行显示设定. 1234server &#123; listen 80 default_server; ...&#125; Configuring LocationsNginx插件可以根据请求的URI将请求派发到不同的代理上, 或者处理不同的文件. 这种功能是通过server指令里的location指令完成的. 例如你可以定义三个location指令, 一个用来将请求派发到一个代理服务器, 一个用来将其他的请求派发到另外的一个代理服务器,最后的一个用来提供本地文件系统服务. NGINX Plus tests request URIs against the parameters of all location directives and applies the directives defined in the matching location. Inside each location block, it is usually possible (with a few exceptions) to place even more location directives to further refine the processing for specific groups of requests. 注意, 在这篇教程中, location这个字指的是一个单独的location上下文. 有俩种location指令参数 prefix strings : 请求的URI是以固定的字符串开头, 例如prefix strings是/some/path/, 那么/some/path/document.html就是这种类型的, 但是/my-site/some/path就不是. regular expressions : 123location /some/path/ &#123; ...&#125; 当使用表达式的时候, 如果使用~开头则表示要区分大小写. 如果以~*开头,则表示忽略大小写. 下面的例子是只要请求包含.html或者.htm这些字符串就都匹配 123location ~ \\.html? &#123; ...&#125; Nginx插件进行location匹配时, 优先进行prefix string匹配, 如果prefix string匹配不到再进行正则匹配. Higher priority is given to regular expressions, unless the ^~ modifier is used. Among the prefix strings NGINX Plus selects the most specific one (that is, the longest and most complete string). The exact logic for selecting a location to process a request is given below: Test the URI against all prefix strings. The = (equals sign) modifier defines an exact match of the URI and a prefix string. If the exact match is found, the search stops. If the ^~ (caret-tilde) modifier prepends the longest matching prefix string, the regular expressions are not checked. Store the longest matching prefix string. Test the URI against regular expressions. Break on the first matching regular expression and use the corresponding location. If no regular expression matches, use the location corresponding to the stored prefix string. =的典型用例是请求/, 如果请求/是非常频繁的, 在location指令上设置= /可以大幅提升访问速度, 这是因为在路径搜索匹配时, 一旦匹配到就不再继续搜素匹配了, 节约了时间. 123location = / &#123; ...&#125; location上下文中可以包含多个指令, 用于说明如何处理一个请求, 例如是想提供静态文件服务还是想向一个代理服务器派发请求. 例如, 在下面的例子中, 第一个请求就是提供/data目录下的静态文件服务, 第二个请求就是向一个代理服务器www.example.com派发请求. 12345678910server &#123; location /images/ &#123; root /data; &#125; location / &#123; proxy_pass http://www.example.com; &#125;&#125; root指令用于指定提供静态文件服务的文件系统路径. 如果有一个请求/images/example.png, 那么nginx插件会在文件系统中进行如下搜索/data/images/example.png. proxy_pass指令会将请求派发到代理服务器上. 在上面的例子中, 只要是请求不是以/images/开头的, 那么请求都会派发到那个代理服务器上. Using Variables你可以在配置文件里使用变量, 以便Nginx插件可以根据不同的情况进行不同的处理. 变量在运行时进行计算, 然后将值传递给指令使用. 我们可以通过$来引用一个变量(例如$time). 在Nginx里已经为我们提前定义好了一些变量, 例如core HTTP. 而且你也可以使用set, map, geo等指令自定义一些变量. Returning Specific Status Codes在一些web站点中, 由于资源移除或者其他原因, 我们需要直接给前端返回一个错误码, 那么我们可以使用return指令来完成. 123location /wrong/url &#123; return 404;&#125; 下面的例子中, 第一个参数是一个错误码. 第二个参数是一个可选参数(代表一个重连接的URL) 123location /permanently/moved/url &#123; return 301 http://www.example.com/moved/here;&#125; return指令既可以放在location指令里, 也可以放在server指令里 Rewriting URIs in Requests请求URI可以在被处理时通过rewrite指令被多次修改, rewrite指令包含一个可选参数和俩个必选参数. 第一个参数(必填)是用来匹配请求的正则表达式. 第二个参数(必填)是用来指向重连接所需要匹配的URI.(下面的例子中我们采用的是正则表达式进行匹配) 第三个参数(选填)是用来标记是继续执行下一个重连接还是执行其他操作(例如返回一个错误码)123location /users/ &#123; rewrite ^/users/(.*)$ /show?user=$1 break;&#125; 在server或者location指令中可以包含多个rewrite指令. Nginx插件会根据rewrite指令出现的顺序依次执行. After NGINX processes a set of rewriting instructions, it selects a location context according to the new URI. If the selected location contains rewrite directives, they are executed in turn. If the URI matches any of those, a search for the new location starts after all defined rewrite directives are processed. 下面的例子展示里rewrite和return指令混合使用的方式 1234567server &#123; ... rewrite ^(/download/.*)/media/(.*)\\..*$ $1/mp3/$2.mp3 last; rewrite ^(/download/.*)/audio/(.*)\\..*$ $1/mp3/$2.ra last; return 403; ...&#125; 上面的例子区分了俩组URI. /download/some/media/file的URI会被替换成/download/some/mp3/file.mp3. 由于这个rewrite指令后面跟里一个last标记, 因此下面的rewrite和return指令就不会再执行到了. 但是如果URI例如/download/some/audio/file并不符合第一个,那么Nginx插件会继续匹配到第二个, 当然第二个符合, 于是URI被替换成/download/some/mp3/file.ra. 如果前俩个都不符合的话, 那么就会返回403错误码. 下面, 我们会介绍俩种终止URIrewrite执行的方式: last – 这种方式只是会在当前的server或者location上下文中停止, 但是Nginx插件会对重写的URI继续在location里进行查找. break – 它不会对新的URI在当前上下文中进行查找, 而是简单的终止掉整个过程. Rewriting HTTP Responses有时候你可能需要重写或者替换HTTP响应中的内容, 或者将一个字符串替换为另一个. sub_filter指令可以实现类似于这种的需求. sub_filter支持变量以及链式替换, 以便实现更加复杂的重写功能. 1234location / &#123; sub_filter /blog/ /blog-staging/; sub_filter_once off;&#125; 另一个例子是将http://改变为https://, 而且将localhost地址改变为请求头中的主机名. sub_filter_once指令是告诉NGINX在location指令里可以开启多个sub_filter. 12345location / &#123; sub_filter &#x27;href=&quot;http://127.0.0.1:8080/&#x27; &#x27;href=&quot;http://$host/&#x27;; sub_filter &#x27;img src=&quot;http://127.0.0.1:8080/&#x27; &#x27;img src=&quot;http://$host/&#x27;; sub_filter_once on;&#125; 注意, 如果响应已经在一个sub_filter修改过里, 那么即使另一个sub_filter也匹配到了,但是不会再次修改. Handling Errors使用error_page指令, 我们可以配置Nginx插件返回一个自定义的界面或者响应一个不同的错误码,甚至可以重定向到一个新的地址上面去. 在下面的例子中, error_page指令会在发生错误时返回一个指定的界面/404.html, 而不是像默认的返回一个404错误码. 1error_page 404 /404.html; 注意, 这个指令并不是直接就返回了(return指令直接返回), 而是指定一种当错误发生时的一种处理方式. 在下面的例子中, 当Nginx找不到文件时, 它会返回301错误码, 同时告诉客户端重定向到http:/example.com/new/path.html这个界面上. 1234location /old/path.html &#123; error_page 404 =301 http:/example.com/new/path.html;&#125; The following configuration is an example of passing a request to the back end when a file is not found. Because there is no status code specified after the equals sign in the error_page directive, the response to the client has the status code returned by the proxied server (not necessarily 404). 1234567891011121314151617server &#123; ... location /images/ &#123; # Set the root directory to search for the file root /data/www; # Disable logging of errors related to file existence open_file_cache_errors off; # Make an internal redirect if the file is not found error_page 404 = /fetch$uri; &#125; location /fetch/ &#123; proxy_pass http://backend/; &#125;&#125; The error_page directive instructs NGINX Plus to make an internal redirect when a file is not found. The $uri variable in the final parameter to the error_page directive holds the URI of the current request, which gets passed in the redirect. For example, if /images/some/file is not found, it is replaced with /fetch/images/some/file and a new search for a location starts. As a result, the request ends up in the second location context and is proxied to http://backend/. The open_file_cache_errors directive prevents writing an error message if a file is not found. This is not necessary here since missing files are correctly handled.","categories":[{"name":"Nginx","slug":"Nginx","permalink":"https://wangmingco.github.io/categories/Nginx/"}],"tags":[]},{"title":"Mybatis SqlSession","slug":"JavaLibrary/Mybatis SqlSession","date":"2016-04-11T16:00:00.000Z","updated":"2021-11-18T02:48:32.874Z","comments":true,"path":"2016/04/12/JavaLibrary/Mybatis SqlSession/","link":"","permalink":"https://wangmingco.github.io/2016/04/12/JavaLibrary/Mybatis%20SqlSession/","excerpt":"","text":"一直在使用Mybatis, 但是一直对Mybatis中的SqlSession的实际操作过程没有深入了解过, 今天在项目中引用了Mybatis-Guice模块, 很好奇Mybatis-Guice是如何做的SqlSeesion自动资源释放,因此今天就找时间好好研究一下SqlSession. 首先看一下Mybatis3官方文档中对SqlSessionFactoryBuilder, SqlSessionFactory和SqlSession的描述： SqlSessionFactoryBuilder : 用于构建SqlSessionFactory. 我们可以使用它来构建一个单数据源或者多数据源的应用程序. SqlSessionFactory : 创建SqlSession, 该实例的生命周期应该是整个应用程序. SqlSession : 包含了面向数据库执行 SQL 命令所需的所有方法, 但它不是线程安全的. 每当向数据库发起一个请求时都应该打开一个SqlSession,然后操作完之后再finally中关闭它. 使用示例SqlSessionFactoryBuilder是通过xml配置文件或者Configuration建构出SqlSessionFactory, 然后SqlSessionFactory通过openSession()来获得一个SqlSession. SqlSession接口实现自Closeable接口. 按照官网所说, 我们应该这样使用SqlSession 123456SqlSession session = sqlSessionFactory.openSession();try &#123; // do work&#125; finally &#123; session.close();&#125; 但其实我们可以使用Java7提供的AutoClose语法 123try (SqlSession sqlSession = sqlSessionFactory.openSession()) &#123; // do work&#125; 这样代码就精简了很多. SqlSession 源码SqlSession接口中定义了大量的我们操作SQL提供的接口 T selectOne(String statement); List selectList(String statement); void select(String statement, ResultHandler handler);等等. 我们看一下它的实现类DefaultSqlSession的实现:123private Configuration configuration;private Executor executor;private boolean dirty; Configuration 是我们通过SqlSessionFactoryBuilder构建出SqlSessionFactory时使用的配置 Executor 是真正的sql执行的部分 我们在DefaultSqlSessionFactory看一下SqlSession的真实创建过程 123456789101112131415private SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) &#123; Transaction tx = null; try &#123; final Environment environment = configuration.getEnvironment(); final TransactionFactory transactionFactory = getTransactionFactoryFromEnvironment(environment); tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit); final Executor executor = configuration.newExecutor(tx, execType, autoCommit); return new DefaultSqlSession(configuration, executor); &#125; catch (Exception e) &#123; closeTransaction(tx); // may have fetched a connection so lets call close() throw ExceptionFactory.wrapException(&quot;Error opening session. Cause: &quot; + e, e); &#125; finally &#123; ErrorContext.instance().reset(); &#125;&#125; 在final Executor executor = configuration.newExecutor(tx, execType, autoCommit);会根据execType创建出不同类型的Executor BatchExecutor ReuseExecutor SimpleExecutor CachingExecutor 下来我们看一下selectList()实现 1234567891011public &lt;E&gt; List&lt;E&gt; selectList(String statement, Object parameter, RowBounds rowBounds) &#123; try &#123; MappedStatement ms = configuration.getMappedStatement(statement); List&lt;E&gt; result = executor.&lt;E&gt;query(ms, wrapCollection(parameter), rowBounds, Executor.NO_RESULT_HANDLER); return result; &#125; catch (Exception e) &#123; throw ExceptionFactory.wrapException(&quot;Error querying database. Cause: &quot; + e, e); &#125; finally &#123; ErrorContext.instance().reset(); &#125;&#125; MappedStatement类在Mybatis框架中用于表示XML文件中一个sql语句节点,即一个&lt;select /&gt;、&lt;update /&gt;或者&lt;insert /&gt;标签.Mybatis框架在初始化阶段会对XML配置文件进行读取,将其中的sql语句节点对象化为一个个MappedStatement对象.从配置中拿到一个MappedStatement然后交给executor去真正的执行, 真正的有query逻辑的只有BaseExecutor和CachingExecutor, 为了简单起见,我们看一下BaseExecutor. 由于中间的过程还涉及到了Mybatis的本地存储, 我们也跳过这部分.BaseExecutor#query() -&gt; BaseExecutor#queryFromDatabase()-&gt; SimpleExecutor#doQuery() 1234567891011121314public &lt;E&gt; List&lt;E&gt; doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException &#123; Statement stmt = null; try &#123; Configuration configuration = ms.getConfiguration(); // StatementHandler用于管理java.sql.Statement, 执行真正的与数据库操作 StatementHandler handler = configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, resultHandler, boundSql); // 通过StatementHandler实例化出一个Statement stmt = prepareStatement(handler, ms.getStatementLog()); // Statement开始执行查询逻辑 return handler.&lt;E&gt;query(stmt, resultHandler); &#125; finally &#123; closeStatement(stmt); &#125; &#125; 我们看一下SimpleStatementHandler里的查询逻辑 12345public &lt;E&gt; List&lt;E&gt; query(Statement statement, ResultHandler resultHandler) throws SQLException &#123; String sql = boundSql.getSql(); statement.execute(sql); return resultSetHandler.&lt;E&gt;handleResultSets(statement); &#125; SqlSource接口只有一个getBoundSql(Object parameterObject)方法,返回一个BoundSql对象.一个BoundSql对象,代表了一次sql语句的实际执行,而SqlSource对象的责任,就是根据传入的参数对象,动态计算出这个BoundSql,也就是说Mapper文件中的节点的计算,是由SqlSource对象完成的.SqlSource最常用的实现类是DynamicSqlSource 那么close()执行的是什么操作呢？ 12345678public void close() &#123; try &#123; executor.close(isCommitOrRollbackRequired(false)); dirty = false; &#125; finally &#123; ErrorContext.instance().reset(); &#125;&#125; 我们还是看BaseExecutor的close() 123456789101112131415161718public void close(boolean forceRollback) &#123; try &#123; try &#123; rollback(forceRollback); &#125; finally &#123; // 真正关闭资源 if (transaction != null) transaction.close(); &#125; &#125; catch (SQLException e) &#123; log.debug(&quot;Unexpected exception on closing transaction. Cause: &quot; + e); &#125; finally &#123; transaction = null; deferredLoads = null; localCache = null; localOutputParameterCache = null; closed = true; &#125; &#125; 我们看一下JdbcTransaction的close() 123456789public void close() throws SQLException &#123; if (connection != null) &#123; resetAutoCommit(); if (log.isDebugEnabled()) &#123; log.debug(&quot;Closing JDBC Connection [&quot; + connection + &quot;]&quot;); &#125; connection.close(); &#125;&#125; Transaction : 包装了一个数据库连接. 处理整个网络连接过程中的所有操作, 例如creation, preparation, commit/rollback and close. 异常测试如果我们不关闭SqlSession会有什么情况发生呢? 1234567891011121314151617181920212223242526272829303132333435363738394041import java.io.IOException;import java.io.InputStream;import java.sql.SQLException;import java.util.ArrayList;import java.util.Date;import java.util.List;import org.apache.ibatis.annotations.Select;import org.apache.ibatis.io.Resources;import org.apache.ibatis.session.SqlSession;import org.apache.ibatis.session.SqlSessionFactory;import org.apache.ibatis.session.SqlSessionFactoryBuilder;public class TestMybatis &#123; public static void main(String[] args) throws IOException &#123; String resource = &quot;mybatis-config.xml&quot;; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); List&lt;SqlSession&gt; list = new ArrayList&lt;&gt;(); for (int i = 1; i &lt; 10; i++) &#123; SqlSession session = sqlSessionFactory.openSession(); QueryMapper mapper = session.getMapper(QueryMapper.class); list.add(session); System.out.println(i + &quot; : &quot; + mapper.select() + &quot; - &quot; + new Date().toLocaleString()); &#125; list.forEach(session -&gt; &#123; try &#123; System.out.println(session.getConnection().isClosed()); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125;); &#125;&#125;interface QueryMapper &#123; @Select(&quot;select name from user&quot;) public List&lt;String&gt; select();&#125; 下面是我们的配置文件 1234567891011121314151617181920212223&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE configuration PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;configuration&gt; &lt;environments default=&quot;development&quot;&gt; &lt;environment id=&quot;development&quot;&gt; &lt;transactionManager type=&quot;JDBC&quot;/&gt; &lt;dataSource type=&quot;POOLED&quot;&gt; &lt;property name=&quot;driver&quot; value=&quot;com.mysql.jdbc.Driver&quot;/&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/test?autoReconnect=true&quot;/&gt; &lt;property name=&quot;username&quot; value=&quot;root&quot;/&gt; &lt;property name=&quot;password&quot; value=&quot;root&quot;/&gt; &lt;property name=&quot;poolMaximumActiveConnections&quot; value=&quot;3&quot;/&gt; &lt;property name=&quot;poolMaximumIdleConnections&quot; value=&quot;1&quot;/&gt; &lt;property name=&quot;poolTimeToWait&quot; value=&quot;5&quot;/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;mappers&gt; &lt;mapper class=&quot;QueryMapper&quot;/&gt; &lt;/mappers&gt;&lt;/configuration&gt; 我们配置了最大可用连接数为3, 最大的闲置连接为1. 结果为 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283841 : [123] - 2016-4-12 18:37:282 : [123] - 2016-4-12 18:37:283 : [123] - 2016-4-12 18:37:284 : [123] - 2016-4-12 18:37:485 : [123] - 2016-4-12 18:37:486 : [123] - 2016-4-12 18:37:487 : [123] - 2016-4-12 18:38:088 : [123] - 2016-4-12 18:38:089 : [123] - 2016-4-12 18:38:08java.sql.SQLException: Error accessing PooledConnection. Connection is invalid. at org.apache.ibatis.datasource.pooled.PooledConnection.checkConnection(PooledConnection.java:254) at org.apache.ibatis.datasource.pooled.PooledConnection.invoke(PooledConnection.java:243) at com.sun.proxy.$Proxy3.isClosed(Unknown Source) at TestMybatis.lambda$main$0(TestMybatis.java:29) at java.util.ArrayList.forEach(ArrayList.java:1249) at TestMybatis.main(TestMybatis.java:27) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)java.sql.SQLException: Error accessing PooledConnection. Connection is invalid. at org.apache.ibatis.datasource.pooled.PooledConnection.checkConnection(PooledConnection.java:254) at org.apache.ibatis.datasource.pooled.PooledConnection.invoke(PooledConnection.java:243) at com.sun.proxy.$Proxy3.isClosed(Unknown Source) at TestMybatis.lambda$main$0(TestMybatis.java:29) at java.util.ArrayList.forEach(ArrayList.java:1249) at TestMybatis.main(TestMybatis.java:27) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)java.sql.SQLException: Error accessing PooledConnection. Connection is invalid. at org.apache.ibatis.datasource.pooled.PooledConnection.checkConnection(PooledConnection.java:254) at org.apache.ibatis.datasource.pooled.PooledConnection.invoke(PooledConnection.java:243) at com.sun.proxy.$Proxy3.isClosed(Unknown Source) at TestMybatis.lambda$main$0(TestMybatis.java:29) at java.util.ArrayList.forEach(ArrayList.java:1249) at TestMybatis.main(TestMybatis.java:27) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)java.sql.SQLException: Error accessing PooledConnection. Connection is invalid. at org.apache.ibatis.datasource.pooled.PooledConnection.checkConnection(PooledConnection.java:254) at org.apache.ibatis.datasource.pooled.PooledConnection.invoke(PooledConnection.java:243) at com.sun.proxy.$Proxy3.isClosed(Unknown Source) at TestMybatis.lambda$main$0(TestMybatis.java:29) at java.util.ArrayList.forEach(ArrayList.java:1249) at TestMybatis.main(TestMybatis.java:27) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)java.sql.SQLException: Error accessing PooledConnection. Connection is invalid. at org.apache.ibatis.datasource.pooled.PooledConnection.checkConnection(PooledConnection.java:254) at org.apache.ibatis.datasource.pooled.PooledConnection.invoke(PooledConnection.java:243) at com.sun.proxy.$Proxy3.isClosed(Unknown Source) at TestMybatis.lambda$main$0(TestMybatis.java:29) at java.util.ArrayList.forEach(ArrayList.java:1249) at TestMybatis.main(TestMybatis.java:27) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)java.sql.SQLException: Error accessing PooledConnection. Connection is invalid. at org.apache.ibatis.datasource.pooled.PooledConnection.checkConnection(PooledConnection.java:254) at org.apache.ibatis.datasource.pooled.PooledConnection.invoke(PooledConnection.java:243) at com.sun.proxy.$Proxy3.isClosed(Unknown Source) at TestMybatis.lambda$main$0(TestMybatis.java:29) at java.util.ArrayList.forEach(ArrayList.java:1249) at TestMybatis.main(TestMybatis.java:27) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144)falsefalsefalse","categories":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://wangmingco.github.io/categories/Mybatis/"}],"tags":[]},{"title":"计算二维数组索引","slug":"算法/计算二维数组索引","date":"2016-03-30T16:00:00.000Z","updated":"2021-11-18T02:53:38.956Z","comments":true,"path":"2016/03/31/算法/计算二维数组索引/","link":"","permalink":"https://wangmingco.github.io/2016/03/31/%E7%AE%97%E6%B3%95/%E8%AE%A1%E7%AE%97%E4%BA%8C%E7%BB%B4%E6%95%B0%E7%BB%84%E7%B4%A2%E5%BC%95/","excerpt":"","text":"假设我们有这样的一个二维数组 1234(X,Y) 0 1 20 0 1 21 3 4 52 6 7 8 (0, 0) -&gt; 0 (1, 0) -&gt; 1 (2, 0) -&gt; 2 (0, 1) -&gt; 3 (1, 1) -&gt; 4 (2, 1) -&gt; 5 (0, 2) -&gt; 6 (1, 2) -&gt; 7 (2, 2) -&gt; 8下面我们实现这个算法123456789101112public class Test &#123; public static void main(String[] args) &#123; int width = 3; int length = 3; for (int x = 0; x &lt; width; x++) &#123; for (int y = 0; y &lt; length; y++) &#123; System.out.println(&quot;(&quot; + x + &quot;, &quot; + y + &quot;)&quot; + (x + y * length)); &#125; &#125; &#125;&#125; 我们可以这样想象: 将这个二维数组串行, 就是以0, 1 , 2, 3, 4, 5, 6, 当计算(1, 1)这个坐标的时候就是用x加上 y在x上移动的倍数","categories":[{"name":"算法","slug":"算法","permalink":"https://wangmingco.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[]},{"title":"类和实例的初始化","slug":"jvm/类和实例的初始化","date":"2016-03-19T16:00:00.000Z","updated":"2021-11-18T02:40:51.968Z","comments":true,"path":"2016/03/20/jvm/类和实例的初始化/","link":"","permalink":"https://wangmingco.github.io/2016/03/20/jvm/%E7%B1%BB%E5%92%8C%E5%AE%9E%E4%BE%8B%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96/","excerpt":"","text":"实例化过程最近面试的时候遇到很多人都在问java初始化的东西, 今天就写个测试程序来个JAVA初始化大揭秘. 1234567891011121314151617181920212223242526272829303132333435public class TestInit &#123; public static void main(String[] args) &#123; new B(); new B(); &#125;&#125;class A &#123; public A() &#123; System.out.println(&quot;A&quot;); &#125; &#123; System.out.println(&quot;A init&quot;); &#125; static &#123; System.out.println(&quot;A static init&quot;); &#125;&#125;class B extends A &#123; public B() &#123; System.out.println(&quot;B&quot;); &#125; &#123; System.out.println(&quot;B init&quot;); &#125; static &#123; System.out.println(&quot;B static init&quot;); &#125;&#125; 这个程序的输出结果为 12345678910A static initB static initA initAB initBA initAB initB 下面我用javap命令反编译一下TestInit的class字节码 123456789101112131415161718192021➜ classes javap -c TestInitCompiled from &quot;TestInit.java&quot;public class TestInit &#123; public TestInit(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return public static void main(java.lang.String[]); Code: 0: new #2 // class B 3: dup 4: invokespecial #3 // Method B.&quot;&lt;init&gt;&quot;:()V 7: pop 8: new #2 // class B 11: dup 12: invokespecial #3 // Method B.&quot;&lt;init&gt;&quot;:()V 15: pop 16: return&#125; 然后看一下A的class字节码 12345678910111213141516171819202122➜ classes javap -c ACompiled from &quot;TestInit.java&quot;class A &#123; public A(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 7: ldc #3 // String A init 9: invokevirtual #4 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 12: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 15: ldc #5 // String A 17: invokevirtual #4 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 20: return static &#123;&#125;; Code: 0: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 3: ldc #6 // String A static init 5: invokevirtual #4 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 8: return&#125; 从上面代码的执行结果我们也可以看出, A的代码是先执行的static静态初始化的(这段代码只有在类被加载进虚拟机中时才会执行一次). 那么我们就先从它分析入手 getstatic 访问java/lang/System.out这个实例熟悉 ldc 从常量池里加载一个常亮进入操作数栈, 这里加载的是A static init字符串 invokevirtual 然后调用java/io/PrintStream.println方法, 输出A static init字符串 构造器的代码开始执行 aload_0 : 从局部变量表加载一个reference类型值到操作数栈, 这个变量应该是this invokespecial : 用于需要特殊处理的实例方法(实例初始化方法, 私有方法和父类方法). 这里是调用A的实例化方法, 也就是&#123;&#125;这中的代码 getstatic 实例化方法访问java/lang/System.out属性 ldc 实例化方法从常量池里加载一个常亮进入操作数栈, 这里加载的是A init字符串 invokevirtual 实例化方法调用java/io/PrintStream.println方法, 输出A init字符串 getstatic 构造器访问java/lang/System.out属性 ldc构造器从常量池里加载一个常亮进入操作数栈, 这里加载的是A字符串 invokevirtual 构造器调用java/io/PrintStream.println方法, 输出A字符串 然后我们看一下B的claa字节码 12345678910111213141516171819202122➜ classes javap -c BCompiled from &quot;TestInit.java&quot;class B extends A &#123; public B(); Code: 0: aload_0 1: invokespecial #1 // Method A.&quot;&lt;init&gt;&quot;:()V 4: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 7: ldc #3 // String B init 9: invokevirtual #4 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 12: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 15: ldc #5 // String B 17: invokevirtual #4 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 20: return static &#123;&#125;; Code: 0: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 3: ldc #6 // String B static init 5: invokevirtual #4 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 8: return&#125; 与A类似, B同样是从类的初始化开始代码执行的 getstatic 访问java/lang/System.out这个实例熟悉 ldc 从常量池里加载一个常亮进入操作数栈, 这里加载的是B static init字符串 invokevirtual 然后调用java/io/PrintStream.println方法, 输出B static init字符串 然后是构造器方法执行 aload_0同样的是加载this进虚拟机栈 invokespecial 调用父类A的实例初始化方法 然后就开死像A一样, 调用自己的实例化过程 如果我们只加载这个类呢？ 12345public class TestInit &#123; public static void main(String[] args) throws ClassNotFoundException &#123; Class.forName(&quot;B&quot;); &#125;&#125; 结果输出为 12A static initB static init 这也间接地验证了我们上面的推算 类的初始化类初始化阶段是类加载过程中最后一步,开始执行类构造器方法. &lt;clinit&gt;方法执行过程可能会影响程序运行行为的一些特点和细节 &lt;clinit&gt;方法由编译器将类变量的赋值动作和静态语句块(static{}块)中的语句合并产生的.编译器收集的顺序是由语句在源文件中出现的顺序决定的,静态语句块只能访问到定义在静态语句块之前的变量,定义在它之后的变量,在前面的静态语句块中可以赋值但是不能访问. &lt;clinit&gt;()方法和实例的构造函数()不同,他不需要显式地调用父类构造器,虚拟机会保证在子类的()方法执行之前,父类的&lt;clinit&gt;方法已经执行完毕,因此虚拟机中第一个被执行的&lt;clinit&gt;()方法的类肯定是java.lang.Object 由于父类的&lt;clinit&gt;()方法先执行,也就意味着父类中定义的静态语句块要优先于子类的变量赋值操作 &lt;clinit&gt;()方法对于对类或者接口来说并不是必须的,如果一个类中没有静态语句块,也没有对变量的赋值操作,那么编译器可以不为这个类生成&lt;clinit&gt;()方法. 接口中不能使用静态语句块,但仍然有变量初始化的赋值操作,因此接口与类一样会生成()方法.但接口与类不同的是,执行接口&lt;clinit&gt;()不需要先执行父接口&lt;clinit&gt;().只有当父接口中定义的变量被使用时,父接口才会被初始化.另外,接口的实现类在初始化时也一样不会执行接口的()方法. 虚拟机会保证一个类的&lt;clinit&gt;()方法在多线程环境中被正确地加锁和同步,如果多个线程同时去初始化一个类,那么只会有一个线程去执行这个类的&lt;clinit&gt;()方法,其他线程都需要阻塞等待,直到活动线程执行&lt;clinit&gt;()方法完毕. 如果,在一个类的()方法中有耗时很长的操作,那就很可能造成多个进程阻塞. &lt;clinit&gt;()方法执行顺序 1234567891011121314151617 public class NewClass &#123; static class Parent &#123; public static int A = 1; static &#123; A = 2; &#125; &#125; static class Sub extends Parent &#123; public static int B = A; &#125; public static void main(String[] args) &#123; System.out.println(Sub.B); &#125;&#125; 字段解析 123456789101112131415161718192021222324252627public class DeadLoopClass &#123; static &#123; if(true) &#123; System.out.println(Thread.currentThread() + &quot; init DeadLoopClass &quot;); while(true)&#123;&#125; &#125; &#125; public static void main(String[] args) &#123; Runnable script = new Runnable() &#123; @Override public void run() &#123; System.out.println(Thread.currentThread() + &quot; start&quot;); DeadLoopClass dlc = new DeadLoopClass(); System.out.println(Thread.currentThread() + &quot; run over&quot;); &#125; &#125;; Thread t1 = new Thread(script); Thread t2 = new Thread(script); t1.start(); t2.start(); &#125;&#125; 类初始化的四种情况 遇到new, getstatic, putstatic, invokestatic, 这四条字节码指令时, 如果类没有进行过初始化,则必须先触发初始化 使用java.lang.reflect包的方法进行反射调用的时候,如果类没有进行过初始化,则需要先触发其初始化 当初始化一个类的时候,如果发现其父类还没有进行过初始化,则需要先触发其父类的初始化. 当虚拟机启动的时候,用户需要指定一个要执行的主类,虚拟机会先初始化这个主类. 通过子类引用父类的静态字段,不会导致子类的类初始化 12345678910111213141516171819202122class SuperClass &#123; static &#123; System.out.println(&quot;SuperClass init&quot;); &#125; public static int value = 123;&#125;class SubClass extends SuperClass &#123; static &#123; System.out.println(&quot;SubClass init&quot;); &#125;&#125;public class NotInitialization &#123; public static void main(String[] args) &#123; System.out.println(SubClass.value); &#125;&#125; 通过数组定义来引用类,不会触发此类的初始化 1234567891011121314class SuperClass &#123; static &#123; System.out.println(&quot;SuperClass init&quot;); &#125; public static int value = 123;&#125;public class NotInitialization &#123; public static void main(String[] args) &#123; SuperClass[] sca = new SuperClass[10]; &#125;&#125; 常量在编译阶段会存入调用类的常量池中,本质上没有直接引用到定义常量的类,因此不会触发定义常量的类的初始化 123456789101112class ConstClass &#123; static &#123; System.out.println(&quot;ConstClass init&quot;); &#125; public static final String HELLOWORLD = &quot;hello world&quot;;&#125;public class NotInitialization &#123; public static void main(String[] args) &#123; System.out.println(ConstClass.HELLOWORLD); &#125;&#125;","categories":[{"name":"JVM","slug":"JVM","permalink":"https://wangmingco.github.io/categories/JVM/"}],"tags":[]},{"title":"Netty Unsafe","slug":"JavaLibrary/Netty Unsafe","date":"2016-03-18T16:00:00.000Z","updated":"2021-11-18T02:50:26.542Z","comments":true,"path":"2016/03/19/JavaLibrary/Netty Unsafe/","link":"","permalink":"https://wangmingco.github.io/2016/03/19/JavaLibrary/Netty%20Unsafe/","excerpt":"","text":"首先我们来看一下Unsafe的继承 UnsafeUnsafe是Channel的内部接口, 它定义了下面的相关功能 localAddress() : 获得本地绑定的SocketAddress对象 remoteAddress() : 返回与网络对等端绑定的地址SocketAddress register() : 将EventLoop注册到Channel上, 一旦注册成功就返回ChannelFuture bind() : 将SocketAddress绑定到Channel上. connect() : Channel与对端的SocketAddress进行连接 disconnect() : Channel与网络对端断开连接 close() : 关闭Channel与网络对端的连接 deregister() : Channel与EventLoop解除注册关系 beginRead() : Schedules a read operation that fills the inbound buffer of the first {@link ChannelInboundHandler} in the {@link ChannelPipeline}. If there’s already a pending read operation, this method does nothing. write() : 调度一个写操作 flush() : 通过write()将全部的写操作进行调用 outboundBuffer() : Returns the {@link ChannelOutboundBuffer} of the {@link Channel} where the pending write requests are stored. AbstractUnsafeAbstractUnsafe是AbstractChannel的内部类, 主要是提供了对AbstractChannel的辅助功能, 它内部实现了N个, 这些方法最终都会调用AbstractChannel子类实现的doXXX()相关方法. 例如: register() -&gt; doRegister()(AbstractNioChannel实现), 调用完成之后调用pipline的fireChannelRegistered()和fireChannelActive(). bind() -&gt; doBind() disconnect() -&gt; doDisconnect() close() -&gt; doClose() deregister -&gt; doDeregister()(AbstractNioChannel实现) beginRead() -&gt; doBeginRead()(AbstractNioChannel实现) flush() -&gt; doWrite() 需要仔细看一下的是AbstractUnsafe内部消息存储的一个环形数组ChannelOutboundBuffer成员 1private ChannelOutboundBuffer outboundBuffer = new ChannelOutboundBuffer(AbstractChannel.this); 下来我们看一下它的write()方法 123456789101112131415161718192021222324252627@Override public final void write(Object msg, ChannelPromise promise) &#123; ChannelOutboundBuffer outboundBuffer = this.outboundBuffer; if (outboundBuffer == null) &#123; // outboundBuffer为空, 说明channel已经关闭了, 那么现在就需要立刻做快速失败处理 safeSetFailure(promise, CLOSED_CHANNEL_EXCEPTION); // 将消息释放掉, 避免发生内存泄漏 ReferenceCountUtil.release(msg); return; &#125; int size; try &#123; msg = filterOutboundMessage(msg); size = estimatorHandle().size(msg); if (size &lt; 0) &#123; size = 0; &#125; &#125; catch (Throwable t) &#123; safeSetFailure(promise, t); ReferenceCountUtil.release(msg); return; &#125; // 我们看到, 在写消息的时候,最后就是将msg写到了一个环形数组里 outboundBuffer.addMessage(msg, size, promise); &#125; 将消息写到outboundBuffer之后, 最终我们还是需要调用flush()将其真正刷到TCP中 12345678910111213141516171819@Override public final void flush() &#123; ChannelOutboundBuffer outboundBuffer = this.outboundBuffer; outboundBuffer.addFlush(); flush0(); &#125; protected void flush0() &#123; final ChannelOutboundBuffer outboundBuffer = this.outboundBuffer; try &#123; doWrite(outboundBuffer); &#125; catch (Throwable t) &#123; &#125; finally &#123; inFlush0 = false; &#125; &#125; 我们看到最终的写到channel中也是由doWrite()方法实现的. AbstractNioUnsafeAbstractNioUnsafe是AbstactNioChannel的内部类. 与AbstractUnsafe类似, 它也是提供了一些对Channel的代理调用 connect() -&gt; doConnect() finishConnect() -&gt; doFinishConnect() NioByteUnsafe我们重点看一下read()和write()方法 我们首先看一下read()方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192@Override public void read() &#123; final ChannelConfig config = config(); if (!config.isAutoRead() &amp;&amp; !isReadPending()) &#123; // ChannelConfig.setAutoRead(false) was called in the meantime removeReadOp(); return; &#125; final ChannelPipeline pipeline = pipeline(); final ByteBufAllocator allocator = config.getAllocator(); // 我们配置的每次读取数据最多读取的数据量 final int maxMessagesPerRead = config.getMaxMessagesPerRead(); RecvByteBufAllocator.Handle allocHandle = this.allocHandle; if (allocHandle == null) &#123; this.allocHandle = allocHandle = config.getRecvByteBufAllocator().newHandle(); &#125; ByteBuf byteBuf = null; int messages = 0; boolean close = false; try &#123; // 读取的总量 int totalReadAmount = 0; // boolean readPendingReset = false; do &#123; // 获取一个byteBuf对象, 用于这次读取数据, 具体的获取策略, 本文最后有介绍 byteBuf = allocHandle.allocate(allocator); int writable = byteBuf.writableBytes(); // 调用NioSocketChannel的doReadBytes()实现, 将数据读进byteBuf中 int localReadAmount = doReadBytes(byteBuf); if (localReadAmount &lt;= 0) &#123; // 如果没有读到数据,则将ByteBuf释放掉 byteBuf.release(); close = localReadAmount &lt; 0; break; &#125; if (!readPendingReset) &#123; readPendingReset = true; setReadPending(false); &#125; // 开始在pipeline里进行ByteBuf数据传播 pipeline.fireChannelRead(byteBuf); byteBuf = null; if (totalReadAmount &gt;= Integer.MAX_VALUE - localReadAmount) &#123; // Avoid overflow. totalReadAmount = Integer.MAX_VALUE; break; &#125; // 统计所有的读到的数据 totalReadAmount += localReadAmount; // stop reading if (!config.isAutoRead()) &#123; break; &#125; if (localReadAmount &lt; writable) &#123; // Read less than what the buffer can hold, // which might mean we drained the recv buffer completely. break; &#125; // 如果仍然有未读数据的话, 则继续读取 &#125; while (++ messages &lt; maxMessagesPerRead); // 当前所有数据都读取完了, 触发 pipeline.fireChannelReadComplete(); // 根据当前读到的字节数预测下个消息的字节数大小 allocHandle.record(totalReadAmount); if (close) &#123; closeOnRead(pipeline); close = false; &#125; &#125; catch (Throwable t) &#123; handleReadException(pipeline, byteBuf, t, close); &#125; finally &#123; // Check if there is a readPending which was not processed yet. // This could be for two reasons: // * The user called Channel.read() or ChannelHandlerContext.read() in channelRead(...) method // * The user called Channel.read() or ChannelHandlerContext.read() in channelReadComplete(...) method // // See https://github.com/netty/netty/issues/2254 if (!config.isAutoRead() &amp;&amp; !isReadPending()) &#123; removeReadOp(); &#125; &#125; &#125; &#125; NioMessageUnsafeNioMessageUnsafe是AbstractNioMessageChannel的内部类. 它的read()方法与NioByteMessage的类似, 只不过这个是用于服务NioServerSocketChannel的, 它内部的doReadMessages()会调用的NioServerSocketChannel的实现. readBuf每个NioMessageUnsafe对象都会生成一个 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384private final List&lt;Object&gt; readBuf = new ArrayList&lt;Object&gt;();@Override public void read() &#123; assert eventLoop().inEventLoop(); final ChannelConfig config = config(); if (!config.isAutoRead() &amp;&amp; !isReadPending()) &#123; // ChannelConfig.setAutoRead(false) was called in the meantime removeReadOp(); return; &#125; // 从配置中获取每次读取消息的最大字节数 final int maxMessagesPerRead = config.getMaxMessagesPerRead(); final ChannelPipeline pipeline = pipeline(); boolean closed = false; Throwable exception = null; try &#123; try &#123; for (;;) &#123; // 从NioServerSocketChannel中读取NioSocketChannel进readBuf中 int localRead = doReadMessages(readBuf); if (localRead == 0) &#123; // 如果没有新的连接, 则不再读取 break; &#125; if (localRead &lt; 0) &#123; closed = true; break; &#125; // stop reading and remove op if (!config.isAutoRead()) &#123; break; &#125; if (readBuf.size() &gt;= maxMessagesPerRead) &#123; break; &#125; &#125; &#125; catch (Throwable t) &#123; exception = t; &#125; setReadPending(false); int size = readBuf.size(); for (int i = 0; i &lt; size; i ++) &#123; // 触发NioServerSocketChannel的pipeline的fireChannelRead()方法 // 从而触发ServerBoostTrap的read方法, 将readBuf里的NioSocketChannel与从Reactor进行注册绑定 pipeline.fireChannelRead(readBuf.get(i)); &#125; // 将所有的NioSocketChannel与从Reactor都完成注册之后, 将readBuf清空 readBuf.clear(); // 最后调用NioServerSocketChannel的fireChannelReadComplete pipeline.fireChannelReadComplete(); if (exception != null) &#123; if (exception instanceof IOException &amp;&amp; !(exception instanceof PortUnreachableException)) &#123; // ServerChannel should not be closed even on IOException because it can often continue // accepting incoming connections. (e.g. too many open files) closed = !(AbstractNioMessageChannel.this instanceof ServerChannel); &#125; pipeline.fireExceptionCaught(exception); &#125; if (closed) &#123; if (isOpen()) &#123; close(voidPromise()); &#125; &#125; &#125; finally &#123; // Check if there is a readPending which was not processed yet. // This could be for two reasons: // * The user called Channel.read() or ChannelHandlerContext.read() in channelRead(...) method // * The user called Channel.read() or ChannelHandlerContext.read() in channelReadComplete(...) method // // See https://github.com/netty/netty/issues/2254 if (!config.isAutoRead() &amp;&amp; !isReadPending()) &#123; removeReadOp(); &#125; &#125; &#125; &#125; AdaptiveRecvByteBufAllocator由于RecvByteBufAllocator只在Unsafe体系中用到了, 就不再单独拿个章节出来讲它, 在这里我们重点分析一个AdaptiveRecvByteBufAllocator 我们首先看一下他的内部成员属性 12345678static final int DEFAULT_MINIMUM = 64;static final int DEFAULT_INITIAL = 1024;static final int DEFAULT_MAXIMUM = 65536;private static final int INDEX_INCREMENT = 4;private static final int INDEX_DECREMENT = 1;private static final int[] SIZE_TABLE; DEFAULT_MINIMUM : 默认的每个ByteBuf的最小值 DEFAULT_INITIAL : 默认的每个ByteBuf的初始值 DEFAULT_MAXIMUM : 默认的每个ByteBuf的最大值 INDEX_INCREMENT : 默认的每个ByteBuf的增大步进大小 INDEX_DECREMENT : 默认的每个ByteBuf的减小步进大小 SIZE_TABLE : 所有ByteBuf消息可能会用到的大小值 然后我们看一下他的静态初始化 1234567891011121314151617static &#123; List&lt;Integer&gt; sizeTable = new ArrayList&lt;Integer&gt;(); // 当消息小于512的时候, 每次步进16字节, 也就是预测下个消息比当前消息仍然大16字节 for (int i = 16; i &lt; 512; i += 16) &#123; sizeTable.add(i); &#125; // 当消息大小大于512的时候, 则采取倍增的方式 for (int i = 512; i &gt; 0; i &lt;&lt;= 1) &#123; sizeTable.add(i); &#125; SIZE_TABLE = new int[sizeTable.size()]; for (int i = 0; i &lt; SIZE_TABLE.length; i ++) &#123; SIZE_TABLE[i] = sizeTable.get(i); &#125; &#125; 下面我们看一下getSizeTableIndex()这个方法, 这个方法主要是根据入参然后推算出下一个消息的大小, 内部算法采用的是一个二分查找 1234567891011121314151617181920212223242526272829private static int getSizeTableIndex(final int size) &#123; // 遍历所有的SIZE_TABLE for (int low = 0, high = SIZE_TABLE.length - 1;;) &#123; if (high &lt; low) &#123; return low; &#125; if (high == low) &#123; return high; &#125; // 找到中间位置索引 int mid = low + high &gt;&gt;&gt; 1; int a = SIZE_TABLE[mid]; int b = SIZE_TABLE[mid + 1]; if (size &gt; b) &#123; // size大于中间值则向前查找 low = mid + 1; &#125; else if (size &lt; a) &#123; // size小于中间值则向后查找 high = mid - 1; &#125; else if (size == a) &#123; // 取a值 return mid; &#125; else &#123; // 取b值 return mid + 1; &#125; &#125; &#125; 但是真正的预测下一个消息的逻辑是放在了AdaptiveRecvByteBufAllocator的内部类HandleImpl中.我们重点看一下他的record方法 12345678910111213141516171819@Override public void record(int actualReadBytes) &#123; if (actualReadBytes &lt;= SIZE_TABLE[Math.max(0, index - INDEX_DECREMENT - 1)]) &#123; // 判断当前可读字节是否小于当前字节数的前一个大小, 如果小于, 则判断是否需要缩小容量 if (decreaseNow) &#123; // 如果需要的话, 则算出前一个索引位置进行缩小下个消息的ByteBuf的大小 index = Math.max(index - INDEX_DECREMENT, minIndex); nextReceiveBufferSize = SIZE_TABLE[index]; decreaseNow = false; &#125; else &#123; decreaseNow = true; &#125; &#125; else if (actualReadBytes &gt;= nextReceiveBufferSize) &#123; // 当前可读字节数大于下个可读字节数, 则对其下个ByteBuf进行扩容处理 index = Math.min(index + INDEX_INCREMENT, maxIndex); nextReceiveBufferSize = SIZE_TABLE[index]; decreaseNow = false; &#125; &#125;","categories":[{"name":"Netty","slug":"Netty","permalink":"https://wangmingco.github.io/categories/Netty/"}],"tags":[{"name":"Netty","slug":"Netty","permalink":"https://wangmingco.github.io/tags/Netty/"}]},{"title":"二叉树","slug":"算法/二叉树","date":"2016-03-18T16:00:00.000Z","updated":"2021-11-18T02:53:54.635Z","comments":true,"path":"2016/03/19/算法/二叉树/","link":"","permalink":"https://wangmingco.github.io/2016/03/19/%E7%AE%97%E6%B3%95/%E4%BA%8C%E5%8F%89%E6%A0%91/","excerpt":"","text":"二叉树就是有一个根节点, 每个节点最多有俩个子节点的树形结构. 二叉树又分为三种状态 满二叉树: 除了叶子节点之外, 所有的节点上都有俩个子节点的树 完全二叉树 : 除了叶子结点之外, 其余的节点上要么有俩个子节点要么一个子节点的树 非完全二叉树 : 除了叶子节点之外, 其余的节点上出现了只有一个子节点的树","categories":[{"name":"算法","slug":"算法","permalink":"https://wangmingco.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[]},{"title":"Netty 压测","slug":"JavaLibrary/Netty 压测","date":"2016-03-16T16:00:00.000Z","updated":"2021-11-18T02:48:44.689Z","comments":true,"path":"2016/03/17/JavaLibrary/Netty 压测/","link":"","permalink":"https://wangmingco.github.io/2016/03/17/JavaLibrary/Netty%20%E5%8E%8B%E6%B5%8B/","excerpt":"","text":"我们知道Netty的性能是非常好的,那究竟有多好呢? 今天我写了一个小程序测试了一下 1234567891011121314151617181920212223242526272829303132333435363738public class NettyServer &#123; public static void main(String[] args) throws InterruptedException &#123; int cpuSize = Runtime.getRuntime().availableProcessors(); EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(cpuSize); try &#123; ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 128) .option(ChannelOption.TCP_NODELAY, true) .option(ChannelOption.AUTO_READ, true) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override public void initChannel(SocketChannel ch) &#123; ch.pipeline().addLast(new InHandler()); &#125; &#125;); ChannelFuture f = b.bind(8881).sync(); f.channel().closeFuture().sync(); &#125; finally &#123; bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); &#125; &#125;&#125;class InHandler extends ChannelInboundHandlerAdapter &#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) &#123; ctx.write(msg); &#125; @Override public void channelReadComplete(ChannelHandlerContext ctx) &#123; ctx.flush(); &#125;&#125; 上面是一个简单的Socket服务器, 不做任何的编解码工作, 当接收到数据之后, 直接返回给客户端. 在启动的这个服务器的时候加上指定虚拟机的堆大小(我们指定了大小为固定的30M) 123456789101112131415161718192021222324-Xmx30m -Xms30m````然后写一个Socket客户端程序(原谅我客户端是用python写的, 现在我正在把我业余时间写代码的语言替换成python)```pythonimport socketimport threadingimport timecount = 0def socketSendData(): client=socket.socket(socket.AF_INET,socket.SOCK_STREAM) client.connect((&#x27;localhost&#x27;,8881)) client.send(&#x27;2&#x27;) time.sleep(60)for i in range(0, 2000, 1): try: t = threading.Thread(target=socketSendData) info = t.start() except: count += 1 print &quot;Error: unable to start thread &quot; + str(count) 由于测试机配置问题, 我的python程序只能启动2000个Socket连接, 但是也无所谓, 我们看一下在这俩千个Socket连接时, Netty服务器的消耗 我们首先看一下客户端连接运行之前的Netty程序的内存占用我们看到了在top中为46M, 在visualVM中分配的30M堆内存也只使用了10M, 而且一直在GC. 那么我们再看一下压测之后的内?top中显示占用了58M的内存, 而在visualVM只不过偶尔比10M多一点的内存,而且又很快的GC掉了. 那么top中多出的12M内存是怎么回事呢?这是因为Netty默认的使用的是UnpooledDirectByteBuf(姑且是这么个名字吧), 它使用的是非池化的直接内存, 也就是说在接受网络连接数据的时候,它并没有直接使用堆内内存,而是使用的堆外的.","categories":[{"name":"Netty","slug":"Netty","permalink":"https://wangmingco.github.io/categories/Netty/"}],"tags":[{"name":"Netty","slug":"Netty","permalink":"https://wangmingco.github.io/tags/Netty/"}]},{"title":"Data too long for column 引起的设置 sql_mod","slug":"数据库/SQL Mod","date":"2016-03-15T16:00:00.000Z","updated":"2021-11-18T02:53:01.348Z","comments":true,"path":"2016/03/16/数据库/SQL Mod/","link":"","permalink":"https://wangmingco.github.io/2016/03/16/%E6%95%B0%E6%8D%AE%E5%BA%93/SQL%20Mod/","excerpt":"","text":"今天游戏上线, 在角色登陆日志里突然发生了 1Data too long for column &#x27;name&#x27; at row 1 当时在我们测试环境测试了,没问题, 这是为啥嘞? 当时没有纠结这个问题, 现在出现问题的这个varchar长度调大, 问题解决. 但是为啥生产环境出现问题, 而测试环境就没问题了, 于是开启了我的探索之旅… 我在自己的机器上创建了一张这样的表 123CREATE TABLE `testvarchar` ( `name` varchar(10) DEFAULT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf8 执行以下语句 12345INSERT INTO testvarchar(NAME) VALUES(&quot;0123456789&quot;);INSERT INTO testvarchar(NAME) VALUES(&quot;0123456789123&quot;);INSERT INTO testvarchar(NAME) VALUES(&quot;中文测试中文测试中文测试&quot;);INSERT INTO testvarchar(NAME) VALUES(&quot;abcdeabcdeabcde&quot;);INSERT INTO testvarchar(NAME) VALUES(&quot;a ee ee&quot;); 查询结果为 1234501234567890123456789中文测试中文测试中文abcdeabcdea e 很奇怪数据都存进去了,但是却把我的数据给截取到指定的长度10个字符. 而且不管是中文还是数字都是10字符长度. 这会不会和刚才那个问题有关系呢? 鉴于刚才那个问题没有头绪, 于是我看下这个截取的是为啥？于是我找到了这篇文章mysql中varchar字段长度超过限制长度自动截取的问题 我在本地种使用 12SET SESSION sql_mode=&#x27;STRICT_TRANS_TABLES&#x27;;SELECT @@sql_mode; 再次执行上面的插入,果真产生了Data too long for column, 看来就是生产环境里设置了这个值引起的. 在本地环境里也要设置成和生产环境一样的, 肯定不能用SESSION，用GLOBLE也不靠谱,我再Windows上对my.ini进行修改 12# Set the SQL mode to strictsql-mode=&quot;STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION&quot; 这样一来,哪怕MySQL重启了,我们的设置仍然有效. 最后贴一下其他的sql_mode的值 ONLY_FULL_GROUP_BY：对于GROUP BY聚合操作，如果在SELECT中的列，没有在GROUP BY中出现，那么这个SQL是不合法的，因为列不在GROUP BY从句中 NO_AUTO_VALUE_ON_ZERO：该值影响自增长列的插入。默认设置下，插入0或NULL代表生成下一个自增长值。如果用户 希望插入的值为0，而该列又是自增长的，那么这个选项就有用了。 STRICT_TRANS_TABLES：在该模式下，如果一个值不能插入到一个事务表中，则中断当前的操作，对非事务表不做限制 NO_ZERO_IN_DATE：在严格模式下，不允许日期和月份为零 NO_ZERO_DATE：设置该值，mysql数据库不允许插入零日期，插入零日期会抛出错误而不是警告。 ERROR_FOR_DIVISION_BY_ZERO：在INSERT或UPDATE过程中，如果数据被零除，则产生错误而非警告。如 果未给出该模式，那么数据被零除时MySQL返回NULL NO_AUTO_CREATE_USER：禁止GRANT创建密码为空的用户 NO_ENGINE_SUBSTITUTION：如果需要的存储引擎被禁用或未编译，那么抛出错误。不设置此值时，用默认的存储引擎替代，并抛出一个异常 PIPES_AS_CONCAT：将”||”视为字符串的连接操作符而非或运算符，这和Oracle数据库是一样的，也和字符串的拼接函数Concat相类似 ANSI_QUOTES：启用ANSI_QUOTES后，不能用双引号来引用字符串，因为它被解释为识别符","categories":[{"name":"数据库","slug":"数据库","permalink":"https://wangmingco.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[]},{"title":"Mysql 数据压缩","slug":"数据库/数据压缩","date":"2016-03-15T16:00:00.000Z","updated":"2021-11-18T02:53:45.483Z","comments":true,"path":"2016/03/16/数据库/数据压缩/","link":"","permalink":"https://wangmingco.github.io/2016/03/16/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%8E%8B%E7%BC%A9/","excerpt":"","text":"我们在创建一个表的时候, 可以采用压缩技术 123CREATE TABLE CUSTOMER ( … ) COMPRESS YES; 如果想要在中途停止表的压缩 1ALTER TABLE CUSTOMER COMPRESS NO; 但是停止之后并不会对已经存在的数据进行解压缩,如果想要对已经存在的数据解压缩的话, 我们可以使用 1REORG TABLE CUSTOMER; 这个语句会根据当前表的压缩状态来重新整理表, 对数据进行压缩解压缩. 如果我们只是想要对某个字符串字段(一般是针对Blob字段进行压缩)进行压缩的话, 那么我们可以使用压缩函数 1COMPRESS(string_to_compress) 然后再对其进行解压缩 1UNCOMPRESS()","categories":[{"name":"数据库","slug":"数据库","permalink":"https://wangmingco.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[]},{"title":"Netty NioEventLoop","slug":"JavaLibrary/Netty NioEventLoop","date":"2016-03-13T16:00:00.000Z","updated":"2021-11-18T02:51:30.511Z","comments":true,"path":"2016/03/14/JavaLibrary/Netty NioEventLoop/","link":"","permalink":"https://wangmingco.github.io/2016/03/14/JavaLibrary/Netty%20NioEventLoop/","excerpt":"","text":"在真实的业务环境中, 我们都是使用主从Reactor线程模型. 在Netty中主从线程池都是使用的NioEventLoopGroup, 它实现了java.util.concurrent.Executor. 虽然在编程中我们使用的是NioEventLoopGroup, 但是主要的逻辑确是在MultithreadEventExecutorGroup里实现的.下来我们首先看一下MultithreadEventExecutorGroup的数据成员 123456789101112131415161718192021private final EventExecutor[] children;private final EventExecutorChooser chooser;protected MultithreadEventExecutorGroup(int nThreads, ThreadFactory threadFactory, Object... args) &#123; children = new SingleThreadEventExecutor[nThreads]; if (isPowerOfTwo(children.length)) &#123; chooser = new PowerOfTwoEventExecutorChooser(); &#125; else &#123; chooser = new GenericEventExecutorChooser(); &#125; for (int i = 0; i &lt; nThreads; i ++) &#123; boolean success = false; try &#123; children[i] = newChild(threadFactory, args); success = true; &#125; catch (Exception e) &#123; // TODO: Think about if this is a good exception type throw new IllegalStateException(&quot;failed to create a child event loop&quot;, e); &#125; &#125; 我们看到了NioEventLoopGroup内部聚合了一个EventExecutor的数组. 这个数组就构成了主从线程池. 线程的选择由EventExecutorChooser chooser来实现 123456789101112131415161718@Overridepublic EventExecutor next() &#123; return chooser.next();&#125;private final class PowerOfTwoEventExecutorChooser implements EventExecutorChooser &#123; @Override public EventExecutor next() &#123; return children[childIndex.getAndIncrement() &amp; children.length - 1]; &#125;&#125;private final class GenericEventExecutorChooser implements EventExecutorChooser &#123; @Override public EventExecutor next() &#123; return children[Math.abs(childIndex.getAndIncrement() % children.length)]; &#125;&#125; 而newChild()的方法实现是由子类来确定的, 我们来直接看一下NioEventLoopGroup的内部实现 1234@Overrideprotected EventExecutor newChild(ThreadFactory threadFactory, Object... args) throws Exception &#123; return new NioEventLoop(this, threadFactory, (SelectorProvider) args[0]);&#125; 它是直接生成了一个NioEventLoop的实例出来. 下来我们看一下NioEventLoop的实现我们看一下NioEventLoop的属性成员 123456// 多路选择复用器Selector selector;// Netty优化过的SelectedSelectionKeysprivate SelectedSelectionKeySet selectedKeys;// SelectorProvider.provider()提供, 在NioEventLoopGroup构造器中实现private final SelectorProvider provider; 我们看到NioEventLoop主要是实现了IO多路复用, 它的任务执行是由父类SingleThreadEventExecutor实现的, 下面我们从它的构造器来追溯到SingleThreadEventExecutor上 12345678NioEventLoop(NioEventLoopGroup parent, ThreadFactory threadFactory, SelectorProvider selectorProvider) &#123; super(parent, threadFactory, false); if (selectorProvider == null) &#123; throw new NullPointerException(&quot;selectorProvider&quot;); &#125; provider = selectorProvider; selector = openSelector();&#125; SingleThreadEventExecutor这个类主要是实现了主从线程池中的线程功能, 所有的任务都在单线程中执行, 因此将这个线程池串行化, 可以将其看待成一个线程. 在SingleThreadEventExecutor中的构造器中,添加向任务队列中添加一个调用NioEventLoop的run()方法的任务 12345678910111213141516171819202122232425262728293031323334353637383940414243444546protected SingleThreadEventExecutor( EventExecutorGroup parent, ThreadFactory threadFactory, boolean addTaskWakesUp) &#123; thread = threadFactory.newThread(new Runnable() &#123; @Override public void run() &#123; boolean success = false; updateLastExecutionTime(); try &#123; SingleThreadEventExecutor.this.run(); success = true; &#125; catch (Throwable t) &#123; &#125; finally &#123; for (;;) &#123; int oldState = STATE_UPDATER.get(SingleThreadEventExecutor.this); if (oldState &gt;= ST_SHUTTING_DOWN || STATE_UPDATER.compareAndSet( SingleThreadEventExecutor.this, oldState, ST_SHUTTING_DOWN)) &#123; break; &#125; &#125; // Check if confirmShutdown() was called at the end of the loop. if (success &amp;&amp; gracefulShutdownStartTime == 0) &#123; logger.error(&quot;Buggy &quot; + EventExecutor.class.getSimpleName()); &#125; try &#123; // Run all remaining tasks and shutdown hooks. for (;;) &#123; if (confirmShutdown()) &#123; break; &#125; &#125; &#125; finally &#123; try &#123; cleanup(); &#125; finally &#123; STATE_UPDATER.set(SingleThreadEventExecutor.this, ST_TERMINATED); threadLock.release(); terminationFuture.setSuccess(null); &#125; &#125; &#125; &#125; &#125;); taskQueue = newTaskQueue(); &#125; 我们看到了一行关键性代码SingleThreadEventExecutor.this.run(), 它调用了自己的run()方法 1protected abstract void run(); 而这个方法是在NioEventLoop中实现的,也是我们要重点分析的代码 12345678910111213141516171819202122232425262728293031323334353637383940414243@Override protected void run() &#123; for (;;) &#123; boolean oldWakenUp = wakenUp.getAndSet(false); try &#123; // 查看taskQueue里是否有任务, 如果有任务的话, 则直接selector.selectNow(); if (hasTasks()) &#123; selectNow(); &#125; else &#123; select(oldWakenUp); if (wakenUp.get()) &#123; selector.wakeup(); &#125; &#125; cancelledKeys = 0; needsToSelectAgain = false; final int ioRatio = this.ioRatio; // 如果当前线程是百分百执行的话, 则直接处理所有的任务 if (ioRatio == 100) &#123; processSelectedKeys(); runAllTasks(); &#125; else &#123; final long ioStartTime = System.nanoTime(); processSelectedKeys(); final long ioTime = System.nanoTime() - ioStartTime; runAllTasks(ioTime * (100 - ioRatio) / ioRatio); &#125; // if (isShuttingDown()) &#123; closeAll(); if (confirmShutdown()) &#123; break; &#125; &#125; &#125; catch (Throwable t) &#123; &#125; &#125; &#125; 上面的run()就是不断的轮询当前NioEventLoop里是否有任务. 然后处理Selector上已经就绪的Channel和任务队列里的任务.然后我们接着往下看processSelectedKeys()方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051private void processSelectedKeys() &#123; if (selectedKeys != null) &#123; processSelectedKeysOptimized(selectedKeys.flip()); &#125; else &#123; processSelectedKeysPlain(selector.selectedKeys()); &#125; &#125; private void processSelectedKeysPlain(Set&lt;SelectionKey&gt; selectedKeys) &#123; // check if the set is empty and if so just return to not create garbage by // creating a new Iterator every time even if there is nothing to process. // See https://github.com/netty/netty/issues/597 if (selectedKeys.isEmpty()) &#123; return; &#125; Iterator&lt;SelectionKey&gt; i = selectedKeys.iterator(); for (;;) &#123; final SelectionKey k = i.next(); // 取出SelectionKey的附件 final Object a = k.attachment(); i.remove(); if (a instanceof AbstractNioChannel) &#123; // a有可能是NioServerSocketChannel或者NioSocketChannel processSelectedKey(k, (AbstractNioChannel) a); &#125; else &#123; // 如果a不是Channel的话, 那就是NioTask了 @SuppressWarnings(&quot;unchecked&quot;) NioTask&lt;SelectableChannel&gt; task = (NioTask&lt;SelectableChannel&gt;) a; processSelectedKey(k, task); &#125; if (!i.hasNext()) &#123; break; &#125; if (needsToSelectAgain) &#123; selectAgain(); selectedKeys = selector.selectedKeys(); // Create the iterator again to avoid ConcurrentModificationException if (selectedKeys.isEmpty()) &#123; break; &#125; else &#123; i = selectedKeys.iterator(); &#125; &#125; &#125; &#125; 然后咱们接着往下看对Channel的处理 1234567891011121314151617181920212223242526272829303132private static void processSelectedKey(SelectionKey k, AbstractNioChannel ch) &#123; final NioUnsafe unsafe = ch.unsafe(); try &#123; int readyOps = k.readyOps(); // Also check for readOps of 0 to workaround possible JDK bug which may otherwise lead // to a spin loop if ((readyOps &amp; (SelectionKey.OP_READ | SelectionKey.OP_ACCEPT)) != 0 || readyOps == 0) &#123; // 如果是读事件或者连接的事件,则直接调用read方法 unsafe.read(); if (!ch.isOpen()) &#123; // Connection already closed - no need to handle write. return; &#125; &#125; if ((readyOps &amp; SelectionKey.OP_WRITE) != 0) &#123; // 如果是写操作位, 则说明有半包消息没有写完, 需要继续 ch.unsafe().forceFlush(); &#125; if ((readyOps &amp; SelectionKey.OP_CONNECT) != 0) &#123; // remove OP_CONNECT as otherwise Selector.select(..) will always return without blocking // See https://github.com/netty/netty/issues/924 int ops = k.interestOps(); ops &amp;= ~SelectionKey.OP_CONNECT; k.interestOps(ops); unsafe.finishConnect(); &#125; &#125; catch (CancelledKeyException ignored) &#123; unsafe.close(unsafe.voidPromise()); &#125;&#125; 在unsafe的多态这我们要多说一些, 我们知道NioEventLoop内部处理的Channel其实是有俩种类型的, 一个是NioServerScoketChannel一个是NioSocketChannel. NioServerSocketChannel继承自AbstractNioMessageChannel, 而这个父类实现了一个NioMessageUnsafe的一个内部类, 这个内部类的read()方法会调用Channel里的doReadMessage()方法. 父类的doReadMessage()方法是由子类来具体实现的. 在NioServerScoketChannel中是生成了一个NioSocketChannel的列表作为消息返回, 然后再让ServerBootstrapAcceptor将NioSocketChannel绑定到从Reactor上. NioSocketChannel继承自AbstractNioByteChannel, 这个父类实现了一个NioByteUnsafe, 这个Unsafe就负责创建ByteBuf, 接受真正的网络数据了.","categories":[{"name":"Netty","slug":"Netty","permalink":"https://wangmingco.github.io/categories/Netty/"}],"tags":[{"name":"Netty","slug":"Netty","permalink":"https://wangmingco.github.io/tags/Netty/"}]},{"title":"环形队列","slug":"算法/环形队列","date":"2016-03-11T16:00:00.000Z","updated":"2021-11-18T02:53:36.565Z","comments":true,"path":"2016/03/12/算法/环形队列/","link":"","permalink":"https://wangmingco.github.io/2016/03/12/%E7%AE%97%E6%B3%95/%E7%8E%AF%E5%BD%A2%E9%98%9F%E5%88%97/","excerpt":"","text":"12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182#-*- coding=utf-8 -*-# 环形队列实现class CircleQueue: # 队列头 queueHead = 0 # 队列尾 queueTail = 0 # 队列容量 queueCacity = 0 # 队列当前长度 queueLength = 0 # 队列容器 queue = [] def __init__(self, capacity): self.queueCacity = capacity self.queue = [0] * capacity # 入列 def enqueue(self, obj): if(self.isFull()): raise RuntimeError(&quot;Queue is Full&quot;) self.queue[self.queueTail] = obj self.queueTail += 1 # 为了让队列头一直在环形队列中进行变化, 因此进行取余操作, # 当队列头达到最大容量时,再增长就回到初始队列头的位置 self.queueTail = self.queueTail % self.queueCacity self.queueLength += 1 return self.queueLength # 出列 def dequeue(self): if(self.isEmpoty()): raise RuntimeError(&quot;Queue is Empoty&quot;) obj = self.queue[self.queueHead] self.queueHead += 1 self.queueHead = self.queueHead % self.queueCacity self.queueLength -= 1 return obj # 判断队列是否为空 def isEmpoty(self): return self.queueLength == 0 # 判断队列是否已满 def isFull(self): return self.queueLength == self.queueCacity# 测试circleQueue = CircleQueue(5)# 入列5个元素assert circleQueue.enqueue(1) == 1assert circleQueue.enqueue(2) == 2assert circleQueue.enqueue(3) == 3assert circleQueue.enqueue(4) == 4assert circleQueue.enqueue(5) == 5# 现在队列的长度为5, 且队列尾已经和队列头重合了assert circleQueue.queueLength == 5assert circleQueue.queueTail == 0assert circleQueue.queueHead == 0assert circleQueue.dequeue() == 1assert circleQueue.dequeue() == 2assert circleQueue.dequeue() == 3assert circleQueue.dequeue() == 4assert circleQueue.dequeue() == 5assert circleQueue.queueTail == 0assert circleQueue.queueHead == 0# 再入列一个数据,当前长度为1,且队列头为0,队列尾为1assert circleQueue.enqueue(6) == 1assert circleQueue.queueTail == 1assert circleQueue.queueHead == 0 环形队列的关键是能让头索引和尾索引能够在整个环形队列中自己循环","categories":[{"name":"算法","slug":"算法","permalink":"https://wangmingco.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[]},{"title":"Nginx 静态资源服务","slug":"nginx/nginx文件服务器","date":"2016-03-05T16:00:00.000Z","updated":"2021-11-18T02:43:40.783Z","comments":true,"path":"2016/03/06/nginx/nginx文件服务器/","link":"","permalink":"https://wangmingco.github.io/2016/03/06/nginx/nginx%E6%96%87%E4%BB%B6%E6%9C%8D%E5%8A%A1%E5%99%A8/","excerpt":"","text":"配置修改nginx.conf文件 123456789server &#123; listen 8000; autoindex on; #开启索引功能 autoindex_exact_size off; # 关闭计算文件确切大小（单位bytes），只显示大概大小（单位kb、mb、gb） autoindex_localtime on; # 显示本机时间而非 GMT 时间 root /home/files/; &#125; 然后在地址栏里访问 1http://192.168.15.20:8000/ 我们就能看见文件列表了. 403异常产生了403异常的话, 说明nginx没有访问该目录, 也就是/home/files/的权限, 需要将nginx用户添加到这个目录的用户组里. 1usermod -G groupname username 然后查看用户组 1cat /etc/group | grep groupname 然后nginx用户要有要访问目录的上层所有父目录的可执行权限, 要有访问目录的读权限 最后nginx用户是在nginx.conf配置里 123#user nobody;user www www;worker_processes 4; user就是了 禁止访问目录跟Apache的Deny from all类似，nginx有deny all指令来实现。 禁止对叫dirdeny目录的访问并返回403 Forbidden，可以使用下面的配置: 1234location /dirdeny &#123; deny all; return 403;&#125;","categories":[{"name":"Nginx","slug":"Nginx","permalink":"https://wangmingco.github.io/categories/Nginx/"}],"tags":[]},{"title":"Nginx安装与启动,关闭","slug":"nginx/nginx安装与命令","date":"2016-03-05T16:00:00.000Z","updated":"2021-11-18T02:43:37.334Z","comments":true,"path":"2016/03/06/nginx/nginx安装与命令/","link":"","permalink":"https://wangmingco.github.io/2016/03/06/nginx/nginx%E5%AE%89%E8%A3%85%E4%B8%8E%E5%91%BD%E4%BB%A4/","excerpt":"","text":"安装在MAC上安装Nginx 使用命令 1brew install nginx homebrew会自动为我们安装. 程序会安装在 1/usr/local/Cellar/nginx/1.6.2 nginx的配置文件在 1cd /usr/local/etc/nginx 一般通过Homebrew安装的程序都会放在/usr/local/Cellar/里, 而配置文件会存储在/usr/local/etc/里 启动我们可以通过下面这个简单的命令直接启动 1/usr/bin/nginx 或者使用一个经过配置化的参数启动 1/usr/bin/nginx -t -c ~/mynginx.conf -g &quot;pid /var/run/nginx.pid; worker_processes 2;&quot; 关闭一般我们可以通过 1/usr/bin/nginx -s stop 但是我们还可以通过想Nginx 主进程发送信号的方式来关闭它. 1kill -QUIT $( cat /usr/local/nginx/logs/nginx.pid ) 一般我们推荐第二种方式, 让Nginx自己去停掉所有的主从进程 Nginx还接受如下参数 TERM, INT : Quick shutdown QUIT : Graceful shutdown KILL : Halts a stubborn process HUP : Configuration reload, Start the new worker processes with a new configuration, Gracefully shutdown the old worker processes USR1 : Reopen the log files USR2 : Upgrade Executable on the fly WINCH : Gracefully shutdown the worker processes","categories":[{"name":"Nginx","slug":"Nginx","permalink":"https://wangmingco.github.io/categories/Nginx/"}],"tags":[]},{"title":"Nginx负载均衡实战","slug":"nginx/nginx负载均衡","date":"2016-03-05T16:00:00.000Z","updated":"2021-11-18T02:43:38.283Z","comments":true,"path":"2016/03/06/nginx/nginx负载均衡/","link":"","permalink":"https://wangmingco.github.io/2016/03/06/nginx/nginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/","excerpt":"","text":"我们测试一次Nginx的负载均衡配置. 首先我们使用python启动俩个HTTP服务器 12345678910111213import BaseHTTPServerimport urlparseimport sysport = sys.argv[1]class WebRequestHandler(BaseHTTPServer.BaseHTTPRequestHandler): def do_GET(self): &quot;&quot;&quot; &quot;&quot;&quot; print portserver = BaseHTTPServer.HTTPServer((&#x27;0.0.0.0&#x27;,int(sys.argv[1])), WebRequestHandler)server.serve_forever() 然后在命令行分别启动 12python ./PyHttpServer.py 8091python ./PyHttpServer.py 8092 然后我们配置nginx.conf文件 12345678910111213141516171819202122232425262728293031323334353637#user nobody;worker_processes 1;pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; sendfile on; upstream big_server_com &#123; server 127.0.0.1:8091 weight=5; server 127.0.0.1:8092 weight=5; &#125; server &#123; listen 8090; server_name localhost; location / &#123; root html; index index.html index.htm; proxy_pass http://big_server_com; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125;&#125; 我们让nginx在8090端口上监听, 然后将其反向代理到8091和8092端口上. 还有一点很重要的是, 要代理的服务必须在Nginx启动之前都启动完毕, 否则Nginx没办法完成代理工作. 最后我们在浏览器上发送HTTP请求 1http://localhost:8090 我们发现那俩个python的HTTP服务器果真都有输出了. 但是我们发现, 就是那俩个服务器同时都有输出, 而不是应该只有其中一个有输出. 所以下来还需要研究一下如何配置Upstream, 看看如何让其真正实现负载均衡和单点失败","categories":[{"name":"Nginx","slug":"Nginx","permalink":"https://wangmingco.github.io/categories/Nginx/"}],"tags":[]},{"title":"Nginx配置大全","slug":"nginx/nginx配置","date":"2016-03-04T16:00:00.000Z","updated":"2021-11-18T02:43:39.200Z","comments":true,"path":"2016/03/05/nginx/nginx配置/","link":"","permalink":"https://wangmingco.github.io/2016/03/05/nginx/nginx%E9%85%8D%E7%BD%AE/","excerpt":"","text":"下面我们看一下Nginx官方给出的nginx.config可有的全部配置内容 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899user www www; ## Default: nobody# 在Nginx启动的时候会启动一个Master进程,和N个worker进程,Master讲接收到的任务分配给worker进程执行. worker进程数一般与主机的CPU的核心数相等worker_processes 5; ## Default: 1# 错误日志的输出位置. (TODO 错误日志指的是哪些?)error_log logs/error.log;# Nginx启动时的主进程IDpid logs/nginx.pid;# worker进程能打开的最多的文件数(TODO 在正式环境中Nginx都会打开什么文件? 指的是Socket连接吗?)worker_rlimit_nofile 8192;# events模块, 包含nginx中所有处理连接的设置events &#123; # worker进程能打开的最大的连接数 (小于worker_rlimit_nofile数) worker_connections 4096; ## Default: 1024&#125;# http模块, 用于处理http请求http &#123; # 引用mime.types配置, 主要是配置HTTP请求中的mineType类型 include conf/mime.types; # 引用nginx的代理配置. (TODO) include /etc/nginx/proxy.conf; # 为nginx引用cgi配置 include /etc/nginx/fastcgi.conf; # 指定当HTTP请求没有任何请求路径时展示的界面. index index.html index.htm index.php; # default_type application/octet-stream; # log输出格式 log_format main &#x27;$remote_addr - $remote_user [$time_local] $status &#x27; &#x27;&quot;$request&quot; $body_bytes_sent &quot;$http_referer&quot; &#x27; &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;; # 访问nginx时, 记录的http请求的日志存储位置 (TODO 如何以时间分割文件?) access_log logs/access.log main; # sendfile并不是发送文件, 而是设置磁盘和TCP Socket传输数据时直接通过系统缓存实现, 不再经过用户区的Read, write操作 sendfile on; # 设置在发送HTTP头文件时一次性全部发送, 而不是一个接一个的发送. (TODO) tcp_nopush on; # TODO server_names_hash_bucket_size 128; # this seems to be required for some vhosts # 开启一个网络监听服务 server &#123; # php/fastcgi # 该server监听的端口 listen 80; # 绑定到的域名地址, 一般我们在主机都是使用localhost server_name domain1.com www.domain1.com; # 该server生成的日志的保存地址 access_log logs/domain1.access.log main; # 指定http请求中主机资源起始位置, 也就是`http://localhost:8090/`后面的位置 root html; # 所有请求以.php结尾的文件都到下面的代理地址中进行代理请求 location ~ \\.php$ &#123; fastcgi_pass 127.0.0.1:1025; &#125; &#125; # 再设置一个网络服务 server &#123; # simple reverse-proxy listen 80; server_name domain2.com www.domain2.com; access_log logs/domain2.access.log main; # serve static files location ~ ^/(images|javascript|js|css|flash|media|static)/ &#123; root /var/www/virtual/big.server.com/htdocs; expires 30d; &#125; # 反向代理设置, 将/下所有的请求进行转发 location / &#123; #设置反向代理的地址, 將80端口接受到的请求转发到localhost的8080端口上 proxy_pass http://127.0.0.1:8080; &#125; &#125; # 设置反向代理 upstream big_server_com &#123; # 按照权重将代理过来的请求代理到俩个代理服务器上 server 127.0.0.3:8000 weight=5; server 127.0.0.3:8001 weight=5; server 192.168.0.1:8000; server 192.168.0.1:8001; &#125; server &#123; # simple load balancing listen 80; server_name big.server.com; access_log logs/big.server.access.log main; location / &#123; # 设置反向代理, 代理到big_server_com上(upstream刚刚定义的) proxy_pass http://big_server_com; &#125; &#125;&#125; 上面谈到的location涉及到的内容较多, 我们单独介绍一下: nginx location语法 1location [=|~|~*|^~] /uri/ &#123; … &#125; = 严格匹配。如果这个查询匹配，那么将停止搜索并立即处理此请求。 ~ 为区分大小写匹配(可用正则表达式) ~* 为不区分大小写匹配(可用正则表达式) !~ 区分大小写不匹配 !~* 不区分大小写不匹配 ^~ 如果路径匹配那么不测试正则表达式。 上面的配置引用里其他的配置文件,而且很多配置没有配置选项,下面是Nginx官网给出的另一种配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128user www www;worker_processes 2;pid /var/run/nginx.pid;# [ debug | info | notice | warn | error | crit ]error_log /var/log/nginx.error_log info;events &#123; worker_connections 2000; # use [ kqueue | rtsig | epoll | /dev/poll | select | poll ] ; use kqueue;&#125;http &#123; include conf/mime.types; default_type application/octet-stream; log_format main &#x27;$remote_addr - $remote_user [$time_local] &#x27; &#x27;&quot;$request&quot; $status $bytes_sent &#x27; &#x27;&quot;$http_referer&quot; &quot;$http_user_agent&quot; &#x27; &#x27;&quot;$gzip_ratio&quot;&#x27;; log_format download &#x27;$remote_addr - $remote_user [$time_local] &#x27; &#x27;&quot;$request&quot; $status $bytes_sent &#x27; &#x27;&quot;$http_referer&quot; &quot;$http_user_agent&quot; &#x27; &#x27;&quot;$http_range&quot; &quot;$sent_http_content_range&quot;&#x27;; # HTTP请求,客户端相关设置 client_header_timeout 3m; client_body_timeout 3m; send_timeout 3m; client_header_buffer_size 1k; large_client_header_buffers 4 4k; # 消息发送时开启gzip设置 gzip on; gzip_min_length 1100; gzip_buffers 4 8k; gzip_types text/plain; output_buffers 1 32k; postpone_output 1460; sendfile on; tcp_nopush on; tcp_nodelay on; send_lowat 12000; keepalive_timeout 75 20; # lingering_time 30; # lingering_timeout 10; # reset_timedout_connection on; server &#123; listen one.example.com; server_name one.example.com www.one.example.com; access_log /var/log/nginx.access_log main; location / &#123; proxy_pass http://127.0.0.1/; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; # proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; client_max_body_size 10m; client_body_buffer_size 128k; client_body_temp_path /var/nginx/client_body_temp; proxy_connect_timeout 90; proxy_send_timeout 90; proxy_read_timeout 90; proxy_send_lowat 12000; proxy_buffer_size 4k; proxy_buffers 4 32k; proxy_busy_buffers_size 64k; proxy_temp_file_write_size 64k; proxy_temp_path /var/nginx/proxy_temp; charset koi8-r; &#125; error_page 404 /404.html; location /404.html &#123; root /spool/www; charset on; source_charset koi8-r; &#125; location /old_stuff/ &#123; rewrite ^/old_stuff/(.*)$ /new_stuff/$1 permanent; &#125; location /download/ &#123; valid_referers none blocked server_names *.example.com; if ($invalid_referer) &#123; #rewrite ^/ http://www.example.com/; return 403; &#125; # rewrite_log on; # rewrite /download/*/mp3/*.any_ext to /download/*/mp3/*.mp3 rewrite ^/(download/.*)/mp3/(.*)\\..*$ /$1/mp3/$2.mp3 break; root /spool/www; # autoindex on; access_log /var/log/nginx-download.access_log download; &#125; location ~* ^.+\\.(jpg|jpeg|gif)$ &#123; root /spool/www; access_log off; expires 30d; &#125; &#125;&#125;","categories":[{"name":"Nginx","slug":"Nginx","permalink":"https://wangmingco.github.io/categories/Nginx/"}],"tags":[]},{"title":"List VS Map","slug":"JavaSE/Java ListVSMap","date":"2016-03-04T16:00:00.000Z","updated":"2021-11-18T02:39:51.748Z","comments":true,"path":"2016/03/05/JavaSE/Java ListVSMap/","link":"","permalink":"https://wangmingco.github.io/2016/03/05/JavaSE/Java%20ListVSMap/","excerpt":"","text":"在日常的使用中, 使用的最多的结构就是List和Map了. 其中又以ArrayList和HashMap使用的最多. 今天特意找了一些时间来看一下他们各自的实现以及添加索引数据时的性能. 首先看一下ArrayList. 12345678910111213transient Object[] elementData;public boolean add(E e) &#123; ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true;&#125;public E get(int index) &#123; rangeCheck(index); return elementData(index);&#125; 它的内部就是一个Object类型的数组, 在添加数据时首先确保数组不会越界, 如果会产生越界则内部进行数组扩容拷贝操作. 对于HashMap它的Javadoc中是如此说的: HashMap是hash table的一个实现。它与HashTable不同之处就是它是非同步的而且键值都支持null.对于put和get操作，HashMap的耗时都是固定的，不会因为Map的大小而变化。因为hash函数会将元素分配到不同的bucket里面取. HashMap的迭代操作与它的容量（bucket数量+键值对数量）成正比关系. 一般情况下, load factor的默认值0.75, 这个值在空间和时间上找到较为平衡的查找性能。 如果高于这个值的话，会减少空间占用但是会增加查询的消耗(这点反应在了大多数的hashMap操作中，包括get和put操作). 下来我们首先看一下它的数据成员 1234567891011// load factor 默认值static final float DEFAULT_LOAD_FACTOR = 0.75f;// hash表存储数据的数据结构, 每个Node都是一个散列桶, 每个桶里是一个链表transient Node&lt;K,V&gt;[] table;// hash表散列桶的大小阀值, 如果超过这个值就对hash表进行拓容 (大小为: capacity * load factor)int threshold;// hash表使用的loadFactorfinal float loadFactor; 然后我们看一下put()方法的实现 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 如果table不存在或者table大小为0, 则重新生成一个table if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 根据与hash值与操作找到要插入的元素所在的散列桶的位置 if ((p = tab[i = (n - 1) &amp; hash]) == null) // 发现当前位置上的散列桶上没有Node则,重新生成一个Node tab[i] = newNode(hash, key, value, null); else &#123; // 发现当前散列桶已经有元素了 Node&lt;K,V&gt; e; K k; // 判断插入key是否与找到的Node的key是否相等, 如果相等则将p赋值给e, 进行value的赋值操作 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; // 插入的key与散列桶链表中的第一个元素不相符, 则遍历整个链表 for (int binCount = 0; ; ++binCount) &#123; // 在连表中找不到存在的元素, 则生成一个新的Node插入进来 if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; // 找到了与要插入的key相等的散列表的元素, 则停止继续查找 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; // 在散列表里找到了相同的key的hash值, 就直接插入了, 不再需要进行下面的hash表拓容操作 if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; // 占有了一个新的hash桶, 判断如果超过了Hash表散列桶的阀值,则对hash表进行拓容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; &#125; 从上面的逻辑我们可以看出,HashMap在插入元素的时候,首先是根据key的hash值找到散列桶的位置, 然后再根据key与散列桶中的散列表的数据进行便利查找. 因此我们应该尽量的调大HashMap的容量, 尽可能的让桶的容量大于元素的个数, 同时尽可能的保证key值hash函数的正确性, 否则如果元素过多但是桶的数量太少, 会将hash 表退化到链表结构, 将O(1)的查找复杂度变成O(N). 说完HashMap的查找复杂度, 我们再来看一下HashMap的内存占有, 每当我们插入一个新的元素的时候都会生成一个Node对象 123456static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://wangmingco.github.io/categories/Java/"}],"tags":[]},{"title":"Jedis 初探","slug":"JavaLibrary/jedis","date":"2016-03-01T16:00:00.000Z","updated":"2021-11-18T02:47:34.476Z","comments":true,"path":"2016/03/02/JavaLibrary/jedis/","link":"","permalink":"https://wangmingco.github.io/2016/03/02/JavaLibrary/jedis/","excerpt":"","text":"using Jedis in a multithreaded environment我们不应该在多线程的情况下使用同一个Jedis实例对象, 因为在Jedis本身不是线程安全的, 它可能会引发一些奇奇怪怪的问题. 但是如果我们在每个线程中都创建一个Jedis实例对象的话这也是不可取的, 因为每个Jedis对象的创建都意味着socket和网络连接的创建. 为了避免这种情况,我们应该使用JedisPool, 它是一个线程安全的网络连接池. 我们可以通过池子创建多个Jedis实例对象, 当使用完之后再将它返回给池子. 在下面的实例中我们初始化一个池子 1JedisPool pool = new JedisPool(new JedisPoolConfig(), &quot;localhost&quot;); 因为JedisPool是线程安全的, 因此我们可以将它缓存起来, 供所有线程使用. JedisPoolConfig包含了一个丰富有用的Redis连接配置参数. JedisPoolConfig基于Commons Pool 2 12345678910/// Jedis implements Closable. Hence, the jedis instance will be auto-closed after the last statement.try (Jedis jedis = pool.getResource()) &#123; /// ... do stuff here ... for example jedis.set(&quot;foo&quot;, &quot;bar&quot;); String foobar = jedis.get(&quot;foo&quot;); jedis.zadd(&quot;sose&quot;, 0, &quot;car&quot;); jedis.zadd(&quot;sose&quot;, 0, &quot;bike&quot;); Set&lt;String&gt; sose = jedis.zrange(&quot;sose&quot;, 0, -1);&#125;/// ... when closing your application:pool.destroy(); 如果你不喜欢try-with-resource这种语法, 那么你可以使用Jedis.close(). 123456789101112131415Jedis jedis = null;try &#123; jedis = pool.getResource(); /// ... do stuff here ... for example jedis.set(&quot;foo&quot;, &quot;bar&quot;); String foobar = jedis.get(&quot;foo&quot;); jedis.zadd(&quot;sose&quot;, 0, &quot;car&quot;); jedis.zadd(&quot;sose&quot;, 0, &quot;bike&quot;); Set&lt;String&gt; sose = jedis.zrange(&quot;sose&quot;, 0, -1);&#125; finally &#123; if (jedis != null) &#123; jedis.close(); &#125;&#125;/// ... when closing your application:pool.destroy(); If Jedis was borrowed from pool, it will be returned to pool with proper method since it already determines there was JedisConnectionException occurred. If Jedis wasn’t borrowed from pool, it will be disconnected and closed. 下来我们来看一段测试代码 123456789101112131415161718192021222324252627282930import redis.clients.jedis.Jedis;import redis.clients.jedis.JedisPool;import redis.clients.jedis.JedisPoolConfig;public class JedisTest &#123; public static void main(String[] args) &#123; JedisPoolConfig jedisPoolConfig = new JedisPoolConfig(); jedisPoolConfig.setMaxTotal(10); JedisPool pool = new JedisPool(jedisPoolConfig, &quot;10.1.4.110&quot;); System.out.println(&quot;begin : &quot; + pool.getNumActive()); System.out.println(&quot;begin : &quot; + pool.getNumIdle()); System.out.println(&quot;begin : &quot; + pool.getNumWaiters()); Jedis jedis = null; try &#123; jedis = pool.getResource(); System.out.println(&quot;borrow : &quot; + pool.getNumActive()); System.out.println(&quot;borrow : &quot; + pool.getNumIdle()); System.out.println(&quot;borrow : &quot; + pool.getNumWaiters()); &#125; finally &#123; if (jedis != null) &#123; jedis.close(); &#125; &#125; System.out.println(&quot;return : &quot; + pool.getNumActive()); System.out.println(&quot;return : &quot; + pool.getNumIdle()); System.out.println(&quot;return : &quot; + pool.getNumWaiters()); pool.destroy(); &#125;&#125; 结果为 123456789begin : 0begin : 0begin : 0borrow : 1borrow : 0borrow : 0return : 0return : 1return : 0 当调用jedis.close();后,池子里空闲的Jedis对象就多了1个, 可是如果我们注释掉这一行后的结果为 123456789begin : 0begin : 0begin : 0borrow : 1borrow : 0borrow : 0return : 1return : 0return : 0 我们发现那个Jedis仍然处于激活状态, 在Jedis 2.8.0版本以前当我们从池子里借用一个Jedis之后还需要将其还回去 123public void close(Jedis resource) &#123; jedisPool.returnResource(resource);&#125; 但是现在已经不需要了, 而且Jedis已经将这个returnResource()的方法舍弃掉了 1234567891011121314/** @deprecated */@Deprecatedpublic void returnResource(Jedis resource) &#123; if(resource != null) &#123; try &#123; resource.resetState(); this.returnResourceObject(resource); &#125; catch (Exception var3) &#123; this.returnBrokenResource(resource); throw new JedisException(&quot;Could not return the resource to the pool&quot;, var3); &#125; &#125;&#125; 接下来我们看一下多线程情况 1234567891011121314151617181920212223242526272829303132public class JedisTest &#123; public static void main(String[] args) throws InterruptedException &#123; JedisPoolConfig jedisPoolConfig = new JedisPoolConfig(); jedisPoolConfig.setMaxTotal(3); JedisPool pool = new JedisPool(jedisPoolConfig, &quot;10.1.4.110&quot;); List&lt;Thread&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 5; i++) &#123; Runnable runnable = () -&gt; &#123; Jedis jedis = null; try &#123; jedis = pool.getResource(); int sleep = new Random().nextInt(5); System.out.println(&quot;sleep:&quot; + sleep + &quot;. time:&quot; + new Date().toLocaleString() + &quot;. active: &quot; + pool.getNumActive() + &quot;. idle: &quot; + pool.getNumIdle()); TimeUnit.SECONDS.sleep(sleep); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; if (jedis != null) &#123; jedis.close(); &#125; &#125; &#125;; list.add(new Thread(runnable)); &#125; list.forEach(thread -&gt; thread.start()); Thread.currentThread().join(); pool.destroy(); &#125;&#125; 结果为 12345sleep:4. time:2016-3-4 10:04:03. active: 3. idle: 0sleep:4. time:2016-3-4 10:04:03. active: 3. idle: 0sleep:3. time:2016-3-4 10:04:03. active: 3. idle: 0sleep:3. time:2016-3-4 10:04:06. active: 3. idle: 0sleep:3. time:2016-3-4 10:04:07. active: 2. idle: 1","categories":[{"name":"Jedis","slug":"Jedis","permalink":"https://wangmingco.github.io/categories/Jedis/"}],"tags":[]},{"title":"NettyServerBootstrap","slug":"JavaLibrary/Netty ServerBootstrap","date":"2016-02-21T16:00:00.000Z","updated":"2021-11-18T02:50:29.971Z","comments":true,"path":"2016/02/22/JavaLibrary/Netty ServerBootstrap/","link":"","permalink":"https://wangmingco.github.io/2016/02/22/JavaLibrary/Netty%20ServerBootstrap/","excerpt":"","text":"我们首先给出一个Netty上的一个Example示例 1234567891011121314151617181920212223242526272829303132333435363738public class NettyServer &#123; public static void main(String[] args) throws InterruptedException &#123; int cpuSize = Runtime.getRuntime().availableProcessors(); EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(cpuSize); try &#123; ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 128) .option(ChannelOption.TCP_NODELAY, true) .option(ChannelOption.AUTO_READ, true) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override public void initChannel(SocketChannel ch) &#123; ch.pipeline().addLast(new InHandler()); &#125; &#125;); ChannelFuture f = b.bind(8881).sync(); f.channel().closeFuture().sync(); &#125; finally &#123; bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); &#125; &#125;&#125;class InHandler extends ChannelInboundHandlerAdapter &#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) &#123; ctx.write(msg); &#125; @Override public void channelReadComplete(ChannelHandlerContext ctx) &#123; ctx.flush(); &#125;&#125; 在这个示例中, 我们采用了主从Reactor线程模型, 然后将接受到的数据写回给客户端. 下来我们分析一下ServerBootstrap的源码. 我们从bind()方法入手. 由于bind()最终调用的是父类AbstractBootstrap的doBind()方法, 因此我们从父类入手 12345678910111213private ChannelFuture doBind(final SocketAddress localAddress) &#123; // 初始化NioServerSocketChannel, 并将其注册主Reactor线程池的IO多路复用器上 final ChannelFuture regFuture = initAndRegister(); final Channel channel = regFuture.channel(); if (regFuture.isDone()) &#123; ChannelPromise promise = channel.newPromise(); doBind0(regFuture, channel, localAddress, promise); return promise; &#125; else &#123; ... return promise; &#125; &#125; 接下来我们看一下AbstractBootstrap#initAndRegister()方法 12345678910111213141516171819202122final ChannelFuture initAndRegister() &#123; // 因为我们调用过channel(NioServerSocketChannel.class)方法, 因此下面这个Channel是NioServerSocketChannel类型 final Channel channel = channelFactory().newChannel(); try &#123; // init方法主要是对NioServerSocketChannel添加一个ServerBootstrapAcceptor的Handler(继承自ChannelInboundHandlerAdapter) // 当channel接受到网络连接的时候, 会生成NioSocketChannel, 将NioSocketChannel与从Reactor进行绑定 init(channel); &#125; catch (Throwable t) &#123; &#125; // 将Reactor模型中的主Reactor线程注册到NioServerSocketChannel的Unsafe对象里. // 此时就将NioServerSocketChannel与Reactor主线程关联起来了 ChannelFuture regFuture = group().register(channel); if (regFuture.cause() != null) &#123; if (channel.isRegistered()) &#123; channel.close(); &#125; else &#123; channel.unsafe().closeForcibly(); &#125; &#125; &#125; init()的ServerBootstrap实现的. 这个方法主要是在NioServerSocketChannel的pipeline里增加一个ServerBootstrapAcceptorhandler.这个handler就是用于处理NioMessageUnsafe#read()方法调用NioServerSocketChannel#doReadMessage()方法后List&lt;NioSocketChannel&gt;的消息列表 12345678910111213141516171819202122@Overridevoid init(Channel channel) throws Exception &#123; // 获取NioServerSocketChannel的Pipeline ChannelPipeline p = channel.pipeline(); if (handler() != null) &#123; p.addLast(handler()); &#125; final EventLoopGroup currentChildGroup = childGroup; final ChannelHandler currentChildHandler = childHandler; final Entry&lt;ChannelOption&lt;?&gt;, Object&gt;[] currentChildOptions; final Entry&lt;AttributeKey&lt;?&gt;, Object&gt;[] currentChildAttrs; p.addLast(new ChannelInitializer&lt;Channel&gt;() &#123; @Override public void initChannel(Channel ch) throws Exception &#123; // 这里主要是产生网络连接时将处理数据的channel与Reactor从线程关联起来 ch.pipeline().addLast(new ServerBootstrapAcceptor( currentChildGroup, currentChildHandler, currentChildOptions, currentChildAttrs)); &#125; &#125;); &#125; 我们看到ServerBootstrapAcceptor也是实现自ChannelInboundHandlerAdapter, 因此它也是一个handler. 在NioMessageUnsafe#read()方法里会遍历List&lt;NioSocketChannel&gt;这个消息列表后触发NioServerSocketChannel的pipeline的fireChannelRead()方法, 接着就会触发ServerBootstrapAcceptor#channelRead(), 12345678910111213141516171819202122private static class ServerBootstrapAcceptor extends ChannelInboundHandlerAdapter &#123; private final EventLoopGroup childGroup; private final ChannelHandler childHandler; ServerBootstrapAcceptor( EventLoopGroup childGroup, ChannelHandler childHandler) &#123; this.childGroup = childGroup; this.childHandler = childHandler; &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) &#123; // msg实际是NioSocketChannel类型 final Channel child = (Channel) msg; child.pipeline().addLast(childHandler); try &#123; // 将处理数据的NioSocketChannel与主从Reactor模型中的从Reactor线程关联起来 childGroup.register(child).addListener(new ChannelFutureListener()); &#125; catch (Throwable t) &#123; &#125; &#125; &#125; 然后我们看一下NioEventLoop的register()方法过程. 这个方法调用其实最终调用的是 1234567SingleThreadEventLoop@Override public ChannelFuture register(final Channel channel, final ChannelPromise promise) &#123; channel.unsafe().register(this, promise); return promise; &#125; 然后后续调用到了AbstractUnsafe的register()方法 12345678910111213141516171819202122232425262728293031@Override public final void register(EventLoop eventLoop, final ChannelPromise promise) &#123; AbstractChannel.this.eventLoop = eventLoop; if (eventLoop.inEventLoop()) &#123; register0(promise); &#125; else &#123; try &#123; eventLoop.execute(new OneTimeTask() &#123; @Override public void run() &#123; register0(promise); &#125; &#125;); &#125; catch (Throwable t) &#123; &#125; &#125; &#125; private void register0(ChannelPromise promise) &#123; try &#123; doRegister(); pipeline.fireChannelRegistered(); // Only fire a channelActive if the channel has never been registered. This prevents firing // multiple channel actives if the channel is deregistered and re-registered. if (firstRegistration &amp;&amp; isActive()) &#123; pipeline.fireChannelActive(); &#125; &#125; catch (Throwable t) &#123; &#125; &#125; 接着调用AbstractNioChannel的doRegister() 12345678910protected void doRegister() throws Exception &#123; boolean selected = false; for (;;) &#123; try &#123; selectionKey = javaChannel().register(eventLoop().selector, 0, this); return; &#125; catch (CancelledKeyException e) &#123; &#125; &#125; &#125; 最终我们看到了, 当前JDK里的Channel注册到了EventLoop的IO多路复用器上面 看到这里之后, 我们再接着返回到doBind()方法继续看doBind0()方法 1234567891011121314151617private static void doBind0( final ChannelFuture regFuture, final Channel channel, final SocketAddress localAddress, final ChannelPromise promise) &#123; // This method is invoked before channelRegistered() is triggered. Give user handlers a chance to set up // the pipeline in its channelRegistered() implementation. channel.eventLoop().execute(new Runnable() &#123; @Override public void run() &#123; if (regFuture.isSuccess()) &#123; channel.bind(localAddress, promise).addListener(ChannelFutureListener.CLOSE_ON_FAILURE); &#125; else &#123; promise.setFailure(regFuture.cause()); &#125; &#125; &#125;); &#125; 我们看到当在bind的时候也是调用的channel的bind(), 真实的bind是在AbstractChannel里发生的 123public ChannelFuture bind(SocketAddress localAddress, ChannelPromise promise) &#123; return pipeline.bind(localAddress, promise);&#125; 然后调用的是DefaultChannelPipeline的bind()方法 1234@Override public ChannelFuture bind(SocketAddress localAddress, ChannelPromise promise) &#123; return tail.bind(localAddress, promise); &#125; 再具体的bind的话, 就要参考DeaultChannelPipeline的实现了 最后我们总结一下 首先将NioServerSocketChannel与主Reactor线程池的Selector进行注册绑定 当NioServerSocketChannel接收到网络连接的时候(doReadMessage())会生成一个NioSocketChannel的消息列表 然后ServerBootstrapAcceptor负责将NioSocketChannel与从Reactor的Selector进行注册绑定 最后由从Reactor线程池中的Selector进行IO调度, 读写网络数据","categories":[{"name":"Netty","slug":"Netty","permalink":"https://wangmingco.github.io/categories/Netty/"}],"tags":[{"name":"Netty","slug":"Netty","permalink":"https://wangmingco.github.io/tags/Netty/"}]},{"title":"MessagePack 初探","slug":"JavaLibrary/MessagePack 初探","date":"2016-02-02T16:00:00.000Z","updated":"2021-11-18T02:58:48.886Z","comments":true,"path":"2016/02/03/JavaLibrary/MessagePack 初探/","link":"","permalink":"https://wangmingco.github.io/2016/02/03/JavaLibrary/MessagePack%20%E5%88%9D%E6%8E%A2/","excerpt":"","text":"MessagePack 是一个高效的二进制数据序列化工具. 使用它可以让你像使用JSON那样在多种语言中进行数据交换, 但是它比JSON更加小巧,迅捷. 在Java中使用的话, 我们首先添加maven依赖 12345 &lt;dependency&gt; &lt;groupId&gt;org.msgpack&lt;/groupId&gt; &lt;artifactId&gt;msgpack&lt;/artifactId&gt; &lt;version&gt;0.6.12&lt;/version&gt;&lt;/dependency&gt; 首先看一个简单的示例 1234567891011121314151617181920212223import org.msgpack.MessagePack;import org.msgpack.annotation.Message;public class Main1 &#123; @Message // Annotation public static class MyMessage &#123; // public fields are serialized. public String name; public double version; &#125; public static void main(String[] args) throws Exception &#123; MyMessage src = new MyMessage(); src.name = &quot;msgpack&quot;; src.version = 0.6; MessagePack msgpack = new MessagePack(); // Serialize byte[] bytes = msgpack.write(src); // Deserialize MyMessage dst = msgpack.read(bytes, MyMessage.class); &#125;&#125; 在上面的例子中我们看到将一个MyMessage序列化成byte数组, 同时又将其反序列化出来了. 但是如果我们要同时序列化多个对象呢？那么我们就可以使用Packer和Unpacker. 12345678910111213141516171819202122232425262728293031323334353637383940414243import java.io.ByteArrayInputStream;import java.io.ByteArrayOutputStream;import org.msgpack.MessagePack;import org.msgpack.annotation.Message;import org.msgpack.packer.Packer;import org.msgpack.unpacker.Unpacker;public class Main2 &#123; @Message public static class MyMessage &#123; public String name; public double version; &#125; public static void main(String[] args) throws Exception &#123; MyMessage src1 = new MyMessage(); src1.name = &quot;msgpack&quot;; src1.version = 0.6; MyMessage src2 = new MyMessage(); src2.name = &quot;muga&quot;; src2.version = 10.0; MyMessage src3 = new MyMessage(); src3.name = &quot;frsyukik&quot;; src3.version = 1.0; MessagePack msgpack = new MessagePack(); // Serialize ByteArrayOutputStream out = new ByteArrayOutputStream(); Packer packer = msgpack.createPacker(out); packer.write(src1); packer.write(src2); packer.write(src3); byte[] bytes = out.toByteArray(); // Deserialize ByteArrayInputStream in = new ByteArrayInputStream(bytes); Unpacker unpacker = msgpack.createUnpacker(in); MyMessage dst1 = unpacker.read(MyMessage.class); MyMessage dst2 = unpacker.read(MyMessage.class); MyMessage dst3 = unpacker.read(MyMessage.class); &#125;&#125; 其实Packer和Unpacker内置了非常多了序列化类型 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465import java.io.ByteArrayInputStream;import java.io.ByteArrayOutputStream;import java.math.BigInteger;import java.nio.ByteBuffer;import org.msgpack.MessagePack;import org.msgpack.packer.Packer;import org.msgpack.unpacker.Unpacker;public class Main3 &#123; public static void main(String[] args) throws Exception &#123; MessagePack msgpack = new MessagePack(); // Serialization ByteArrayOutputStream out = new ByteArrayOutputStream(); Packer packer = msgpack.createPacker(out); // 对原生类型进行序列化 packer.write(true); // boolean value packer.write(10); // int value packer.write(10.5); // double value // 对原生包装类型进行序列化 packer.write(Boolean.TRUE); packer.write(new Integer(10)); packer.write(new Double(10.5)); // 对数组进行序列化 packer.write(new int[] &#123; 1, 2, 3, 4 &#125;); packer.write(new Double[] &#123; 10.5, 20.5 &#125;); packer.write(new String[] &#123; &quot;msg&quot;, &quot;pack&quot;, &quot;for&quot;, &quot;java&quot; &#125;); packer.write(new byte[] &#123; 0x30, 0x31, 0x32 &#125;); // byte array // 对其他引用类型进行序列化 packer.write(&quot;MessagePack&quot;); // String object packer.write(ByteBuffer.wrap(new byte[] &#123; 0x30, 0x31, 0x32 &#125;)); // ByteBuffer object packer.write(BigInteger.ONE); // BigInteger object // 反序列化 byte[] bytes = out.toByteArray(); ByteArrayInputStream in = new ByteArrayInputStream(bytes); Unpacker unpacker = msgpack.createUnpacker(in); // 反序列化出原生类型 boolean b = unpacker.readBoolean(); // boolean value int i = unpacker.readInt(); // int value double d = unpacker.readDouble(); // double value // 反序列化出原生包装类型 Boolean wb = unpacker.read(Boolean.class); Integer wi = unpacker.read(Integer.class); Double wd = unpacker.read(Double.class); // 反序列化出数组 int[] ia = unpacker.read(int[].class); Double[] da = unpacker.read(Double[].class); String[] sa = unpacker.read(String[].class); byte[] ba = unpacker.read(byte[].class); // 反序列化出 String, ByteBuffer, BigInteger, List 和 Map String ws = unpacker.read(String.class); ByteBuffer buf = unpacker.read(ByteBuffer.class); BigInteger bi = unpacker.read(BigInteger.class); &#125;&#125; 对于List, Map这俩种类型的序列化, 我们需要额外说明一下. 在序列化List, Map的时候, 我们需要使用Template对其进行转换. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import java.io.ByteArrayInputStream;import java.io.ByteArrayOutputStream;import java.util.*;import org.msgpack.MessagePack;import org.msgpack.packer.Packer;import org.msgpack.template.Template;import org.msgpack.unpacker.Unpacker;import static org.msgpack.template.Templates.tList;import static org.msgpack.template.Templates.tMap;import static org.msgpack.template.Templates.TString;public class Main4 &#123; public static void main(String[] args) throws Exception &#123; MessagePack msgpack = new MessagePack(); // 创建序列化/反序列化 List 和 Map 对象的模板 Template&lt;List&lt;String&gt;&gt; listTmpl = tList(TString); Template&lt;Map&lt;String, String&gt;&gt; mapTmpl = tMap(TString, TString); // 开始序列化 ByteArrayOutputStream out = new ByteArrayOutputStream(); Packer packer = msgpack.createPacker(out); // 序列化 List 对象 List&lt;String&gt; list = new ArrayList&lt;String&gt;(); list.add(&quot;msgpack&quot;); list.add(&quot;for&quot;); list.add(&quot;java&quot;); packer.write(list); // List object // 序列化 Map 对象 Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;(); map.put(&quot;sadayuki&quot;, &quot;furuhashi&quot;); map.put(&quot;muga&quot;, &quot;nishizawa&quot;); packer.write(map); // Map object // 开始反序列化 byte[] bytes = out.toByteArray(); ByteArrayInputStream in = new ByteArrayInputStream(bytes); Unpacker unpacker = msgpack.createUnpacker(in); // 反序列化出 List 对象 List&lt;String&gt; dstList = unpacker.read(listTmpl); // 反序列化出 Map 对象 Map&lt;String, String&gt; dstMap = unpacker.read(mapTmpl); &#125;&#125; 有时候我们可能没有办法将POJO类添加上Message注解(可能没有访问那个类的权限), 但是我们又想对其进行序列化, 那怎么办呢？ 12MessagePack msgpack = new MessagePack();msgpack.register(MyMessage2.class); 我们只要向需要序列化的类注册到MessagePack上就可以了. 有时候,我们可能不需要对某个属性进行序列化, 例如线上某个老版本里并没有A属性, 但是在新的版本里填上了A属性, 但是又要兼容老版本怎么办呢？我们可以使用@Optional注解 123456789@Messagepublic static class MyMessage &#123; public String name; public double version; // new field @Optional public int flag = 0;&#125; MessagePack还提供了动态类型特性. 12345678910111213141516171819202122232425262728import java.util.*;import org.msgpack.MessagePack;import org.msgpack.type.Value;import org.msgpack.unpacker.Converter;import static org.msgpack.template.Templates.*;public class Main5 &#123; public static void main(String[] args) throws Exception &#123; // Create serialize objects. List&lt;String&gt; src = new ArrayList&lt;String&gt;(); src.add(&quot;msgpack&quot;); src.add(&quot;kumofs&quot;); src.add(&quot;viver&quot;); MessagePack msgpack = new MessagePack(); // Serialize byte[] raw = msgpack.write(src); // Deserialize directly using a template List&lt;String&gt; dst1 = msgpack.read(raw, tList(TString)); // Or, Deserialze to Value then convert type. Value dynamic = msgpack.read(raw); List&lt;String&gt; dst2 = new Converter(dynamic).read(tList(TString)); &#125;&#125; 当从MessagePack里读取数据的时候, 我们可以先不指定其转换的类型, 使用Value来代替, 等后期我们再使用Converter 对其转换. 接下来我们对其与JSON进行对比 12345678910111213141516171819202122232425262728293031323334353637public class msgpack &#123; public static void main(String[] args) throws Exception &#123; MessagePack msgpack = new MessagePack(); List&lt;SeObj&gt; list = list(); long start1 = System.currentTimeMillis(); byte[] bytes1 = msgpack.write(list); long end1 = System.currentTimeMillis(); System.out.println((end1 - start1) + &quot; : &quot; + bytes1.length); long start2 = System.currentTimeMillis(); String json = JSON.toJSONString(list); long end2 = System.currentTimeMillis(); System.out.println((end2 - start2) + &quot; : &quot; + json.getBytes().length); &#125; public static List&lt;SeObj&gt; list() &#123; List&lt;SeObj&gt; list = new ArrayList&lt;&gt;(); Random random = new Random(); for (int i = 0; i &lt; 10000; i++) &#123; SeObj seObj = new SeObj(); seObj.id = random.nextInt(100000); seObj.tall = random.nextFloat(); seObj.name = &quot;name&quot; + random.nextInt(100000); list.add(seObj); &#125; return list; &#125;&#125;@Messageclass SeObj &#123; public int id; public String name; public float tall;&#125; 结果为 123456789101112131415100的结果194 : 196050 : 49471000的结果210 : 1958970 : 4942410000的结果212 : 195765160 : 493987100000的结果283 : 1956964330 : 49402701000000的结果649 : 195735081878 : 49404120 我们发现MessagePack的耗时相对来说是比较稳定的, 但是在生成的数据量上比JSON要强一倍多","categories":[{"name":"Java 网络库","slug":"Java-网络库","permalink":"https://wangmingco.github.io/categories/Java-%E7%BD%91%E7%BB%9C%E5%BA%93/"}],"tags":[{"name":"MessagePack","slug":"MessagePack","permalink":"https://wangmingco.github.io/tags/MessagePack/"}]},{"title":"volatile 使用","slug":"JavaSE/Java volatile","date":"2016-02-01T16:00:00.000Z","updated":"2021-11-18T02:39:47.332Z","comments":true,"path":"2016/02/02/JavaSE/Java volatile/","link":"","permalink":"https://wangmingco.github.io/2016/02/02/JavaSE/Java%20volatile/","excerpt":"","text":"在讲volatile的之前,我们先看一下java的内存模型. 我们知道当我们new出来一个对象的时候,这个对象会被直接分配到堆上(暂不考虑栈上分配等技术). 而程序的逻辑是在方法中定义的,方法运行在线程里也就是栈上. 因此JVM会将线程里使用的数据从堆上拷贝到线程的本地存储上. 这个过程涉及了下列8个操作 lock: 将堆上的变量标志为某个线程独享的状态 unlock: 将堆上的变量释放出来, 以便被其他线程锁定 read: 将某个变量从堆上拷贝到线程的工作内存上 load: 将已经从堆上拷贝到线程的工作内存上的变量放入到变量副本中 use: 将线程变量副本中的变量传递给虚拟机执行引擎. (每当虚拟机遇到一个需要使用该变量的字节码指令时,都会执行该操作) assign: 将虚拟机执行引擎返回的变量的值赋值到工作变量中 store: 将工作变量值传递到堆内存中. write: 将从线程工作变量中接受到的值写入到主内存变量中 当一个变量被volatile修饰后, 每次load操作都是从堆中获取值, assign的时候也是直接写回到堆中内存变量中, 而不是在线程本地变量中操作. volatile变量具备俩种特性 线程可见性: 某个线程修改了被volatile修饰的变量后,其他线程可以里面看见这个最新的值. 禁止指令重排序优化 volatile最适用的场景是一个线程写,多个线程读的场景. 如果有多个线程同时写的话还是需要锁或者并发容器等等进行保护 下面我们看一个指令重排序的例子 12345678910111213141516public class Test &#123; private static boolean stop = false; public static void main(String[] args) throws InterruptedException &#123; Thread thread = new Thread(() -&gt; &#123; int i = 0; while (!stop) &#123; i++; &#125; &#125;); thread.start(); TimeUnit.SECONDS.sleep(3); stop = true; &#125;&#125; 上面的这段代码会被优化成(这种优化也被称为提升优化) 123456789101112131415161718public class Test &#123; private static boolean stop = false; public static void main(String[] args) throws InterruptedException &#123; Thread thread = new Thread(() -&gt; &#123; int i = 0; if (!stop) &#123; while (true) &#123; i++; &#125; &#125; &#125;); thread.start(); TimeUnit.SECONDS.sleep(3); stop = true; &#125;&#125; 但是如果stop变量被volatile修饰后 12345678910111213141516public class Test &#123; private static volatile boolean stop = false; public static void main(String[] args) throws InterruptedException &#123; Thread thread = new Thread(() -&gt; &#123; int i = 0; while (!stop) &#123; i++; &#125; &#125;); thread.start(); TimeUnit.SECONDS.sleep(3); stop = true; &#125;&#125; 程序就能正确的停止运行了 Java中对于重排序是这样规定的, 只要在单线程环境中, 重排序前后代码的运行结果总是一致的, 那么这段代码的重排序就是合法的. 但是当在多线程的环境中, 重排序就会影响到程序的执行, 就像刚才我们的例子展示的那样. 例外还有一点值得说明的是, 当代码中运行时包含native方法时, 会打断编译器的重排序(例如System.out.println()或者Threads.sleep()) volatile并不能解决并发写的情况, 正如我们开头所说的volatile最适用的场景是一个线程写,多个线程读的场景. 例如下面的程序, 无论我是否对counter进行volatile修饰都不能解决并发异常的问题 12345678910111213141516171819202122232425262728293031public class Test &#123; private static volatile int counter = 0; public static void main(String[] args) throws InterruptedException &#123; List&lt;Thread&gt; threads = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 100000; i++) &#123; Thread thread = new Thread(() -&gt; &#123; // 并发写counter try &#123; TimeUnit.MILLISECONDS.sleep(50); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; counter++; &#125;); thread.start(); threads.add(thread); &#125; threads.forEach(thread -&gt; &#123; try &#123; thread.join(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); System.out.println(counter); &#125;&#125; 上面的程序最后的输出结果, 总是小于100000. 还有一点需要说明的是,volatile修饰的数组,只能保证数组本身的内存可见性,但是对于其中的元素的修改是不会保证的.","categories":[{"name":"Java","slug":"Java","permalink":"https://wangmingco.github.io/categories/Java/"}],"tags":[]},{"title":"Netty ChannelHandler 和 ChannelPipeline","slug":"JavaLibrary/Netty ChannelPipeline","date":"2016-02-01T16:00:00.000Z","updated":"2021-11-18T02:50:36.668Z","comments":true,"path":"2016/02/02/JavaLibrary/Netty ChannelPipeline/","link":"","permalink":"https://wangmingco.github.io/2016/02/02/JavaLibrary/Netty%20ChannelPipeline/","excerpt":"","text":"ChannelHandler在写Netty Application的时候, 我们一般要做的就是俩件事 使用ServerBootstrap构建一个启动器, 监听网络事件 实现ChannelHandler接口完成网络事件的decoder和encoder功能 之所以在提供了handle的接口之后还提供Adapter, 是因为如果我们直接实现handler接口的话, 那么我们就需要实现handler里的所有方法, 但是我们可能要在不同的handler里实现不同的功能, 而这些功能恰巧由不同的handler里的方法实现, 那么每个实现了handler接口的类都会有大量的冗余代码. 但是如果我们继承Adapter的话, 我们只需要重写需要实现功能的方法就可以了. 今天就来看看ChannelHandler的写法和实现, 首先我们看一下ChannelHandler的继承结构我们用ChannelInboundHandler处理写入事件, 用ChannelOutboundHandler处理写出事件. 下面我们看一下如何自己实现一个inbound和outbound handler 123456789101112131415public class MyInboundHandler extends ChannelInboundHandlerAdapter &#123; @Override public void channelActive(ChannelHandlerContext ctx) &#123; System.out.println(&quot;Connected!&quot;); ctx.fireChannelActive(); &#125;&#125;public clas MyOutboundHandler extends ChannelOutboundHandlerAdapter &#123; @Override public void close(ChannelHandlerContext ctx, ChannelPromise&#125; promise) &#123; System.out.println(&quot;Closing ..&quot;); ctx.close(promise); &#125;&#125; ChannelPipeline简单地介绍了一下ChannelHandler, 但是在说它之前, 还是不得不先介绍一下ChannelPipeline, 它是一个基于链表实现的ChannelHandler的集合, 用于处理或者截断Channel的inbound events和outbound operations. (ChannelPipeline是Intercepting Filter的一个高级实现, 它保证了用户对事件处理的完整控制权以及确保了ChannelHandler在pipeline中的运行方式.) 1234567891011121314151617public class DefaultChannelPipeline implements ChannelPipeline &#123; final AbstractChannelHandlerContext head; final AbstractChannelHandlerContext tail; private final Channel channel; protected DefaultChannelPipeline(Channel channel) &#123; this.channel = ObjectUtil.checkNotNull(channel, &quot;channel&quot;); tail = new TailContext(this); head = new HeadContext(this); head.next = tail; tail.prev = head; &#125;&#125; 每当创建一个Channel的时候, 都会创建出一个对应的ChannelPipeline, 也就是说每个Channel都有其自己的ChannelPipeline. 在AbstractChannel中 1234567891011121314public abstract class AbstractChannel extends DefaultAttributeMap implements Channel &#123; private final Channel parent; private final DefaultChannelPipeline pipeline; protected AbstractChannel(Channel parent) &#123; this.parent = parent; pipeline = newChannelPipeline(); &#125; protected DefaultChannelPipeline newChannelPipeline() &#123; return new DefaultChannelPipeline(this); &#125;&#125; 看到这里就需要点出一点了, 网络事件是从Channel中传递到Pipeline中, 然后在Pipeline中遍历ChannelHandler链表, 触发相应的方法. 当我们增加一个ChannelHandler时 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849@Overridepublic ChannelPipeline addFirst(EventExecutorGroup group, final String name, ChannelHandler handler) &#123; synchronized (this) &#123; checkDuplicateName(name); // 我们将handler和ChannelPipeline, EventLoop封装到一个Context里 DefaultChannelHandlerContext newCtx = new DefaultChannelHandlerContext(this, group, name, handler); addFirst0(name, newCtx); &#125; return this;&#125;private void addFirst0(String name, DefaultChannelHandlerContext newCtx) &#123; checkMultiplicity(newCtx); // 我们将添加的handler放到链表的第一个位置上 DefaultChannelHandlerContext nextCtx = head.next; newCtx.prev = head; newCtx.next = nextCtx; head.next = newCtx; nextCtx.prev = newCtx; name2ctx.put(name, newCtx); callHandlerAdded(newCtx);&#125;private void callHandlerAdded(final ChannelHandlerContext ctx) &#123; if (ctx.channel().isRegistered() &amp;&amp; !ctx.executor().inEventLoop()) &#123; // 如果Channel已经注册到eventLoop上, 且当前线程与eventLoop中的线程不是同一个, 也就是说当前操作是多线程进行的, // 则将callHandlerAdded0()逻辑放到任务队列中进行执行 ctx.executor().execute(new Runnable() &#123; @Override public void run() &#123; callHandlerAdded0(ctx); &#125; &#125;); return; &#125; callHandlerAdded0(ctx);&#125;private void callHandlerAdded0(final ChannelHandlerContext ctx) &#123; try &#123; ctx.handler().handlerAdded(ctx); &#125; catch (Throwable t) &#123; &#125;&#125; 我们看到最终的时候在ChannelHandler里添加了ChannelHandlerContext. 但是经过查看ByteToMessageDecoder, ChannelInboundHandlerAdapter, ChannelHandlerAdapter这个都是空实现, 也就是说, 如果用户自己没有重载的话, 那么这里不会有任何的逻辑产生. 我们可以在任何时间在ChannelPipeline上添加或者移除ChannelHandler, 因为ChannelPipeline是线程安全的. 例如我们可以在线上环境中因为业务原因动态的添加或者移除handler. 下面的图给出了IO事件是如何在ChannelPipeline里的ChannelHandler进行传递处理的. IO事件由ChannelInboundHandler或者ChannelOutboundHandler处理, 我们在handler中调用ChannelHandlerContext中的事件传播方法将event传播给下一个handler继续执行, 例如调用ChannelHandlerContext#fireChannelRead(Object)和ChannelHandlerContext#write(Object) 1234567891011121314151617181920212223242526272829303132333435363738 I/O Request via Channel&#125; or ChannelHandlerContext&#125; |+---------------------------------------------------+---------------+| ChannelPipeline | || \\|/ || +---------------------+ +-----------+----------+ || | Inbound Handler N | | Outbound Handler 1 | || +----------+----------+ +-----------+----------+ || /|\\ | || | \\|/ || +----------+----------+ +-----------+----------+ || | Inbound Handler N-1 | | Outbound Handler 2 | || +----------+----------+ +-----------+----------+ || /|\\ . || . . || ChannelHandlerContext.fireIN_EVT() ChannelHandlerContext.OUT_EVT()|| [ method call] [method call] || . . || . \\|/ || +----------+----------+ +-----------+----------+ || | Inbound Handler 2 | | Outbound Handler M-1 | || +----------+----------+ +-----------+----------+ || /|\\ | || | \\|/ || +----------+----------+ +-----------+----------+ || | Inbound Handler 1 | | Outbound Handler M | || +----------+----------+ +-----------+----------+ || /|\\ | |+---------------+-----------------------------------+---------------+ | \\|/+---------------+-----------------------------------+---------------+| | | || [ Socket.read() ] [ Socket.write() ] || || Netty Internal I/O Threads (Transport Implementation) |+-------------------------------------------------------------------+ 从上图中我们可以看出左边是inboundhandler(从下向上进行处理), 右图是outbound流程(从上向下进行处理).inboundhandler通常处理的是由IO线程生成的inbound数据(例如SocketChannel#read(ByteBuffer)).outboundhandler一般由write请求生成或者转换传输数据. 如果outbound数据传输到上图的底部后, 它就会被绑定到Channel上的IO线程进行操作. IO线程一般会进行SocketChannel#write(ByteBuffer)数据输出操作. 底层的SocketChannel#read()方法读取ByteBuf, 然后由IO线程NioEventLoop调用ChannelPipeline#fireChannelRead()方法,将消息ByteBuf传递到ChannelPipeline中. 可以预想到的是, 用户在使用pipeline中肯定最少会有一个ChannelHandler用来接受IO事件(例如read操作)和响应IO操作(例如write和close). 例如一个标准的服务器在每个channel中的pipeline中会有如下的handler Protocol Decoder ： 将二进制的字节码(例如ByteBuf中的数据)解析成Java对象 Protocol Encoder : 将Java对象转换成二进制数据进行网络传输 Business Logic Handler : 执行真正的业务逻辑 在下面的示例中我们分别在pipeline中添加俩个inboundhandler和俩个outboundhandler.(以Inbound开头的类名表示为一个inboundhandler, 以Outbound开头的类名表示为一个outboundhandler.) 123456ChannelPipeline p = ...;p.addLast(&quot;1&quot;, new InboundHandlerA());p.addLast(&quot;2&quot;, new InboundHandlerB());p.addLast(&quot;3&quot;, new OutboundHandlerA());p.addLast(&quot;4&quot;, new OutboundHandlerB());p.addLast(&quot;5&quot;, new InboundOutboundHandlerX()); 事件在inboundhandler中的执行过程是1, 2, 3, 4, 5. 事件在outboundhandler中的执行过程是5, 4, 3, 2, 1. 但是在真实的执行过程中, 由于3, 4并没有实现ChannelInboundHandler, 因此inbound流程中真正执行的handler只有1, 2, 5. 而由于1, 2并没有实现ChannelOutboundHandler因此在outbound流程中真正执行的handler只有5, 4, 3.如果5都实现了ChannelInboundHandler和ChannelOutboundHandler, 那么事件的执行顺序分别是125和543. fireXXX在AbstractChannel中持有一个ChannelPipeline的实例, 一般是由Unsafe里通过调用ChannelPipeline的fireXXX()方法时, 去调用AbstractChannelHandlerContext的invokeChannelXXX静态方法来完成ChannelHandler链表遍历, 这个遍历咋完成的呢？用fireChannelActive()举个例子 12345@Overridepublic final ChannelPipeline fireChannelActive() &#123; AbstractChannelHandlerContext.invokeChannelActive(head); return this;&#125; 在上面我们贴出了俩个方法, 下面我们看一下fireChannelRead()的处理流程. 在AbstractChannelHandlerContext#fireChannelRead() 1234567891011121314151617181920212223242526272829303132333435363738394041static void invokeChannelActive(final AbstractChannelHandlerContext next) &#123; EventExecutor executor = next.executor(); if (executor.inEventLoop()) &#123; next.invokeChannelActive(); &#125; else &#123; executor.execute(new Runnable() &#123; @Override public void run() &#123; next.invokeChannelActive(); &#125; &#125;); &#125;&#125;// 进行处理, 是用当前Context的ChannelHandler处理真实逻辑,还是要继续遍历ChannelHandler链表,找下一个合适的ChannelHandlerprivate void invokeChannelActive() &#123; if (invokeHandler()) &#123; try &#123; ((ChannelInboundHandler) handler()).channelActive(this); &#125; catch (Throwable t) &#123; notifyHandlerException(t); &#125; &#125; else &#123; fireChannelActive(); &#125;&#125;// ChannelHandler链表遍历, 关键就是在这实现的public ChannelHandlerContext fireChannelActive() &#123; final AbstractChannelHandlerContext next = findContextInbound(); invokeChannelActive(next); return this;&#125;// 一直遍历整个链表直到找到inbound handlerprivate AbstractChannelHandlerContext findContextInbound() &#123; AbstractChannelHandlerContext ctx = this; do &#123; ctx = ctx.next; &#125; while (!ctx.inbound); return ctx;&#125; 这里就直接找到了handler, 触发了我们最终自己实现的channelRead()方法. 也许你已经注意到了, 在handler中不得不调用ChannelHandlerContext的事件传播方法, 将事件传递给下一个handler. 下面的是能够触发inbound事件的方法(ChannelInboundHandler) channelRegisteredChannel注册事件 123456789SingleThreadEventLoop#register() ↓AbstractChannel#AbstractUnsafe#register() ↓AbstractChannel#AbstractUnsafe#register0() ↓ DefaultChannelPipeline#fireChannelRegistered() ↓ChannelInboundHandler#channelRegistered() channelActiveTCP链路建立成功,Channel激活事件 123456789SingleThreadEventLoop#register() ↓AbstractChannel#AbstractUnsafe#register() ↓AbstractChannel#AbstractUnsafe#register0() ↓ DefaultChannelPipeline#fireChannelActive() ↓ChannelInboundHandler#channelActive() channelRead读事件 channelReadComplete读操作完成通知事件 exceptionCaught异常通知事件 userEventTriggered用户自定义事件 channelWritabilityChangedChannel的可写状态变化通知事件 channelInactiveTCP链路关闭, 链路不可用通知事件 触发outbound事件的方法有(ChannelOutboundHandler) bind绑定本地地址事件 connect连接服务端事件 flush刷新事件 read读事件 disconnect断开连接事件 close关闭当前Channel事件 解码器为了解决网络数据流的拆包粘包问题,Netty为我们内置了如下的解码器 ByteToMessageDecoder MessageToMessageDecoder LineBasedFrameDecoder StringDecoder DelimiterBasedFrameDecoder FixedLengthFrameDecoder ProtoBufVarint32FrameDecoder ProtobufDecoder LengthFieldBasedFrameDecoder Netty还内置了如下的编码器 ProtobufEncoder MessageToByteEncoder MessageToMessageEncoder LengthFieldPrepender Netty还为我们提供HTTP相关的编解码器 HttpRequestDecoder : Http消息解码器 HttpObjectAggregator : 将多个消息转换为单一的FullHttpRequest或者FullHttpResponse HttpResponseEncoder : 对Http消息影响进行编码 ChunkedWriteHandler : 异步大码流消息发送 ByteToMessageDecoder如果我们自己想要实现自己的半包解码器,我们可以继承ByteToMessageDecoder, 实现更加复杂的半包解码 1public abstract class ByteToMessageDecoder extends ChannelInboundHandlerAdapter ChannelInboundHandlerAdapter参考 我们只需要继承该类并实现 1protected abstract void decode(ChannelHandlerContext ctx, ByteBuf in, List&lt;Object&gt; out) throws Exception; 这个方法, 在这个方法里完成byte字节到java对象的转换, 也就是我们将ByteBuf解析成java对象然后抛给List&lt;Object&gt; out就可以了. 需要注意的这个类没有实现粘包组包等情况, 这个就需要我们自己实现了. MessageToMessageDecoderMessageToMessageDecoder一般作为二次解码器, 当我们在ByteToMessageDecoder将一个bytes数组转换成一个java对象的时候, 我们可能还需要将这个对象进行二次解码成其他对象, 我们就可以继承这个类, 1public abstract class MessageToMessageDecoder&lt;I&gt; extends ChannelInboundHandlerAdapter 然后实现 1protected abstract void decode(ChannelHandlerContext ctx, I msg, List&lt;Object&gt; out) throws Exception; 这个方法就可以了 LineBasedFrameDecoderLineBasedFrameDecoder的原理是从ByteBuf的可读字节中找到\\n或者\\r\\n,找到之后就以此为结束,然后将当前读取到的数据组成一行. 如果我们设置每一行的最大长度, 但是当达到最大长度之后还没有找到结束符,就会抛出异常,同时将读取的数据舍弃掉. LineBasedFrameDecoder的用法很简单, 我们可以向其指定大小或者不指定大小 1234567...ch.pipline().addLast(new LineBasedFrameDecoder());...或者...ch.pipline().addLast(new LineBasedFrameDecoder(1024));... 它的源码也很简单 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960protected Object decode(ChannelHandlerContext ctx, ByteBuf buffer) throws Exception &#123; // 找到 \\n 的位置 (如果是\\n\\r的话, 则向前移动一位,只取\\n) final int eol = findEndOfLine(buffer); // if (!discarding) &#123; if (eol &gt;= 0) &#123; // 找到了 \\n ，开始截取有效数据 final ByteBuf frame; final int length = eol - buffer.readerIndex(); // 如果分隔符是\\n的话,分隔符长度是1, 如果分隔符是\\n\\r的话,则分隔符长度是2 final int delimLength = buffer.getByte(eol) == &#x27;\\r&#x27;? 2 : 1; if (length &gt; maxLength) &#123; // 超过最大长度, 将读取的数据舍掉 buffer.readerIndex(eol + delimLength); fail(ctx, length); return null; &#125; if (stripDelimiter) &#123; // 读取数据不带分隔符, 读取有效数据后将分隔符去掉 frame = buffer.readRetainedSlice(length); buffer.skipBytes(delimLength); &#125; else &#123; // 有效数据中带有分隔符 frame = buffer.readRetainedSlice(length + delimLength); &#125; return frame; &#125; else &#123; // 没有找到分隔符, 返回null final int length = buffer.readableBytes(); if (length &gt; maxLength) &#123; // 如果数据超过最大长度, 则将多余的数据舍弃 discardedBytes = length; buffer.readerIndex(buffer.writerIndex()); discarding = true; if (failFast) &#123; fail(ctx, &quot;over &quot; + discardedBytes); &#125; &#125; return null; &#125; &#125; else &#123; if (eol &gt;= 0) &#123; final int length = discardedBytes + eol - buffer.readerIndex(); final int delimLength = buffer.getByte(eol) == &#x27;\\r&#x27;? 2 : 1; buffer.readerIndex(eol + delimLength); discardedBytes = 0; discarding = false; if (!failFast) &#123; fail(ctx, length); &#125; &#125; else &#123; discardedBytes += buffer.readableBytes(); buffer.readerIndex(buffer.writerIndex()); &#125; return null; &#125;&#125; DelimiterBasedFrameDecoder使用DelimiterBasedFrameDecoder我们可以自定义设定分隔符 123...ByteBuf delimiter = Unpooled.copiedBuffer(&quot;$_&quot;.getBytes());ch.pipline().addLast(new DelimiterBasedFrameDecoder(1024, delimiter)); 在上面的例子中我们使用了自定义的分隔符$_, 同样的如果在1024个字节中找不到$_, 也会抛出. FixedLengthFrameDecoderFixedLengthFrameDecoder为定长解码器, 它会按照指定长度对消息进行解码. 1ch.pipline().addLast(new FixedLengthFrameDecoder(1024)); 上面的例子会每隔1024个长度之后进行消息解码,如果不足1024,则会将消息缓存起来,然后再进行解码 ProtobufVarint32FrameDecoderProtoBufVarint32FrameDecoder是Netty为我们提供的Protobuf半包解码器, 通过它配合使用ProtobufDecoder和ProtobufEncoder我们就可以使用Protobuf进行通信了 123ch.pipline().addLast(new ProtobufVarint32FrameDecoder());ch.pipline().addLast(new ProtobufDecoder());ch.pipline().addLast(new ProtobufEncoder()); LengthFieldBasedFrameDecoderLengthFieldBasedFrameDecoder是Netty为我们提供的通用半包解码器. 1public class LengthFieldBasedFrameDecoder extends ByteToMessageDecoder 这个类的半包读取策略由下面的属性控制 lengthFieldOffset : 标志长度字段的偏移量. 也就是在一个bytes字节流中,表示消息长度的字段是从流中哪个位置开始的. lengthFieldLength : 长度字段的长度(单位byte) lengthAdjustment : 当消息长度包含了消息头的长度的时候,需要使用这个变量进行校正, 例如lengthFieldOffset为0,lengthFieldLength为2, 那么消息正体在解析时就需要校正2个字节, 故这里为-2. initialBytesToStrip: 这个是当我们解析ByteBuf时要跳过的那些字段, (一般为lengthFieldOffset + lengthFieldLength) MessageToByteEncoder该类负责将java对象编码成ByteBuf, 我们只需要继承该类然后实现 1protected abstract void encode(ChannelHandlerContext ctx, I msg, ByteBuf out) throws Exception; 方法就可以了 MessageToMessageEncoder如果要将java对象不编码成ByteBuf, 而是编译成, 其他对象, 那我们可以继承这个类实现 1protected abstract void encode(ChannelHandlerContext ctx, I msg, List&lt;Object&gt; out) throws Exception; 这个方法就可以了 这个类与MessageToByteEncoder的不同是, 将java对象放到一个List&lt;Object&gt; out, 而不是编码成ByteBuf发送 LengthFieldPrependerLengthFieldPrepender是一个非常实用的工具类, 如果我们在发送消息的时候采用的是:消息长度字段+原始消息的形式, 那么我们就可以使用LengthFieldPrepender了. 这是因为LengthFieldPrepender可以将待发送消息的长度(二进制字节长度)写到ByteBuf的前俩个字节.例如: 1Hello,World 编码前是12个字节,但是经过LengthFieldPrepender编码后变成了 10x000E Hello,World 成为了14个字节 HTTP解码器 使用HttpObjectAggregator是因为在解码Http消息中会产生多个对象(HttpRequest, HttpResponse, HttpContent, LastHttpContent), 使用HttpObjectAggregator我们可以将这些对象都组合到一起去. 然后当我们自己在处理消息时就可以直接使用FullHttpRequest了 1234ch.pipline().addLast(&quot;http-decoder&quot;, new HttpRequestDecoder());ch.pipline().addLast(&quot;http-aggregator&quot;, new HttpObjectAggregator());ch.pipline().addLast(&quot;http-encoder&quot;, new HttpResponseEncoder());ch.pipline().addLast(&quot;http-chunked&quot;, new ChunkedWriteHandler());","categories":[{"name":"Netty","slug":"Netty","permalink":"https://wangmingco.github.io/categories/Netty/"}],"tags":[{"name":"Netty","slug":"Netty","permalink":"https://wangmingco.github.io/tags/Netty/"}]},{"title":"Typesafe Config 初探","slug":"JavaLibrary/Typesafe Config 初探","date":"2016-01-29T16:00:00.000Z","updated":"2021-11-18T02:49:49.038Z","comments":true,"path":"2016/01/30/JavaLibrary/Typesafe Config 初探/","link":"","permalink":"https://wangmingco.github.io/2016/01/30/JavaLibrary/Typesafe%20Config%20%E5%88%9D%E6%8E%A2/","excerpt":"","text":"Typesafe Config 是为JVM平台语言提供的配置类库. 目前config只支持配置文件，如果想从数据库获取配置文件，需要自己diy。 config库很擅长合并配置。 我们可以直接使用maven方式依赖该库 12345&lt;dependency&gt; &lt;groupId&gt;com.typesafe&lt;/groupId&gt; &lt;artifactId&gt;config&lt;/artifactId&gt; &lt;version&gt;1.3.0&lt;/version&gt;&lt;/dependency&gt; API示例 123456import com.typesafe.config.ConfigFactoryConfig conf = ConfigFactory.load();int bar1 = conf.getInt(&quot;foo.bar&quot;);Config foo = conf.getConfig(&quot;foo&quot;);int bar2 = foo.getInt(&quot;bar&quot;); 在上面的例子中我们使用了最简单的方式ConfigFactory.load()加载出了一个配置类Config, config会自动去classPath中查找reference.conf. ConfigFactory.load()会按照下面的优先级依次从classpath中查找文件进行加载 system properties application.conf (all resources on classpath with this name) application.json (all resources on classpath with this name) application.properties (all resources on classpath with this name) reference.conf (all resources on classpath with this name)如果我们不想要使用上面的文件名或者我们将配置分配到多个文件中,那么我们可以使用ConfigFactory.load(&quot;test.conf&quot;); 当然如果你想自己创建Config也可以调用ConfigFactory的parseXXX方法 123ConfigFactory.parseFile(new File(&quot;&quot;));ConfigFactory.parseMap(new HashMap&lt;&gt;());ConfigFactory.parseProperties(new Properties()); 需要注意的从Config实例中得到的Config, ConfigParseOptions, ConfigResolveOptions, ConfigObject 得到的对象都是不可变的.","categories":[{"name":"Java 类库","slug":"Java-类库","permalink":"https://wangmingco.github.io/categories/Java-%E7%B1%BB%E5%BA%93/"}],"tags":[{"name":"Typesafe Config","slug":"Typesafe-Config","permalink":"https://wangmingco.github.io/tags/Typesafe-Config/"}]},{"title":"使用Classloader加载类","slug":"jvm/Classloader 示例","date":"2016-01-28T16:00:00.000Z","updated":"2021-11-18T02:43:27.748Z","comments":true,"path":"2016/01/29/jvm/Classloader 示例/","link":"","permalink":"https://wangmingco.github.io/2016/01/29/jvm/Classloader%20%E7%A4%BA%E4%BE%8B/","excerpt":"","text":"类加载器不单单是用于实现类的加载动作, 对于任意一个类,都需要由加载它的类加载器和类本身一同确立其在java虚拟机中的唯一性.换句话说:比较俩个类是否相等,只有在这俩个类是由同一个类加载器加载的前提下才有意义. 否则即使来自同一个源文件,只要加载它们的类加载器不同,这俩个类就必定不相等. 判断俩个类相等可以通过下面方法: Class对象的equals()方法, isAssignbleFrom()方法, isInstance()方法的返回结果, 也包括使用instanceof关键字做对象所属关系判断等. 不同的类加载器对instanceof关键字运算结果的影响 从JVM来角度讲, 只存在俩种不同的类加载器: 启动类加载器: 使用C++语言实践,是虚拟机自身的一部分. 其他类加载器: 这些类加载器都由java语言实现,独立于虚拟机外部,并且全部都继承自抽象类:java.lang.ClassLoader 系统提供的类加载器 启动类加载器 : 这个类加载器负责将&lt;JAVA_HOME&gt;\\lib目录中的,或者-Xbootclasspath参数所指定的路径中的,并且是虚拟机识别的(仅按照文件名识别,如rt,jar,名字不符合的类库即使放在lib目录里也不会被加载)类库加载到虚拟机内存中,启动类加载器无法被java程序直接使用. 扩展类加载器 : 这个类加载器由sun.misc.Launcher$ExtClassLoader实现,负责加载&lt;JAVA_HOME&gt;\\lib\\ext目录中的,或者被java.ext.dirs系统变量所指定的路径中的所有类库, 开发者可以直接使用扩展类加载器. 应用程序加载器 : 这个类加载器由sun.misc.Launcher$AppClassLoader来实现. 由于类加载器是ClassLoader中getSystemClassLoader()方法的返回值,所以一般也称它为系统类加载器. 它负责加载用户类路径(ClassPath)上所指定的类库,开发者可以直接使用这个类加载器,如果应用程序中没有自定义过自己的类加载器,一般情况下就是程序中默认的类加载器. 类加载器收到类加载请求,它不会自己去尝试加载这个类,而把这个请求委派给父类加载器去完成,每一个层次的类加载都是如此,因此所有的类加请求最终都应该传送到顶层的启动类加载器中,只有当父加载器反馈自己无法完成这个加载请求(它的搜索范围中没有找到所需的类)时,子类加载器才会尝试自己去加载. 123456789101112131415161718192021222324252627282930313233343536373839protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; synchronized (getClassLoadingLock(name)) &#123; // 第一步检查被加载的类是否已经被加载进入了虚拟机 Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; // 如果没有被加载进虚拟机中则进行加载 long t0 = System.nanoTime(); try &#123; // 优先从父类加载器中进行加载, 所有的类加请求最终都应该传送到顶层的启动类加载器中 if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; // c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; if (c == null) &#123; // 父类加载器找不到则调用自己的findClass(name)找到类然后进行加载 long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125; &#125; 使用双亲委派模型来组织类加载之间的关系, 可以确保我们自己JVM的安全. 因为当我们自己写一个 java.lang.Object, 这个类虽然能够被正常编译, 但是它永远不会被加载器虚拟机中, 因为这个类会在启动类加载器中完成了加载. 在刚才的loadClass()方法中我们看到最终我们自己实现类加载的逻辑是在findClass()中进行的, 这是为了向前兼容,JDK1.2之后添加的方法.JDK1.2之后已不提倡用户再去覆盖loadClass()方法,而在loadClass()方法的逻辑里如果父类加载失败,则会调用自己的findClass()方法来完成加载,这样就可以保证新写出来的类加载器是符合双亲委派规则的. 为了解决各个类加载器的基础类调用用户代码, java设计团队引入了这样一个设计:线程上下文类加载器,这个类加载器可以通过java.lang.Thread类的setContextClassLoaser()方法进行设置,如果创建线程时还未设置,它将会从父线程中继承一个:如果在应用程序的全局范围内都没有设置过,那么这个类加载器默认就是应用程序类加载器.有了线程上下文类加载器,JNDI服务使用这个线程上下文类加载器去加载所需要的SPI代码,也就是父类加载器请求子类加载器去完成类加载的动作,这种行为实际就是打通了双亲委派模型的层次结构来逆向使用类加载器,已经违背了双亲委派模型的一般性原则. 上面所说只完成了类加载的动作, 但是如果我们想要实现热更代码的这种功能的话,就不能单纯依赖重写findClass(name)了，而是要重写loadClass(String name)了，这是因为在ClassLoader中的loadClass(String name)方法当发现已经加载过的类就不会再重新加载了 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970import java.io.File;import java.lang.reflect.Field;import java.net.URL;import java.net.URLClassLoader;import java.util.Random;import static org.objectweb.asm.Opcodes.*;public class TestClassLoader &#123; public static void main(String[] arg) throws Exception &#123; URL url = new File(&quot;.&quot;).toURL(); for (int i = 0; i&lt; 5; i++) &#123; MyClassLoader myLoader = new MyClassLoader(new URL[]&#123;url&#125;); Class&lt;?&gt; obj = myLoader.loadClass(&quot;Mesurable&quot;); for (Field field : obj.getFields()) &#123; System.out.println(field.getName()); &#125; &#125; &#125;&#125;class MyClassLoader extends URLClassLoader &#123; public MyClassLoader(URL[] urls) &#123; super(urls); &#125; @Override public Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException &#123; Class&lt;?&gt; loadClass = null; if (name.contains(&quot;java.lang.Object&quot;)) &#123; // 因为我们的父类是java.lang.Object, 因此我们要调用父类加载器进行加载 loadClass = super.loadClass(name); &#125; else &#123; loadClass = findLoadedClass(name); if (loadClass != null) &#123; return loadClass; &#125; byte[] bytes = generateClass(); loadClass = defineClass(name, bytes, 0, bytes.length); &#125; return loadClass; &#125; private byte[] generateClass() &#123; ClassWriter cw = new ClassWriter(0); cw.visit(V1_8, // 指定class文件版本号, 我们将其设置为java8 ACC_PUBLIC, // 设置接口的修饰符 &quot;Mesurable&quot;, // 我们设置classname, 需要在这里指定全限定名 null, // 设置泛型信息, 因为我们的接口是非泛化的, 因此我们将其设置为null &quot;java/lang/Object&quot;, // 设置父类, 同时需要设定全限定名 null); // 设置接口, 同样需要设置全限定名 cw.visitField( ACC_PUBLIC, // 设置字段的修饰符 &quot;LESS__&quot; + random.nextInt(100), // 设置字段名 &quot;I&quot;, // 设置字段类型 null, // 设置泛型信息 new Long(-1)) // 设置字面量值. .visitEnd(); cw.visitEnd(); return cw.toByteArray(); &#125; private Random random = new Random();&#125; URLClassLoader根据URL指定的路径从JAR文件或者目录里加载class文件或者其他资源文件. 如果URL以/结束,就表示到某个目录里进行加载. 否则就表示到某个JAR文件里进行加载. 线程里用于创建URLClassLoader实例的AccessControlContext会在加载类文件以及资源文件时使用到. URLClassLoader实例创建好之后会根据默认的授权权限依据指定的URL来进行加载类. 从文件中加载class 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960import java.io.*;import java.lang.reflect.Method;import java.net.URL;import java.net.URLClassLoader;import java.util.concurrent.TimeUnit;public class Test &#123; public static void main(String[] arg) throws Exception &#123; for (int i = 0; i&lt; 5; i++) &#123; MyClassLoader myLoader = new MyClassLoader(new URL[]&#123;&#125;); Class&lt;?&gt; obj = myLoader.loadClass(&quot;D:\\\\ming\\\\test\\\\target\\\\classes\\\\Test.class&quot;); for (Method method : obj.getMethods()) &#123; if (method.getName().equals(&quot;printTime&quot;)) &#123; method.invoke(null); TimeUnit.SECONDS.sleep(10); &#125; &#125; &#125; &#125; public static void printTime() &#123; System.out.println(123); &#125;&#125;class MyClassLoader extends URLClassLoader &#123; public MyClassLoader(URL[] urls) &#123; super(urls); &#125; @Override public Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException &#123; Class&lt;?&gt; loadClass = findLoadedClass(name); if (loadClass != null) &#123; return loadClass; &#125; try &#123; byte[] bytes = loadClassFromFile(name); int idx = name.lastIndexOf(&quot;\\\\&quot;); name = name.substring(idx + 1); name = name.split(&quot;\\\\.class&quot;)[0]; loadClass = defineClass(name, bytes, 0, bytes.length); &#125; catch (Exception e) &#123; loadClass = super.loadClass(name); &#125; return loadClass; &#125; private byte[] loadClassFromFile(String fileName) throws Exception &#123; InputStream input = new FileInputStream(new File(fileName)); byte[] bytes = new byte[input.available()]; input.read(bytes); return bytes; &#125;&#125; 同一个类加载器不同加载同一个类俩次, 例如我们利用上面的MyClassLoader进行加载 123456789101112public class Test &#123; public static void main(String[] arg) throws Exception &#123; MyClassLoader myLoader1 = new MyClassLoader(new URL[]&#123;&#125;); Class&lt;?&gt; obj1 = myLoader1.loadClass(&quot;D:\\\\ming\\\\test\\\\target\\\\classes\\\\Test.class&quot;); MyClassLoader myLoader2 = new MyClassLoader(new URL[]&#123;&#125;); Class&lt;?&gt; obj2 = myLoader2.loadClass(&quot;D:\\\\ming\\\\test\\\\target\\\\classes\\\\Test.class&quot;); System.out.println(obj1.equals(obj2)); Class&lt;?&gt; obj3 = myLoader2.loadClass(&quot;D:\\\\ming\\\\test\\\\target\\\\classes\\\\Test.class&quot;); System.out.println(obj2.equals(obj3)); &#125;&#125; 会产生异常 123456789101112falseException in thread &quot;main&quot; java.lang.LinkageError: loader (instance of MyClassLoader): attempted duplicate class definition for name: &quot;Test&quot; at java.lang.ClassLoader.defineClass1(Native Method) at java.lang.ClassLoader.defineClass(ClassLoader.java:763) at java.lang.ClassLoader.defineClass(ClassLoader.java:642) at MyClassLoader.loadClass(Test.java:37) at Test.main(Test.java:15) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144) 上面使用ClassLoader加载类. 但是我们还可以使用一个更简单的方式Class.forName()让系统来加载一个类. 其实我们看它的源码实现的话, 会发现, 它自己也是通过ClassLoader实现的加载 12345678@CallerSensitivepublic static Class&lt;?&gt; forName(String className) throws ClassNotFoundException &#123; return forName0(className, true, ClassLoader.getClassLoader(Reflection.getCallerClass()));&#125;private static native Class&lt;?&gt; forName0(String name, boolean initialize, ClassLoader loader) throws ClassNotFoundException; 我们看到了, 它内部也是找到了一个系统的ClassLoader开始对Class进行加载的. 我们写个测试代码测试一下 12345678910111213import java.lang.reflect.Method;public class TestClassForName &#123; public static void main(String[] args) throws InterruptedException, ClassNotFoundException &#123; Class&lt;?&gt; simpleClass = Class.forName(&quot;SimpleClass&quot;); for (Method method: simpleClass.getMethods()) &#123; System.out.println(method.getName()); &#125; Class&lt;?&gt; simpleClass1 = Class.forName(&quot;SimpleClass&quot;); System.out.println(simpleClass.equals(simpleClass1)); System.out.println(simpleClass == simpleClass1); &#125;&#125; 然后我在同一级包下定义一个类 123public class SimpleClass &#123; public void empotyMethod() &#123;&#125;&#125; 我们运行一下看一下结果 123456789101112empotyMethodwaitwaitwaitequalstoStringhashCodegetClassnotifynotifyAlltruetrue ok, 类已经被成功加载并且找到了.","categories":[{"name":"JVM","slug":"JVM","permalink":"https://wangmingco.github.io/categories/JVM/"}],"tags":[]},{"title":"Retrofit 初探","slug":"JavaLibrary/Retrofit","date":"2016-01-19T16:00:00.000Z","updated":"2021-11-18T02:58:48.891Z","comments":true,"path":"2016/01/20/JavaLibrary/Retrofit/","link":"","permalink":"https://wangmingco.github.io/2016/01/20/JavaLibrary/Retrofit/","excerpt":"","text":"首先添加Maven依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.squareup.retrofit2&lt;/groupId&gt; &lt;artifactId&gt;retrofit&lt;/artifactId&gt; &lt;version&gt;2.0.2&lt;/version&gt;&lt;/dependency&gt; 注意我们使用的是retrofit2 Get请求Retrofit 将HTTP API转换为了接口形式, 如下 1234public interface GitHubService &#123; @GET(&quot;users/&#123;user&#125;/repos&quot;) Call&lt;List&lt;Repo&gt;&gt; listRepos(@Path(&quot;user&quot;) String user);&#125; 然后Retrofit会自动完成其实现类 12345Retrofit retrofit = new Retrofit.Builder() .baseUrl(&quot;https://api.github.com&quot;) .build();GitHubService service = retrofit.create(GitHubService.class); 在上面的示例中我们完成了一个Get请求, 然后使用@Path进行参数替换 Post请求上面我们展示的是一个Get请求, 下面我们再看一个Post请求的示例 12@POST(&quot;users/new&quot;)Call&lt;User&gt; createUser(@Body User user); @Body注解会将User对象转换为请求体 form-encoded我们我们想要将格式转换为form-encoded形式, 参考如下示例 123@FormUrlEncoded@POST(&quot;user/edit&quot;)Call&lt;User&gt; updateUser(@Field(&quot;first_name&quot;) String first, @Field(&quot;last_name&quot;) String last); @Field注解会组成一个个字典结构的数据进行发送. HEADER有时候我们也许想要设置其他的消息头, 我们可以如此做 123@Headers(&quot;Cache-Control: max-age=640000&quot;)@GET(&quot;widget/list&quot;)Call&lt;List&lt;Widget&gt;&gt; widgetList(); 异步我们在Call对象中分别可以调用异步和同步方法进行通信 1234567891011121314151617181920212223Retrofit retrofit = new Retrofit.Builder() .baseUrl(&quot;https://api.github.com&quot;) .build();GitHubService service = retrofit.create(GitHubService.class);Call&lt;List&lt;String&gt;&gt; repos = service.listRepos(&quot;octocat&quot;); // 同步调用 Response&lt;List&lt;String&gt;&gt; result = repos.execute(); // 异步调用 repos.enqueue(new Callback() &#123; @Override public void onResponse(Response response) &#123; &#125; @Override public void onFailure(Throwable t) &#123; &#125; &#125;); 测试在我的windows的机器上进行测试, 只是测试一下Retrofit的性能消耗 1234567891011121314151617181920212223242526272829@Testpublic void testIte1Minite() throws IOException &#123; int count = 0; long start = System.currentTimeMillis(); while (true) &#123; long end = System.currentTimeMillis(); if ((end - start) &gt; 1000 * 60) &#123; break; &#125; Retrofit retrofit = new Retrofit.Builder() .baseUrl(&quot;http://192.168.15.20:9091&quot;) .addConverterFactory(GsonConverterFactory.create()) .build(); ServerListService loginServerPushService = retrofit.create(ServerListService.class); loginServerPushService.serverlist().execute().body(); count++; &#125; System.out.println(count);&#125;public interface ServerListService &#123; @GET(&quot;server/serverlist&quot;) Call&lt;MyServer&gt; serverlist();&#125;public class MyServer &#123; public List&lt;Map&lt;String, String&gt;&gt; serverlist; public List&lt;Map&lt;String, String&gt;&gt; serverlogin;&#125; 结果如图 12345678910111213141516171819@Testpublic void testIte1Minite() throws IOException &#123; int count = 0; long start = System.currentTimeMillis(); Retrofit retrofit = new Retrofit.Builder() .baseUrl(&quot;http://192.168.15.20:9091&quot;) .addConverterFactory(GsonConverterFactory.create()) .build(); while (true) &#123; long end = System.currentTimeMillis(); if ((end - start) &gt; 1000 * 60) &#123; break; &#125; ServerListService loginServerPushService = retrofit.create(ServerListService.class); loginServerPushService.serverlist().execute().body(); count++; &#125; System.out.println(count);&#125; 结果如图这俩次的结果都能达到每分钟13000个请求, 吞吐量和性能消耗是差不多. ConverterRetrofit2为我们提供了多种转换器 Gson: com.squareup.retrofit2:converter-gson Jackson: com.squareup.retrofit2:converter-jackson Moshi: com.squareup.retrofit2:converter-moshi Protobuf: com.squareup.retrofit2:converter-protobuf Wire: com.squareup.retrofit2:converter-wire Simple XML: com.squareup.retrofit2:converter-simplexml Scalars (primitives, boxed, and String): com.squareup.retrofit2:converter-scalars在使用Retrofit2的时候, 必须指定Converter, 否则程序在运行中会报错. Scalars 只是支持String和基本类型的装包和拆包","categories":[{"name":"Java 网络库","slug":"Java-网络库","permalink":"https://wangmingco.github.io/categories/Java-%E7%BD%91%E7%BB%9C%E5%BA%93/"}],"tags":[{"name":"Retrofit","slug":"Retrofit","permalink":"https://wangmingco.github.io/tags/Retrofit/"}]},{"title":"OWNER 初探","slug":"JavaLibrary/OWNER 初探","date":"2016-01-18T16:00:00.000Z","updated":"2021-11-18T02:49:01.783Z","comments":true,"path":"2016/01/19/JavaLibrary/OWNER 初探/","link":"","permalink":"https://wangmingco.github.io/2016/01/19/JavaLibrary/OWNER%20%E5%88%9D%E6%8E%A2/","excerpt":"","text":"OWNER是一个Java库，目标是最大限度的减少应用程序中处理Java properties的代码。 主要功能 加载策略：OWNER通过匹配接口类名和properties文件名自动解析并映射；也可以通过注解定制properties文件名。 导入properties：另外一种加载properties文件到映射接口的方法。 参数化properties：另外一个实用功能，给接口方法提供参数，通过参数配置。 类型转换：支持从String类型到基本类型和枚举类型的转换。 变量扩展：引用properties中的其他属性。 热加载：支持热加载。 可访问和可变：可以继承Config的子接口Accessible或者Mutable实现属性的可访问和可变。 调试：支持调试功能。 禁用功能：可禁用引起问题的功能。 配置ConfigFactory：ConfigFactory也是可配置的。 XML支持：支持XML配置。 事件支持：OWNER实现了功能丰富的事件系统，使你知道热加载的发生和属性变化。 单例模式：配置信息在一个应用中是单例的。 OWNER同样是开源的, 我们可以使用maven来引用它 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.aeonbits.owner&lt;/groupId&gt; &lt;artifactId&gt;owner&lt;/artifactId&gt; &lt;version&gt;1.0.8&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 或者使用java8版本 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.aeonbits.owner&lt;/groupId&gt; &lt;artifactId&gt;owner-java8&lt;/artifactId&gt; &lt;version&gt;1.0.6&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 基本用法我们现在在MAVEN项目中测试一下首先我们在test\\src\\main\\java\\ownerTest目录下创建一个配置类 12345678910package ownerTest;import org.aeonbits.owner.Config;public interface ServerConfig extends Config &#123; int port(); String hostname(); @DefaultValue(&quot;42&quot;) int maxThreads();&#125; 然后在test\\src\\main\\resources\\ownerTest目录下创建配置文件ServerConfig.properties 123port=80hostname=foobar.commaxThreads=100 然后我们书写一个测试类 1234567891011package ownerTest;import org.aeonbits.owner.ConfigFactory;public class Main &#123; public static void main(String[] args) &#123; ServerConfig cfg = ConfigFactory.create(ServerConfig.class); System.out.println(&quot;Server &quot; + cfg.hostname() + &quot;:&quot; + cfg.port() + &quot; will run &quot; + cfg.maxThreads()); &#125;&#125; 这时OWNER会自动地将ServerConfig.properties配置文件匹配到ServerConfig上, 输出结果为 1Server foobar.com:80 will run 100 我们看到在ServerConfig里我们使用了一个@DefaultValue注解, 当在配置文件里找不到这个值的时候, 这个注解值会为我们设置上注解里的默认值. 如果在配置文件里找不到这个设置也没有添加@DefaultValue会产生一个空指针异常 有时候我们在配置文件里会使用server.http.port=80的配置, 那么这种情况下我们就在使用@Key注解 123456789101112131415package ownerTest;import org.aeonbits.owner.Config;public interface ServerConfig extends Config &#123; @Key(&quot;server.http.port&quot;) int port(); @Key(&quot;server.host.name&quot;) String hostname(); @Key(&quot;server.max.threads&quot;) @DefaultValue(&quot;42&quot;) int maxThreads();&#125; 我们的配置文件如下 123server.http.port=80server.host.name=foobar.comserver.max.threads=100 加载策略正如上文所说, OWNER是按照classpath去自动匹配配置类和配置文件的, 但是其实我们可以自定义配置文件的加载策略, 如下例 1234567891011121314@Sources(&#123; &quot;file:~/.myapp.config&quot;, &quot;file:/etc/myapp.config&quot;, &quot;classpath:foo/bar/baz.properties&quot; &#125;)public interface ServerConfig extends Config &#123; @Key(&quot;server.http.port&quot;) int port(); @Key(&quot;server.host.name&quot;) String hostname(); @Key(&quot;server.max.threads&quot;); @DefaultValue(&quot;42&quot;) int maxThreads();&#125; 我们使用了@Sources指定配置文件的路径, 按照上面的代码, 它依次按照下面的流程进行文件匹配,一旦匹配成功就进行加载忽略后面的文件 file:~/.myapp.config 从home目录开始查找 file:/etc/myapp.config 从绝对目录进行查找 classpath:foo/bar/baz.properties classpath从classpath中查找 其实上面的加载策略称为LoadType.FIRST(完整注解@LoadPolicy(LoadType.FIRST)). 我们还有其他选择LoadType.MERGE, 示例如下: 1234567@LoadPolicy(LoadType.MERGE)@Sources(&#123; &quot;file:~/.myapp.config&quot;, &quot;file:/etc/myapp.config&quot;, &quot;classpath:foo/bar/baz.properties&quot; &#125;)public interface ServerConfig extends Config &#123; ...&#125; 上面的加载策略是, 不管当前路径下是否找到了都会进行路径下查找, 但与LoadType.FIRST不同的是, 当找到之后它会替换之前知道的配置文件. TODO 是局部替换还是整个文件一起替换呢？ 参数化我们还可以向配置里传递参数 1234567public interface Sample extends Config &#123; @DefaultValue(&quot;Hello Mr. %s!&quot;) String helloMr(String name);&#125;Sample cfg = ConfigFactory.create(Sample.class);print(cfg.helloMr(&quot;Luigi&quot;)); // will println &#x27;Hello Mr. Luigi!&#x27; OWNER还为我们提供了@DisableFeature注解, 让我们关闭参数化功能. 这个注解可以用在类或者方法的级别上 自定义类型当我们使用OWNER的时候, 不仅仅可以使用原生类型, 还可以使用数组, 集合甚至是自定义类型 下来我们自定义一个类型 1 下面我们定义一个数组和集合 1234567891011121314151617181920212223public class MyConfig extends Config &#123; @DefaultValue(&quot;apple, pear, orange&quot;) public String[] fruit(); @Separator(&quot;;&quot;) @DefaultValue(&quot;0; 1; 1; 2; 3; 5; 8; 13; 21; 34; 55&quot;) public int[] fibonacci(); @DefaultValue(&quot;1, 2, 3, 4&quot;) List&lt;Integer&gt; ints(); @DefaultValue( &quot;http://aeonbits.org, http://github.com, http://google.com&quot;) MyOwnCollection&lt;URL&gt; myBookmarks(); // Concrete class are allowed (in this case java.util.Stack) // when type is not specified &lt;String&gt; is assumed as default @DefaultValue( &quot;The Lord of the Rings,The Little Prince,The Da Vinci Code&quot;) Stack books();&#125; OWNER默认使用,分割元素. 但是我们可以通过@Separator(&quot;;&quot;)指定使用;进行切割, 需要注意的是OWNER只支持数组, 集合, Java原生类型, 并不支持Map. 支持的集合有Collection, List, Set, SortedSet 虽然我们可以使用@Separator(&quot;;&quot;)进行切割, 但是如果我们有更复杂的切割逻辑的话, 这可能就不再符合需求了, 我们可以使用@TokenizerClass来实现更复杂的切割逻辑 1234567891011121314151617181920public class MyConfig extends Config &#123; @Separator(&quot;;&quot;) @DefaultValue(&quot;0; 1; 1; 2; 3; 5; 8; 13; 21; 34; 55&quot;) public int[] fibonacci(); @TokenizerClass(CustomDashTokenizer.class) @DefaultValue(&quot;foo-bar-baz&quot;) public String[] withSeparatorClass();&#125;public class CustomDashTokenizer implements Tokenizer &#123; // this logic can be as much complex as you need @Override public String[] tokens(String values) &#123; return values.split(&quot;-&quot;, -1); &#125;&#125; 虽然 @Separator(&quot;;&quot;) 和 @TokenizerClass(CustomDashTokenizer.class)都可以在方法和类的级别上进行注解, 但是他们不允许同时出现在同一个级别上, 而且当分别出现在了方法和类的级别上后, 方法上的注解会替换类上的注解. OWNER还提供了@ConverterClass注解来实现更加复杂的转换逻辑 1234567891011121314151617181920212223242526272829303132333435interface MyConfig extends Config &#123; @DefaultValue(&quot;foobar.com:8080&quot;) @ConverterClass(ServerConverter.class) Server server(); @DefaultValue( &quot;google.com, yahoo.com:8080, owner.aeonbits.org:4000&quot;) @ConverterClass(ServerConverter.class) Server[] servers();&#125;class Server &#123; private final String name; private final Integer port; public Server(String name, Integer port) &#123; this.name = name; this.port = port; &#125;&#125;public class ServerConverter implements Converter&lt;Server&gt; &#123; public Server convert(Method targetMethod, String text) &#123; String[] split = text.split(&quot;:&quot;, -1); String name = split[0]; Integer port = 80; if (split.length &gt;= 2) port = Integer.valueOf(split[1]); return new Server(name, port); &#125;&#125;MyConfig cfg = ConfigFactory.create(MyConfig.class);Server s = cfg.server(); // will return a single serverServer[] ss = cfg.servers(); // it works also with collections OWNER 支持的全部自动转换类型 原生类型: boolean, byte, short, integer, long, float, double. 枚举 java.lang.String java.net.URL, java.net.URI. java.io.File java.lang.Class 公有构造器只有一个java.lang.String的类 公有构造器只有一个java.lang.Object的类 被public static修饰, 签名为valueOf(java.lang.String)返回自身的方法 带有上述元素的数组 带有上述类的集合(Set, List, SortedSet or concrete implementations like LinkedHashSet). Map and sub-interfaces are not supported. 变量表达式OWNER还提供了一个非常霸道的功能 —— 变量表达式, 参考如下配置文件 12345story=The $&#123;animal&#125; jumped over the $&#123;target&#125;animal=quick $&#123;color&#125; foxtarget=$&#123;target.attribute&#125; dogtarget.attribute=lazycolor=brown 然后定义一个配置类 123public interface ConfigWithExpansion extends Config &#123; String story();&#125; 猜猜会输出什么, 对了 1The quick brown fox jumped over the lazy dog 我们可以在配置文件里引用其他的配置 同样的我们还可以在配置类完成这样的功能 12345678910111213141516171819202122232425public interface ConfigWithExpansion extends Config &#123; @DefaultValue( &quot;The $&#123;animal&#125; jumped over the $&#123;target&#125;&quot;) String story(); @DefaultValue(&quot;quick $&#123;color&#125; fox&quot;) String animal(); @DefaultValue(&quot;$&#123;target.attribute&#125; dog&quot;) String target(); @Key(&quot;target.attribute&quot;) @DefaultValue(&quot;lazy&quot;) String targetAttribute(); @DefaultValue(&quot;brown&quot;) String color();&#125;ConfigWithExpansion conf = ConfigFactory .create(ConfigWithExpansion.class);String story = conf.story(); 如果我们不需要开启变量表达式的话, 我们可以使用@DisableFeature(VARIABLE_EXPANSION) 12345678910public interface Sample extends Config &#123; @DefaultValue(&quot;Earth&quot;) String world(); @DisableFeature(VARIABLE_EXPANSION) @DefaultValue(&quot;Hello $&#123;world&#125;.&quot;) // will return the string &quot;Hello $&#123;world&#125;.&quot; String sayHello();&#125;","categories":[{"name":"Java 类库","slug":"Java-类库","permalink":"https://wangmingco.github.io/categories/Java-%E7%B1%BB%E5%BA%93/"}],"tags":[{"name":"OWNER","slug":"OWNER","permalink":"https://wangmingco.github.io/tags/OWNER/"}]},{"title":"ASM Core(5) 工具","slug":"JavaLibrary/ASM Core(5) 工具","date":"2016-01-13T16:00:00.000Z","updated":"2021-11-18T02:51:10.573Z","comments":true,"path":"2016/01/14/JavaLibrary/ASM Core(5) 工具/","link":"","permalink":"https://wangmingco.github.io/2016/01/14/JavaLibrary/ASM%20Core(5)%20%E5%B7%A5%E5%85%B7/","excerpt":"","text":"ASM通过org.objectweb.asm.util对ClassVisitor, ClassReader, ClassWriter提供非常多有帮助的类，通过这些类可以帮助开发者简化字节码的操作过程. Type在前面的文章中我们看到ASM API暴露了存储在字节码中的类型信息等等, 但是上文中的信息我们看到了可读性比较差, 因此ASM提供了Type这个工具类,让我们可以像源码中那样看到可读性更高的类型信息. 每个Type对象都代表着一个java类型, 我们可以通过类型描述符或者Class对象中构建出一个Type对象. 另外Type中还包含一些静态成员属性用于表示原生类型, 例如e Type.INT_TYPE就表示int类型. getInternalName方法用于获取类型的全限定名, 例如Type.getType(String.class).getInternalName()我们会得到一个&quot;java/lang/String&quot;.值, 需要注意的是这个方法只能用在class或者interface类型上. getDescriptor方法返回一个类型的描述符. 例如&quot;Ljava/lang/String;&quot;代表一个字符串类型, 但是我们可以在代码中使用Type.getType(String.class).getDescriptor()替代这种写法, 来换取更高的可读性. Type对象还可以表示一个方法类型. 方法类型的Type对象可以通过方法描述符或者Method对象构建出来. 同样的除了我们可以使用getDescriptor方法外,还可以使用getArgumentTypes和getReturnType来获取方法的参数或者返回值类型. 例如Type.getArgumentTypes(&quot;(I)V&quot;)和Type.getReturnType(&quot;(I)V&quot;)来获得更好的可读性. TraceClassVisitor我们使用ClassWriter生成的新的class字节码是一个byte数组, 这种东西根本不具有可读性,因此ASM为我们提供了TraceClassVisitor, 它同样是继承自ClassVisitor, 他会输出一个文本格式的可读的新的类出来. 下面的例子中我们同时使用了ClassWriter和TraceClassVisitor, TraceClassVisitor代理了ClassWriter的全部方法调用 123456ClassWriter cw = new ClassWriter(0);TraceClassVisitor cv = new TraceClassVisitor(cw, printWriter);cv.visit(...);...cv.visitEnd();byte b[] = cw.toByteArray(); CheckClassAdapterClassWriter并不会检查生成的方法在调用的时候是顺序且参数是否都是正确的. 因此当JVM加载类进行验证的时候可能会抛出异常. 因此当我们秉持着错误越早发现越好, ASM为我们提供了CheckClassAdapter, 这个工具类会为我们检查上述问题. 同样的CheckClassAdapter继承自ClassWriter., 它可以代理TraceClassVisitor或者ClassWriter的全部方法. 下面我们给出一个示例 1234567ClassWriter cw = new ClassWriter(0);TraceClassVisitor tcv = new TraceClassVisitor(cw, printWriter);CheckClassAdapter cv = new CheckClassAdapter(tcv);cv.visit(...);...cv.visitEnd();byte b[] = cw.toByteArray(); 注意, 我们要确定visitor之间的顺序关系, 如下 123ClassWriter cw = new ClassWriter(0);CheckClassAdapter cca = new CheckClassAdapter(cw);TraceClassVisitor cv = new TraceClassVisitor(cca, printWriter); 上面的例子是先进行文本输出然后再进行方法检查, 这是因为相当于TraceClassVisitor最终代理了所有的方法调用","categories":[{"name":"ASM","slug":"ASM","permalink":"https://wangmingco.github.io/categories/ASM/"}],"tags":[{"name":"asm","slug":"asm","permalink":"https://wangmingco.github.io/tags/asm/"}]},{"title":"ASM Core(3) Methods","slug":"JavaLibrary/ASM Core(3) Methods","date":"2016-01-12T16:00:00.000Z","updated":"2021-11-18T02:51:27.615Z","comments":true,"path":"2016/01/13/JavaLibrary/ASM Core(3) Methods/","link":"","permalink":"https://wangmingco.github.io/2016/01/13/JavaLibrary/ASM%20Core(3)%20Methods/","excerpt":"","text":"asm4-guide学习心得 本文主要是讲述如何通过ASM CORE API来生成和转换编译好的方法. 执行模型在讲解字节码结构之前我们要首先讲解一下JVM的执行模型. java代码都是在线程中执行. 每一个线程都有它自己执行栈, 每个执行栈都是由N个栈帧组成. 每个栈帧都代表着一个方法调用, 每当我们调用一个方法的时候, 就会向当前执行栈(活动线程)中push一个栈帧. 当方法结束(return或者抛出异常)时就会将当前栈帧出栈. 然后继续调用下一个方法. 每一个栈帧都有俩部分组成 local variables 本地变量 operand stack 操作数栈 我们通过索引来访问local variables. operand stack存储的是操作数, 正如其名, 它也是一个栈结构, 因此我们通过Last In First Out对其进行访问. local variables和 operand stack的大小取决于方法的大小. 这些大小是在编译期进行计算, 而且也是进行单独存储的.","categories":[{"name":"ASM","slug":"ASM","permalink":"https://wangmingco.github.io/categories/ASM/"}],"tags":[{"name":"asm","slug":"asm","permalink":"https://wangmingco.github.io/tags/asm/"}]},{"title":"ASM Core(2) Class的增删改查","slug":"JavaLibrary/ASM Core(2) 操作","date":"2016-01-11T16:00:00.000Z","updated":"2021-11-18T02:51:29.628Z","comments":true,"path":"2016/01/12/JavaLibrary/ASM Core(2) 操作/","link":"","permalink":"https://wangmingco.github.io/2016/01/12/JavaLibrary/ASM%20Core(2)%20%E6%93%8D%E4%BD%9C/","excerpt":"","text":"asm4-guide学习心得 获取class信息下来的示例中我们通过重写ClassVisitor相关函数然后依次打印出类型信息, 字段信息和函数信息. 123456789101112131415161718192021222324252627282930class ClassPrinter extends ClassVisitor &#123; public ClassPrinter() &#123; super(Opcodes.ASM4); &#125; public void visit(int version, int access, String name, String signature, String superName, String[] interfaces) &#123; System.out.println(name + &quot; extends &quot; + superName + &quot; &#123;&quot;); &#125; public void visitSource(String source, String debug) &#123; &#125; public void visitOuterClass(String owner, String name, String desc) &#123; &#125; public AnnotationVisitor visitAnnotation(String desc, boolean visible) &#123; return null; &#125; public void visitAttribute(Attribute attr) &#123; &#125; public void visitInnerClass(String name, String outerName, String innerName, int access) &#123; &#125; public FieldVisitor visitField(int access, String name, String desc, String signature, Object value) &#123; System.out.println(&quot; &quot; + desc + &quot; &quot; + name); return null; &#125; public MethodVisitor visitMethod(int access, String name, String desc, String signature, String[] exceptions) &#123; System.out.println(&quot; &quot; + name + desc); return null; &#125; public void visitEnd() &#123; System.out.println(&quot;&#125;&quot;); &#125;&#125; 然后我们写一段运行代码 123456789public class Test &#123; public static void main(String[] args) throws IOException &#123; // 读取解析二进制字节流 ClassReader cr = new ClassReader(&quot;Test&quot;); ClassPrinter cp = new ClassPrinter(); // 开始处理字节流信息 cr.accept(cp, 0); &#125;&#125; 结果为 123456Test extends java/lang/Object &#123; &lt;init&gt;()V main([Ljava/lang/String;)V lambda$main$22(Ljava/lang/Integer;)V lambda$main$21(Ljava/lang/Integer;Ljava/lang/Integer;)I&#125; 在测试代码中我们首先创建了一个ClassReader实例用于读取Test字节码. 然后由accept()方法依次调用ClassPrinter的方法 动态生成Class我们仅仅使用ClassWriter就可以生成一个类, 例如我们要生成一个如下的接口 1234567package pkg;public interface Comparable extends Mesurable &#123; int LESS = -1; int EQUAL = 0; int GREATER = 1; int compareTo(Object o);&#125; 我们仅仅需要调用ClassVisitor的六个方法 12345678910111213141516171819202122232425262728293031public class Test &#123; public static void main(String[] args) throws IOException &#123; ClassWriter cw = new ClassWriter(0); cw.visit(V1_8, // 指定class文件版本号, 我们将其设置为java8 ACC_PUBLIC + ACC_ABSTRACT + ACC_INTERFACE, // 设置接口的修饰符, 需要指出的是由于interface是不可实例化的, // 因此我们将其设置为ACC_ABSTRACT的 &quot;pkg/Comparable&quot;, // 我们设置classname, 需要在这里指定全限定名 null, // 设置泛型信息, 因为我们的接口是非泛化的, 因此我们将其设置为null &quot;java/lang/Object&quot;, // 设置父类, 同时需要设定全限定名 new String[] &#123; &quot;pkg/Mesurable&quot; &#125;); // 设置接口, 同样需要设置全限定名 cw.visitField( ACC_PUBLIC + ACC_FINAL + ACC_STATIC, // 设置字段的修饰符 &quot;LESS&quot;, // 设置字段名 &quot;I&quot;, // 设置字段类型 null, // 设置泛型信息 new Integer(-1)) // 设置字面量值. (如果这个字段是常量值的话,例如 final static, // 那么我们就必须设置这个值) .visitEnd(); cw.visitMethod(ACC_PUBLIC + ACC_ABSTRACT, // 设置字段的修饰符 &quot;compareTo&quot;, // 设置方法名 &quot;(Ljava/lang/Object;)I&quot;, // 设置返回值类型 null, // 设置泛型信息 null) // 设置异常信息 .visitEnd(); cw.visitEnd(); byte[] b = cw.toByteArray(); &#125;&#125; 使用生成的类记下来我们自定义一个ClassLoader来加载生成的字节码 12345class MyClassLoader extends ClassLoader &#123; public Class defineClass(String name, byte[] b) &#123; return defineClass(name, b, 0, b.length); &#125;&#125; 然后使用它 123byte[] bytes = genComparableInterface();MyClassLoader myClassLoader = new MyClassLoader();Class c = myClassLoader.defineClass(&quot;pkg.Comparable&quot;, bytes); 我们直接使用defineClass函数来加载这个类. 另外我们还可以重写findClass这个函数来动态的生成我们所需要的类 123456789101112class StubClassLoader extends ClassLoader &#123; @Override protected Class findClass(String name) throws ClassNotFoundException &#123; if (name.endsWith(&quot;_Stub&quot;)) &#123; ClassWriter cw = new ClassWriter(0); ... byte[] b = cw.toByteArray(); return defineClass(name, b, 0, b.length); &#125; return super.findClass(name); &#125;&#125; 修改已存在的Class在上篇文章中我们只是单独的使用了ClassReader和ClassWriter,但是更多的应用其实应该是将其组合到一起使用 12345byte[] b1 = ...;ClassWriter cw = new ClassWriter(0);ClassReader cr = new ClassReader(b1);cr.accept(cw, 0);byte[] b2 = cw.toByteArray(); // b2 represents the same class as b1 这个例子中我们什么都没有做, 只不过完成了一个copy字节码的功能, 接下来我们在这俩个过程中加入ClassVisitor 1234567byte[] b1 = ...;ClassWriter cw = new ClassWriter(0);// cv forwards all events to cwClassVisitor cv = new ClassVisitor(ASM4, cw) &#123; &#125;;ClassReader cr = new ClassReader(b1);cr.accept(cv, 0);byte[] b2 = cw.toByteArray(); // b2 represents the same class as b1 这段代码的处理流程如下图 方框代表我们的核心组件, 箭头代表我们的数据流. 下面我们给出一个ClassVisitor小例子 1234567891011121314151617class ChangeVersionAdapter extends ClassVisitor &#123; public ChangeVersionAdapter(ClassVisitor cv) &#123; // ASM4为ASM的版本号 super(ASM4, cv); &#125; @Override public void visit(int version, int access, String name, String signature, String superName, String[] interfaces) &#123; // 修改class信息 cv.visit(V1_5, // 改变class的版本号 access, // 改变class的标识符 name, // 改变类名 signature, // 泛型信息 superName, // 父类信息 interfaces); // 接口信息 &#125;&#125; 在上面的实现中,除了调用visit函数(修改类本身函数, 将class版本号转化为1.5), 其他的方法都没有重写,因此他们什么改变都不会做. 下来我们给出这个类执行的时序图从这个时序图中我们可以看出, 用户调用了accept方法之后, 有ASM自动调用ClassReader的visti(version)方法, 接着调用ChangeVersionAdapter的visti(1.5)方法, 最后调用ClassWriter的相关方法. 从这个模式中我们可以看出, ASM的调用模式是链式调用的, 先调用visit, 然后调用责任链中所有的ClassVisitor的vist最后调用ClassWriter的完结方法. 当visit调用完之后再调用visitSource责任链流程, 依次类推下去. 优化在上述的代码中, 其实代码的运行效率并不是高效进行的. 这是因为当b1字节码被ClassReader读取并通过ClassVisitor将其执行转换的时候, 我们可能只改变了class的版本号, 其他部分并没有转换, 但是在实际的执行中其他的部分也都被执行了一边, 那这就浪费了cpu计算和内存空间的占用, 其实只需要将不需要改变的字节从b1直接拷贝到b2就好了. 好在ASM为我们内部构建了这种优化过程.* 删除成员如果我们想将class中的某个成员删除掉, 那么只需在执行asm责任链调用时, 中断调用过程(不调用super或者直接return)就可以了. 例如我们下面的例子我们将类中的内部类和外部类以及编译成该class的源文件信息删除掉 1234567891011121314class RemoveDebugAdapter extends ClassVisitor &#123; public RemoveDebugAdapter(ClassVisitor cv) &#123; super(ASM4, cv); &#125; @Override public void visitSource(String source, String debug) &#123; &#125; @Override public void visitOuterClass(String owner, String name, String desc) &#123; &#125; @Override public void visitInnerClass(String name, String outerName, String innerName, int access) &#123; &#125;&#125; 看,就是如此简单, 我们在这三个方法内部什么都不做(不进行super调用)就轻松地完成了我们需要的功能, 但是这种做法却并不适合字段和方法的删除, 因为在字段和方法的删除中除了不进行super调用之外还需要return null, 如下: 12345678910111213141516171819class RemoveMethodAdapter extends ClassVisitor &#123; private String mName; private String mDesc; public RemoveMethodAdapter( ClassVisitor cv, String mName, String mDesc) &#123; super(ASM4, cv); this.mName = mName; this.mDesc = mDesc; &#125; @Override public MethodVisitor visitMethod(int access, String name, String desc, String signature, String[] exceptions) &#123; if (name.equals(mName) &amp;&amp; desc.equals(mDesc)) &#123; // do not delegate to next visitor -&gt; this removes the method return null; &#125; return cv.visitMethod(access, name, desc, signature, exceptions); &#125;&#125; 添加成员当我们中断方法调用的时候,会删除成员. 但是当我们在责任链中的原生方法调用(visitXxx方法)中新增加一些方法调用的话, 会增加成员. 例如如果你想要增加一个字段, 那么你必须在visitXxx方法中增加一个visitField方法调用. 需要注意的是visitXxx方法只包含visitInnerClass,visitField, visitMethod,visitEnd这四个方法, 这是因为visit,visitSource,visitOuterClass,visitAnnotation,visitAttribute 这些方法正如我们在第一篇文章中给出那些顺序一样, visitField方法只能在这些方法之后调用. 需要注意的是,由于visitInnerClass,visitField, visitMethod这些方法会进行多次调用, 因此有可能会添加N个相同的成员, 因此我们建议在visitEnd的时候进行成员添加, 这是因为这个方法总会有且只有一次调用. 如下例 1234567891011121314151617181920212223242526272829class AddFieldAdapter extends ClassVisitor &#123; private int fAcc; private String fName; private String fDesc; private boolean isFieldPresent; public AddFieldAdapter(ClassVisitor cv, int fAcc, String fName, String fDesc) &#123; super(ASM4, cv); this.fAcc = fAcc; this.fName = fName; this.fDesc = fDesc; &#125; @Override public FieldVisitor visitField(int access, String name, String desc, String signature, Object value) &#123; if (name.equals(fName)) &#123; isFieldPresent = true; &#125; return cv.visitField(access, name, desc, signature, value); &#125; @Override public void visitEnd() &#123; if (!isFieldPresent) &#123; FieldVisitor fv = cv.visitField(fAcc, fName, fDesc, null, null); if (fv != null) &#123; fv.visitEnd(); &#125; &#125; cv.visitEnd(); &#125;&#125;","categories":[{"name":"ASM","slug":"ASM","permalink":"https://wangmingco.github.io/categories/ASM/"}],"tags":[{"name":"asm","slug":"asm","permalink":"https://wangmingco.github.io/tags/asm/"}]},{"title":"ASM Core(1) 初探","slug":"JavaLibrary/ASM Core(1) 初探","date":"2016-01-10T16:00:00.000Z","updated":"2021-11-18T02:51:28.628Z","comments":true,"path":"2016/01/11/JavaLibrary/ASM Core(1) 初探/","link":"","permalink":"https://wangmingco.github.io/2016/01/11/JavaLibrary/ASM%20Core(1)%20%E5%88%9D%E6%8E%A2/","excerpt":"","text":"asm4-guide学习心得 ASM是一种小巧轻便的 Java 字节码操控框架，它能方便地生成和改造 Java 代码 ASM通过ClassVisitor来生成和转换class字节码. ClassVisitor中的每个方法都对应着class数据结构, 你可以通过每个方法名轻松的判断出这个方法对应的是哪个数据结构. ClassVisitor内的方法调用顺序如下: visit : 调用visit方法(有且仅有调用一次) visitSource? : 调用visitSource函数(最多调用一次) visitOuterClass? : 调用visitOuterClass函数(最多调用一次) ( visitAnnotation | visitAttribute )* : 调用visitAnnotation和visitAttribute函数, 这俩个函数的调用可调用任意次且不分前后顺序 ( visitInnerClass | visitField | visitMethod )* : 调用visitInnerClass,visitField和visitMethod函数, 同样对这三个函数的调用不限制次数以及不分前后顺序 visitEnd : 调用visitEnd函数(有且仅有调用一次),调用这个函数用于结束整个过程. ASM通过基于ClassVisitor的三个API来生成和转换class字节码 ClassReader: 用于解析一个给定的class二进制字节数组, 然后按照上文介绍的顺序依次调用accept()的ClassVisitor参数的方法. ClassWriter : 一个ClassVisitor的子类, 用于直接生成二进制的字节码. ClassVisitor : 代理了全部的字节码相关的方法调用. 它接收另一个ClassVisitor对象形成责任链模式调用. 我们通过ClassReader来解析一个二进制的class结构数据, 然后ClassReader按照一定的顺序调用ClassVisitor 来改变class结构数据, 最后通过ClassVisitor生成新的class二进制数据.","categories":[{"name":"ASM","slug":"ASM","permalink":"https://wangmingco.github.io/categories/ASM/"}],"tags":[{"name":"asm","slug":"asm","permalink":"https://wangmingco.github.io/tags/asm/"}]},{"title":"PHP 语法初探","slug":"编程语言/PHP 语法初探","date":"2015-12-15T16:00:00.000Z","updated":"2021-11-18T02:28:39.731Z","comments":true,"path":"2015/12/16/编程语言/PHP 语法初探/","link":"","permalink":"https://wangmingco.github.io/2015/12/16/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/PHP%20%E8%AF%AD%E6%B3%95%E5%88%9D%E6%8E%A2/","excerpt":"","text":"PHP 脚本以 &lt;?php 开头，以 ?&gt; 结尾： 123&lt;?php// 此处是 PHP 代码?&gt; 变量123456&lt;?php// 定义一个变量$x=5;// 调用echo函数输出变量x的值echo $x;?&gt; PHP 有三种不同的变量作用域： local : 函数里定义的变量,只能在函数内部访问,函数外部不可访问 global: 函数外部定义的变量,只能在函数外部访问,函数内部不可访问 static: 当变量脱离它的作用域之后,并不会被删除掉,而是缓存起来 1234567891011121314&lt;?php$x=5; // 全局作用域function socpePrint() &#123; $y=10; // 局部作用域 echo $y; echo $x;&#125; myTest();echo $y;echo $x;?&gt; 刚才我们只是介绍了global这个作用域,其实还有global关键字,这个关键字是在函数内部定义一个全局变量,让函数外访问函数内部的变量 12345678&lt;?phpfunction socpePrint() &#123; global $x=10;&#125;socpePrint();echo $x;?&gt; php里有如下的数据类型 字符串 整数 浮点数 逻辑 数组 对象 NULL1234567&lt;?php$stringVar=&quot;this is a string&quot;; // 定义一个字符串$numVar=10; // 定义一个整数$floatVar=1.0; // 定义一个浮点数$boolVar=true; // 定义一个布尔值$arrayVar=array(1,2); // 定义一个数组?&gt; 数组相关操作 123456&lt;?php$arrayVar=array(1,2); // 定义一个数组$ele1=$arrayVar[0]; // 访问数组第一个元素$arrayCount=count($arrayVar); // 求数组长度$arrayVar[2]=3; // 向数组中追加元素?&gt; 函数下面我们定义了一个求和函数, 这个函数定义了俩个参数x, y, 其中y是一个默认参数,它有一个默认值, 最后我们还定义了一个函数返回值. 12345678&lt;?phpfunction sum($x,$y=5) &#123; $z=$x+$y; return $z;&#125;echo sum(5,10);?&gt; 常量函数在php中,我们如果想要定义一个常量,则必须使用常量函数define() 1234&lt;?phpdefine(&quot;constant&quot;, &quot;I am constant&quot;, true);echo CONSTANT;?&gt; 最后一个参数是一个可选参数,如果设置为true,则说明访问常量的时候是不区分大小写的. 访问常量则不需要$符号 日期函数我们使用date(format,timestamp)函数来获得系统的时间, 第二个参数是可选的,如果不填则是当前时间. 第一个参数则是格式化时间戳的格式, 有如下选项 d - 表示月里的某天（01-31） m - 表示月（01-12） Y - 表示年（四位数） 1 - 表示周里的某天 h - 带有首位零的 12 小时小时格式 i - 带有首位零的分钟 s - 带有首位零的秒（00 -59） a - 小写的午前和午后（am 或 pm）12345&lt;?php $now = date(&quot;Y-m-d h:i:sa&quot;);echo $now;?&gt; 流程控制if else123456789&lt;?phpdefine(&quot;TEN&quot;, 10);if (TEN&lt;&quot;20&quot;) &#123; echo &quot;10 &lt; 20&quot;;&#125; else &#123; echo &quot;ERROR&quot;;&#125;?&gt; 如果还有其他条件的话我们可以采用 1234567891011&lt;?phpdefine(&quot;TEN&quot;, 10);if (TEN&lt;20) &#123; echo &quot;10 &lt; 20&quot;;&#125; elseif (TEN==20) &#123; echo &quot;ERROR&quot;;&#125; else &#123; echo &quot;ERROR&quot;;&#125;?&gt; switch12345678910111213&lt;?phpswitch ($x)&#123;case 1: echo &quot;Number 1&quot;; break;case 2: echo &quot;Number 2&quot;; break;default: echo &quot;No number between 1 and 3&quot;;&#125;?&gt; while1234567&lt;?php $x=1; while($x&lt;=5) &#123; echo &quot;这个数字是：$x &lt;br&gt;&quot;; $x++;&#125; ?&gt; for12345&lt;?php for ($x=0; $x&lt;=10; $x++) &#123; echo $x;&#125; ?&gt; 另外还有一种适用于数组的foreach 1234567&lt;?php $colors = array(&quot;red&quot;,&quot;green&quot;,&quot;blue&quot;,&quot;yellow&quot;); foreach ($colors as $value) &#123; echo &quot;$value&quot;;&#125;?&gt; 如果我们遍历数组的时候,数组的元素是一个键值对的话, 我们可以这样处理&lt;?php$colors = array(“red:555”,”green:123”,”blue:856”); foreach ($colors as $colerKey =&gt; $colorValue) { echo “$colerKey is $colorValue”;}?&gt; 12345678910111213141516`=&gt;`就表示一个键值对## 文件我们使用`fopen(fileName, openMode)`函数打开文件, 第一个参数是文件名, 第二个参数打开模式* `r`: 打开文件为只读。文件指针在文件的开头开始。* `w`: 打开文件为只写。删除文件的内容或创建一个新的文件，如果它不存在。文件指针在文件的开头开始。* `a`: 打开文件为只写。文件中的现有数据会被保留。文件指针在文件结尾开始。创建新的文件，如果文件不存在。* `x`: 创建新文件为只写。返回 FALSE 和错误，如果文件已存在。* `r+`: 打开文件为读/写、文件指针在文件开头开始。* `w+`: 打开文件为读/写。删除文件内容或创建新文件，如果它不存在。文件指针在文件开头开始。* `a+`: 打开文件为读/写。文件中已有的数据会被保留。文件指针在文件结尾开始。创建新文件，如果它不存在。* `x+`: 创建新文件为读/写。返回 FALSE 和错误，如果文件已存在。```php&lt;?php$demofile = fopen(&quot;demo.txt&quot;, &quot;r&quot;) or die(&quot;Unable to open file!&quot;);?&gt; 读取文件内容, fread()函数会读取整个文件内容 1234&lt;?php $demofile = fopen(&quot;demo.txt&quot;, &quot;r&quot;) or die(&quot;Unable to open file!&quot;);fread($demofile,filesize(&quot;demo.txt&quot;));?&gt; 按行读取 1234567&lt;?php$demofile = fopen(&quot;demo.txt&quot;, &quot;r&quot;) or die(&quot;Unable to open file!&quot;);while(!feof($demofile)) &#123; // 如果文件没有到达结尾的话,则继续读取 echo fgets($demofile); // 读取一行&#125;fclose($myfile); // 关闭文件?&gt; 向文件中写入数据 12345&lt;?php $demofile = fopen(&quot;demo.txt&quot;, &quot;w&quot;) or die(&quot;Unable to open file!&quot;);fwrite($demofile, &quot;hello world&quot;);fclose($myfile);?&gt; mysql建立连接 12345678910111213141516171819202122&lt;?php // 建立mysql连接$con = mysql_connect(&quot;localhost&quot;,&quot;root&quot;,&quot;root&quot;);if (!$con) &#123; die(&#x27;Could not connect: &#x27; . mysql_error());&#125;// 选择数据库mysql_select_db(&quot;my_db&quot;, $con);// 执行sql语句$result = mysql_query(&quot;SELECT * FROM Persons&quot;);// 遍历结果while($row = mysql_fetch_array($result)) &#123; // 输出某个列元素 echo $row[&#x27;FirstName&#x27;];&#125;// 关闭连接mysql_close($con);?&gt;","categories":[{"name":"PHP","slug":"PHP","permalink":"https://wangmingco.github.io/categories/PHP/"}],"tags":[]},{"title":"Lombok 初探","slug":"JavaLibrary/lombok","date":"2015-12-08T16:00:00.000Z","updated":"2021-11-18T02:48:18.672Z","comments":true,"path":"2015/12/09/JavaLibrary/lombok/","link":"","permalink":"https://wangmingco.github.io/2015/12/09/JavaLibrary/lombok/","excerpt":"","text":"参考文档lombok在使用lombok的时候, 我们需要在IDE上安装上lombok插件以及引用相关的jar包依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.6&lt;/version&gt;&lt;/dependency&gt; lombok其实帮我们做的事情是, 在编译java源码的时候,会根据相关注解编译出相关的代码. 例如如果我们使用@Setter注解的话,那么在编译的会在class文件中添加相应的setter代码 val下来我们看一个小例子 1234val example = new ArrayList&lt;String&gt;();example.add(&quot;Hello, World!&quot;);val foo = example.get(0);System.out.println(foo.equals(&quot;Hello, World!&quot;)); 上面这个例子我们使用val代替了ArrayList类型. 插件会只能地帮我们识别出这个真正的类型是什么. 注意, new ArrayList&lt;String&gt;()菱形符里应该指定类型,否则我们既可以在example上添加String又可以添加int,会带来类型上的不安全 NonNull123456789public class TestNonNull &#123; public static void main(String[] args) &#123; print(null); &#125; public static void print(@NonNull String content) &#123; System.out.println(content); &#125;&#125; 这个注解很简单就是检查参数非null,如果传进的参数为null的就抛出 123Exception in thread &quot;main&quot; java.lang.NullPointerException: content at Lombok.TestNonNull.print(TestNonNull.java:13) at Lombok.TestNonNull.main(TestNonNull.java:10) Cleanup这个注解会在资源在其作用域离开之后,自动将资源关闭掉 1@Cleanup BufferedReader fileReader1 = new BufferedReader(new FileReader(&quot;D://hazelcast-documentation-3.5.3.pdf&quot;)); Getter Setter12345678910111213141516public class TestGetterSetter &#123; public static void main(String[] args) &#123; A a = new A(); a.getA2(); a.getA3(); a.setA1(&quot;a1&quot;); a.setA3(&quot;a3&quot;); &#125;&#125;class A &#123; @Setter private String a1; @Getter private String a2; @Setter @Getter private String a3;&#125; @Getter和@Setter注解有一点需要说明的是,我们可以指定他们的访问级别 1@Setter(value = AccessLevel.MODULE) private String a1; 可设置的级别有: PUBLIC, MODULE, PROTECTED, PACKAGE, PRIVATE, NONE; ToString@ToString注解既可以用在类上可以用在方法上, 这个注解会修改类的toString()方法 1234567891011121314151617181920212223242526public class TestToString &#123; public static void main(String[] args) &#123; C c = new C(); c.c1 = &quot;c_1&quot;; c.c2 = &quot;c_2&quot;; c.b1 = &quot;b_1&quot;; c.b2 = &quot;b_2&quot;; System.out.println(c); &#125;&#125;// toString()中不包含b1和b2这俩个属性@ToString(exclude=&#123;&quot;b1&quot;, &quot;b2&quot;&#125;)class B &#123; public String b1; public String b2; public String b3;&#125;// 调用父类的toString和在输出时包含字段名称@ToString(callSuper=true, includeFieldNames = true)class C extends B &#123; public String c1; public String c2;&#125; 上面代码输出为 123C(super=B(b2=null), c1=null, c2=null)B(b2=null)C(super=B(b2=b_2), c1=c_1, c2=c_2) EqualsAndHashCode这个注解人如其名, 会为我们生成俩个规范的equals()和hashCode()方法, 至于什么是规范的,参考Effective java这本书 1234@EqualsAndHashCodeclass D &#123;&#125; Data@Data注解是@ToString, @EqualsAndHashCode, @Getter / @Setter and @RequiredArgsConstructor 这些注解的一个集合. 它会默认地为我们使用那些注解. 1234567@Data class Simple &#123; private int id; public void init() &#123; setId(123); &#125;&#125; Value@Value是@Data注解的一个变种, 它是在@Data注解的基础将,将类成为不可变的. 123@Value class E &#123;&#125; Builder@Builder将类修改成Builder模式(同样参考Effective Java). 12345678910111213141516171819202122232425public class TestBuilder &#123; public static void main(String[] args) &#123; F f = F.builder().f1(&quot;fff&quot;).fAB(123).build(); System.out.println(f.getF1()); System.out.println(f.getFABs().size()); G g = G.GBuilder().buildG(); &#125;&#125;@Builder class F &#123; @Getter private String f1; @Singular @Getter private Set&lt;Integer&gt; fABs; @Singular @Getter private Set&lt;Integer&gt; fAsBs;&#125;@Builder(builderClassName = &quot;GBuilder&quot;, buildMethodName = &quot;buildG&quot;, builderMethodName = &quot;GBuilder&quot;)class G &#123; public static void printG() &#123; System.out.println(&quot;GGG&quot;); &#125;&#125; 使用@Singular注解的集合属性名必须使用s结尾, lombok会将属性名结尾的s去掉,剩余的名字会作为方法名, 向这个集合中添加元素","categories":[{"name":"Java 类库","slug":"Java-类库","permalink":"https://wangmingco.github.io/categories/Java-%E7%B1%BB%E5%BA%93/"}],"tags":[{"name":"Lombok","slug":"Lombok","permalink":"https://wangmingco.github.io/tags/Lombok/"}]},{"title":"Guice Mybatis 使用笔记","slug":"JavaLibrary/mybatis-guice","date":"2015-12-08T16:00:00.000Z","updated":"2021-11-18T02:48:38.000Z","comments":true,"path":"2015/12/09/JavaLibrary/mybatis-guice/","link":"","permalink":"https://wangmingco.github.io/2015/12/09/JavaLibrary/mybatis-guice/","excerpt":"","text":"参考文档mybatis-guice mybatis-guice需要依赖 1234567891011121314151617181920212223242526&lt;dependency&gt; &lt;groupId&gt;com.google.inject&lt;/groupId&gt; &lt;artifactId&gt;guice&lt;/artifactId&gt; &lt;version&gt;4.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-guice&lt;/artifactId&gt; &lt;version&gt;3.7&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.2.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.google.inject.extensions&lt;/groupId&gt; &lt;artifactId&gt;guice-multibindings&lt;/artifactId&gt; &lt;version&gt;4.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.37&lt;/version&gt;&lt;/dependency&gt;&lt;/dependencies&gt; 表结构 1234CREATE TABLE `user` ( `userId` varchar(100) DEFAULT NULL, `name` varchar(100) DEFAULT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf8 我们首先定义使用到的model类和mapper类 123456789class User &#123; public String userId; public String name;&#125;interface UserMapper &#123; @Select(&quot;SELECT * FROM user WHERE userId = #&#123;userId&#125;&quot;) User getUser(@Param(&quot;userId&quot;) String userId);&#125; 然后我们实现Guice对Mybatis的注解管理 12345678910111213141516171819202122232425262728293031323334353637383940414243class MySqlManager &#123; private static final Injector injector; static &#123; injector = Guice.createInjector(JdbcHelper.MySQL, new MysqlModule()); &#125; private MySqlManager() &#123; &#125; public static &lt;T&gt; T getInstance(Class&lt;T&gt; var1) &#123; return injector.getInstance(var1); &#125; private static class MysqlModule extends MyBatisModule &#123; @Override protected void initialize() &#123; bindDataSourceProviderType(PooledDataSourceProvider.class); bindTransactionFactoryType(JdbcTransactionFactory.class); Names.bindProperties(binder(), createUnpooledProperties()); addMapperClass(); &#125; // 添加映射类 private void addMapperClass() &#123; addMapperClass(UserMapper.class); &#125; private Properties createUnpooledProperties() &#123; Properties myBatisProperties = new Properties(); myBatisProperties.setProperty(&quot;mybatis.environment.id&quot;, &quot;test&quot;); myBatisProperties.setProperty(&quot;JDBC.schema&quot;, &quot;test&quot;);// myBatisProperties.setProperty(&quot;JDBC.url&quot;, &quot;localhost&quot;);// myBatisProperties.setProperty(&quot;JDBC.driver&quot;, &quot;&quot;); myBatisProperties.setProperty(&quot;JDBC.username&quot;, &quot;root&quot;); myBatisProperties.setProperty(&quot;JDBC.password&quot;, &quot;root&quot;); myBatisProperties.setProperty(&quot;JDBC.loginTimeout&quot;, &quot;10&quot;); myBatisProperties.setProperty(&quot;JDBC.autoCommit&quot;, &quot;false&quot;); myBatisProperties.setProperty(&quot;derby.create&quot;, &quot;true&quot;); return myBatisProperties; &#125; &#125;&#125; 然后我们写一个测试类 123456789101112public class GettingStarted &#123; public static void main(String[] args) &#123; UserMapper user = MySqlManager.getInstance(UserMapper.class); User user1 = user.getUser(&quot;1&quot;); System.out.println(user1.name); UserMapper userMapper = new UserMapper(); injector.injectMembers(userMapper); System.out.println(userMapper.name); &#125;&#125; MyBatisModule还为我们提供了下述功能的接口 添加自己的拦截器 : addInterceptorClass(MySqlInterceptor.class); 添加自己的类型转换器 : handleType() 添加别名 : addSimpleAlias(User.class);或者addAlias(&quot;AUser&quot;).to(User.class); 开启事务我们在FooServiceMapperImpl中还能定义开启事务 12345678910// 开启事务@Transactional( executorType = ExecutorType.BATCH, isolation = Isolation.READ_UNCOMMITTED,// rethrowExceptionsAs = MyDaoException.class, exceptionMessage = &quot;Something went wrong&quot;)public User getUser(String userId) &#123; return this.userMapper.getUser(userId);&#125; 定义自己的连接池12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455private void addPooledProperties(Binder binder) &#123; // 连接池并发访问数据的连接数, 默认为10 binder.bindConstant().annotatedWith(Names.named(&quot;mybatis.pooled.maximumActiveConnections&quot;)).to(10); // 在被强制返回之前，池中连接被检查的时间 binder.bindConstant().annotatedWith(Names.named(&quot;mybatis.pooled.maximumCheckoutTime&quot;)).to(20000); // 连接池里空闲连接数, 默认为5 binder.bindConstant().annotatedWith(Names.named(&quot;mybatis.pooled.maximumIdleConnections&quot;)).to(5); // 由于数据库会检查连接达到8小时(默认值)闲置会单方面断开连接, 而客户端如果继续使用已经断开的连接,则会产生异常. // mybatis里内带了ping机制, 设置该值为true的话, 就开启了ping机制 binder.bindConstant().annotatedWith(Names.named(&quot;mybatis.pooled.pingEnabled&quot;)).to(false); // 设置空闲连接ping时间间隔, 如果超时就进行ping,查看连接是否有效 binder.bindConstant().annotatedWith(Names.named(&quot;mybatis.pooled.pingConnectionsNotUsedFor&quot;)).to(3600000); // 执行ping时执行的语句 // binder.bindConstant().annotatedWith(Names.named(&quot;mybatis.pooled.pingQuery&quot;)).to(&quot;&quot;); // 这是一个低层设置，如果获取连接花费的相当长的时间，它会给连接池打印日志并重新尝试获取一个连接的机会（避免在误配置的情况下一直安静的失败），默认值：20000 毫秒（即 20 秒）。 binder.bindConstant().annotatedWith(Names.named(&quot;mybatis.pooled.timeToWait&quot;)).to(0);&#125;private void addC3P0Properties(Binder binder) &#123; // 当连接池中的的连接耗尽的时候c3p0一次同时获取的连接数，但是池中最大数不会超过maxPoolSize binder.bindConstant().annotatedWith(Names.named(&quot;c3p0.acquireIncrement&quot;)).to(1); // 从数据库请求连接失败之后,尝试的次数 binder.bindConstant().annotatedWith(Names.named(&quot;c3p0.acquireRetryAttempts&quot;)).to(1); // 连接池耗尽, 连续获得俩个连接直接的间隔时间. 单位ms binder.bindConstant().annotatedWith(Names.named(&quot;c3p0.acquireRetryDelay&quot;)).to(1000); binder.bindConstant().annotatedWith(Names.named(&quot;c3p0.automaticTestTable&quot;)).to(&quot;test&quot;); // 如果为true，则当连接获取失败时自动关闭数据源 binder.bindConstant().annotatedWith(Names.named(&quot;c3p0.breakAfterAcquireFailure&quot;)).to(false); // 连接池所有连接耗尽时,应用程序获得新的连接的等待时间. 为0则无限等待直至有其他连接释放或者创建新的连接， binder.bindConstant().annotatedWith(Names.named(&quot;c3p0.checkoutTimeout&quot;)).to(1); binder.bindConstant().annotatedWith(Names.named(&quot;c3p0.connectionCustomizerClassName&quot;)).to(1); binder.bindConstant().annotatedWith(Names.named(&quot;c3p0.connectionTesterClassName&quot;)).to(1); // 检查所有连接池中的空闲连接的时间间隔, 单位秒 binder.bindConstant().annotatedWith(Names.named(&quot;c3p0.idleConnectionTestPeriod&quot;)).to(900); // 连接池初始化时创建的连接数,default : 3 binder.bindConstant().annotatedWith(Names.named(&quot;c3p0.initialPoolSize&quot;)).to(3); binder.bindConstant().annotatedWith(Names.named(&quot;c3p0.maxAdministrativeTaskTime&quot;)).to(1); binder.bindConstant().annotatedWith(Names.named(&quot;c3p0.maxConnectionAge&quot;)).to(1); // 池中连接最大空闲时长,如果超时则断开这个连接. 单位是秒 binder.bindConstant().annotatedWith(Names.named(&quot;c3p0.maxIdleTime&quot;)).to(600); binder.bindConstant().annotatedWith(Names.named(&quot;c3p0.maxIdleTimeExcessConnections&quot;)).to(1); // 接池中拥有的最大连接数，如果获得新连接时会使连接总数超过这个值则不会再获取新连接，而是等待其他连接释放 binder.bindConstant().annotatedWith(Names.named(&quot;c3p0.maxPoolSize&quot;)).to(15); binder.bindConstant().annotatedWith(Names.named(&quot;c3p0.maxStatements&quot;)).to(1); binder.bindConstant().annotatedWith(Names.named(&quot;c3p0.maxStatementsPerConnection&quot;)).to(1); // 连接池保持的最小连接数 binder.bindConstant().annotatedWith(Names.named(&quot;c3p0.minPoolSize&quot;)).to(3); binder.bindConstant().annotatedWith(Names.named(&quot;c3p0.preferredTestQuery&quot;)).to(1); binder.bindConstant().annotatedWith(Names.named(&quot;c3p0.propertyCycle&quot;)).to(1); binder.bindConstant().annotatedWith(Names.named(&quot;c3p0.testConnectionOnCheckin&quot;)).to(1); binder.bindConstant().annotatedWith(Names.named(&quot;c3p0.testConnectionOnCheckout&quot;)).to(1); binder.bindConstant().annotatedWith(Names.named(&quot;c3p0.unreturnedConnectionTimeout&quot;)).to(1); binder.bindConstant().annotatedWith(Names.named(&quot;c3p0.usesTraditionalReflectiveProxies&quot;)).to(1);&#125; 我们还可以采用配置文件的方式设置 1234567891011121314151617181920212223242526import org.mybatis.guice.XMLMyBatisModule;import org.mybatis.guice.datasource.helper.JdbcHelper;import com.google.inject.Guice;import com.google.inject.Injector;public class MybatisManager &#123; private static Injector injector; static &#123; injector = Guice.createInjector(JdbcHelper.MySQL, new MysqlModule()); &#125; private MybatisManager() &#123; &#125; public static &lt;T&gt; T getInstance(Class&lt;T&gt; var1) &#123; return injector.getInstance(var1); &#125; private static class MysqlModule extends XMLMyBatisModule &#123; @Override protected void initialize() &#123; setClassPathResource(&quot;configuration.xml&quot;); &#125; &#125;&#125;","categories":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://wangmingco.github.io/categories/Mybatis/"}],"tags":[]},{"title":"Guice 笔记","slug":"JavaLibrary/guice","date":"2015-12-07T16:00:00.000Z","updated":"2021-11-18T02:46:52.258Z","comments":true,"path":"2015/12/08/JavaLibrary/guice/","link":"","permalink":"https://wangmingco.github.io/2015/12/08/JavaLibrary/guice/","excerpt":"","text":"示例Google Guice 是一个轻量级的依赖注入框架 在Guice的依赖注入中我们使用如下API进行注入 Binder Injector Module Guice直接看例子123456789101112131415161718public class CarModule implements Module &#123; @Override public void configure(Binder binder) &#123; binder.bind(Car.class).to(Benci.class); &#125;&#125;public interface Car &#123; public void run();&#125;public class Benci implements Car &#123; @Override public void run() &#123; System.out.println(&quot;Benci Run&quot;); &#125;&#125; 测试代码123Injector injector = Guice.createInjector(new CarModule());Car benci = injector.getInstance(Car.class);benci.run(); ImplementedBy12345678910111213141516171819202122public class LunYu implements Book &#123; @Override public String content() &#123; return &quot;Lunyu&quot;; &#125;&#125;@ImplementedBy(LunYu.class)public interface Book &#123; public String content();&#125;public class ReadBook &#123; public void readLunyu() &#123; System.out.println(book.content()); &#125; @Inject private Book book;&#125; 测试代码 123Injector intjector = Guice.createInjector();Book lunyu = intjector.getInstance(Book.class);System.out.println(lunyu.content()); Inject12345678910111213141516171819202122232425262728public class Man implements People &#123; @Override public String name() &#123; return &quot;Tom&quot;; &#125;&#125;public interface People &#123; public String name();&#125;public class PeopleModule implements Module &#123; @Override public void configure(Binder binder) &#123; binder.bind(People.class).to(Man.class); &#125;&#125;public class PrintName &#123; public void print() &#123; System.out.println(man.name()); &#125; @Inject private People man;&#125; 测试代码 123Injector intjector = Guice.createInjector(new PeopleModule());PrintName pn = intjector.getInstance(PrintName.class);pn.print(); Scopes默认的,Guice每次在getInstance()的时候都会返回一个新的对象. 12345678910111213141516171819public class TestScopes &#123; public static void main(String[] args) &#123; AbstractModule module1 = new AbstractModule() &#123; @Override protected void configure() &#123; bind(A.class); &#125; &#125;; Injector injector = Guice.createInjector(module1); A a = injector.getInstance(A.class); A b = injector.getInstance(A.class); System.out.println(a.equals(b)); &#125;&#125;class A &#123; public void print() &#123; System.out.println(&quot;A&quot;); &#125;&#125; 输出结果为false, 但是我们可以使用Singleton注解采用单例方式创建全局唯一的对象 12345678910111213141516171819202122232425public class TestSingleton &#123; public static void main(String[] args) &#123; Injector injector = Guice.createInjector(new AbstractModule() &#123; @Override protected void configure() &#123; bind(A.class).to(B.class); &#125; &#125;); A b1 = injector.getInstance(A.class); A b2 = injector.getInstance(A.class); System.out.println(b1 == b2); &#125;&#125;interface A &#123; void print();&#125;@Singletonclass B implements A &#123; @Override public void print() &#123; System.out.println(&quot;B&quot;); &#125;&#125; 输出结果为 1true 我们使用Singleton注解可以得到一个全局唯一的B实例, 每次注解B实例时, 都是同一个实例. 另外,我们还可以在绑定的时候进行设置 123456class ABCModule extends AbstractModule &#123; @Override protected void configure() &#123; bind(A.class).to(B.class).in(Singleton.class); &#125;&#125; 注入构造器注入对构造器进行注入 1234567891011121314151617181920212223242526272829303132333435363738394041public class TestInject &#123; public static void main(String[] args) &#123; Injector injector = Guice.createInjector(new AbstractModule() &#123; @Override protected void configure() &#123; // A类型的变量都使用B的实例值进行注入. 也就是说当我们对A类型的变量注入值的时候, 其实注入的是B类型 // B一定要继承A或者实现A接口 bind(A.class).to(B.class); &#125; &#125;); Print print = injector.getInstance(Print.class); print.print(); &#125;&#125;class A &#123; void print() &#123; System.out.println(&quot;A&quot;); &#125;&#125;class B extends A&#123; @Override public void print() &#123; System.out.println(&quot;B&quot;); &#125;&#125;class Print &#123; private A a; @Inject Print(A a) &#123; this.a = a; &#125; public void print() &#123; a.print(); &#125;&#125; 输出结果为B, 注入成功 方法参数注入123456789101112131415161718192021222324252627282930public class TestInject &#123; public static void main(String[] args) &#123; Injector injector = Guice.createInjector(new ABCModule()); Print print = injector.getInstance(Print.class); print.print(); &#125;&#125;interface A &#123; void print();&#125;class B implements A &#123; @Override public void print() &#123; System.out.println(&quot;B&quot;); &#125;&#125;class Print &#123; private A a; @Inject public void setA(A a) &#123; this.a = a; &#125; public void print() &#123; a.print(); &#125;&#125; 输出结果同样是B 方法注入当一个方法使用Inject注解时, 如果getInstance该类的实例就会调用该方法一次 1234567891011121314151617public class TestStaticInjection &#123; public static void main(String[] args) &#123; Injector injector = Guice.createInjector(new AbstractModule() &#123; @Override protected void configure() &#123; &#125; &#125;); Print b1 = injector.getInstance(Print.class); &#125;&#125;class Print &#123; @Inject public void print() &#123; System.out.println(&quot;Hello world&quot;); &#125;&#125; 成员属性注入12345678910111213141516171819202122232425262728293031323334public class TestInject &#123; public static void main(String[] args) &#123; Injector injector = Guice.createInjector(new ABCModule()); Print print = injector.getInstance(Print.class); print.print(); &#125;&#125;interface A &#123; void print();&#125;class B implements A &#123; @Override public void print() &#123; System.out.println(&quot;B&quot;); &#125;&#125;class Print &#123; @Inject private A a; public void print() &#123; a.print(); &#125;&#125;class ABCModule extends AbstractModule &#123; @Override protected void configure() &#123; bind(A.class).to(B.class); &#125;&#125; Guice会对被Inject注解过的属性赋值 Optional Injections12345678910111213141516171819202122232425262728293031323334public class TestInject &#123; public static void main(String[] args) &#123; Injector injector = Guice.createInjector(new ABCModule()); Print print = injector.getInstance(Print.class); print.print(); &#125;&#125;interface A &#123; void print();&#125;class B implements A &#123; @Override public void print() &#123; System.out.println(&quot;B&quot;); &#125;&#125;class Print &#123; @Inject(optional=true) private A a; public void print() &#123; a.print(); &#125;&#125;class ABCModule extends AbstractModule &#123; @Override protected void configure() &#123;// bind(A.class).to(B.class); &#125;&#125; 如果我将要被Inject注解的属性设置为optional=true的话,当我注释掉绑定代码,在运行代码时会产生一个空指针异常,这是因为当找不到绑定的时候,就不进行注解 1Exception in thread &quot;main&quot; java.lang.NullPointerException 但是如果我将Inject注解的属性设置为optional=false的话,在运行代码会产生 123456Exception in thread &quot;main&quot; com.google.inject.ConfigurationException: Guice configuration errors:1) No implementation for guice.A was bound. while locating guice.A for field at guice.Print.a(TestInject.java:37) while locating guice.Print 说明如果可选值如果是false的话就必须对其进行绑定 静态属性注入对类中的静态字段进行注入 123456789101112131415161718192021222324252627public class TestStaticInjection &#123; public static void main(String[] args) &#123; Injector injector = Guice.createInjector(new AbstractModule() &#123; @Override protected void configure() &#123; requestStaticInjection(Print.class); &#125; &#125;); Print b1 = injector.getInstance(Print.class); b1.print(); &#125;&#125;class A &#123; public void print() &#123; System.out.println(&quot;A&quot;); &#125;&#125;class Print &#123; @Inject private static A a; public void print() &#123; a.print(); &#125;&#125; 但是我们应该避免静态属性注入 绑定单绑定123456789101112131415161718public class TestBindings &#123; public static void main(String[] args) &#123; Injector injector = Guice.createInjector(new AbstractModule() &#123; @Override protected void configure() &#123; bind(BindingA.class); &#125; &#125;); BindingA a = injector.getInstance(BindingA.class); a.print(); &#125;&#125;class BindingA &#123; public void print() &#123; System.out.println(&quot;A&quot;); &#125;&#125; 输出结果为 1A 我们可以将BindingA绑定到Guice里, 当我们getInstance时会直接获得该实例 注意如果单邦定时, BindingA必须为class, 如果为接口的话会产生No implementation for testGuice.BindingA was bound.异常 参考@ImplementedBy or @ProvidedBy 链式绑定123456789101112131415161718192021222324252627282930313233343536public class TestBindings &#123; public static void main(String[] args) &#123; Injector injector = Guice.createInjector(new AbstractModule() &#123; @Override protected void configure() &#123; bind(BindingA.class).to(BindingB.class); bind(BindingB.class).to(BindingC.class); &#125; &#125;); BindingC c = injector.getInstance(BindingC.class); c.print(); BindingB b = injector.getInstance(BindingB.class); b.print(); BindingA a = injector.getInstance(BindingA.class); a.print(); &#125;&#125;class BindingA &#123; public void print() &#123; System.out.println(&quot;A&quot;); &#125;&#125;class BindingB extends BindingA &#123; @Override public void print() &#123; System.out.println(&quot;B&quot;); &#125;&#125;class BindingC extends BindingB &#123; @Override public void print() &#123; System.out.println(&quot;c&quot;); &#125;&#125; 这段代码的最后调用结果都是 123ccc 这就是Guice的Linked Bindings, 当binding形成一条链之后,会以最终的绑定为最终绑定 注意绑定关系必须是继承关系 命名绑定这种特性是为了,当某个接口有多种实现时,我们可以通过@Named指定我们具体使用哪种实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class TestNamedBindings &#123; public static void main(String[] args) &#123; Injector injector = Guice.createInjector(new AbstractModule() &#123; @Override protected void configure() &#123; bind(A.class).annotatedWith(Names.named(&quot;BType&quot;)).to(B.class); bind(A.class).annotatedWith(Names.named(&quot;CType&quot;)).to(C.class); &#125; &#125;); Print print = injector.getInstance(Print.class); print.printB(); &#125;&#125;interface A &#123; void print();&#125;class B implements A &#123; @Override public void print() &#123; System.out.println(&quot;B&quot;); &#125;&#125;class C implements A &#123; @Override public void print() &#123; System.out.println(&quot;C&quot;); &#125;&#125;class Print &#123; public void printB() &#123; b.print(); &#125; public void printC() &#123; c.print(); &#125; @Inject @Named(&quot;BType&quot;) private A b; @Inject @Named(&quot;CType&quot;) private A c;&#125; 输出结果为 123BCB 我们还可以使用BindingAnnotation来实现相同的功能 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class TestNamedBindings &#123; public static void main(String[] args) &#123; Injector injector = Guice.createInjector(new AbstractModule() &#123; @Override protected void configure() &#123; bind(A.class).annotatedWith(BType.class).to(B.class); bind(A.class).annotatedWith(CType.class).to(C.class); &#125; &#125;); Print print = injector.getInstance(Print.class); print.printB(); print.printC(); &#125;&#125;interface A &#123; void print();&#125;class B implements A &#123; @Override public void print() &#123; System.out.println(&quot;B&quot;); &#125;&#125;class C implements A &#123; @Override public void print() &#123; System.out.println(&quot;C&quot;); &#125;&#125;@BindingAnnotation@Target(&#123; FIELD, PARAMETER, METHOD &#125;) @Retention(RUNTIME)@interface BType &#123;&#125;@BindingAnnotation@Target(&#123; FIELD, PARAMETER, METHOD &#125;) @Retention(RUNTIME)@interface CType &#123;&#125;class Print &#123; public void printB() &#123; b.print(); &#125; public void printC() &#123; c.print(); &#125; @Inject @BType private A b; @Inject @CType private A c;&#125; 多模块绑定我们可以在不同的模块里绑定实现不同的绑定 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class TestMultipleModules &#123; public static void main(String[] args) &#123; AbstractModule module1 = new AbstractModule() &#123; @Override protected void configure() &#123; bind(A.class).to(B.class); &#125; &#125;; AbstractModule module2 = new AbstractModule() &#123; @Override protected void configure() &#123; bind(B.class).to(C.class); &#125; &#125;; Injector injector = Guice.createInjector(module1, module2); A a = injector.getInstance(A.class); B b = injector.getInstance(B.class); a.print(); b.print(); &#125;&#125;class A &#123; public void print() &#123; System.out.println(&quot;A&quot;); &#125;&#125;class B extends A &#123; @Override public void print() &#123; System.out.println(&quot;B&quot;); &#125;&#125;class C extends B &#123; @Override public void print() &#123; System.out.println(&quot;C&quot;); &#125;&#125;class Print &#123; @Inject private A a; public void print() &#123; a.print(); &#125;&#125; 结果为 12CC module1和module2里对A只能进行相同的绑定,也就是说即使在不同的module里也不能即A绑定到B又绑定到C Provides绑定我们可以使用Provides注解替代configure()实现的绑定. 12345678910111213141516171819202122232425262728public class TestProvidesMethods &#123; public static void main(String[] args) &#123; Injector injector = Guice.createInjector(new AbstractModule() &#123; @Override protected void configure() &#123; &#125; @Provides public A provideA() &#123; B b = new B(); return b; &#125; &#125;); A print = injector.getInstance(A.class); print.print(); &#125;&#125;class A &#123; public void print() &#123; System.out.println(&quot;A&quot;); &#125;&#125;class B extends A &#123; @Override public void print() &#123; System.out.println(&quot;B&quot;); &#125;&#125; 我们在module实现里添加了@Provides注释, 当我们在测试代码里要获取某种类型的对象的时候, Guice会根据返回某种类型的方法调用. @Provides注释下的名字可以是任意的. 但是我们还是建议采用provideXXX的形式 需要注意的是, 返回的类型必须是唯一的, 如果我们添加下面的代码 123456789101112class C implementsA &#123; @Override public void print() &#123; System.out.println(&quot;c&quot;); &#125;&#125;@Providespublic A provideC() &#123; C b = new C(); return b;&#125; guice会产生异常 123Exception in thread &quot;main&quot; com.google.inject.CreationException: Unable to create injector, see the following errors:1) A binding to guice.A was already configured at guice.ABCModule.provideA(). 还有一点需要注意的是,如果@Provides已经使用过某种类型,那么在config()方法里就不能再次使用 1234@Overrideprotected void configure() &#123; bind(A.class).to(C.class);&#125; 同样会产生异常 123Exception in thread &quot;main&quot; com.google.inject.CreationException: Unable to create injector, see the following errors:1) A binding to guice.A was already configured at guice.ABCModule.provideA(). 如果我们的provide方法很复杂,我们可以将其抽取到一个类里 123456789101112131415161718192021222324252627282930313233public class TestLinkedBindings &#123; public static void main(String[] args) &#123; Injector injector = Guice.createInjector(new ABCModule()); A print = injector.getInstance(A.class); print.print(); &#125;&#125;interface A &#123; void print();&#125;class B implements A &#123; @Override public void print() &#123; System.out.println(&quot;B&quot;); &#125;&#125;class BProvider implements Provider&lt;A&gt; &#123; @Override public A get() &#123; return new B(); &#125;&#125;class ABCModule extends AbstractModule &#123; @Override protected void configure() &#123; bind(A.class).toProvider(BProvider.class); &#125;&#125;","categories":[{"name":"Java 类库","slug":"Java-类库","permalink":"https://wangmingco.github.io/categories/Java-%E7%B1%BB%E5%BA%93/"}],"tags":[{"name":"Guice","slug":"Guice","permalink":"https://wangmingco.github.io/tags/Guice/"}]},{"title":"Instrumentation","slug":"jvm/instrument","date":"2015-11-23T16:00:00.000Z","updated":"2021-11-18T02:43:28.682Z","comments":true,"path":"2015/11/24/jvm/instrument/","link":"","permalink":"https://wangmingco.github.io/2015/11/24/jvm/instrument/","excerpt":"","text":"利用 java.lang.instrument 做动态 Instrumentation 是 Java SE 5 的新特性, 它把 Java 的 instrument 功能从本地代码中解放出来,使之可以用 Java 代码的方式解决问题. 使用 Instrumentation,开发者可以构建一个独立于应用程序的代理程序(Agent),用来监测和协助运行在 JVM 上的程序,甚至能够替换和修改某些类的定义.有了这样的功能,开发者就可以实现更为灵活的运行时虚拟机监控和 Java 类操作了,这样的特性实际上提供了一种虚拟机级别支持的 AOP 实现方式,使得开发者无需对 JDK 做任何升级和改动,就可以实现某些 AOP 的功能了. 在 Java SE 6 里面,instrumentation 包被赋予了更强大的功能：启动后的 instrument、本地代码(native code)instrument,以及动态改变 classpath 等等.这些改变,意味着 Java 具有了更强的动态控制、解释能力,它使得 Java 语言变得更加灵活多变. 在 Java SE6 里面,最大的改变使运行时的 Instrumentation 成为可能.在 Java SE 5 中,Instrument 要求在运行前利用命令行参数或者系统参数来设置代理类,在实际的运行之中,虚拟机在初始化之时(在绝大多数的 Java 类库被载入之前),instrumentation 的设置已经启动,并在虚拟机中设置了回调函数,检测特定类的加载情况,并完成实际工作.但是在实际的很多的情况下,我们没有办法在虚拟机启动之时就为其设定代理,这样实际上限制了 instrument 的应用.而 Java SE 6 的新特性改变了这种情况,通过 Java Tool API 中的 attach 方式,我们可以很方便地在运行过程中动态地设置加载代理类,以达到 instrumentation 的目的. 另外,对 native 的 Instrumentation 也是 Java SE 6 的一个崭新的功能,这使以前无法完成的功能 —— 对 native 接口的 instrumentation 可以在 Java SE 6 中,通过一个或者一系列的 prefix 添加而得以完成.最后,Java SE 6 里的 Instrumentation 也增加了动态添加 class path 的功能.所有这些新的功能,都使得 instrument 包的功能更加丰富,从而使 Java 语言本身更加强大. java.lang.instrument包的具体实现,依赖于 JVMTI. JVMTI(Java Virtual Machine Tool Interface)是一套由 Java 虚拟机提供的,为 JVM 相关的工具提供的本地编程接口集合. JVMTI 是从 Java SE 5 开始引入,整合和取代了以前使用的 Java Virtual Machine Profiler Interface (JVMPI) 和 the Java Virtual Machine Debug Interface (JVMDI),而在 Java SE 6 中,JVMPI 和 JVMDI 已经消失了.JVMTI 提供了一套”代理”程序机制,可以支持第三方工具程序以代理的方式连接和访问 JVM,并利用 JVMTI 提供的丰富的编程接口,完成很多跟 JVM 相关的功能.事实上,java.lang.instrument 包的实现,也就是基于这种机制的：在 Instrumentation 的实现当中,存在一个 JVMTI 的代理程序,通过调用 JVMTI 当中 Java 类相关的函数来完成 Java 类的动态操作.除开 Instrumentation 功能外,JVMTI 还在虚拟机内存管理,线程控制,方法和变量操作等等方面提供了大量有价值的函数.关于 JVMTI 的详细信息,请参考 Java SE 6 文档(请参见 参考资源)当中的介绍.Instrumentation 的最大作用,就是类定义动态改变和操作.在 Java SE 5 及其后续版本当中,开发者可以在一个普通 Java 程序(带有 main 函数的 Java 类)运行时,通过 – javaagent参数指定一个特定的 jar 文件(包含 Instrumentation 代理)来启动 Instrumentation 的代理程序. 使用 Instrumentation,开发者可以构建一个独立于应用程序的代理程序(Agent),用来监测和协助运行在 JVM 上的程序,甚至能够替换和修改某些类的定义. Instrumentation提供了这样的功能： 获取某个对象的大小 热加载class文件 获取JVM信息 要知道一个对象所使用的内存量,需要将所有实例变量使用的内存和对象本身的开销(一般是16字节)相加.这些开销包括一个指向对象的类的引用,垃圾收集信息和同步信息.另外一般内存的使用会被填充为8字节的倍数. Premainpremain函数是JavaSE5中实现instrument的方式. 使用premain我们要自定义MANIFEST.MF文件, 定义Premain-Class 12Manifest-Version: 1.0Premain-Class: wang.yu66.instrument.core.Premain 然后我们在maven文件中输出该文件 12345678910111213141516171819202122232425262728&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifestFile&gt; src/main/resources/META-INF/MANIFEST.MF &lt;/manifestFile&gt; &lt;manifest&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;classpathPrefix&gt;lib/&lt;/classpathPrefix&gt; &lt;mainClass&gt; &lt;/mainClass&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 获取对象大小首先我们要写一个代理文件出来(该文件放在core-1.0-SNAPSHOT.jar中) 123456789101112public class Premain &#123; private static Instrumentation instrumentation; public static void premain(String agentArgs, Instrumentation inst) &#123; instrumentation = inst; &#125;; public static Instrumentation getInstrumentation() &#123; return instrumentation; &#125;&#125; 然后在自己的应用程序中引用该文件(在examples-1.0-SNAPSHOT.jar中) 123456789101112131415public class PrintObjectSize &#123; public static void main(String[] args) &#123; System.out.println(&quot;Hello world, App&quot;); objectSize(); &#125; public static void objectSize() &#123; Instrumentation inst = Premain.getInstrumentation(); String str = &quot;123456789&quot;; long size = inst.getObjectSize(str); System.out.println(str + &quot; 对象大小: &quot; + size); &#125;&#125; 然后执行命令 1java -javaagent:../instrument/target/core-1.0-SNAPSHOT.jar -cp ./target/examples-1.0-SNAPSHOT.jar wang.yu66.instrument.examples.PrintObjectSize 然后就会获得对象的大小 12Hello world, App123456789 对象大小: 24 加载jar包我们在Premain类中增加一个动态向系统cp加载jar的功能 123456789101112131415161718192021public static void appendJarToSystemClassLoader(String path) &#123; JarFile jarFile = null; try &#123; jarFile = new JarFile(path); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; instrumentation.appendToSystemClassLoaderSearch(jarFile);&#125;public static void appendJarToBootstrapClassLoader(Instrumentation inst, String path) &#123; JarFile jarFile = null; try &#123; jarFile = new JarFile(path); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; inst.appendToBootstrapClassLoaderSearch(jarFile);&#125; 然后我们写一个测试类 12345678910111213141516171819public class TestJarLoader &#123; public static void main(String[] args) &#123; for (int i = 0; i &lt; 120; i++) &#123; Premain.appendJarToSystemClassLoader(args[0]); Print.print(); Stream.of(Premain.getInstrumentation().getAllLoadedClasses()) .filter(clazz -&gt; clazz.getName().contains(&quot;Print&quot;)) .forEach(aClass -&gt; System.out.println(aClass.getName() + &quot; &quot; + aClass.getMethods().length)); try &#123; TimeUnit.SECONDS.sleep(5); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 然后执行命令 1java -javaagent:../instrument/target/core-1.0-SNAPSHOT.jar -cp ./target/examples-1.0-SNAPSHOT.jar wang.yu66.instrument.examples.TestJarLoader D:/workspace/idea/instrument/trunk/print/target/print-1.0-SNAPSHOT.jar 结果输出为 12345678Now Time is Thu Dec 31 10:50:39 CST 2015wang.yu66.instrument.print.Print 11java.io.PrintStream 44Now Time is Thu Dec 31 10:50:44 CST 2015wang.yu66.instrument.print.Print 11java.io.PrintStream 44 热加载 redefineClasses()使用新的字节码全部替换原先存在的Class字节码. (它并不会触发初始化操作, 也不会抛出初始化时的异常. 因此一些静态属性并不会被重新赋值) retransformClasses() 修改原先存在的Class字节码. 对于已经在栈帧中的字节码, 他们会继续执行下去, 但是当方法再次调用的时候,则会使用刚刚加载完成的新的字节码. 在重新加载类的时候, 该类已经实例化出的对象同时也不会受到影响. 该方法的操作过程是一个基于操作集合的, 也就是说在redefine的时候, 可能有A B俩个类都进行, 而且A依赖于B, 那么在redefine的时候这俩个操作是同时完成的, 类似于原子操作. redefine 操作可以改变修改如下字节码 方法体 常量池 属性但是redefine过程不能产生如下影响 对方法进行增加,删除,重命名的操作 对属性进行增加,删除,重命名的操作 不能修改方法签名以及修改继承关系. 在redefine过程中,一旦抛出异常, 那么此过程执已经redefine成功的class也会被会滚成原来的. 想使用这个功能我们需要在MANIFEST.MF文件中增加这样一行Can-Redefine-Classes: true, 然后我们在Premain中增加一个load方法, 用于重新加载某个文件夹下所有的文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149import org.apache.log4j.Logger;import java.io.*;import java.lang.instrument.ClassDefinition;import java.lang.instrument.Instrumentation;import java.security.MessageDigest;import java.security.NoSuchAlgorithmException;import java.util.HashMap;import java.util.Map;import java.util.concurrent.ConcurrentHashMap;import java.util.zip.ZipEntry;import java.util.zip.ZipFile;import java.util.zip.ZipInputStream;/** * 实现服务器局部代码热加载功能 * 目前只支持方法体代码热更以及对属性值的改变 * 但是不能修改类的继承结构, 不能修改方法签名, 不能增加删除方法以及属性成员 * * 使用方法 * java -javaagent:D:\\premain\\target\\agent-1.0-SNAPSHOT.jar -cp .;./* MainServerStart * 只需要将该项目打包出来然后参照上面的例子进行代理处理就好了, 然后正常启动游戏服就好 * */public class Premain &#123; private static final Logger logger = Logger.getLogger(Premain.class); private static Instrumentation instrumentation; public static void premain(String agentArgs, Instrumentation inst) &#123; instrumentation = inst; &#125; private static int classSize = 0; /** * 遍历某个目录加载所有的class文件 * @param directionPath */ public static void loadFromDirection(String directionPath) &#123; loadFromDirection(new File(directionPath), &quot;&quot;); &#125; private static void loadFromDirection(File dir, String parantName) &#123; try &#123; for (File file : dir.listFiles()) &#123; if (file.isFile() &amp;&amp; !file.getName().endsWith(&quot;.class&quot;)) &#123; continue; &#125; if (file.isDirectory()) &#123; String fileName = file.getName(); if (parantName != null &amp;&amp; !parantName.equals(&quot;&quot;)) &#123; fileName = parantName + &quot;.&quot; + fileName; &#125; loadFromDirection(file, fileName); continue; &#125; try(InputStream input = new FileInputStream(file);) &#123; String fileName = file.getPath(); String className = findClassName(fileName); if (parantName != null &amp;&amp; !parantName.equals(&quot;&quot;)) &#123; className = parantName + &quot;.&quot; + className; &#125; redefineClassesFromBytes(input, className, null); &#125; catch (final Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; catch (final Exception e) &#123; e.printStackTrace(); &#125; &#125; /** * 从jar包或者ZIP里加载所有的class文件 * @param jarPath */ public static void loadFromZipFile(String jarPath, String prfixName) &#123; Class[] allLoadClasses = instrumentation.getAllLoadedClasses(); Map&lt;String, Class&gt; allLoadClassesMap = new HashMap&lt;&gt;(classSize); for (Class loadedClass : allLoadClasses) &#123; if (loadedClass.getName().startsWith(prfixName)) &#123; allLoadClassesMap.put(loadedClass.getName(), loadedClass); &#125; &#125; // 加载的类我们不会主动去卸载它, 因此, 我们记录下来上次更新时的类的数量, 下次就根据这个数量直接分配, 避免动态扩容 classSize = allLoadClassesMap.size(); try(InputStream in = new BufferedInputStream(new FileInputStream(new File(jarPath))); ZipInputStream zin = new ZipInputStream(in);) &#123; ZipEntry ze; while ((ze = zin.getNextEntry()) != null) &#123; if (ze.isDirectory()) &#123; // TODO 检查是否还有其他操作要做 &#125; else &#123; long size = ze.getSize(); if (size &gt; 0) &#123; String fileName = ze.getName(); if (!fileName.endsWith(&quot;.class&quot;)) &#123; continue; &#125; ZipFile zf = new ZipFile(jarPath); InputStream input = zf.getInputStream(ze); if (input == null) &#123; logger.error(&quot;Code Reload cant find file : &quot; + fileName); continue; &#125; redefineClassesFromBytes(input, fileName, allLoadClassesMap); input.close(); zf.close(); &#125; &#125; &#125; &#125; catch (final Exception e) &#123; e.printStackTrace(); &#125; &#125; private static String findClassName(String fileName) &#123; int idx = fileName.lastIndexOf(&quot;\\\\&quot;); fileName = fileName.substring(idx + 1); fileName = fileName.split(&quot;\\\\.class&quot;)[0]; return fileName; &#125; /* 使用instrumentation将读取的class byte数组加载进虚拟机 */ private static void redefineClassesFromBytes(InputStream input, String fileName, Map&lt;String, Class&gt; allLoadClassesMap) &#123; try &#123; String className = getClassName(fileName); logger.info(&quot;Start Hot Reload Class : &quot; + fileName + &quot; (&quot; + className + &quot;)&quot;); byte[] bytes = new byte[input.available()]; input.read(bytes); Class loadedClass = allLoadClassesMap.get(className); if (loadedClass != null) &#123; instrumentation.redefineClasses(new ClassDefinition(loadedClass, bytes)); &#125; &#125; catch (final Exception e) &#123; logger.error(&quot;Code Reload Failed : &quot; + fileName, e); &#125; catch (Error error) &#123; logger.error(&quot;Code Reload Failed : &quot; + fileName, error); &#125; &#125; private static String getClassName(String fileName) &#123; fileName = fileName.split(&quot;\\\\.class&quot;)[0]; fileName = fileName.replace(&quot;\\\\\\\\&quot;, &quot;.&quot;); fileName = fileName.replace(&quot;/&quot;, &quot;.&quot;); return fileName; &#125; 然后我们写一个测试类 12345678910111213141516171819202122232425262728293031323334353637import java.util.concurrent.TimeUnit;public class TestReload &#123; public static void main(String[] args) throws InterruptedException &#123; fromDirection(); &#125; public static void fromJar() throws InterruptedException&#123; for (int i = 0; i &lt; 300; i++) &#123; Premain.loadFromJarFile(&quot;D:\\\\ming\\\\test\\\\target\\\\test-1.0-SNAPSHOT.jar&quot;); TestReload.printTime(); new TestReload().printNewTime(); TimeUnit.SECONDS.sleep(5); &#125; &#125; public static void fromDirection() throws InterruptedException &#123; for (int i = 0; i &lt; 300; i++) &#123; Premain.loadFromDirection(&quot;D:\\\\ming\\\\test\\\\target\\\\classes&quot;); TestReload.printTime(); new TestReload().printNewTime(); TimeUnit.SECONDS.sleep(5); &#125; &#125; public static void printTime() &#123; System.out.println(2); &#125; public void printNewTime() &#123; System.out.println(2); System.out.println(id); &#125; public int id = 2;&#125; 我们不断地修改printTime()和printNewTime()以及Id的值, 最后成功输出 123456789101112111111111222 在上面的实现中我分别实现了从目录和jar包对class文件进行热加载 下面我们测试一下,如果增加了属性和方法成员, 看看有什么变化(下面只列出了TestReload.java的新增以及修改部分) 1234567891011121314151617public class TestReload &#123; ... public void printNewTime() &#123; System.out.println(id); printName(); &#125; public int id = 2; public String name = &quot;abc&quot;; public void printName() &#123; System.out.println(name); &#125;&#125; 当我们再次重新加载的时候就会抛出异常 1234567891011121314151617181920212223D:\\ming\\test\\target&gt;java -javaagent:D:\\premain\\target\\agent-1.0-SNAPSHOT.jar -cp .;./* TestReload112222java.lang.UnsupportedOperationException: class redefinition failed: attempted to change the schema (add/remove fields) at sun.instrument.InstrumentationImpl.redefineClasses0(Native Method) at sun.instrument.InstrumentationImpl.redefineClasses(Unknown Source) at Premain.redefineClassesFromBytes(Premain.java:44) at Premain.loadFromDirection(Premain.java:24) at TestReload.fromDirection(TestReload.java:19) at TestReload.main(TestReload.java:6)2java.lang.UnsupportedOperationException: class redefinition failed: attempted to change the schema (add/remove fields) at sun.instrument.InstrumentationImpl.redefineClasses0(Native Method) at sun.instrument.InstrumentationImpl.redefineClasses(Unknown Source) at Premain.redefineClassesFromBytes(Premain.java:44) at Premain.loadFromDirection(Premain.java:24) at TestReload.fromDirection(TestReload.java:19) at TestReload.main(TestReload.java:6)2 完整项目JVM-reload Agentmain在 Java SE 5 中premain 所作的 Instrumentation 也仅限与 main 函数执行前,这样的方式存在一定的局限性.Java SE 6 针对这种状况做出了改进,开发者可以在 main 函数开始执行以后,再启动自己的 Instrumentation 程序.在 Java SE 6 的 Instrumentation 当中,有一个跟 premain“并驾齐驱”的“agentmain”方法,可以在 main 函数开始运行之后再运行. 首先我们还是需要修改MANIFEST.MF文件, 在其中添加 1234Manifest-Version: 1.0Agent-Class: AgentMainCan-Redefine-Classes: true 然后我们写一个代理类 12345678910111213141516171819202122import javax.xml.transform.Transformer;import java.lang.instrument.Instrumentation;import java.lang.instrument.UnmodifiableClassException;public class AgentMain &#123; public static void agentmain(String agentArgs, Instrumentation inst) throws ClassNotFoundException, UnmodifiableClassException, InterruptedException &#123; for (Class clazz : inst.getAllLoadedClasses()) &#123; System.out.println(&quot;Loaded Class : &quot; + clazz.getName()); &#125; Printer.printTime(); &#125;&#125;class Printer &#123; public static void printTime() &#123; System.out.println(&quot;now is &quot; + new Date()); &#125;&#125; 然后写一个启动类 1234567891011121314151617181920import com.sun.tools.attach.VirtualMachine;import java.lang.management.ManagementFactory;import java.util.concurrent.TimeUnit;public class AgentLoader &#123; public static void main(String[] args) throws Exception &#123; String name = ManagementFactory.getRuntimeMXBean().getName(); String pid = name.split(&quot;@&quot;)[0]; System.out.println(pid); VirtualMachine vm = VirtualMachine.attach(pid); for (int i = 0; i &lt; 100; i++) &#123;// vm.loadAgent(&quot;D:\\\\ming\\\\test\\\\target\\\\test-1.0-SNAPSHOT.jar&quot;); vm.loadAgentPath(&quot;D:\\\\ming\\\\test\\\\target\\\\test-1.0-SNAPSHOT.jar&quot;); System.out.println(&quot;Load Agent Over!!!&quot;); TimeUnit.SECONDS.sleep(10); &#125; &#125;&#125; 打包后, 执行命令 1java -cp .;./* AgentLoader","categories":[{"name":"JVM","slug":"JVM","permalink":"https://wangmingco.github.io/categories/JVM/"}],"tags":[]},{"title":"Netty Channel","slug":"JavaLibrary/Netty Channel","date":"2015-11-22T16:00:00.000Z","updated":"2021-11-18T02:50:40.372Z","comments":true,"path":"2015/11/23/JavaLibrary/Netty Channel/","link":"","permalink":"https://wangmingco.github.io/2015/11/23/JavaLibrary/Netty%20Channel/","excerpt":"","text":"Channel是Netty网络抽象类. 它的功能包括网络IO的读写,链路的连接和关闭, 通信双方的通信地址等. 下面我们看一下Channel提供的API parent() : 获取父Channel unsafe() : localAddress() : 当前Channel的本地绑定地址 eventLoop() : 当前Channel注册到的EventLoop对象 config() : 获取当前Channel的配置信息 remoteAddress() : 当前Channel通信的远程Socket地址 metadata() : 当前Channel的元数据描述信息,例如TCP参数等等 isOpen() : 判断当初Channel是否已经打开 isWritable() : 当前Channel是否可写 isRegistered() : 是否注册当EventLoop上 isActive() : 当前Channel是否处于激活状态 pipeline() : 当前Channel的ChannelPipeline对象 下面的网络IO操作会直接调用ChannelPipeline里的方法, 在ChannelPipeline里进行事件传播 read() : 从Channel中读取数据到inbound缓冲区 write() : 将消息通过ChannelPipeline写入到目标Channel中 close() : 主动关闭与网络对端的连接 flush() : 将之前写到环形队列里的消息全部写到目标Channel中,发送给网络对端 connect() : 与网络对端发起连接请求(一般由客户端调用这个方法) bind() : disconnect() : 请求关闭与网络对端的连接. AbstractChannel我们首先看一下AbstractChannel里定义的成员 1234567891011121314151617181920212223242526272829303132// 链路已经关闭异常static final ClosedChannelException CLOSED_CHANNEL_EXCEPTION = new ClosedChannelException();// 链路尚未连接异常static final NotYetConnectedException NOT_YET_CONNECTED_EXCEPTION = new NotYetConnectedException();static &#123; CLOSED_CHANNEL_EXCEPTION.setStackTrace(EmptyArrays.EMPTY_STACK_TRACE); NOT_YET_CONNECTED_EXCEPTION.setStackTrace(EmptyArrays.EMPTY_STACK_TRACE);&#125;// 用于预测下一个报文的大小.private MessageSizeEstimator.Handle estimatorHandle;private final Channel parent;private final Unsafe unsafe;private final ChannelPipeline pipeline;private final ChannelFuture succeededFuture = new SucceededChannelFuture(this, null);private final VoidChannelPromise voidPromise = new VoidChannelPromise(this, true);private final VoidChannelPromise unsafeVoidPromise = new VoidChannelPromise(this, false);private final CloseFuture closeFuture = new CloseFuture(this);// 本地IP地址private volatile SocketAddress localAddress;// 网络通信对端的IP地址private volatile SocketAddress remoteAddress;private volatile EventLoop eventLoop;// Channel是否注册到了EventLoop上private volatile boolean registered;/** Cache for the string representation of this channel */private boolean strValActive;private String strVal; AbstractChannel聚合了所有Channel使用到的能力的对象. 如果某个功能和子类相关则定义抽象方法,由子类去实现. 在这里我们主要关注三个变量 unsafe : 真实网络IO的操作类 pipeline : 当前Channel对应的ChannelPipeline. 负责 eventLoop : 该Channel注册到的EventLoop在实例化的时候, 会对pipeline和unsafe进行赋值.12345protected AbstractChannel(Channel parent) &#123; this.parent = parent; unsafe = newUnsafe(); pipeline = new DefaultChannelPipeline(this);&#125; unsafe实例化由子类实现, 这是因为unsafe的类型是个Unsafe接口, 而且AbstractChannel的内部类AbstractUnsafe是个抽象类, 那么我们就不知道如果要实例化这个类型究竟要使用哪个类型, 因此让AbstractChannel的子类继续实现自己的Unsafe接口的内部类和newUnsafe()方法, unsafe实质类型就有很大的可扩展性 我们看到每一个Channel都有一个自己的pipeline和unsafe. eventLoop是在AbstractUnsafe中register()方法调用时进行赋值的 123public final void register(EventLoop eventLoop, final ChannelPromise promise) &#123; AbstractChannel.this.eventLoop = eventLoop;&#125; AbstractChannel完成的功能很少, 只是实现了一些初始化的工作, 然后将网络相关的建立,数据读写操作等交给pipeline来完成. 123456789101112131415161718192021222324252627282930@Overridepublic ChannelFuture disconnect(ChannelPromise promise) &#123; return pipeline.disconnect(promise);&#125;@Overridepublic ChannelFuture close(ChannelPromise promise) &#123; return pipeline.close(promise);&#125;@Overridepublic ChannelFuture bind(SocketAddress localAddress, ChannelPromise promise) &#123; return pipeline.bind(localAddress, promise);&#125;@Overridepublic ChannelFuture connect(SocketAddress remoteAddress, ChannelPromise promise) &#123; return pipeline.connect(remoteAddress, promise);&#125;Overridepublic Channel read() &#123; pipeline.read(); return this;&#125;@Overridepublic ChannelFuture write(Object msg) &#123; return pipeline.write(msg);&#125; 还提供了一个unsafe()方法 123public Unsafe unsafe() &#123; return unsafe;&#125; 我们看一下AbstractUnsafe的定义protected abstract class AbstractUnsafe implements Unsafe, 它是作为一个AbstractChannel的抽象内部类, 这种关系也很容易让AbstractUnsafe访问AbstractChannel定义的一些空实现方法. 例如AbstractUnsafe中调用AbstractChannel的方法如下 beginRead() -&gt; doBeginRead() doBind() -&gt; doBind() doDisconnect() -&gt; doDisconnect()() doClose() -&gt; doClose() register() -&gt; doRegister()以及调用pipeline的相关方法(fireChannelRegistered()和fireChannelActive()) AbstractNioChannelAbstractNioChannel主要是实现了AbstractChannel的doRegister(), doDeregister(), doBeginRead()方法. 通过下面的变量我们也可以看出这个类主要是为了完成SelectableChannel向Selector的注册功能. 123private final SelectableChannel ch;protected final int readInterestOp;volatile SelectionKey selectionKey; java.nio.channels.ServerSocketChannel和java.nio.channels.SocketChannel都是实现了java.nio.channels.SelectableChannel接口. 而NioSocketChannel和NioServerSocketChannel实现了AbstractNioChannel接口, 因此我们在AbstractNioChannel内定义了一个SelectableChannel成员用于实现ServerSocketChannel和SocketChannel的共用 然后我们看一下doRegister()方法 123456789101112131415161718192021222324@Overrideprotected void doRegister() throws Exception &#123; boolean selected = false; for (;;) &#123; try &#123; // 我们将ServerSocketChannel或者SocketChannel注册到NioEventLoop里的Selector上 // 0表示我们对任何事件Channel里的任何事件都不感兴趣 // 同时我们将this作为附件传送进去, selectionKey = javaChannel().register(eventLoop().selector, 0, this); return; &#125; catch (CancelledKeyException e) &#123; if (!selected) &#123; // Force the Selector to select now as the &quot;canceled&quot; SelectionKey may still be // cached and not removed because no Select.select(..) operation was called yet. eventLoop().selectNow(); selected = true; &#125; else &#123; // We forced a select operation on the selector before but the SelectionKey is still cached // for whatever reason. JDK bug ? throw e; &#125; &#125; &#125;&#125; 最后我们看一下doBeginRead()方法 123456789101112131415161718192021@Overrideprotected void doBeginRead() throws Exception &#123; // Channel.read() or ChannelHandlerContext.read() was called if (inputShutdown) &#123; return; &#125; final SelectionKey selectionKey = this.selectionKey; if (!selectionKey.isValid()) &#123; return; &#125; readPending = true; // 获取selectionKey的操作位 final int interestOps = selectionKey.interestOps(); if ((interestOps &amp; readInterestOp) == 0) &#123; // 如果slectionKey不对读事件感兴趣, 那么就修改selectionKey的操作位, 开始设置对读事件感兴趣 selectionKey.interestOps(interestOps | readInterestOp); &#125;&#125; 还记得在AbstractChannel中的AbstractUnsafe吗?里面有个beginRead(), 这个doBeginRead()正是由其调用的. AbstractNioByteChannelAbstractNioByteChannel内部只有一个Runnable类型的flushTask属性, 它是用来写半包的, 当我们使用到它的时候,我们再具体分析. 我们来重点看一下doWrite()方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104protected void doWrite(ChannelOutboundBuffer in) throws Exception &#123; int writeSpinCount = -1; for (;;) &#123; // 从环形数组ChannelOutboundBuffer中弹出一个消息对象 Object msg = in.current(); if (msg == null) &#123; // 如果全部消息都发送完毕累,则清除半包标志, clearOpWrite() 内部操作 TODO ??? clearOpWrite(); break; &#125; if (msg instanceof ByteBuf) &#123; ByteBuf buf = (ByteBuf) msg; int readableBytes = buf.readableBytes(); if (readableBytes == 0) &#123; // 当前消息没有可读内容, 也就是没有内容需要向外发送, // 则将其从还行数组中删除, 然后继续处理下一个消息 in.remove(); continue; &#125; //设置半包标志 boolean setOpWrite = false; // 设置消息是否发送完毕 boolean done = false; // 设置消息发送的总得数量 long flushedAmount = 0; if (writeSpinCount == -1) &#123; // 从配置中我们获取每次写半包消息进行的最大次数. 也即是如果环形数组里的消息一次性发送 // 不完, 需要循环发送的次数,至于为什么不一直发送, 这是因为如果网络阻塞或者对方接受数据很慢,可能会造成网络IO线程假死 writeSpinCount = config().getWriteSpinCount(); &#125; for (int i = writeSpinCount - 1; i &gt;= 0; i --) &#123; // 将buf内部的数据进行发送, 返回值是数据发送量 int localFlushedAmount = doWriteBytes(buf); if (localFlushedAmount == 0) &#123; // 数量为0,说明一个数据都没有发送出去, 可能是TCP缓冲区满了. 因此设置写半包标志 // 同时退出写循环,这是因为下次写数据还可能TCP缓冲区处于已满状态,导致IO线程空循环 setOpWrite = true; break; &#125; // 数据发送成功, 将发送的数据量累加到flushedAmount上. flushedAmount += localFlushedAmount; if (!buf.isReadable()) &#123; // 当前消息里的数据已经发送完毕, 退出buf发送循环,继续处理环形队列中下一个消息 done = true; break; &#125; &#125; // 将发送的数据量同步到环形队列中 in.progress(flushedAmount); if (done) &#123; // buf数据已经发送完, 则将该消息从环形队列中删除 in.remove(); &#125; else &#123; // 在写半包消息最大循环次数之内都没有将buf数据写完, 可能是数据量太多或者TCP缓冲区已满 // 释放当前IO线程,让其进行其他工作. incompleteWrite(setOpWrite); break; &#125; &#125; else if (msg instanceof FileRegion) &#123; FileRegion region = (FileRegion) msg; boolean done = region.transfered() &gt;= region.count(); boolean setOpWrite = false; if (!done) &#123; long flushedAmount = 0; if (writeSpinCount == -1) &#123; writeSpinCount = config().getWriteSpinCount(); &#125; for (int i = writeSpinCount - 1; i &gt;= 0; i--) &#123; long localFlushedAmount = doWriteFileRegion(region); if (localFlushedAmount == 0) &#123; setOpWrite = true; break; &#125; flushedAmount += localFlushedAmount; if (region.transfered() &gt;= region.count()) &#123; done = true; break; &#125; &#125; in.progress(flushedAmount); &#125; if (done) &#123; in.remove(); &#125; else &#123; incompleteWrite(setOpWrite); break; &#125; &#125; else &#123; // Should not reach here. throw new Error(); &#125; &#125; &#125; doWrite()方法是由AbstractUnsafe的flush()调用的. 从AbstractUnsafe我们可以看到每个Unsafe类都有一个ChannelOutboundBuffer属性. 下来我们看一下incompleteWrite()方法实现 1234567891011121314151617181920protected final void incompleteWrite(boolean setOpWrite) &#123; // 从doWrite()方法中可以看到只有当TCP缓冲区已满的时候才会设置写半包操作 if (setOpWrite) &#123; // 设置累写半包的话,则将SelectionKey注册为OP_WRITE, 让多路复用器不断的轮训对应的Channel, // 继续处理没有发送完的消息 setOpWrite(); &#125; else &#123; // 如果没有半包,则让eventLoop继续执行写半包操作 Runnable flushTask = this.flushTask; if (flushTask == null) &#123; flushTask = this.flushTask = new Runnable() &#123; @Override public void run() &#123; flush(); &#125; &#125;; &#125; eventLoop().execute(flushTask); &#125; &#125; AbstractNioMessageChannel12345678910111213141516171819202122232425262728293031323334353637383940414243protected void doWrite(ChannelOutboundBuffer in) throws Exception &#123; final SelectionKey key = selectionKey(); final int interestOps = key.interestOps(); for (;;) &#123; // 从环形队列中获取一条消息 Object msg = in.current(); if (msg == null) &#123; // 消息为空,说明所有的消息都已经发送出去了. TODO if ((interestOps &amp; SelectionKey.OP_WRITE) != 0) &#123; key.interestOps(interestOps &amp; ~SelectionKey.OP_WRITE); &#125; break; &#125; try &#123; boolean done = false; for (int i = config().getWriteSpinCount() - 1; i &gt;= 0; i--) &#123; // 在配置的最大次数下,将msg发送出去 if (doWriteMessage(msg, in)) &#123; done = true; break; &#125; &#125; if (done) &#123; // 如果消息发送完毕累, 则将其从环形数组中删除 in.remove(); &#125; else &#123; // 如果没有发送完毕, 则设置SelectionKey为写操作位, 让多路复用器不断的轮训channel,发送剩余的数据 if ((interestOps &amp; SelectionKey.OP_WRITE) == 0) &#123; key.interestOps(interestOps | SelectionKey.OP_WRITE); &#125; break; &#125; &#125; catch (IOException e) &#123; if (continueOnWriteError()) &#123; in.remove(e); &#125; else &#123; throw e; &#125; &#125; &#125; &#125; NioServerSocketChannelNioServerSocketChannel的主要作用是接受客户端连接 1234567891011121314151617181920protected int doReadMessages(List&lt;Object&gt; buf) throws Exception &#123; SocketChannel ch = javaChannel().accept(); try &#123; if (ch != null) &#123; buf.add(new NioSocketChannel(this, ch)); return 1; &#125; &#125; catch (Throwable t) &#123; logger.warn(&quot;Failed to create a new channel from an accepted socket.&quot;, t); try &#123; ch.close(); &#125; catch (Throwable t2) &#123; logger.warn(&quot;Failed to close a socket.&quot;, t2); &#125; &#125; return 0; &#125; 这个方法调用主要是由NioMessageUnsafe的read()方法调用 NioSocketChannel","categories":[{"name":"Netty","slug":"Netty","permalink":"https://wangmingco.github.io/categories/Netty/"}],"tags":[{"name":"Netty","slug":"Netty","permalink":"https://wangmingco.github.io/tags/Netty/"}]},{"title":"Netty ByteBuf","slug":"JavaLibrary/Netty ByteBuf","date":"2015-11-19T16:00:00.000Z","updated":"2021-11-18T02:50:44.196Z","comments":true,"path":"2015/11/20/JavaLibrary/Netty ByteBuf/","link":"","permalink":"https://wangmingco.github.io/2015/11/20/JavaLibrary/Netty%20ByteBuf/","excerpt":"","text":"首先我们来看一下netty buffer包的继承结构接下来我会对几个类进行代码测试. 首先我们来看一下如何使用Netty提供的工具类构建一个ByteBuf 12ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024);Assert.assertEquals(1024, buf.capacity()); 我们使用ByteBufAllocator这个工具类构建了一个1024大小的ByteBuf出来. ByteBuf提供了 readerIndex 和 writerIndex 进行缓冲区的顺序读写操作. readerIndex标志读取索引 writerIndex标志写入索引 [0, readerIndex] 已经读取多的缓冲区区间 [readerIndex, writerIndex] 可读的缓冲区区间 [writerIndex, capacity] 可写的缓冲区区间 每个索引移动的单位是bytes, 在下例中我们向ByteBuf写入一个int数值, writerIdex会移动4个bytes ByteBuf API我们首先看一下ByteBuf提供的API ByteBuf write接下来我们看一下向ByteBuf缓冲区写入数据的API writeInt123456public void testWriteInt() &#123; ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024); buf.writeInt(1); // 写入一个Int数值, writerIndex向后移动4个字节 Assert.assertEquals(4, buf.writerIndex());&#125; writeChar123456public void testWriteChar() &#123; ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024); buf.writeChar(&#x27;a&#x27;); // 写入一个Char字符, writerIndex向后移动2个字节 Assert.assertEquals(2, buf.writerIndex());&#125; writeBytes12345678public void testWriteBytes() &#123; ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024); byte[] bytes = new byte[]&#123;100&#125;; buf.writeBytes(bytes); // 写入一个byte数组, 由于byte数组只有一个元素, writerIndex向后移动1个字节 Assert.assertEquals(1, buf.writerIndex());&#125; writeBytes123456789public void testWriteBytesWithStartEndIndex() &#123; ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024); byte[] bytes = new byte[]&#123;100, 1, 3&#125;; buf.writeBytes(bytes, 1, 1); // 我们将三个元素的byte数组写入ByteBuf中,但是在写入的时候我们指定了开始索引和结束索引, // 由于我们的开始索引和结束索引相等, 因此ByteBuf中只写入了1这个元素 Assert.assertEquals(1, buf.writerIndex());&#125; writeBytes12345678public void testWriteBytes3() &#123; ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024); ByteBuf buf1 = ByteBufAllocator.DEFAULT.buffer(1024); buf1.writeInt(1); buf.writeBytes(buf1); // 我们向ByteBuf中写入另一个ByteBuf, 它的索引仍然是增长4. ByteBuf不仅仅可以写入BuyeBuf,还可以写入InputStream和ByteBuffer Assert.assertEquals(4, buf.writerIndex());&#125; writeFloat1234567public void testWriteFloat() &#123; ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024); buf.writeFloat(0.1f); // 写入一个float, 由于float也是占用4个字节, 因此writerIndex向后移动4个字节 Assert.assertEquals(4, buf.writerIndex());&#125; writeByte12345678public void testWriteByte() &#123; ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024); buf.writeByte(1); Assert.assertEquals(1, buf.writerIndex()); buf.writeByte(1000); // 写入一个byte, writerIndex向后移动1个字节,至于写进去的数字大于128,会发生什么,我们在read的时候看一下结果 Assert.assertEquals(2, buf.writerIndex());&#125; writeShort123456public void testWriteShort() &#123; ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024); buf.writeShort(1000); // 写入一个short, writerIndex向后移动2个字节 Assert.assertEquals(2, buf.writerIndex());&#125; writeDouble123456public void testWriteDouble() &#123; ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024); buf.writeDouble(1000.0d); // 写入一个double, writerIndex向后移动8个字节 Assert.assertEquals(8, buf.writerIndex());&#125; writeBoolean123456public void testWriteBoolean() &#123; ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024); buf.writeBoolean(false); // 写入一个boolean, writerIndex向后移动1个字节 Assert.assertEquals(1, buf.writerIndex());&#125; writeLong1234567public void testWriteLong() &#123; ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024); buf.writeLong(100l); // 写入一个long, writerIndex向后移动8个字节 Assert.assertEquals(8, buf.writerIndex());&#125; writeBytes1234567public void testWriteOverLoadMaxCapacity() &#123; ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(5); buf.writeBytes(&quot;123456&quot;.getBytes()); // 虽然在分配的时候我们只分配了5个字节大小的缓冲区,但是我们写入6个字节它也并不报错, // 而且我们观察到writerIndex确实增长到了6,说明ByteBuf会进行自动拓容. Assert.assertEquals(6, buf.writerIndex());&#125; ByteBuf read刚才我们看了向ByteBuf缓冲区写入数据的API,接下来我们看一下从ByteBuf缓冲区读取数据的API readInt12345678public void testReadInt() &#123; ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024); buf.writeInt(1); int read = buf.readInt(); // 读取Int, readerIndex向后移动4字节 Assert.assertEquals(4, buf.readerIndex()); Assert.assertEquals(1, read);&#125; readChar123456789public void testReadChar() &#123; ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024); buf.writeChar(&#x27;1&#x27;); char read = buf.readChar(); // 读取Char, readerIndex向后移动2字节 Assert.assertEquals(2, buf.readerIndex()); Assert.assertEquals(&#x27;1&#x27;, read);&#125; readBytes123456789public void testReadBytes() &#123; ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024); buf.writeBytes(new byte[]&#123;1, 2, 3, 4, 5, 6, 7, 8, 9, 0&#125;); byte[] read = new byte[10]; buf.readBytes(read); // 读取byte数组, 这里需要注意的是, read字节数组的长度不能大于ByteBuf的readerIndex的值,否则会产生数组越界 Assert.assertEquals(10, buf.readerIndex()); Assert.assertEquals(0, read[9]);&#125; 123456789public void testReadBytesWithStartEndIndex() &#123; ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024); buf.writeBytes(new byte[]&#123;1, 2, 3, 4, 5, 6, 7, 8, 9, 0&#125;); byte[] read = new byte[10]; buf.readBytes(read, 2, 3); // 从第三个索引开始读取到第4个索引的位置, 读取2个字节, readerIndex移动到第4个索引位置上 Assert.assertEquals(3, buf.readerIndex()); Assert.assertEquals(3, read[0]);&#125; 1234567public void testRead3Bytes() &#123; ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024); buf.writeBytes(new byte[]&#123;1, 2, 3, 4, 5, 6, 7, 8, 9, 0&#125;); buf.readBytes(3); // 读取3个字节, readerIndex向后移动3字节 Assert.assertEquals(3, buf.readerIndex());&#125; readFloat123456789public void testReadFloat() &#123; ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024); buf.writeFloat(10.0f); float read = buf.readFloat(); // 读取Float, readerIndex向后移动4字节 Assert.assertEquals(4, buf.readerIndex()); Assert.assertEquals(10.f, read);&#125; readLong12345678public void testReadLong() &#123; ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024); buf.writeLong(10l); buf.readLong(); // 读取long, readerIndex向后移动8字节 Assert.assertEquals(8, buf.readerIndex());&#125; readByte1234567public void testReadByte() &#123; ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024); buf.writeBytes(new byte[]&#123;1, 2, 3, 4, 5, 6, 7, 8, 9, 0&#125;); buf.readByte(); // 读取byte, readerIndex向后移动1字节 Assert.assertEquals(1, buf.readerIndex());&#125; readShort1234567public void testReadShort() &#123; ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024); buf.writeShort(10); buf.readShort(); // 读取short, readerIndex向后移动2字节 Assert.assertEquals(2, buf.readerIndex());&#125; readBoolean1234567public void testReadBoolean() &#123; ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024); buf.writeBoolean(true); buf.readBoolean(); // 读取boolean, readerIndex向后移动1字节 Assert.assertEquals(1, buf.readerIndex());&#125; readDouble1234567public void testReadDouble() &#123; ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024); buf.writeDouble(10.0d); buf.readDouble(); // 读取double, readerIndex向后移动8字节 Assert.assertEquals(8, buf.readerIndex());&#125; readUnsignedByte123456789public void testReadUnsignedByte() &#123; ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024); buf.writeByte(-10); short read = buf.readUnsignedByte(); // 读取无符号byte, readerIndex向后移动1字节 Assert.assertEquals(1, buf.readerIndex()); Assert.assertEquals(246, read);&#125; readUnsignedShort12345678910public void testReadUnsignedShort() &#123; ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024); buf.writeShort(-1024); // 我们首先读取出-1024,这个负数,然后转化成无符号数字64512 int read = buf.readUnsignedShort(); // 读取无符号Short, readerIndex向后移动2字节 Assert.assertEquals(2, buf.readerIndex()); Assert.assertEquals(64512, read);&#125; readerIndex123456public void testReaderIndex() &#123; ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024); buf.writeBytes(new byte[]&#123;1, 2, 3, 4, 5, 6, 7, 8, 9, 0&#125;); Assert.assertEquals(0, buf.readerIndex());&#125; readByte123456789public void testReadableBytes() &#123; ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024); buf.writeBytes(new byte[]&#123;1, 2, 3, 4, 5, 6, 7, 8, 9, 0&#125;); Assert.assertEquals(10, buf.readableBytes()); buf.readByte(); // 我们读取一个byte之后, 可读取字节变成了9个字节 Assert.assertEquals(9, buf.readableBytes());&#125; readUnsignedInt12345678public void testReadUnsignedInt() &#123; ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024); buf.writeInt(10); long read = buf.readUnsignedInt(); Assert.assertEquals(4, buf.readerIndex()); Assert.assertEquals(10, read);&#125; readSlice1234567891011public void testReadSlice() &#123; ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024); buf.writeBytes(new byte[]&#123;1, 2, 3, 4, 5, 6, 7, 8, 9, 0&#125;); ByteBuf read = buf.readSlice(5); // slice出来的ByteBuf与原ByteBuf共享缓冲区 Assert.assertEquals(5, buf.readerIndex()); Assert.assertEquals(1, read.readByte()); Assert.assertEquals(6, buf.readByte());&#125; readInt1234567public void testWriteBytesReadInt() &#123; ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(1024); buf.writeBytes(new byte[]&#123;1, 2, 3, 4, 5, 6, 7, 8, 9, 0&#125;); int read = buf.readInt(); // 从一个byte数组中读取一个int, 会读取出1, 2, 3, 4这四个byte转换成int为16909060 Assert.assertEquals(16909060, read);&#125; discard bytes在前面的测试中我们看到了,当向ByteBuf写入数据时,当超出分配内存大小时,ByteBuf会进行自动拓容(重新生成一个数组缓冲区,然后将原先的缓冲区内容拷贝到新的缓冲区中),这样一来ByteBuf占用的内从会越来越大. 我们可以是discardReadBytes()这个方法重用以前的缓冲区, 它会将[0, readerIndex]区间的内存舍弃掉(内部也是数组复制), 这么着就节间的重用了以前的缓冲区,但是这种方式有一点就是如果频繁的调用这个方法会带来性能问题. 1234567891011121314ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(50);buf.writeBytes(&quot;123456789&quot;.getBytes());buf.readBytes(3); // 读取三个字节System.out.println(buf.readerIndex()); // readerIndex位置 : 3System.out.println(buf.writerIndex()); // writerIndex位置: 9System.out.println(buf.readableBytes()); // 可读字节 9 - 3 = 6System.out.println(buf.writableBytes()); // 可写字节 50 - 9 = 41// 舍弃已读字节, readerIndex重置为0buf.discardReadBytes();System.out.println(buf.readerIndex()); // readerIndex位置 : 0System.out.println(buf.writerIndex()); // writerIndex位置: 6System.out.println(buf.readableBytes()); // 可读字节 6System.out.println(buf.writableBytes()); // 可写字节 50 - 6 = 44 clear这个操作并不会情况缓冲区的内容只是用来将readerIndex和writerIndex重置为0. 但是缓冲区的内容我们是仍然可以读到的. 123456789101112131415161718192021ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(50);buf.writeBytes(&quot;123456789&quot;.getBytes());buf.readBytes(3); // 读取三个字节System.out.println(buf.readerIndex()); // readerIndex位置 : 3System.out.println(buf.writerIndex()); // writerIndex位置: 9System.out.println(buf.readableBytes()); // 可读字节 9 - 3 = 6System.out.println(buf.writableBytes()); // 可写字节 50 - 9 = 41// 重置readerIndex和writerIndexbuf.clear();System.out.println(buf.readerIndex()); // readerIndex位置 : 0System.out.println(buf.writerIndex()); // writerIndex位置: 0System.out.println(buf.readableBytes()); // 可读字节 readerIndex = 0System.out.println(buf.writableBytes()); // 可写字节 capacity - writerIndex = 50// 设置writerIndexbuf.writerIndex(6);System.out.println(buf.readerIndex()); // readerIndex位置 : 0System.out.println(buf.writerIndex()); // writerIndex位置: 6System.out.println(buf.readableBytes()); // 可读字节 writerIndex - readerIndex = 6System.out.println(buf.writableBytes()); // 可写字节 44System.out.println(buf.readByte()); mark resetmark reset相关的四个方法也是对指针位置的操作 markReaderIndex() 记录readerIndex markWriterIndex() 记录writerIndex resetReaderIndex() 将记录的readerIndex重置到当前的readerIndex值 resetWriterIndex() 将记录的writerIndex重置到当前的writerIndex值 12345678910111213141516171819202122public void testReaderIndex() &#123; ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(50); buf.writeBytes(&quot;123456789&quot;.getBytes()); buf.readBytes(3); buf.markReaderIndex(); buf.readBytes(1); Assert.assertEquals(4, buf.readerIndex()); buf.resetReaderIndex(); Assert.assertEquals(3, buf.readerIndex());&#125;```javapublic void testWriterIndex() &#123; ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(50); buf.writeBytes(&quot;123456789&quot;.getBytes()); buf.markWriterIndex(); buf.writeByte(1); Assert.assertEquals(10, buf.writerIndex()); buf.resetWriterIndex(); Assert.assertEquals(9, buf.writerIndex());&#125; 查找ByteBuf提供丰富的API让我查找某个Byte 123456789101112131415161718192021ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(50);buf.writeBytes(new byte[]&#123;1, 2, 3, 4 ,5, 6, 7, 8, 9&#125;);// 在指定的范围内查找某个byteint idx = buf.indexOf(0, buf.writerIndex(), (byte)2);System.out.println(idx); // 1idx = buf.indexOf(3, buf.writerIndex(), (byte)2);System.out.println(idx); // -1// 在[readerIndex, writerIndex]之间查找值idx = buf.bytesBefore((byte)2);System.out.println(idx); // 4buf.readBytes(3);idx = buf.bytesBefore((byte)2);System.out.println(idx); // -1// 在[readerIndex, writerIndex]之间遍历查找值idx = buf.forEachByte(b -&gt; b == (byte) 6);System.out.println(idx); // 3 derived buffersByteBuf提供多种API用于创建某个ByteBuf的视图或者复制版本 duplicate() 复制ByteBuf对象, 俩个对象共享同一个缓冲区,但是各自维护自己的索引(readerIndex, writerIndex) copy() 复制ByteBuf对象, 俩个对象共享有自己的缓冲区, 缓冲区和索引都不共享 slice() 复制Bytebuf对象,但是只复制[readerIndex, writerIndex]区间的缓冲区, 俩个对象的缓冲区是共享的,但是维护各自的索引 get setByteBuf不仅仅支持read, write的顺序读写还支持get,set的随机读取。 但是get/set不会进行自动拓容. 1234567ByteBuf buf = ByteBufAllocator.DEFAULT.buffer(50);buf.writeBytes(new byte[]&#123;1, 2, 3, 4 ,5, 6, 7, 8, 9&#125;);byte b = buf.getByte(2);System.out.println(buf.readableBytes()); // 9System.out.println(buf.readerIndex()); // 0System.out.println(b); // 3 内存池Netty的内存池由PoolArea. PoolArea由多个PoolChunk组成. ButeBuf 类型看完ByteBuf的API操作我们来看一下ByteBuf的分类,在内存使用种类上ByteBuf分为以下俩类 DirectByteBuf : 使用JVM堆外内存分配. 虽然分配和回收速度慢一些,但是从SocketChannel中写入或者读取数据由于少了一次内存复制,因此速度较快.(SocketIO通信时适合使用) HeapByteBuf: 使用JVM堆内内存分配. 内存分配和回收速度较快,但是读写Socket IO的时候由于会额外进行一次内存复制,堆内存对应的缓冲区复制到内核Channel中,性能会有下降.(后端业务在编解码时适合使用) 在内存使用种类上由分为以下俩类 PooledByteBuf: 基于内存对象池的ByteBuf, UnpooledByteBuf: UnpooledDirectByteBuf, UnpooledHeapByteBuf, UnpooledUnsafeDirectByteBuf ,PooledDirectByteBuf, PooledHeapByteBuf AbstractByteBufAbstractByteBuf继承自ByteBuf, 它内部并没有定义ByteBuf的缓冲区实现,只是通过定义readerIndex, writerIndex, capacity等实现ByteBuf接口中的各种API, 具体的缓冲区实现则由子类实现 12345678910static final ResourceLeakDetector&lt;ByteBuf&gt; leakDetector = new ResourceLeakDetector&lt;ByteBuf&gt;(ByteBuf.class);int readerIndex;private int writerIndex;private int markedReaderIndex;private int markedWriterIndex;private int maxCapacity;private SwappedByteBuf swappedBuf; 除了操作具体缓冲区API没有实现之外 AbstractByteBuf为我们实现了大量的API,首先我们看一下读数据的API 12345678910@Overridepublic ByteBuf readBytes(byte[] dst, int dstIndex, int length) &#123; // 检查当前缓冲区中的可读数据是否满足length长度 checkReadableBytes(length); // 将当前缓冲区的数据从readerIndex开始读取length个长度到目标dst缓冲区中. // 这个方法也就是拷贝一部分数据到新的缓冲区中,但是并不会改变当前缓冲区的readerIndex和writerIndex getBytes(readerIndex, dst, dstIndex, length); readerIndex += length; return this;&#125; 下面我们看一下写数据的API实现 1234567@Overridepublic ByteBuf writeBytes(byte[] src, int srcIndex, int length) &#123; ensureWritable(length); setBytes(writerIndex, src, srcIndex, length); writerIndex += length; return this;&#125; 同样的setBytes();是由子类具体实现, 我们着重看一下ensureWritable()方法实现 1234567891011121314151617181920212223242526@Overridepublic ByteBuf ensureWritable(int minWritableBytes) &#123; // 如果要写入数据的字节小于0的话, 则直接抛出异常 if (minWritableBytes &lt; 0) &#123; throw new IllegalArgumentException(String.format( &quot;minWritableBytes: %d (expected: &gt;= 0)&quot;, minWritableBytes)); &#125; // minWritableBytes &lt;= capacity() - writerIndex, 要写入的字节数小于可写的字节数则直接返回 if (minWritableBytes &lt;= writableBytes()) &#123; return this; &#125; if (minWritableBytes &gt; maxCapacity - writerIndex) &#123; throw new IndexOutOfBoundsException(String.format( &quot;writerIndex(%d) + minWritableBytes(%d) exceeds maxCapacity(%d): %s&quot;, writerIndex, minWritableBytes, maxCapacity, this)); &#125; // Normalize the current capacity to the power of 2. int newCapacity = calculateNewCapacity(writerIndex + minWritableBytes); // Adjust to the new capacity. capacity(newCapacity); return this;&#125; ResourceLeakDetectorResourceLeakDetector用于检测内存泄漏. 它被所有ByteBuf实例共享. SwappedByteBufAbstractReferenceCountedByteBufUnPooledHeapByteBuf不使用对象池的基于堆内存分配的字节缓冲区. 每次IO读写的时候都会创建一个新的UnPooledHeapByteBuf.","categories":[{"name":"Netty","slug":"Netty","permalink":"https://wangmingco.github.io/categories/Netty/"}],"tags":[{"name":"Netty","slug":"Netty","permalink":"https://wangmingco.github.io/tags/Netty/"}]},{"title":"Redis事务","slug":"nosql/Redis事务","date":"2015-11-18T16:00:00.000Z","updated":"2021-11-18T02:43:50.584Z","comments":true,"path":"2015/11/19/nosql/Redis事务/","link":"","permalink":"https://wangmingco.github.io/2015/11/19/nosql/Redis%E4%BA%8B%E5%8A%A1/","excerpt":"","text":"普通事务首先介绍普通事务MULTI，EXEC，DISCARD: MULTI告诉 redis 服务器开启一个事务 EXEC告诉 redis 开始执行事务 DISCARD告诉 redis 取消事务 MULTI命令执行后, redis进入事务状态,redis会持续缓存某个客户端的命令(其他客户端处于饥饿状态).当redis接受到客户端的EXEC命令后会开始执行刚才缓存在事务队列里的任务. DISCARD 会将事务队列清空. 12345678910111213141516171819202122232425262728293031323334redis 127.0.0.1:7006&gt; MULTIOKredis 127.0.0.1:7006&gt; SET a &quot;&quot;redis 127.0.0.1:7006&gt; SET a &quot;&quot;QUEUEDredis 127.0.0.1:7006&gt; SET a &quot;a&quot;QUEUEDredis 127.0.0.1:7006&gt; EXEC1) OK2) OKredis 127.0.0.1:7006&gt; SET b &quot;b&quot;OKredis 127.0.0.1:7006&gt; EXEC(error) ERR EXEC without MULTIredis 127.0.0.1:7006&gt; MULTIOKredis 127.0.0.1:7006&gt; SET n &quot;n&quot;QUEUEDredis 127.0.0.1:7006&gt; EXEC1) OKredis 127.0.0.1:7006&gt; MULTIOKredis 127.0.0.1:7006&gt; SET c &quot;c&quot;QUEUEDredis 127.0.0.1:7006&gt; DISCARDOKredis 127.0.0.1:7006&gt; GET a&quot;a&quot;redis 127.0.0.1:7006&gt; GET b&quot;b&quot;redis 127.0.0.1:7006&gt; Get c(error) ERR Operation against a key holding the wrong kind of valueredis 127.0.0.1:7006&gt; GET n&quot;n&quot;redis 127.0.0.1:7006&gt; 使用MULTI命令开启事务 输入一个错误的命令,点击回车,redis并没有报错,说明这个命令确实是被缓存起来了没有执行 使用SET命令将a设置为”a” 然后执行事务,我们看到俩条事务都执行完了,但是第一条命令并没有报错 然后再次使用SET命令将b设置为”b” 再次执行事务, 并不成功,提示我们要开启事务,说明事务一旦执行完就自动退出了 再次开启事务,然后使用SET命令将n设置为”n” 退出事务 接下来我们依次使用GET命令获取值,但是n取不到,说明退出事务确实没有执行事务队列里的命令 watch机制下来我们来看一下redis的watch机制 pipline机制参考文章","categories":[{"name":"NoSql","slug":"NoSql","permalink":"https://wangmingco.github.io/categories/NoSql/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://wangmingco.github.io/tags/Redis/"}]},{"title":"memcached","slug":"nosql/Memcache","date":"2015-11-17T16:00:00.000Z","updated":"2021-11-18T02:43:41.850Z","comments":true,"path":"2015/11/18/nosql/Memcache/","link":"","permalink":"https://wangmingco.github.io/2015/11/18/nosql/Memcache/","excerpt":"","text":"原理memcached是一个高性能内存对象缓存系统. 它基于libevent,可方便地拓展为任意大小, 而且对防止内存swap和使用非阻塞IO做了大量优化工作. memcached内存分配：memcached默认情况下采用了名为Slab Allocator的机制分配、管理内存. 如果我们在启动memcached时没有指定-m参数的话, 那么memcached能使用的最大内存为默认的64M,但是memcached启动的时候并不会一次性就都分配出来,而是当发现memcached已被分配的内存不够用的时候才会进行申请. memcached申请内存时一次会申请一个Slab(默认为1M). 然后会将这一个Slab分成不同的Class, 每个Class内部都有N个大小相等的Chunk.每个chunk中都保存了一个item结构体、一对key value键值对. 安装Memcached依赖libevent,所以我们首先需要安装libevent 1234wget http://jaist.dl.sourceforge.net/project/levent/libevent/libevent-2.0/libevent-2.0.22-stable.tar.gztar -zxvf libevent-2.0.22-stable.tar.gzcd libevent-2.0.22-stable./configure --prefix=/usr &amp;&amp; make &amp;&amp; make install 接下来安装Memcached 1234wget http://memcached.org/latesttar -zxvf memcached-1.x.x.tar.gzcd memcached-1.x.x./configure --with-libevent=/usr &amp;&amp; make &amp;&amp; make test &amp;&amp; sudo make install memcached命令选项网络相关 -s &lt;file&gt; : Unix socket path to listen on (disables network support). -a &lt;perms&gt; : 当通过s选项创建socket的时候,我们可以通过-a选项指定创建socket使用的权限(权限为八进制). -l &lt;ip_addr&gt; : 监听的主机地址. 默认是本机任何可用的地址. -d : 以后台进程方式运行memcached -u &lt;username&gt; : memcached不能以root用户运行，如果当前用户为root, 我们需要通过该参数指定用户为root -c &lt;num&gt; : 设置最大同时连接数.(默认是1024). -C : 关闭CAS. (每个对象都会减少8bytes大小). -p &lt;num&gt; : 设置监听TCP端口号, 默认是11211. -P : 设置pid存储文件. -U &lt;num&gt; : 设置监听UDP端口号, 默认是11211, 0 表示关闭UDP监听. -r : 将最大的核心文件大小限制提升到允许的最大值. -v : 设置为verbose 同时会输出发生的errors 和warnings. -i : 打印memcached 和libevent 授权. -R &lt;num&gt; : 这个选项是设置服务器可以处理一个独立客户端连接顺序请求的数量,以防止产生其他客户端饥饿的情况. 一旦设置了这个值当服务器处理一个连接超过20个(默认值)请求之后,就会尝试处理其他的连接请求. 内存相关 -m &lt;num&gt; : 设置对象存储能使用的最大内存(单位是MB,默认是64M) -M : 关闭对象存储所需内存超过最大内存时,自动删除缓存对象的功能. 如果memcached的配置内存达到最大值就不可再存储新的对象. -f &lt;factor&gt; : Class的成长因子(默认是1.25). 也就是说如果Class1是100B,那么Class2就是125B. -n &lt;size&gt; : key, value, and flags分配到的最小字节数(默认是48字节). 如果你的键值对的值都很小,你可以调低这个值来达到更高的性能. 如果你的成长因子比较大,那么你可以调高这个值,提升命中率. -t &lt;threads&gt; : 处理请求的线程数(默认是4). 这个选项只有memcached被编译的时候指定了线程开启才有用. -k : 锁定所有的分页内存. 在巨大的缓存系统中,使用这个选项是非常危险的,使用的使用要参考README文件和memcached homepage进行配置. -L : 尝试使用尽可能使用到的内存叶. 增加内存叶大小可以减少TLB未命中和提供性能. 为了可以从OS获得更大的内存页,memcached会在一个巨大的chunk上分配所有的item -I &lt;size&gt; : 指定slab page大小(默认是1mb,最小是1k, 最大是128m). 改变这个值会增加每个item大小的值. 使用-vv来查看更改后的值 -F : 关闭flush_all命令. 1memcached -d -p 10021 -l 10.234.10.12 -u root -c 1024 -P ./memcached1.pid java使用我们使用spymemcached作为java客户端连接memcached. 在Maven项目中添加以下依赖 123&lt;groupId&gt;net.spy&lt;/groupId&gt; &lt;artifactId&gt;spymemcached&lt;/artifactId&gt;&lt;version&gt;2.12.0&lt;/version&gt; 然后连接memcached 1MemcachedClient client = new MemcachedClient(new InetSocketAddress(&quot;10.234.10.12&quot;, 10021)); 通过这一行我们就成功的连接上了memcached.然后我们就可以使用spymemcached提供的大量api来操作memcached memcached信息统计我们可以使用telnet命令直接连接memcachedtelnet 127.0.0.1 10021,然后输入下列命令查看相关信息 stats统计memcached的各种信息 STAT pid 20401 memcache服务器的进程ID STAT uptime 47 服务器已经运行的秒数 STAT time 1447835371 服务器当前的unix时间戳 STAT version 1.4.24 memcache版本 STAT libevent 2.0.22-stable libevent版本 STAT pointer_size 64 当前操作系统的指针大小（32位系统一般是32bit） STAT rusage_user 0.002999 进程的累计用户时间 STAT rusage_system 0.001999 进程的累计系统时间 STAT curr_connections 10 当前打开着的连接数 STAT total_connections 11 从服务器启动以后曾经打开过的连接数 STAT connection_structures 11 服务器分配的连接构造数 STAT reserved_fds 20 STAT cmd_get 0 get命令（获取）总请求次数 STAT cmd_set 0 set命令（保存）总请求次数 STAT cmd_flush 0 STAT cmd_touch 0 STAT get_hits 0 总命中次数 STAT get_misses 0 总未命中次数 STAT delete_misses 0 delete命令未命中次数 STAT delete_hits 0 delete命令命中次数 STAT incr_misses 0 incr命令未命中次数 STAT incr_hits 0 incr命令命中次数 STAT decr_misses 0 decr命令未命中次数 STAT decr_hits 0 decr命令命中次数 STAT cas_misses 0 cas命令未命中次数 STAT cas_hits 0 cas命令命中次数 STAT cas_badval 0 STAT touch_hits 0 touch命令命中次数 STAT touch_misses 0 touch命令未命中次数 STAT auth_cmds 0 STAT auth_errors 0 STAT bytes_read 7 总读取字节数（请求字节数） STAT bytes_written 0 总发送字节数（结果字节数） STAT limit_maxbytes 67108864 分配给memcache的内存大小（字节） STAT accepting_conns 1 STAT listen_disabled_num 0 STAT threads 4 当前线程数 STAT conn_yields 0 STAT hash_power_level 16 hash等级 STAT hash_bytes 524288 hash字节数 STAT hash_is_expanding 0 STAT malloc_fails 0 分配失败次数 STAT bytes 0 当前服务器存储items占用的字节数 STAT curr_items 0 服务器当前存储的items数量 STAT total_items 0 从服务器启动以后存储的items总数量 STAT expired_unfetched 0 STAT evicted_unfetched 0 STAT evictions 0 为获取空闲内存而删除的items数（分配给memcache的空间用满后需 STAT reclaimed 0 STAT crawler_reclaimed 0 STAT crawler_items_checked 0 STAT lrutail_reflocked 0 我们也可以使用java获取这些信息 1234567MemcachedClient client = new MemcachedClient(new InetSocketAddress(&quot;10.234.10.12&quot;, 10021));client.getStats().entrySet().stream().forEach(entry -&gt; &#123; System.out.println(&quot;Node : &quot; + entry.getKey()); entry.getValue().entrySet().stream().forEach(value -&gt; &#123; System.out.println(&quot; &quot; + value.getKey() + &quot; : &quot; + value.getValue()); &#125;);&#125;); stats reset重新统计数据 stats slabs显示slabs信息，可以详细看到数据的分段存储情况 STAT active_slabs 0 STAT total_malloced 0 stats items显示slab中的item数目 stats cachedump 1 0列出slabs第一段里存的KEY值 STAT evictions 0表示要腾出新空间给新的item而移动的合法item数目","categories":[{"name":"NoSql","slug":"NoSql","permalink":"https://wangmingco.github.io/categories/NoSql/"}],"tags":[{"name":"Memcached","slug":"Memcached","permalink":"https://wangmingco.github.io/tags/Memcached/"}]},{"title":"Redis SortedSet","slug":"nosql/Redis_SortedSet","date":"2015-11-15T16:00:00.000Z","updated":"2021-11-18T02:43:47.635Z","comments":true,"path":"2015/11/16/nosql/Redis_SortedSet/","link":"","permalink":"https://wangmingco.github.io/2015/11/16/nosql/Redis_SortedSet/","excerpt":"","text":"在命令行中使用Redis客户端连接Redis服务器： redis-cli -h 127.0.0.1 -p 7000 增加成员ZADD语法：ZADD key score member [[score member] [score member] ...]. ZADD redis命令 key 有序集合名 score 值 (可以是整数值或双精度浮点数) member 键 这个命令也就是将键值对(member score)插入到有序集合key中. 如果集合不存在就创建一个集合,如果键已经存在就代替原来的值. 示例 12redis 127.0.0.1:7006&gt; ZADD test1 10 a(integer) 1 修改成员ZINCRBY语法ZINCRBY key increment member ZINCRBY redis命令 key 有序集合名 increment score值的增量 member 针对哪个成员进行改变 这个命令就是对某个成员进行增加或者减少(通过负数实现). (member 成员的新 score 值,以字符串形式表示) 示例 123456redis 127.0.0.1:7006&gt; zadd test1 23 t(integer) 1redis 127.0.0.1:7006&gt; ZINCRBY test1 10 t&quot;33&quot;redis 127.0.0.1:7006&gt; zincrby test1 -20 t&quot;13&quot; 删除成员ZREM语法ZREM key member [member ...] ZREM redis命令 key 有序集合名 member 成员名 移除有序集 key 中的一个或多个成员,不存在的成员将被忽略. 示例 123456redis 127.0.0.1:7006&gt; zcard test1(integer) 7redis 127.0.0.1:7006&gt; zrem test1 a(integer) 1redis 127.0.0.1:7006&gt; zcard test1(integer) 6 ZREMRANGEBYRANK语法ZREMRANGEBYRANK key start stop ZREMRANGEBYRANK redis命令 key 有序集合名 start 开始索引从0开始(默认闭区间,使用(表示开区间) stop 结束索引从0开始(默认闭区间,使用(表示开区间) 移除有序集 key 中,指定排名(rank)区间内的所有成员. 示例 12redis 127.0.0.1:7006&gt; ZREMRANGEBYRANK test1 1 2 # 将第二名和第三名移除(integer) 2 ZREMRANGEBYSCORE语法ZREMRANGEBYSCORE key min max ZREMRANGEBYSCORE redis命令 key 有序集合名 min最小值(默认闭区间,使用(表示开区间) max 最大值(默认闭区间,使用(表示开区间) 将集合key里的score值区间为[min,max]的成员删除 +和-在 min 参数以及 max 参数中表示正无限和负无限. 示例 12redis 127.0.0.1:7006&gt; ZREMRANGEBYSCORE test1 10 20(integer) 1 合并集合ZUNIONSTORE语法ZUNIONSTORE destination numkeys key [key ...] [WEIGHTS weight [weight ...]] [AGGREGATE SUM|MIN|MAX] ZUNIONSTORE redis命令 destination 有序集合名 numkeys 需要合并的集合数量 key 需要合并的集合 WEIGHTS 指定该值,则在合并的时候,对每个score值都乘以该元素 AGGREGATE 指定并集的结果集的聚合方式 对多个集合采取并集 AGGREGATE有三种值：A. SUM,将相同的成员的score相加. MIN,取相同成员的最小score值. MAX,取相同成员的最大score值 示例 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950redis 127.0.0.1:7006&gt; zadd a 10 a1 20 a2 30 a3 40 a4 50 a5(integer) 5redis 127.0.0.1:7006&gt; zadd b 11 b1 12 b2 13 b3 14 b4 15 b5(integer) 5redis 127.0.0.1:7006&gt; ZUNIONSTORE c 2 a b(integer) 10redis 127.0.0.1:7006&gt; ZRANGE c 0 -1 WITHSCORES 1) &quot;a1&quot; 2) &quot;10&quot; 3) &quot;b1&quot; 4) &quot;11&quot; 5) &quot;b2&quot; 6) &quot;12&quot; 7) &quot;b3&quot; 8) &quot;13&quot; 9) &quot;b4&quot;10) &quot;14&quot;11) &quot;b5&quot;12) &quot;15&quot;13) &quot;a2&quot;14) &quot;20&quot;15) &quot;a3&quot;16) &quot;30&quot;17) &quot;a4&quot;18) &quot;40&quot;19) &quot;a5&quot;20) &quot;50&quot;redis 127.0.0.1:7006&gt; ZUNIONSTORE e 2 c a(integer) 10redis 127.0.0.1:7006&gt; ZRANGE e 0 -1 WITHSCORES 1) &quot;b1&quot; 2) &quot;11&quot; 3) &quot;b2&quot; 4) &quot;12&quot; 5) &quot;b3&quot; 6) &quot;13&quot; 7) &quot;b4&quot; 8) &quot;14&quot; 9) &quot;b5&quot;10) &quot;15&quot;11) &quot;a1&quot;12) &quot;20&quot;13) &quot;a2&quot;14) &quot;40&quot;15) &quot;a3&quot;16) &quot;60&quot;17) &quot;a4&quot;18) &quot;80&quot;19) &quot;a5&quot;20) &quot;100&quot; ZINTERSTORE语法ZINTERSTORE destination numkeys key [key ...] [WEIGHTS weight [weight ...]] [AGGREGATE SUM|MIN|MAX] ZINTERSTORE redis命令 destination 有序集合名 numkeys 需要合并的集合数量 key 需要合并的集合 WEIGHTS 指定该值,则在合并的时候,对每个score值都乘以该元素 AGGREGATE 指定并集的结果集的聚合方式 对多个集合采取交集 AGGREGATE有三种值：A. SUM,将相同的成员的score相加. MIN,取相同成员的最小score值. MAX,取相同成员的最大score值 示例 12345678910redis 127.0.0.1:7006&gt; zadd h 1 a1 2 a2(integer) 2redis 127.0.0.1:7006&gt; ZINTERSTORE j 2 e h(integer) 2redis 127.0.0.1:7006&gt; zrange j 0 -1 WITHSCORES1) &quot;a1&quot;2) &quot;21&quot;3) &quot;a2&quot;4) &quot;42&quot;redis 127.0.0.1:7006&gt; 获取集合数量ZCARD语法ZCARD key ZCARD redis命令 key 有序集合名 获得集合大小 示例 12redis 127.0.0.1:7006&gt; ZCARD test1(integer) 2 ZCOUNT语法ZCOUNT key min max ZCOUNT redis命令 key 有序集合名 min最小值(默认闭区间,使用(表示开区间) max 最大值(默认闭区间,使用(表示开区间)这个命令就是统计score 值在 min 和 max 之间(默认包括 score 值等于 min 或 max )的成员的数量 +和-在 min 参数以及 max 参数中表示正无限和负无限. 示例 12redis 127.0.0.1:7006&gt; ZCOUNT test 10 50(integer) 6 获取集合列表ZRANGE语法ZRANGE key start stop [WITHSCORES] ZRANGE redis命令 key 有序集合名 start 开始索引从0开始(默认闭区间,使用(表示开区间) stop 结束索引从0开始(默认闭区间,使用(表示开区间) WITHSCORES 同时也返回成员对应的值 返回有序集key中指定区间内的成员,得到的成员是递增(从小到大)排序的. 索引从0开始, 如果索引为负数则代表从倒序,即-1代表最后一个,-2代表倒数第二个. ( ZRANGE test1 0 -1 WITHSCORES显示整个有序集成员) 示例 1234567891011121314redis 127.0.0.1:7006&gt; zrange test1 0 31) &quot;a&quot;2) &quot;c&quot;3) &quot;t&quot;4) &quot;b&quot;redis 127.0.0.1:7006&gt; zrange test1 0 3 WITHSCORES1) &quot;a&quot;2) &quot;10&quot;3) &quot;c&quot;4) &quot;12&quot;5) &quot;t&quot;6) &quot;13&quot;7) &quot;b&quot;8) &quot;20&quot; ZREVRANGE语法ZREVRANGE key start stop [WITHSCORES] ZREVRANGE redis命令 key 有序集合名 start 开始索引从0开始(默认闭区间,使用(表示开区间) stop 结束索引从0开始(默认闭区间,使用(表示开区间) WITHSCORES 输出score值 和ZRANGE命令不同的是它是从按 score 值递减(从大到小)来排列,其他和ZRANGE命令一样 示例 123redis 127.0.0.1:7006&gt; ZREVRANGE test1 1 1001) &quot;d&quot;2) &quot;f&quot; ZRANGEBYSCORE语法ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count] ZRANGEBYSCORE redis命令 key 有序集合名 min最小值(默认闭区间,使用(表示开区间) max 最大值(默认闭区间,使用(表示开区间) WITHSCORES 输出score值 LIMIT offset count 返回有序集key中,score值介于 [min, max]之间(闭区间)的成员,按 score 值递增(从小到大)次序排列 +和-在 min 参数以及 max 参数中表示正无限和负无限. 示例 1234567891011121314151617181920212223242526272829redis 127.0.0.1:7006&gt; ZRANGEBYSCORE test1 10 56 WITHSCORES # 闭区间 1) &quot;a&quot; 2) &quot;10&quot; 3) &quot;c&quot; 4) &quot;12&quot; 5) &quot;t&quot; 6) &quot;13&quot; 7) &quot;b&quot; 8) &quot;20&quot; 9) &quot;f&quot;10) &quot;42&quot;11) &quot;d&quot;12) &quot;56&quot;redis 127.0.0.1:7006&gt; ZRANGEBYSCORE test1 (10 (56 WITHSCORES # 开区间1) &quot;c&quot;2) &quot;12&quot;3) &quot;t&quot;4) &quot;13&quot;5) &quot;b&quot;6) &quot;20&quot;7) &quot;f&quot;8) &quot;42&quot;redis 127.0.0.1:7006&gt; ZRANGEBYSCORE test1 10 56 WITHSCORES LIMIT 0 3 # 从第一个成员开始选择三个成员1) &quot;a&quot;2) &quot;10&quot;3) &quot;c&quot;4) &quot;12&quot;5) &quot;t&quot;6) &quot;13&quot; ZREVRANGEBYSCORE语法ZREVRANGEBYSCORE key max min [WITHSCORES] [LIMIT offset count] ZREVRANGEBYSCORE redis命令 key 有序集合名 min最小值(默认闭区间,使用(表示开区间) max 最大值(默认闭区间,使用(表示开区间) WITHSCORES 输出score值 LIMIT offset count 除了成员按 score 值递减的次序排列这一点外, ZREVRANGEBYSCORE 命令的其他方面和 ZRANGEBYSCORE 命令一样. +和-在 min 参数以及 max 参数中表示正无限和负无限. 示例 1234567891011redis 127.0.0.1:7006&gt; ZREVRANGE test1 1 100 WITHSCORES 1) &quot;f&quot; 2) &quot;42&quot; 3) &quot;d&quot; 4) &quot;40&quot; 5) &quot;c&quot; 6) &quot;30&quot; 7) &quot;b&quot; 8) &quot;20&quot; 9) &quot;a&quot;10) &quot;10&quot; ZRANGEBYLEX语法ZRANGEBYLEX key min max [LIMIT offset count] ZRANGEBYLEX redis命令 key 有序集合名 min最小值(默认闭区间,使用(表示开区间) max 最大值(默认闭区间,使用(表示开区间) 根据成员进行排序而不是根据score值排序,然后返回[min, max]区间内的成员 +和-在 min 参数以及 max 参数中表示正无限和负无限. 示例 1redis 127.0.0.1:7006&gt; ZRANGEBYLEX test1 10 30 查询某个成员ZRANK语法ZRANK key member ZRANK redis命令 key 有序集合名 member 成员值 返回有序集 key 中成员 member 的排名.其中有序集成员按 score 值递增(从小到大)顺序排列.（排名从0开始） 示例 12redis 127.0.0.1:7006&gt; ZRANK test1 d(integer) 5 ZREVRANK语法ZREVRANK key member ZREVRANK redis命令 key 有序集合名 member 成员值除了成员按 score 值递减的次序排列这一点外, ZREVRANK 命令的其他方面和 ZRANK 命令一样. 示例 12redis 127.0.0.1:7006&gt; ZREVRANK test1 c(integer) 3 ZSCORE语法ZSCORE key member ZSCORE redis命令 key 有序集合名 member 成员 返回有序集 key 中,成员 member 的 score 值. 示例 12redis 127.0.0.1:7006&gt; ZSCORE test1 a&quot;10&quot;","categories":[{"name":"NoSql","slug":"NoSql","permalink":"https://wangmingco.github.io/categories/NoSql/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://wangmingco.github.io/tags/Redis/"}]},{"title":"自旋锁","slug":"算法/自旋锁","date":"2015-10-14T16:00:00.000Z","updated":"2021-11-18T02:53:53.384Z","comments":true,"path":"2015/10/15/算法/自旋锁/","link":"","permalink":"https://wangmingco.github.io/2015/10/15/%E7%AE%97%E6%B3%95/%E8%87%AA%E6%97%8B%E9%94%81/","excerpt":"","text":"自旋锁spinlock自旋锁是指当一个线程尝试获取某个锁时，如果该锁已被其他线程占用，就一直循环检测锁是否被释放，而不是进入线程挂起或睡眠状态。自旋锁适用于锁保护的临界区很小的情况，临界区很小的话，锁占用的时间就很短。SimpleSpinLock里有一个owner属性持有锁当前拥有者的线程的引用，如果该引用为null，则表示锁未被占用，不为null则被占用。这里用AtomicReference是为了使用它的原子性的compareAndSet方法（CAS操作），解决了多线程并发操作导致数据不一致的问题，确保其他线程可以看到锁的真实状态。缺点CAS操作需要硬件的配合；保证各个CPU的缓存（L1、L2、L3、跨CPU Socket、主存）的数据一致性，通讯开销很大，在多处理器系统上更严重；没法保证公平性，不保证等待进程/线程按照FIFO顺序获得锁。 123456789101112131415161718public class Spinlock &#123; private AtomicReference&lt;Thread&gt; owner = new AtomicReference&lt;Thread&gt;(); public void lock() &#123; Thread currentThread = Thread.currentThread(); // 如果锁未被占用，则设置当前线程为锁的拥有者 while (owner.compareAndSet(null, currentThread)) &#123; &#125; &#125; public void unlock() &#123; Thread currentThread = Thread.currentThread(); // 只有锁的拥有者才能释放锁 owner.compareAndSet(currentThread, null); &#125;&#125; TicketSpinLockTicket Lock 是为了解决上面的公平性问题，类似于现实中银行柜台的排队叫号：锁拥有一个服务号，表示正在服务的线程，还有一个排队号；每个线程尝试获取锁之前先拿一个排队号，然后不断轮询锁的当前服务号是否是自己的排队号，如果是，则表示自己拥有了锁，不是则继续轮询。 当线程释放锁时，将服务号加1，这样下一个线程看到这个变化，就退出自旋。Ticket Lock 虽然解决了公平性的问题，但是多处理器系统上，每个进程/线程占用的处理器都在读写同一个变量serviceNum ，每次读写操作都必须在多个处理器缓存之间进行缓存同步，这会导致繁重的系统总线和内存的流量，大大降低系统整体的性能。 12345678910111213141516171819202122public class TicketSpinLock &#123; private AtomicInteger serviceNum = new AtomicInteger(); // 服务号 private AtomicInteger ticketNum = new AtomicInteger(); // 排队号 public int lock() &#123; // 首先原子性地获得一个排队号 int myTicketNum = ticketNum.getAndIncrement(); // 只要当前服务号不是自己的就不断轮询 while (serviceNum.get() != myTicketNum) &#123; &#125; return myTicketNum; &#125; public void unlock(int myTicket) &#123; // 只有当前线程拥有者才能释放锁 int next = myTicket + 1; serviceNum.compareAndSet(myTicket, next); &#125;&#125; CLHSpinLockCLH锁也是一种基于链表的可扩展、高性能、公平的自旋锁，申请线程只在本地变量上自旋，它不断轮询前驱的状态，如果发现前驱释放了锁就结束自旋。 *差异： * 从代码实现来看，CLH比MCS要简单得多。 从自旋的条件来看，CLH是在本地变量上自旋，MCS是自旋在其他对象的属性。 从链表队列来看，CLH的队列是隐式的，CLHNode并不实际持有下一个节点；MCS的队列是物理存在的。 CLH锁释放时只需要改变自己的属性，MCS锁释放则需要改变后继节点的属性。 注意：这里实现的锁都是独占的，且不能重入的。 1234567891011121314151617181920212223242526 public class CLHSpinLock &#123; public static class CLHNode &#123; private boolean isLocked = true; // 默认是在等待锁 &#125; @SuppressWarnings(&quot;unused&quot;) private volatile CLHNode tail; private static final AtomicReferenceFieldUpdater&lt;CLHSpinLock, CLHNode&gt; UPDATER = AtomicReferenceFieldUpdater .newUpdater(CLHSpinLock.class, CLHNode.class, &quot;tail&quot;); public void lock(CLHNode currentThread) &#123; CLHNode preNode = UPDATER.getAndSet(this, currentThread); if (preNode != null) &#123;// 已有线程占用了锁，进入自旋 while (preNode.isLocked) &#123; &#125; &#125; &#125; public void unlock(CLHNode currentThread) &#123; // 如果队列里只有当前线程，则释放对当前线程的引用（for GC）。 if (!UPDATER.compareAndSet(this, currentThread, null)) &#123; // 还有后续线程 currentThread.isLocked = false;// 改变状态，让后续线程结束自旋 &#125; &#125;&#125; MCSSpinLockMCS Spinlock 是一种基于链表的可扩展、高性能、公平的自旋锁，申请线程只在本地变量上自旋，直接前驱负责通知其结束自旋，从而极大地减少了不必要的处理器缓存同步的次数，降低了总线和内存的开销。 12345678910111213141516171819202122232425262728293031323334353637383940public class MCSSpinLock &#123; public static class MCSNode &#123; volatile MCSNode next; volatile boolean isLocked = true; // 默认是在等待锁 &#125; volatile MCSNode queue;// 指向最后一个申请锁的MCSNode private static final AtomicReferenceFieldUpdater&lt;MCSSpinLock, MCSNode&gt; UPDATER = AtomicReferenceFieldUpdater .newUpdater(MCSSpinLock.class, MCSNode.class, &quot;queue&quot;); public void lock(MCSNode currentThread) &#123; MCSNode predecessor = UPDATER.getAndSet(this, currentThread);// step 1 if (predecessor != null) &#123; predecessor.next = currentThread;// step 2 while (currentThread.isLocked) &#123;// step 3 &#125; &#125; &#125; public void unlock(MCSNode currentThread) &#123; if (UPDATER.get(this) == currentThread) &#123;// 锁拥有者进行释放锁才有意义 if (currentThread.next == null) &#123;// 检查是否有人排在自己后面 if (UPDATER.compareAndSet(this, currentThread, null)) &#123;// step 4 // compareAndSet返回true表示确实没有人排在自己后面 return; &#125; else &#123; // 突然有人排在自己后面了，可能还不知道是谁，下面是等待后续者 // 这里之所以要忙等是因为：step 1执行完后，step 2可能还没执行完 while (currentThread.next == null) &#123; // step 5 &#125; &#125; &#125; currentThread.next.isLocked = false; currentThread.next = null;// for GC &#125; &#125;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://wangmingco.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[]},{"title":"双线程锁","slug":"算法/1_1_双线程锁","date":"2015-10-11T16:00:00.000Z","updated":"2021-11-18T02:51:41.619Z","comments":true,"path":"2015/10/12/算法/1_1_双线程锁/","link":"","permalink":"https://wangmingco.github.io/2015/10/12/%E7%AE%97%E6%B3%95/1_1_%E5%8F%8C%E7%BA%BF%E7%A8%8B%E9%94%81/","excerpt":"","text":"所谓的双线程锁指的是这种锁适用于俩个线程运行的前提下. 下面我们依次给出了三种双线程锁解决方案： 双线程算法遵循以下俩点约定: 线程标志为0或者1. 若当前线程调用者的标志为i,则另一方的调用者为1 - i 通过ThreadId.get()获取自己的标志 互斥: 俩个线程的临界区是没有重叠的,那么我们撑这俩个临界区是互斥的. 无死锁: 如果一个线程尝试获得一个锁,那么总会成功获得这个锁. 无饥饿：每一个尝试获得锁的线程都能成功. 当线程调用一个锁方法的时候,这个方法立即返回,我们便称这个锁是无饥饿的. LockOne123456789101112131415class LockOne &#123; private volatile boolean[] flags = new boolean[2]; public void lock() &#123; int i = ThreadID.get(); int j = 1- i; flag[i] = true; while(flag[j]) &#123;&#125; &#125; public void unlock() &#123; int i = ThreadID.get(); flag[i] = false; &#125;&#125; 假设线程A对应flag[0]标志,线程B对应flag[1]标志,那么我们得出下面这一个流程: write_A(flag[0] = true) -&gt; read_A(flag[1] == false) -&gt; CS_A这段话的意思是线程A将flag[0]的值置为true然后读取flag[1]的值,这个过程称为CS_A事件 write_B(flag[1] = true) -&gt; read_B(flag[0] == false) -&gt; CS_B这段话的意思是线程B将flag[1]的值置为true然后读取flag[0]的值,这个过程称为CS_B事件 我们验证一下LockOne算法是否满足互斥 123456假设这个算法不是互斥的，也就是无法得到`CS_A -&gt; CS_B`且`CS_B -&gt; CS_A`.假设CS_A事件先于CS_B事件,那么有：write_A(flag[0] = true) -&gt; read_A(flag[1] == false) -&gt; write_B(flag[1] = true)=&gt;read_A(flag[1] == false) -&gt; write_B(flag[1] = true)可以看到这俩个事件是互斥的(它们的临界区是没有重叠的). LockOne算法满足了互斥,但是如果俩个线程并发执行的话，就会进入死锁,同样我们来证明一下 123假设write_A(flag[0] = true) -&gt; write_B(flag[1] = true) -&gt; read_A(flag[1] == false) -&gt; read_B(flag[0] == false)那么`flag[0]`和`flag[1]`就都成为true,也就是线程A和线程B进入了死锁. 至于说为什么要使用volatile关键字,这是为了保证flags变量的内存可见性,因为Java会将这段代码 1234567while(flag[j]) &#123;&#125;=&gt;if(flag[j]) &#123; while(true) &#123; &#125;&#125; 编译后的代码进行了提升优化,加上volatile关键字,就是告诉编译器,不要提升优化我的代码. LockTwo1234567891011121314class LockTwo &#123; private int lock; public void lock() &#123; int tid = ThreadID.get(); lock = tid; while(lock == tid)&#123;&#125; &#125; public void unlock() &#123; int tid = ThreadID.get(); lock = tid; &#125;&#125; 同样我们假设有俩个事件发生 write_A(lock = 1) -&gt; read_A(lock == 1) -&gt; CS_A write_B(lock = 2) -&gt; read_B(lock == 2) -&gt; CS_B很明显任何线程调用加锁操作都会造成死循环. 但是,如果锁调用交叉调用的话1write_A(lock = 1) -&gt; write_B(lock = 2) -&gt; read_A(lock == 2) -&gt; read_B(lock == 2) 直到A线程释放锁,B线程就一直在阻塞着. 因此只要这俩个事件并发执行就能完成互斥要求. Peterson算法实现 123456789101112131415161718class Peterson &#123; private voliate boolean[] flag = new boolean[2]; private int lock; public void lock() &#123; int tid = ThreadID.get(); int oid = 1 - tid; flag[oid] = true; lock = tid; while(flag[tid] &amp;&amp; lock == tid) &#123;&#125; &#125; public void unlock() &#123; int tid = ThreadID.get(); flag[tid] = false; &#125;&#125; 同样的我们看看俩个线程依次调用锁过程(假设线程A对应flag[0]标志,线程B对应flag[1]标志)： 12write_A(flag[1] = true) -&gt; write_A(lock = 0) -&gt; read_A(flag[0] == false) -&gt; read_A(lock == 0) -&gt; CS_Awrite_B(flag[0] = true) -&gt; write_B(lock = 1) -&gt; read_B(flag[1] == true) -&gt; read_B(lock == 1) -&gt; CS_B 好，首先我们看一下 CS_A先于CS_B事件执行的话,那么B线程会进入锁等待. CS_A和CS_B事件并发执行我们分俩种情况分析： 1write_A(flag[1] = true) -&gt; write_A(lock = 0) -&gt; write_B(flag[0] = true) -&gt; write_B(lock = 1) -&gt; read_A(flag[1] == true) -&gt; read_A(lock == 0) -&gt; read_B(flag[1] == true) -&gt; read_B(lock == 1) 同样的A线程事件先于B线程事件,我们看到A线程并没有进入锁等待,而是B线程进入了锁等待 1write_A(flag[1] = true) -&gt; write_A(lock = 0) -&gt; write_B(flag[0] = true) -&gt; write_B(lock = 1) -&gt; read_B(flag[1] == true) -&gt; read_B(lock == 1) -&gt; read_A(flag[1] == true) -&gt; read_A(lock == 0) 我们发现这个锁算法仍然是有问题的.","categories":[{"name":"算法","slug":"算法","permalink":"https://wangmingco.github.io/categories/%E7%AE%97%E6%B3%95/"}],"tags":[]},{"title":"Mysql 增删改查","slug":"数据库/Mysql 增删改查","date":"2015-10-07T16:00:00.000Z","updated":"2021-11-18T02:53:47.300Z","comments":true,"path":"2015/10/08/数据库/Mysql 增删改查/","link":"","permalink":"https://wangmingco.github.io/2015/10/08/%E6%95%B0%E6%8D%AE%E5%BA%93/Mysql%20%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5/","excerpt":"","text":"连接数据库1mysql -h 主机地址 -u 用户名 －p 用户密码 （注:u与root可以不用加空格，其它也一样） 用户操作创建用户 1CREATE USER &#x27;username&#x27;@&#x27;host&#x27; IDENTIFIED BY &#x27;password&#x27;; 授权: 1GRANT privileges ON databasename.tablename TO &#x27;username&#x27;@&#x27;host&#x27; privileges - 用户的操作权限,如SELECT,INSERT,UPDATE等.如果要授予所的权限则使用ALL;如果要授予该用户对所有数据库和表的相应操作权限则可用表示, 如.*. 用以上命令授权的用户不能给其它用户授权,如果想让该用户可以授权,用以下命令: 1GRANT privileges ON databasename.tablename TO &#x27;username&#x27;@&#x27;host&#x27; WITH GRANT OPTION; 设置与更改用户密码 1SET PASSWORD FOR &#x27;username&#x27;@&#x27;host&#x27; = PASSWORD(&#x27;newpassword&#x27;); 撤销用户权限 1REVOKE privilege ON databasename.tablename FROM &#x27;username&#x27;@&#x27;host&#x27;; 删除用户 1DROP USER &#x27;username&#x27;@&#x27;host&#x27;; 数据库操作 显示数据库：SHOW databases; 创建库：CREATE DATABASE 库名; 删除库：DROP DATABASE 库名; 使用库(选中库)：USE 库名; 表操作 显示数据表：SHOW tables 显示表结构：DESC 表名 删除表：DROP TABLE 表名; 输入创建表的DDL语句 SHOW CREATE TABLE 表名; 创建表：12345678910111213CREATE TABLE USER ( name VARCHAR(30) NOT NULL, id INT DEFAULT &#x27;0&#x27; NOT NULL, stu_id INT, phone VARCHAR(20), address VARCHAR(30) NOT NULL, age INT(4) NOT NULL, PRIMARY KEY (name), CONSTRAINT stu_id UNIQUE (stu_id) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; 表数据操作 清空表数据truncate table 表名;. truncate删除后不记录mysql日志，不可以恢复数据。相当于保留mysql表的结构，重新创建了这个表，所有的状态都相当于新表。 清空表数据delete from 表名. delete的效果有点像将mysql表中所有记录一条一条删除到删完 修改表结构 修改列名alter table 表名称 change 字段名称 字段名称 修改表名alter table 表名称 rename 表名称 修改某个表的字段类型及指定为空或非空alter table 表名称 change 字段名称字段名称 字段类型 [null/not null]; 修改某个表的字段名称及指定为空或非空alter table 表名称 change 字段原名称字段新名称 字段类型 [null/not null]; 增加一个字段(一列)alter table table_name add column column_name type default value; type指该字段的类型,value指该字段的默认值 更改一个字段名字(也可以改变类型和默认值)alter table table_name change sorce_col_name dest_col_name type defaultvalue; source_col_name指原来的字段名称,dest_col_name指改后的字段名称 改变一个字段的默认值alter table table_name alter column_name set default value; 改变一个字段的数据类型alter table table_name change column column_name column_name type; 向一个表中增加一个列做为主键alter table table_name add column column_name type auto_increment PRIMARYKEY; 向一个表中增加一个列做为主键alter table table_name add column column_name type auto_increment PRIMARYKEY; 删除字段alter table form1 drop column 列名; 复制表 含有主键等信息的完整表结构 CREATE table 新表名 LIKE book; 只有表结构，没有主键等信息 `create table 新表名 select * from books; 将旧表中的数据灌入新表 INSERT INTO 新表 SELECT * FROM 旧表； 注：新表必须已经存在 导入导出数据库 数据库某表的备份,在命令行中输入:mysqldump -u root -p database_name table_name &gt; bak_file_name 导出数据select_statment into outfile”dest_file”; 导入数据load data infile”file_name” into table table_name; 将两个表里的数据拼接后插入到另一个表里insert into tx select t1.com1,concat(t1.com2,t2.com1) from t1,t2; 查询表mysql查询的五种子句 where(条件查询)1SELECT * FROM t1 WHERE id &gt; 100; 数值谓词:&gt;,=,&lt;,&lt;&gt;,!=,!&gt;,!&lt;,=&gt;,=&lt; 字符串谓词：=，like 日期谓词：= (SELECT * from t1 WHERE create_time = &#39;2011-04-08&#39;) having（筛选）1 group by（分组）1SELECT id FROM player GROUP BY vip; order by（排序）1SELECT id FROM player ORDER BY id; limit（限制结果数）查询前n条记录(默认从第0个开始) 1SELECT id FROM player LIMIT 10; 从结果集中第1个开始查询, 查询10个 1SELECT id FROM player LIMIT 1, 10; 执行顺序sql语句的执行顺序 12345678910(7) SELECT (8) DISTINCT &lt;select_list&gt;(1) FROM &lt;left_table&gt;(3) &lt;join_type&gt; JOIN &lt;right_table&gt;(2) ON &lt;join_condition&gt;(4) WHERE &lt;where_condition&gt;(5) GROUP BY &lt;group_by_list&gt;(6) HAVING &lt;having_condition&gt;(9) ORDER BY &lt;order_by_condition&gt;(10) LIMIT &lt;limit_number&gt; 也就是 1FROM-&gt;ON-&gt;JOIN-&gt;WHERE-&gt;GROUP BY-&gt;HAVING-&gt;SELECT-&gt;DISTINCT-&gt;ORDER BY-&gt;LIMIT 多表查询 SELECT * FROM a, b WHERE a.id=b.id; SELECT * FROM a INNER JOIN b ON a.id=b.id; SELECT * FROM a FULL JOIN b ON a.id=b.id; SELECT * FROM a LEFT JOIN b ON a.id=b.id; SELECT * FROM a RIGHT JOIN b ON a.id=b.id; SELECT * FROM a CROSS JOIN b ON a.id=b.id; SELECT * FROM a INNER JOIN b USING(id); SELECT * FROM a FULL JOIN b USING(id); SELECT * FROM a LEFT JOIN b USING(id); SELECT * FROM a RIGHT JOIN b USING(id); SELECT * FROM a CROSS JOIN b USING(id);","categories":[{"name":"数据库","slug":"数据库","permalink":"https://wangmingco.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://wangmingco.github.io/tags/mysql/"}]},{"title":"MySQL事务","slug":"数据库/数据库事务","date":"2015-10-07T16:00:00.000Z","updated":"2021-11-18T02:53:44.517Z","comments":true,"path":"2015/10/08/数据库/数据库事务/","link":"","permalink":"https://wangmingco.github.io/2015/10/08/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A1/","excerpt":"","text":"事务事务（Transaction）是一个操作序列，它构成了并发执行的基本单元。事务的提出主要是为了解决并发情况下保持数据一致性。 数据库事务具有ACID特性,即 原子性： 原子性体现在对事务的修改,要么全部执行要么都不执行 一致性： 保持数据的一致性,例如整数类型的数据大小不能溢出,字符型数据长度不能超过规定范围，保证数据的完整性. 隔离性： 如果数据库并发执行A,B俩个事务,那么在A事务执行完之前对B事务是不可见的,也就是说,B事务是看不见A事务的中间状态的. 持久性： 事务完成后,它对数据库的影响是永久的,即使数据库出现异常也是如此. 隔离级别 Read Uncommitted: 读取未提交的数据,即其他事务已经提交修改但还未提交的数据(这是最低的隔离级别) Read Committed: 读取已经提交的数据,但是在一个事务中,对同一个项,前后俩次读取的结果可能不同. Repetable Read: 可重复读取,在一个事务中,对同一个项,确保前后俩次读取的结果一样 Serializable: 可序列话,即数据库的事务是可串行执行的,就像一个事务执行的时候没有别的事务同时在执行我们使用下面的语句来改变数据库的隔离级别1SET [SESSION|GLOBAL] TRANSACTION ISOLATION LEVEL READ UNCOMMITTED | READ COMMITTED | REPEATABLE READ | SERIALIZABLE 不带SESSION、GLOBAL的SET命令,只对下一个事务有效 SET SESSION 为当前会话设置隔离模式 SET GLOBAL为以后新建的所有MYSQL连接设置隔离模式（当前连接不包括在内） 读写异常 Lost Update: 俩个事务并发修改同一个数据,A事务提交成功,B事务提交失败回滚后,A事务的修改都可能会丢失 Dirty Reads: A事务读取了B事务更新却没有提交的数据 Non-Repeatable Reads: 一个事务对同一个数据项的多次读取可能得到不同的结果 Second Lost Updates:俩个事务并发修改同一个数据, B事务可能会覆盖掉A事务的修改 Phantom Reads: A事务进行前后俩次查询,但是在查询过程中出现了B事务向其中插入数据,那么A事务可能读取到未出现的数据 隔离级别与读写异常的关系 12345 LU DR NRR SLU PRRU N Y Y Y YRC N N Y Y YRR N N N N YS N N N N N 事务语句 开始事物：BEGIN TRANSACTION 提交事物：COMMIT TRANSACTION 回滚事务：ROLLBACK TRANSACTION 1234567891011# 开启一个事务START TRANSACTION;INSERT INTO db1.`t1`(id) VALUES(1);# 提交事务COMMIT;# 开启事务START TRANSACTION;INSERT INTO db1.`t1`(id) VALUES(2);# 回滚刚才的事务ROLLBACK; 并发控制锁写时复制多版本并发控制Mysql InnoDB存储引擎,InnoDB对每一行维护了俩个隐含的列,一列用于存储行被修改的时间,另一列存储每一行被删除的时间. 这里的时间并不是绝对时间,而是与时间对应的数据库系统的版本号,每当一个事务开始时,InnoDB都会给这个事务分配一个递增的版本号,所以版本号也可以被任务是事务好.对于每一行的查询语句,InnoDB都会把这个查询语句的版本号同这个查询雨具遇到的行的版本号进行对比,然后结合不同的事务隔离级别来决定是否返回改行. 下面以SELECT,DELETE,INSERT,UPDATE为例: SELECT只有同时满足下面俩个条件的行才能被返回: 行的版本号小于等于该事务的版本号 行的删除版本号要么没有定义,要么大于等于事务的版本号如果行的修改或者删除版本号大于事务号,说明行是被该食物后面启动的事务修改或者删除的 DELETEInnoDB直接把该行的删除版本号设置为当前的事务号,相当于标记为删除而不是物理删除 INSERT对于新插入的行,行的修改版本号更新为该事务的事务号 UPDATE更新行的时候,InnoDB会把原来的行复制一份,并把当前的事务号作为改行的修改版本号 事务异常","categories":[{"name":"数据库","slug":"数据库","permalink":"https://wangmingco.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[]},{"title":"AWK","slug":"编程语言/AWK","date":"2015-10-07T16:00:00.000Z","updated":"2021-11-18T02:53:52.417Z","comments":true,"path":"2015/10/08/编程语言/AWK/","link":"","permalink":"https://wangmingco.github.io/2015/10/08/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/AWK/","excerpt":"","text":"AWKawk就是把文件逐行的读入，以空格为默认分隔符将每行切片，切开的部分再进行各种分析处理。 语法 1awk [-F field-separator] &#x27;commands&#x27; input-file(s) -F: 域分隔符,由域分隔符分开的每一项称为一个域。通常，在不指名-F域分隔符的情况下，默认的域分隔符是空格。(我们指定:为分隔符-F &#39;:&#39;) commands: ‘PATTERN{COMMAND}’. PATTERN为模式(正在表达式),COMMAND为要执行的命令. 1awk -F &#x27;:&#x27; &#x27;BEGIN &#123;print &quot;start&quot;&#125; &#123;print $1&quot;&#125; END &#123;print &quot;end&quot;&#125;&#x27; ./txt 上面的例子是读取txt文件,然后使用:分割每一行数据,在开始处理的时候输出start，在处理过程中第一列数据，最后输出end。 变量内置变量我们可以在AWK命令中直接使用以下内置变量 1234567891011ARGC 命令行参数个数ARGV 命令行参数排列ENVIRON 支持队列中系统环境变量的使用FILENAME awk浏览的文件名FNR 浏览文件的记录数FS 设置输入域分隔符，等价于命令行 -F选项NF 浏览记录的域的个数NR 已读的记录数OFS 输出域分隔符ORS 输出记录分隔符RS 控制记录分隔符 例如 1jps -l | awk &#x27;&#123;print ARGC&#125;&#x27; 自定义变量我们通过赋值的方式直接定义一个变量 1jps -l | awk &#x27;BEGIN&#123;size=0;&#125; &#123;size=1+size&#125; &#123;print $1&#125; END&#123;print size&#125;&#x27; 上面我们定义了一个数值型的size变量. 数组运算符 = += -= *= /= %= ^= **= 赋值 ?: C条件表达式 || 逻辑或 &amp;&amp; 逻辑与 ~ ~! 匹配正则表达式和不匹配正则表达式 &lt; &lt;= &gt; &gt;= != == 关系运算符 空格 连接 + - 加，减 * / &amp; 乘，除与求余 + - ! 一元加，减和逻辑非 ^ *** 求幂 ++ -- 增加或减少，作为前缀或后缀 $ 字段引用 in 数组成员 流程控制条件语句下面输出了大于10000的java进程号 1jps -l | awk &#x27;BEGIN&#123;size=0&#125; &#123;if($1&gt;10000) &#123;size++;print $1&#125;&#125; END&#123;print size&#125;&#x27; 循环语句awk中的循环语句借鉴于C语言，支持while、do/while、for、break、continue，这些关键字的语义和C语言中的语义完全相同。 字符串处理sub函数匹配从左侧开始找到的第一个符合规则的字符串，然后使用替换字符串替换这些字符串 1jps -l | awk &#x27;&#123;sub(/moon/, &quot;sun&quot;)&#125; &#123;print $2&#125;&#x27; 上面这个例子就使用sun这个字符串替换了$2中的moon字符串。 我们还可以指定在哪列执行查找替换 1jps -l | awk &#x27;&#123;sub(/moon/, &quot;sun&quot;, $1)&#125; &#123;print $2&#125;&#x27; 上面的例子中我们只在第一列进行查找替换 gsub函数与sub函数不同的是，这个执行的是全局替换 1jps -l | awk &#x27;&#123;gsub(/moon/, &quot;sun&quot;)&#125; &#123;print $2&#125;&#x27; index函数返回子字符串第一次被匹配的位置，偏移量从位置1开始 1jps -l | awk &#x27;&#123;print$2; $2=index($2, &quot;moon&quot;)&#125; &#123;print $2&#125;&#x27; length函数返回记录的字符数 1jps -l | awk &#x27;&#123;print$2; $2=length($2)&#125; &#123;print $2&#125;&#x27; substr函数返回从位置1开始的子字符串，如果指定长度超过实际长度，就返回整个字符串 1jps -l | awk &#x27;&#123;print substr($2, 2, 10)&#125; &#x27; 上面的例子将$2字符串从第二个字符还是截取，截取10个长度的字符串出来 toupper和tolower函数可用于字符串大小间的转换 1awk &#x27;&#123;print toupper($2)&#125; &#x27; split函数可按给定的分隔符把字符串分割为一个数组 1jps -l | awk &#x27;&#123; split($2, array, &quot;/&quot;); print array[3]&#125; &#x27; 上面的例子我们将$2这一列按照/进行分割,然后将分割出的数据存储到array数组里. 注意这里首先不需要转义 正则表达式\\将下一字符标记为特殊字符、文本、反向引用或八进制转义符。例如，“n”匹配字符“n”。“\\n”匹配换行符。序列“\\”匹配“\\”，“(”匹配“(”。 1awk &#x27;/\\\\/&#123;print $0&#125;&#x27; ./txt 过滤出带有\\的行 ^匹配输入字符串与最左侧开始的位置的字符串。 1awk &#x27;/^\\\\n/&#123;print $0&#125;&#x27; ./txt 找到所有以\\n字符串开始的数据 $匹配输入字符串结尾的位置。 1awk &#x27;/)。$/&#123;print $0&#125;&#x27; ./txt 过滤以)。结尾的行 *零次或多次匹配前面的字符或子表达式。例如，zo* 匹配“z”和“zoo”。* 等效于 {0,}。 1awk &#x27;/反向引用*/&#123;print $0&#125;&#x27; ./txt +一次或多次匹配前面的字符或子表达式。例如，“zo+”与“zo”和“zoo”匹配，但与“z”不匹配。+ 等效于 {1,}。 1awk &#x27;/反向引用+/&#123;print $0&#125;&#x27; ./txt ?零次或一次匹配前面的字符或子表达式。例如，“do(es)?”匹配“do”或“does”中的“do”。? 等效于 {0,1}。 1awk &#x27;/反向引用?/&#123;print $0&#125;&#x27; ./txt {n}n 是非负整数。正好匹配 n 次。例如，“o{2}”与“Bob”中的“o”不匹配，但与“food”中的两个“o”匹配。 1 {n,}n 是非负整数。至少匹配 n 次。例如，“o{2,}”不匹配“Bob”中的“o”，而匹配“foooood”中的所有 o。“o{1,}”等效于“o+”。“o{0,}”等效于“o*”。 1 {n,m}M 和 n 是非负整数，其中 n &lt;= m。匹配至少 n 次，至多 m 次。例如，“o{1,3}”匹配“fooooood”中的头三个 o。’o{0,1}’ 等效于 ‘o?’。注意：您不能将空格插入逗号和数字之间。 1 .匹配除“\\n”之外的任何单个字符。若要匹配包括“\\n”在内的任意字符，请使用诸如“[\\s\\S]”之类的模式。 1 (pattern)匹配 pattern 并捕获该匹配的子表达式。可以使用 $0…$9 属性从结果“匹配”集合中检索捕获的匹配。若要匹配括号字符 ( )，请使用“(”或者“)”。 1 (?:pattern)匹配 pattern 但不捕获该匹配的子表达式，即它是一个非捕获匹配，不存储供以后使用的匹配。这对于用“or”字符 (|) 组合模式部件的情况很有用。例如，’industr(?:y|ies) 是比 ‘industry|industries’ 更经济的表达式。 1 (?=pattern)执行正向预测先行搜索的子表达式，该表达式匹配处于匹配 pattern 的字符串的起始点的字符串。它是一个非捕获匹配，即不能捕获供以后使用的匹配。例如，’Windows (?=95|98|NT|2000)’ 匹配“Windows 2000”中的“Windows”，但不匹配“Windows 3.1”中的“Windows”。预测先行不占用字符，即发生匹配后，下一匹配的搜索紧随上一匹配之后，而不是在组成预测先行的字符后。 1 (?!pattern)执行反向预测先行搜索的子表达式，该表达式匹配不处于匹配 pattern 的字符串的起始点的搜索字符串。它是一个非捕获匹配，即不能捕获供以后使用的匹配。例如，’Windows (?!95|98|NT|2000)’ 匹配“Windows 3.1”中的 “Windows”，但不匹配“Windows 2000”中的“Windows”。预测先行不占用字符，即发生匹配后，下一匹配的搜索紧随上一匹配之后，而不是在组成预测先行的字符后。 1 x|y匹配 x 或 y。 1awk &#x27;/换页符等|十六进制转义码必须正好是两位数长/ &#123;print $0&#125;&#x27; ./txt [xyz]匹配是否包含xyz中任意一个字符 1awk &#x27;/[前面至少有]/ &#123;print $0&#125;&#x27; ./txt [^xyz]匹配不能包含xyz任意一个字符 1awk &#x27;/[^前面至少有]/ &#123;print $0&#125;&#x27; ./txt [a-z]与[xyz]规则相同,只不过这个模式提供了一个范围模式.例如[a-c]实际为匹配[abc] 1awk &#x27;/[a-b]/ &#123;print $0&#125;&#x27; ./txt [^a-z]反向范围字符。匹配不在指定的范围内的任何字符。例如，“[^a-z]”匹配任何不在“a”到“z”范围内的任何字符。 1awk &#x27;/[^a-z]/ &#123;print $0&#125;&#x27; ./txt 需要注意的是’\\t’会被匹配出来 \\d数字字符匹配。等效于 [0-9]。 1awk &#x27;/\\d/ &#123;print $0&#125;&#x27; ./txt \\D非数字字符匹配。等效于 [^0-9]。 1awk &#x27;/\\D/ &#123;print $0&#125;&#x27; ./txt \\n换行符匹配。等效于 \\x0a 和 \\cJ。 1awk &#x27;/\\n/ &#123;print $0&#125;&#x27; ./txt \\r匹配一个回车符。等效于 \\x0d 和 \\cM。 1awk &#x27;/\\t/ &#123;print $0&#125;&#x27; ./txt \\s匹配任何空白字符，包括空格、制表符、换页符等。与 [ \\f\\n\\r\\t\\v] 等效。 1awk &#x27;/\\s/ &#123;print $0&#125;&#x27; ./txt \\S匹配任何非空白字符。与 [^ \\f\\n\\r\\t\\v] 等效。 1awk &#x27;/\\S/ &#123;print $0&#125;&#x27; ./txt \\w匹配任何字类字符，包括下划线。与“[A-Za-z0-9_]”等效。 1awk &#x27;/\\w/ &#123;print $0&#125;&#x27; ./txt \\W与任何非单词字符匹配。与“[^A-Za-z0-9_]”等效。 1awk &#x27;/\\W/ &#123;print $0&#125;&#x27; ./txt","categories":[{"name":"awk","slug":"awk","permalink":"https://wangmingco.github.io/categories/awk/"}],"tags":[]},{"title":"Shell 编程","slug":"编程语言/shell","date":"2015-10-07T16:00:00.000Z","updated":"2021-11-18T02:28:57.342Z","comments":true,"path":"2015/10/08/编程语言/shell/","link":"","permalink":"https://wangmingco.github.io/2015/10/08/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/shell/","excerpt":"","text":"每个shell脚本文件第一行都要指定使用哪个shell,我们默认使用#!/bin/bash 变量变量类型运行shell时，会同时存在三种变量： 局部变量： 局部变量在脚本或命令中定义，仅在当前shell实例中有效，其他shell启动的程序不能访问局部变量。 环境变量：所有的程序，包括shell启动的程序，都能访问环境变量，有些程序需要环境变量来保证其正常运行。必要的时候shell脚本也可以定义环境变量。 shell变量：shell变量是由shell程序设置的特殊变量。shell变量中有一部分是环境变量，有一部分是局部变量，这些变量保证了shell的正常运行 变量声明1v1=123 在上面的声明语法中我们需要注意以下几点 =左右不能用空格 变量的默认类型是字符串 该变量对当前以及子shell都有效 命令结果赋值将命令执行的结果作为值传送给一个变量可以使用 123dirName=`date +%Y_%m_%d_%H_%M_%S`#或者dirName=$(date +%Y_%m_%d_%H_%M_%S) 12345678910Group_port=18080port_name=Groupport=\\$$&#123;port_name&#125;&quot;_port&quot;port1=`eval echo $port`echo $&#123;port&#125;echo $&#123;port1&#125;echo $&#123;Group_port&#125; 变量引用我们通过使用$或者$&#123;&#125;符号可以引用一个变量 123v=1echo $vecho $&#123;v&#125; 需要注意的是, $()是用来做命令替换的(\\`也是用来做命令替换的), 而${}是用来做变量替换的($var与${var}`并没有啥不一样) 只读变量readonly 命令可以将变量定义为只读变量 1readonly myUrl 删除变量1unset myUrl 特殊变量 $0: 当前脚本的文件名 $n: 传递给脚本或函数的参数。(第一个参数是$1，第二个参数是$2) $#: 传递给脚本或函数的参数个数。 $*: 传递给脚本或函数的所有参数。 $@: 传递给脚本或函数的所有参数。被双引号(“ “)包含时，与 $* 稍有不同 $?: 上个命令的退出状态，或函数的返回值。 $$: 当前Shell进程ID。对于 Shell 脚本，就是这些脚本所在的进程ID。 数组数组定义一对括号表示是数组，数组元素用“空格”符号分割开。 1array=(1 2 3 4 5) 数组长度12$&#123;#数组名[@或*]&#125; : 可以得到数组长度$&#123;#array[@]&#125; 索引数组成员$&#123;数组名[下标]&#125; : 下标是从0开始 (下标是：*或者@ 得到整个数组内容) 1$&#123;array[2]&#125; 数组成员赋值数组名[下标]: 进行数组元素引用，如果下标不存在，自动添加新一个数组元素 1array[1]=100 删除数组unset 数组[下标]：删除下标相应的元素，不带下标，则删掉整个数组。 1unset array[1] 数组分片$&#123;数组名[@或*]:起始位置:长度&#125;： 切片数组，返回一个用“空格”分割元素的字符串 如果加上()，将得到切片数组 1c=($&#123;array[@]:1:4&#125;) 数组替换$&#123;数组名[@或*]/查找字符/替换字符&#125;: 该操作不会改变原先数组内容 1$&#123;array[@]/old/new&#125; 运算符算术运算符我们可以使用expr, let, (()), []等四种方式进行算术运算 +: 加法 (($a + $b)) - : 减法(($a - $b)) *: 乘法 (($a \\* $b)) /: 除法 (($b / $a)) %: 取余 (($b % $a)) =: 赋值 a=$b ==: 相等。用于比较两个数字，相同则返回 true。 [ $a == $b ] 返回 false。 !=: 不相等。用于比较两个数字，不相同则返回 true。 [ $a != $b ] 返回 true。 关系运算符关系运算符只支持数字，不支持字符串，除非字符串的值是数字。 -eq 检测两个数是否相等，相等返回 true。 [ $a -eq $b ] 返回 true。 -ne 检测两个数是否相等，不相等返回 true。 [ $a -ne $b ] 返回 true。 -gt 检测左边的数是否大于右边的，如果是，则返回 true。 [ $a -gt $b ] 返回 false。 -lt 检测左边的数是否小于右边的，如果是，则返回 true。 [ $a -lt $b ] 返回 true。 -ge 检测左边的数是否大等于右边的，如果是，则返回 true。 [ $a -ge $b ] 返回 false。 -le 检测左边的数是否小于等于右边的，如果是，则返回 true。 [ $a -le $b ] 返回 true。 逻辑运算符 ! 非运算，表达式为 true 则返回 false，否则返回 true。 [ ! false ] 返回 true。 -o 或运算，有一个表达式为 true 则返回 true。 [ $a -lt 20 -o $b -gt 100 ] 返回 true。 -a 与运算，两个表达式都为 true 才返回 true。 [ $a -lt 20 -a $b -gt 100 ] 返回 false。 字符串运算符 = 检测两个字符串是否相等，相等返回 true。 [ $a = $b ] 返回 false。 != 检测两个字符串是否相等，不相等返回 true。 [ $a != $b ] 返回 true。 -z 检测字符串长度是否为0，为0返回 true。 [ -z $a ] 返回 false。 -n 检测字符串长度是否为0，不为0返回 true。 [ -z $a ] 返回 true。 str 检测字符串是否为空，不为空返回 true。 [ $a ] 返回 true。 文件测试运算符 -b 文件是否是块设备文件，如果是，则返回 true。 [ -b $file ] 返回 false。 -c 文件是否是字符设备文件，如果是，则返回 true。 [ -b $file ] 返回 false。 -d 文件是否是目录，如果是，则返回 true。 [ -d $file ] 返回 false。 -f 文件是否是普通文件（既不是目录，也不是设备文件），如果是，则返回 true。 [ -f $file ] 返回 true。 -g 文件是否设置了 SGID 位，如果是，则返回 true。 [ -g $file ] 返回 false。 -k 文件是否设置了粘着位(Sticky Bit)，如果是，则返回 true。 [ -k $file ] 返回 false。 -p 文件是否是具名管道，如果是，则返回 true。 [ -p $file ] 返回 false。 -u 文件是否设置了 SUID 位，如果是，则返回 true。 [ -u $file ] 返回 false。 -r 文件是否可读，如果是，则返回 true。 [ -r $file ] 返回 true。 -w 文件是否可写，如果是，则返回 true。 [ -w $file ] 返回 true。 -x 文件是否可执行，如果是，则返回 true。 [ -x $file ] 返回 true。 -s 文件是否为空（文件大小是否大于0），不为空返回 true。 [ -s $file ] 返回 true。 -e 文件（包括目录）是否存在，如果是，则返回 true。 [ -e $file ] 返回 true。 流程控制shell流程控制包含： if while until case for 同样的shell也支持break和continue ifcondition 可以使用 文件测试运算符 或者 关系运算符 进行条件判断 语法格式 1234567if conditionthen command1 command2 ... commandNfi 示例 123456#!/bin/bashv=123if [ -b $txt ]; then echo &quot;ok&quot;;fi 我们一定要注意if前后的空格 if else 123456789if conditionthen command1 command2 ... commandNelse commandfi if else-if else 12345678if condition1then command1elif condition2 command2else commandNfi case case语句为多选择语句 1234567891011121314case 值 in模式1) command1 command2 ... commandN ;;模式2） command1 command2 ... commandN ;;esac 示例 123456789101112131415161718#!/bin/bashfor i in 1 2 3 4 5;do case $i in 1) echo &#x27;你选择了 1&#x27; ;; 2) echo &#x27;你选择了 2&#x27; ;; 3) echo &#x27;你选择了 3&#x27; ;; 4) echo &#x27;你选择了 4&#x27; ;; *) echo &#x27;你没有输入 1 到 4 之间的数字&#x27; ;; esacdone for1234567for var in item1 item2 ... itemNdo command1 command2 ... commandNdone 示例 123456#!/bin/bashfor i in 1 2 3 4;do echo $idone while1234while conditiondo commanddone 示例 12345678#!/bin/bashi=1while(( $i&lt;=5 ))do echo $i ((i++))done untiluntil循环执行一系列命令直至条件为真时停止。 1234until conditiondo commanddone 示例 12345678#!/bin/bashi=1until(( $i&gt;3 ))do echo $i ((i++))done 函数调用函数不需要加() 12345vi=123546789f() &#123; echo $vi&#125;f 带参数的函数参数名是固定的$n, 如果参数大于10的话就需要$&#123;10&#125; 1234f() &#123;echo $1&#125;f 789 函数的返回值函数返回值在调用该函数后通过 $? 来获得 12345f() &#123;echo $1&#125;f 789echo $? 如果不写return, 则直接返回0 123456f() &#123;echo $1return 569&#125;f 789echo $? 在当前shell里执行一个文件里的命令：1source /home/user/file.name","categories":[{"name":"Shell","slug":"Shell","permalink":"https://wangmingco.github.io/categories/Shell/"}],"tags":[]},{"title":"java lambda","slug":"JavaSE/Java8 lambda","date":"2015-09-07T16:00:00.000Z","updated":"2021-11-18T02:43:24.248Z","comments":true,"path":"2015/09/08/JavaSE/Java8 lambda/","link":"","permalink":"https://wangmingco.github.io/2015/09/08/JavaSE/Java8%20lambda/","excerpt":"","text":"函数接口函数接口定义函数接口只是一个抽象方法的接口,用作lambda表达式类型. 注意, 上面这个定义有三个需要注意的地方 函数接口是一个接口 函数接口有且只有一个抽象方法(只有一个表示数量上是唯一的,重载也是不可以) 函数接口用作lambda表达式类型 函数接口示例:12345678910111213141516// 定义一个非泛型没有返回值没有参数的函数接口interface Run1 &#123; public void runFast();&#125;// 定义一个非泛型没有返回值有参数的函数接口interface Run2 &#123; public void runFast(int seconds);&#125;// 定义一个非泛型有返回值有参数的函数接口interface Run3 &#123; public int runFast(int seconds);&#125;// 定义一个泛型有返回值有参数的函数接口interface Run4&lt;T&gt; &#123; public int runFast(T t, int seconds);&#125; 默认方法我们知道java8对核心集合类进行了大幅度修改,例如Collection接口添加了stream()方法. 那么所有的Collection实现类都必须来实现该方法. 为了保持二进制接口的兼容性,java8提供了默认方法,来保证这一兼容性(例如来源在java1到jav7平台写出的代码仍然可以在java8平台上编译运行) 123456789101112131415161718interface Run10 &#123; public void runFast(); public default void runAt9Clock() &#123; System.out.println(&quot;run10 runAt9Clock&quot;); &#125;&#125;interface Run11 extends Run10 &#123;&#125;// 调用Run11 run11 = () -&gt; &#123; System.out.println();&#125;;run11.runAt9Clock(); 那么所有的子类都可以来调用这个默认方法, 而不必实现它。 如果接口中只有一个默认方法,那么这个接口就不是接口函数. 继承默认方法1234567891011121314interface Run11 extends Run10 &#123; public default void runAt9Clock() &#123; System.out.println(&quot;run11 runAt9Clock&quot;); &#125;&#125;class Run12 implements Run10 &#123; @Override public void runFast() &#123;&#125; public void runAt9Clock() &#123; System.out.println(&quot;run12 runAt9Clock&quot;); &#125;&#125; 从上面的例子中我们可以看到如果接口Run11继承了接口Run10, 同时重载了默认方法, 那么Run11中的默认方法也必须含有default关键字. 但是在类中重载的话,就可以不必存在了. 1234567891011Run11 run11 = () -&gt; &#123; System.out.println();&#125;;run11.runAt9Clock();Run12 run12 = new Run12();run12.runAt9Clock();//resultrun11 runAt9Clockrun12 runAt9Clock 接着我们都调用默认方法,我们发现当调用默认方法时都会优先调用子类中的方法. 多重继承123456789101112131415161718interface Run10 &#123; public default void runAt9Clock() &#123; System.out.println(&quot;run10 runAt9Clock&quot;); &#125;&#125;interface Run13 &#123; public default void runAt9Clock() &#123; System.out.println(&quot;run13 runAt9Clock&quot;); &#125;&#125;class Run14 implements Run10, Run13 &#123; @Override public void runAt9Clock() &#123; &#125;&#125; 在上面这个情况下,我们需要手动在Run14这个类中指定重载哪个方法, 否则会产生编译错误： 123456class Run14 implements Run10, Run13 &#123; @Override public void runAt9Clock() &#123; Run10.super.runAt9Clock(); &#125;&#125; 接口静态方法我们定义一个接口静态方法 12345678910interface Run1 &#123; public void runFast(); public static void runSlowly() &#123; System.out.println(&quot;run1 run slowly&quot;); &#125;&#125;//Run1.runSlowly(); 需要注意的是： 接口静态方法不会被继承到子接口或者子类中 @FunctionalInterface所有的函数接口都应该添加@FunctionalInterface注释. 该注释会强制检查javac检查一个接口是否符合函数接口的标准. 如果将这个注释添加给类，枚举，多个方法的接口都会产生编译错误. lambda表达式lambda表达式定义接下来我们根据上面定义的函数接口来定义一下lambda表达式 123456789101112131415161718192021// 不带参数的版本Run1 run1 = () -&gt; &#123; System.out.println(&quot;I am running&quot;);&#125;;// 参数要指定Run2 run2 = seconds -&gt; &#123; System.out.println(&quot;I am running &quot; + seconds + &quot; seconds&quot;);&#125;;// 下面这个版本就必须要有个返回值了Run3 run3 = seconds -&gt; &#123; System.out.println(&quot;I am running&quot;); return 0;&#125;;// 我们在下面的版本中指定了它的泛型信息Run4&lt;String&gt; run4 = (name, seconds) -&gt; &#123; System.out.println(name + &quot; is running&quot;); return 0;&#125;; lambda表达式使用接下来我们使用上面定义的lambda表达式 1234567891011run1.runFast();-&gt; I am runningrun2.runFast(10);-&gt; I am running 10 secondsint result = run3.runFast(10);-&gt; I am runningrun4.runFast(&quot;小狗&quot;, 10); 小狗 is running-&gt; 注意我们引用lambda表达式外部的一个变量 1234String name = &quot;sam&quot;;Run1 run1 = () -&gt; &#123; System.out.println(name + &quot; am running&quot;);&#125;; 编译运行通过没有问题,但是如果我们将name在lambda表达式内部重新赋值的话 12345String name = &quot;sam&quot;;Run1 run1 = () -&gt; &#123; name = &quot;&quot;; System.out.println(name + &quot; am running&quot;);&#125;; 会提示variable used in lambda expression shouble be final, 这说明lambda其实内部引用的是值而不是变量. 好,接下来我们换种方式再次验证一下我们的结果： 12345String name = &quot;sam&quot;;name = &quot;Jams&quot;;Run1 run1 = () -&gt; &#123; System.out.println(name + &quot; am running&quot;);&#125;; 同样的产生了编译错误. java中重要的函数接口 Predicate&lt;T&gt;: boolean test(T t) 判断输入的对象是否符合某个条件 Consumer&lt;T&gt;: void accept(T t); 接收一个输入参数并且没有返回值 Supplier&lt;T&gt;: T get(); 可以看成一个对象的工厂，每次调用返回一个给定类型的对象 UnaryOperator&lt;T&gt;: `` BinaryOperator&lt;T&gt;: `` 函数在Java8中什么是函数呢？ 123Run1 run1 = () -&gt; &#123; System.out.println(&quot;I am running&quot;);&#125;; 上面run1这个就代表一个函数. 一般我们把属于某个类的函数称为方法, 而不依赖于类而存在的函数称之为方法. 高阶函数如果某个函数A作为函数B的参数或者返回值, 那么我们称函数B为高阶函数,像下面的run6就是一个高级函数 12345678910interface Run6 &#123; public void run(Run1 run1);&#125;Run6 run6 = run1Param -&gt; &#123; System.out.println(&quot;run6&quot;); run1Param.runFast(); &#125;;run6.run(run1); 我们将run1这个函数作为方法传递给了run6. 返回函数123456789101112131415interface Run8 &#123; public void run(String name, int second, int mils);&#125;interface Run9 &#123; public Run8 run(Run8 run8);&#125;Run8 run8 = (name, second, mils) -&gt; &#123; System.out.println();&#125;;Run9 run9 = run8Param -&gt; &#123; return run8Param.run(&quot;lily&quot;);&#125;; 在上述的例子中产生了编译错误, 在Haskell这种纯FP语言中可以将一个调用函数但是参数不完整的函数从某个参数中返回或者定义一个参数不完整的函数值. 重载解析我们使用函数接口作为方法参数,然后进行重载 1234567891011121314151617181920212223// 定义函数接口interface Run1 &#123; public void runFast();&#125;interface Run2 &#123; public void runFast();&#125;// 定义重载代码 public static void run(Run1 run1)&#123; System.out.println(&quot;run1&quot;); &#125; public static void run(Run2 run2)&#123; System.out.println(&quot;run2&quot;); &#125;// 定义运行代码public static void main(String[] args) &#123; run(() -&gt; System.out.println());&#125; 当我们进行如上定义时,javac提示了编译错误：不确定的方法调用,run(Run1 run1)和run(Run2 run2)都符合. 但是如果Run2继承了Run1这个接口之后 1234567interface Run1 &#123; public void runFast();&#125;interface Run2 extends Run1 &#123; public void runFast();&#125; 当我们运行测试代码之后,我们发现输出的run2. 当Lambda表达式作为参数时,其类型由它的目标类型推导得出,推导过程遵循如下规则： 如果只有一个可能的目标类型,由相应的函数接口里的参数类型推导得出 如果有多个可能的目标类型，由最具体的类型推导得出 如果有多个可能的目标类型且最具体的类型不明确，则需要人为指定类型 方法引用方法引用是简洁的Lambda表达式，能够用于已经拥有名称的方法。 静态方法 (ClassName::methName) 对象实例方法 (instanceRef::methName) 类型的实例方法 (ClassName::methName, 引用时和静态方法是一样的，但这里的 methName 是个实例方法) 构造方法 (ClassName::new) 数组的构造方法 (TypeName[]::new) 静态方法引用12345678910111213141516public class Print &#123; public static void main(String[] args) throws Exception &#123; F f = Print::p; f.m(); &#125; public static void p() &#123; System.out.println(&quot;Print&quot;); &#125;&#125;@FunctionalInterfaceinterface F &#123; void m();&#125; 类型实例方法引用123456789101112public class Print &#123; public static void main(String[] args) throws Exception &#123; F f = String::length; int len = f.m(&quot;12&quot;); System.out.println(len); &#125;&#125;@FunctionalInterfaceinterface F &#123; int m(String p);&#125; 构造方法引用123456789101112public class Print &#123; public static void main(String[] args) throws Exception &#123; F f = Print::new; Print p = f.m(); System.out.println(p == null); // 结果为null &#125;&#125;@FunctionalInterfaceinterface F &#123; Print m();&#125; 闭包Java8还提供了闭包这个特性,虽然我不知道闭包这个特性有啥用,但是还是实验了一下 1234567891011121314151617181920212223242526272829303132333435public class Java8 &#123; public static void main(String[] args) &#123; I i = () -&gt; &#123; C c = new C(); c.count = 10; J j = () -&gt; &#123; System.out.println(&quot;J print c:&quot; + c.count); return c; &#125;; System.out.println(&quot;I print c:&quot; + c.count); return j; &#125;; J j = i.r(); C c = j.c(); c.count = 20; System.out.println(&quot;main print c:&quot; + c.count); &#125;&#125;interface I &#123; public J r();&#125;interface J &#123; public C c();&#125;class C &#123; public int count;&#125; 我们定义了俩个接口, I和J, 我们在I的lambada中调用J的lambada, 然后让J返回一个定义在I的对象C, 最后我们在main函数中成功的返回了这个对象.","categories":[{"name":"Java","slug":"Java","permalink":"https://wangmingco.github.io/categories/Java/"}],"tags":[]},{"title":"java8 流","slug":"JavaSE/Java8 流","date":"2015-09-07T16:00:00.000Z","updated":"2021-11-18T02:39:48.282Z","comments":true,"path":"2015/09/08/JavaSE/Java8 流/","link":"","permalink":"https://wangmingco.github.io/2015/09/08/JavaSE/Java8%20%E6%B5%81/","excerpt":"","text":"流java8中新添加的流又称为Streams API. 它是对集合（Collection）对象功能的增强，它专注于对集合对象进行各种非常便利、高效的聚合操作（aggregate operation），或者大批量数据操作 (bulk data operation). 接下来我们构建一个流: 123Stream.of(1, 2, 3) .filter(ele -&gt; ele.equals(&quot;123&quot;)) .count(); 我们通过上述代码构建流一个流,这里有俩个概念要说: 惰性求值方法:像filter方法,它只是在刻画Stream,它并不会被调用.(在Stream方法中凡事返回Stream对象的都是这种方法) 及早求值方法:像count方法,它会从Stream中最终产生值.(在Stream方法中凡事返回空或者另一个值都是这种方法) 常用的流操作collect()该方法会产生一个列表,是一个及早求值方法. 123Stream.of(1, 2, 3) .filter(ele -&gt; ele.equals(&quot;123&quot;)) .collect(Collectors.toList()); 当然我们还可以调用Collectors.toSet()等其他方法,构建其他集合 map该操作会将一个流中的值转换为一个新的流 12345678910Stream.of(1, 2, 3) .map(num -&gt; &#123; if (num &gt; 1) &#123; return 0; &#125; else &#123; return 1; &#125; &#125;) .collect(Collectors.toSet()) .forEach(ele -&gt; System.out.println(ele)); filter遍历数据并检查其中的元素是否符合某种条件 这个操作看起来和map很像, 但是map是根据操作的结果产生新的流,而filter是判断流中的数据是否符合条件保留下来 12345678910Stream.of(1, 2, 3) .filter(ele -&gt; &#123; if (ele &gt; 1) &#123; return true; &#125; else &#123; return false; &#125; &#125;) .collect(Collectors.toSet()) .forEach(ele -&gt; System.out.println(ele)); flatMap用于Stream替换值然后将多个流连接到一起 首先我们看一种情况,流里有俩个列表 1234567 Stream.of(Arrays.asList(1, 2, 3),Arrays.asList(7, 8, 9)) .collect(Collectors.toSet()) .forEach(ele -&gt; System.out.println(ele));输出的结果是:[1, 2, 3][7, 8, 9] 如果我们想将这俩个列表组合到一起呢? 123456Stream.of(Arrays.asList(1, 2, 3),Arrays.asList(7, 8, 9)) .flatMap(list -&gt; &#123; return list.stream(); &#125;) .collect(Collectors.toSet()) .forEach(ele -&gt; System.out.println(ele)); 看到了吧,我们首先讲列表转换成流,然后由flatMap操作将流组合到一起 max查找流中的最大值 1234Integer max = Stream.of(1, 2, 3) .max(Comparator.comparing(ele -&gt; ele)) .get(); System.out.println(max); 我们需要向max操作中传递一个排序的动作. Comparator.comparing()这个静态方法是java8新添加的方法,它实现流一个方便的比较器.以前我们需要比较俩个对象的某项属性的值,现在只需要提供一个取值方法就好了. min查找流中的最小值 1234Integer min = Stream.of(1, 2, 3) .min(Comparator.comparing(ele -&gt; ele)) .get(); System.out.println(min); 和max相似 reduce从一组值生成一个值. 12345Integer sum = Stream.of(1, 2, 3) .reduce((inSum, element) -&gt; &#123; return inSum + element; &#125;).get(); System.out.println(sum); reduce中的BinaryOperator类型的lambda表达式第一个参数是上个元素执行reduce操作的结果, 第二个参数是流中的每个元素. 另外Stream中还有其他的reduce操作,可以指定开始结束的的位置 元素顺序在一个有序集合中创建一个流时，流中元素就按照出现的顺序进行排列: 1Arrays.asList(1, 2, 3).stream().forEach(ele -&gt; System.out.println(ele)); 上面这个输出顺序总是1, 2, 3. 而如果一个集合本身是无序的话，那么生成的流也是无序的，最后由流生成的集合也是无序的 使用收集器java.util.stream.Collectors这是java提供的一种通用的，从流生成复杂值结构的收集器. 转换成其他集合Collectors提供了转换成其他集合的方式 Collectors.toCollection()： 接受一个函数作为参数，来创建集合 Collectors.toConcurrentMap() Collectors.toList()： 不需要指定具体的类型，Stream会自动挑选出合适的类型 Collectors.toMap() Collectors.toSet()： 不需要指定具体的类型，Stream会自动挑选出合适的类型 groupingBy数据分组 lambda表达式类型 123public interface Function&lt;T, R&gt; &#123; R apply(T t);&#125; 示例： 123456789101112131415161718192021222324252627List&lt;Integer&gt; list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8); Map&lt;Integer, List&lt;Integer&gt;&gt; group = list.stream().collect(Collectors.groupingBy(ele -&gt; &#123; if (ele &gt; 5) &#123; return 1; &#125; else &#123; return 2; &#125; &#125;));// 最后结果为&#123;1:[ 10, 9, 11, 6, 7, 8 ], 2:[ 1, 2, 3, 2, 4, 5 ]&#125; 当然分组的key,我们还可以取其他的类型,这完全取决于我们的返回值 1234567Map&lt;String, List&lt;Integer&gt;&gt; group = list.stream().collect(Collectors.groupingBy(ele -&gt; &#123; if (ele &gt; 5) &#123; return &quot;1&quot;; &#125; else &#123; return &quot;2&quot;; &#125; &#125;)); groupingByConcurrent并发版本的group by实现 lambda表达式类型 123public interface Function&lt;T, R&gt; &#123; R apply(T t);｝ 示例： 123456789101112List&lt;Integer&gt; list = Arrays.asList(1, 10, 2, 3, 2);ConcurrentMap&lt;Integer, List&lt;Integer&gt;&gt; result = list.stream().collect(Collectors.groupingByConcurrent(ele -&gt; ele - 3));// 结果&#123;-2:[1], -1:[ 2, 2 ], 0:[3], 7:[10]&#125; partitioningBy数据分组,key为True和False lambda表达式类型 123public interface Predicate&lt;T&gt; &#123; boolean test(T t);｝ 示例： 1234567891011121314151617181920List&lt;Integer&gt; list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);Map&lt;Boolean, List&lt;Integer&gt;&gt; result = list.stream().collect(Collectors.partitioningBy(ele -&gt; ele == 1));System.out.println(JSON.toJSONString(result, true));// 结果为&#123;false:[ 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8 ],true:[1]&#125; averagingDoublelambda表达式类型 123public interface ToDoubleFunction&lt;T&gt; &#123; double applyAsDouble(T value);&#125; 示例： 12345List&lt;Integer&gt; list = Arrays.asList(1, 10, 2, 3, 2);Double result = list.stream().collect(Collectors.averagingDouble(ele -&gt; ele - 3));// 结果0.6 averagingIntlambda表达式类型 123public interface ToIntFunction&lt;T&gt; &#123; int applyAsInt(T value);&#125; 示例： 1234List&lt;Integer&gt; list = Arrays.asList(1, 10, 2, 3, 2);Double result = list.stream().collect(Collectors.averagingInt(ele -&gt; ele - 3));// 结果0.6 averagingLong对流中数据进行进行平均数操作 lambda表达式类型 123public interface ToLongFunction&lt;T&gt; &#123; long applyAsLong(T value);&#125; 示例： 12List&lt;Integer&gt; list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);Double result = list.stream().collect(Collectors.averagingLong(ele -&gt; ele)); summarizingIntlambda表达式类型 123public interface ToIntFunction&lt;T&gt; &#123; int applyAsInt(T value);&#125; 示例： 1234567891011List&lt;Integer&gt; list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);IntSummaryStatistics result = list.stream().collect(Collectors.summarizingInt(ele -&gt; ele));// 结果为&#123; &quot;average&quot;:5.666666666666667, &quot;count&quot;:12, &quot;max&quot;:11, &quot;min&quot;:1, &quot;sum&quot;:68&#125; summarizingLong统计流中数据分布 lambda表达式类型 123public interface ToLongFunction&lt;T&gt; &#123; long applyAsLong(T value);&#125; 示例： 1234567891011List&lt;Integer&gt; list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);LongSummaryStatistics result = list.stream().collect(Collectors.summarizingLong(ele -&gt; ele));// 结果为&#123; &quot;average&quot;:5.666666666666667, &quot;count&quot;:12, &quot;max&quot;:11, &quot;min&quot;:1, &quot;sum&quot;:68&#125; summarizingDouble统计流中数据分布 lambda表达式类型 123public interface ToDoubleFunction&lt;T&gt; &#123; double applyAsDouble(T value);&#125; 示例： 1234567891011List&lt;Integer&gt; list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);DoubleSummaryStatistics result = list.stream().collect(Collectors.summarizingDouble(ele -&gt; ele));// 结果&#123; &quot;average&quot;:5.666666666666667, &quot;count&quot;:12, &quot;max&quot;:11, &quot;min&quot;:1, &quot;sum&quot;:68&#125; counting统计流中数据数量 示例： 12List&lt;Integer&gt; list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);Long result = list.stream().collect(Collectors.counting()); maxBy取出一个列表中的最大值,不过我们要自己定义一个对比规则 lambda表达式类型 123public interface Comparator&lt;T&gt; &#123; int compare(T o1, T o2);&#125; 示例： 12List&lt;Integer&gt; list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);Optional&lt;Integer&gt; result = list.stream().collect(Collectors.maxBy((ele1, ele2) -&gt; ele1 - ele2)); minBy取出一个列表中的最大值,不过我们要自己定义一个对比规则 lambda表达式类型 123public interface Comparator&lt;T&gt; &#123; int compare(T o1, T o2);&#125; 示例： 12List&lt;Integer&gt; list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);Optional&lt;Integer&gt; result = list.stream().collect(Collectors.minBy((ele1, ele2) -&gt; ele1 - ele2)); summingDouble对列表数据取和操作,结果为Double lambda表达式类型 123public interface ToDoubleFunction&lt;T&gt; &#123; double applyAsDouble(T value);&#125; 示例： 1234List&lt;Integer&gt; list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);Double result = list.stream().collect(Collectors.summingDouble(ele -&gt; ele));// 结果为68 summingInt对列表数据取和操作,结果为Int lambda表达式类型 123public interface ToIntFunction&lt;T&gt; &#123; int applyAsInt(T value);&#125; 示例： 12List&lt;Integer&gt; list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);Integer result = list.stream().collect(Collectors.summingInt(ele -&gt; ele)); summingLong对列表数据取和操作,结果为Long lambda表达式类型 123public interface ToLongFunction&lt;T&gt; &#123; long applyAsLong(T value);&#125; 示例： 12List&lt;Integer&gt; list = Arrays.asList(1, 10, 2, 3, 2, 9, 4, 5, 11, 6, 7, 8);Long result = list.stream().collect(Collectors.summingLong(ele -&gt; ele)); joining将流中的数据拼接成一个字符串. 需要注意的是如果流中的数据不是String类型的数据,可以通过map操作将流中数据转换成String类型 lambda表达式类型 123public interface Function&lt;T, R&gt; &#123; R apply(T t);&#125; 示例： 1234List&lt;String&gt; list = Arrays.asList(&quot;1&quot;, &quot;10&quot;, &quot;2&quot;, &quot;3&quot;, &quot;2&quot;);String result = list.stream().collect(Collectors.joining(&quot;,&quot;, &quot;(&quot;, &quot;)&quot;));// 结果&quot;(1,10,2,3,2)&quot; reducinglambda表达式类型 1R apply(T t, U u); 示例： 1 mappinglambda表达式类型 123public interface Function&lt;T, R&gt; &#123; R apply(T t);&#125; 示例： 12345678910List&lt;String&gt; list = Arrays.asList(&quot;1&quot;, &quot;10&quot;, &quot;2&quot;, &quot;3&quot;, &quot;2&quot;);List&lt;String&gt; result = list.stream().collect(Collectors.mapping(ele -&gt; ele + 1, Collectors.toList()));// 结果[ &quot;11&quot;, &quot;101&quot;, &quot;21&quot;, &quot;31&quot;, &quot;21&quot;] distinct limit peek skip","categories":[{"name":"Java","slug":"Java","permalink":"https://wangmingco.github.io/categories/Java/"}],"tags":[]},{"title":"Archiva 初探","slug":"JavaLibrary/Archiva","date":"2015-09-07T16:00:00.000Z","updated":"2021-11-18T02:46:01.403Z","comments":true,"path":"2015/09/08/JavaLibrary/Archiva/","link":"","permalink":"https://wangmingco.github.io/2015/09/08/JavaLibrary/Archiva/","excerpt":"","text":"安装步骤 从Archiva官网下载Archiva后解压到D:\\archiva里 运行bin\\archiva.bat install, archiva就启动成功了 在浏览器运行http://localhost:8080/就可以进入archiva本地主页了 当进入之后我们需要创建一个账号： 接着我们创建一个私有的仓库 我们创建一个最简单的私有仓库： 创建一个连接器 同样我们只选用必须的 接着如图操作 然后我们修改项目中的pom.xml文件!12345678910111213141516171819202122232425262728293031323334&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;testMaven&lt;/groupId&gt; &lt;artifactId&gt;testDeply&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;ID2015_09_17&lt;/id&gt; &lt;name&gt;NAME2015_09_17&lt;/name&gt; &lt;url&gt;http://localhost:8080/repository/ID2015_09_17&lt;/url&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;ID2015_09_17&lt;/id&gt; &lt;name&gt;NAME2015_09_17&lt;/name&gt; &lt;url&gt;http://localhost:8080/repository/ID2015_09_17&lt;/url&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;ID2015_09_17&lt;/id&gt; &lt;name&gt;NAME2015_09_17&lt;/name&gt; &lt;url&gt;http://localhost:8080/repository/ID2015_09_17&lt;/url&gt; &lt;/repository&gt; &lt;/distributionManagement&gt;&lt;/project&gt; 修改本地仓库中的setting.xml文件(我的目录C:\\Users\\Administrator\\.m2),我们添加私有仓库的用户名和密码!12345678910111213&lt;settings xmlns=&quot;http://maven.apache.org/settings/1.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd&quot;&gt; &lt;servers&gt; &lt;server&gt; &lt;id&gt;ID2015_09_17&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin1&lt;/password&gt; &lt;/server&gt; &lt;/servers&gt; &lt;/settings&gt;","categories":[{"name":"Java 类库","slug":"Java-类库","permalink":"https://wangmingco.github.io/categories/Java-%E7%B1%BB%E5%BA%93/"}],"tags":[{"name":"Archiva","slug":"Archiva","permalink":"https://wangmingco.github.io/tags/Archiva/"}]},{"title":"JavaScript 变量和流程控制","slug":"前端/JavaScript","date":"2015-09-07T16:00:00.000Z","updated":"2021-11-18T02:53:50.418Z","comments":true,"path":"2015/09/08/前端/JavaScript/","link":"","permalink":"https://wangmingco.github.io/2015/09/08/%E5%89%8D%E7%AB%AF/JavaScript/","excerpt":"","text":"JavaScript是一门基于原型继承的函数式的面向对象的编程语言,对象可以直接从其他对象继承属性,且JavaScript是无类型的. 数据类型数字JavaScript只有一个数字类型,它在内部被表示为64位的浮点数. 它没有分离出整数类型,因此1和1.0的值是相同的 NaN是一个数值，它表示一个不能产生正常结果的运算结果。NaN不等于任何值，包括它自己。可以使用函数isNaN来检测NaN。 字符串字符串可以由一对单引号或者一对双引号构成，可以包含0到多个字符。\\是转义字符。JavaScript采用Unicode16作为字符集，因此所有的字符都是16位的。 字符串有一个length属性，可以获得字符串长度。 字符串同样也是不可变的。一旦字符串被创建出来就无法改变它。我们同+链接其他字符串创建一个新的字符串。俩个包含着相同字符且字符顺序也相同的字符被认为是同一个字符串。===进行字符串判断。 变量我们通过 var关键字来声明一个变量 函数私有变量JavaScript通过函数管理作用域。在函数内部声明的变量只在这个函数内部可用，而在函数外面不可用。 全局变量每个JavaScript环境有一个全局对象，当你在任意的函数外面使用this的时候可以访问到。你创建的每一个全局变量都成了这个全局对象的属性。 控制流程我们可以通过条件语句(if和switch),循环语句（while，for和do）强制跳转语句（break,return，throw）和函数调用来改变执行序列。 if进行if判断时，下列值被作为假： false null 空字符串 &#39;&#39; 数字0 数字NaN switch其表达式的值和case条件进行匹配。表达式可以是字符串或者数字。case表达式不一定必须是常量 12345678switch (num)&#123; case 1: x=&quot;输入正确&quot;; break; default: x=&quot;输入错误&quot;;&#125; while1234while (i&lt;5)&#123; sum += i;&#125; for1234for (var i = 0; i&lt;5; i++)&#123; sum += i;&#125; for…in 12345var array = [1, 2]for (i in array)&#123; sum += i;&#125;","categories":[{"name":"前端","slug":"前端","permalink":"https://wangmingco.github.io/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://wangmingco.github.io/tags/JavaScript/"}]},{"title":"JavaScript函数","slug":"前端/JavaScript函数","date":"2015-09-07T16:00:00.000Z","updated":"2021-11-18T02:53:57.917Z","comments":true,"path":"2015/09/08/前端/JavaScript函数/","link":"","permalink":"https://wangmingco.github.io/2015/09/08/%E5%89%8D%E7%AB%AF/JavaScript%E5%87%BD%E6%95%B0/","excerpt":"","text":"JavaScript是一门基于原型继承的函数式的面向对象的编程语言,对象可以直接从其他对象继承属性,且JavaScript是无类型的. JavaScript中函数就是对象。函数对象连接到Function.prototype(该原型连接到Object.prototype). 每个函数对象在创建时也随配一个prototype属性,它的值是一个拥有constructor属性且值为该函数的对象（这和连接到Function.prototype全完不同）. 因为函数是对象,所以函数可以保存在变量,对象和数组中. 函数可以当做参数传递给其他函数,函数也可以再返回给函数.而且因为函数是对象,函数还可以拥有方法 一个函数总会有一个返回值,如果没有指定返回值则返回undefined(如果函数调用前加上了new前缀,且返回的不是一个对象,则返回this) 函数字面量我们定义一个函数字面量 123var add = function(a, b) &#123; return a + b;&#125; 上面这个函数字面量是通过将一个匿名函数赋值给一个变量. 函数字面量可以出现在任何允许表达式出现的地方. 函数可以被定义在其他函数中. 可以作为函数参数或者函数返回值出现。函数甚至拥有自己的作用域(就像变量有自己的作用域一样) 每声明一个函数实际是创建了一个Function 实例,上面的函数等价于 123var Add = new Function(&quot;a&quot;,&quot;b&quot;,&quot;a + b;&quot;);var add = new Add(1, 2); 闭包内部函数可以访问自己内部的参数和变量还可以访问嵌套在父函数的参数和变量。通过函数字面量创建的函数对象包含了一个连接到外部上下文的连接，这杯称为闭包(每个函数在创建时会附加俩个隐藏属性：函数的上下文和实现函数行为的代码). 函数调用当调用函数时除了显示地向其传递的参数,每个函数还会接受俩个附加参数this, arguments. 当实际参数大于形式参数时,多余的参数会被忽略,而当实际参数小于形式,参数时缺少的参数会被赋值为undefined. 下面会介绍四种调用模式,每种调用模式对this参数的初始化是不一样的. 方法调用模式当一个函数作为一个对象的属性时,我们称其为方法.方法里的this参数被被绑定到该对象上. 12345678var obj = &#123; value : 1; addOne : function() &#123; this.value += 1; &#125;&#125;;obj.addOne(); 函数调用模式当一个函数并非一个对象属性时,那么它就被当做是一个函数来调用 12345function add(a, b) &#123; return a + b;&#125;c = add(1, 2); 这种模式下this被绑定到全局对象上 构造器调用模式一个函数如果创建的目的就是希望集合new关键字来使用,那么它就是构造器函数 如果在一个函数前面带上一个new来调用,实际上会创建一个连接到该函数prototype成员的新对象,同时this也会绑定到那个新对象上. 123456789var Quo = function(string) &#123; this.status = string;&#125;Quo.prototype.get_status = function() &#123; return this.status;&#125;var myQuo = new Quo(&quot;hello&quot;); Apply调用模式JavaScript的函数可以拥有方法,apply方法可以让我们构建一个参数数组传递给调用函数. apply方法接受俩个参数this和参数数组. 123456var add = function(a, b) &#123; return a + b;&#125;var argus = [3, 4];var sum = add.apply(null, argus); arguments数组在函数内部我们可以通过arguments数组变量访问所有的实际参数 12345678var add = function () &#123; var sum = 0; for(i = 0; i &lt; arguments.length; i += 1) &#123; sum += argements[i]; &#125;&#125;;var sum = add(1, 2, 3, 4, 5); 异常throw语句中断函数的执行,它应该抛出一个exception对象,这个对象包含一个name和message属性(你也可以添加额外的属性). 我们使用try catch来捕获异常 123456789101112131415161718var add = function(a, b) &#123; if(arguments.length &lt; 2) &#123; throw &#123; name: &quot;arguments error&quot;, message: &quot;need more arguments&quot; &#125; &#125;&#125;var tryAdd = function(a, b) &#123; try &#123; return add(a, b); &#125; catch(e) &#123; &#125;&#125;tryAdd(1, 2, 3); 作用域代码块是包在一对花括号中的一组语句，JavaScript中的代码块不会创建新的作用域.但是函数确实是有其自己的作用域的,但是在函数内部定义的变量在整个函数体的任意位置都是可见的,因此变量应该被定义在函数的头部。 作用域的好处是内部函数可以访问定义在他们的外部函数的参数和变量(除了this和arguments) 闭包当我们在函数A中定义了函数B,函数B引用了函数A中的变量I,当函数A执行完毕,函数B作为返回值继续被执行时,函数A的变量I是仍然可以被访问的,这就是闭包. 123456789101112var f1 = function() &#123; var id = 1132; return &#123; add: function() &#123; return id += 1; &#125; &#125;&#125;var if1 = fi();var id = if1.add(); // 结果是1133 简而言之呢,闭包的特性是保存了创建它时的上下文信息. 模块我们可以使用函数和闭包来构造模块. 模块是一个提供接口却隐藏状态与实现的函数或者对象. 模块的一般形式是：一个定义了私有变量和函数的函数,利用闭包创建可以访问私有变量和函数的特权函数,最后返回这个特权函数,或者将他们保存到一个可访问到的地方. 柯里化函数也是值,我们可以像往常操作值那样去操作函数, 将函数作为一个变量. 123456789var f = function(a, b, c) &#123;&#125;var f1 = function() &#123; return p(1);&#125; var c = f1(); 上面就实现了函数的柯里化 普通函数123function add(a, b) &#123; return a + b;&#125;","categories":[{"name":"前端","slug":"前端","permalink":"https://wangmingco.github.io/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://wangmingco.github.io/tags/JavaScript/"}]},{"title":"JavaScript面向对象和原型链","slug":"前端/JavaScript面向对象","date":"2015-09-07T16:00:00.000Z","updated":"2021-11-18T02:53:51.400Z","comments":true,"path":"2015/09/08/前端/JavaScript面向对象/","link":"","permalink":"https://wangmingco.github.io/2015/09/08/%E5%89%8D%E7%AB%AF/JavaScript%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/","excerpt":"","text":"JavaScript是一门基于原型继承的函数式的面向对象的编程语言,对象可以直接从其他对象继承属性,且JavaScript是无类型的. 对象JavaScript的简单数据类型包括数字，字符串，布尔值，null值和undefined值，其他值都是对象(数组，函数都是对象)。 数字，字符串和布尔值虽然拥有方法，但他们是不可变的，因此不能称他们为对象。JavaScript中的对象是可变的键控集合。 对象是属性的容器，每个属性都有名字和值。 属性名：包括空串在内的任意字符串。如果字符串不是JavaScript保留的关键字切是合法的标识符则可以不必使用双引号。 属性值：包括undefined值之外的任何值 但是JavaScript里的对象是无类型的。 JavaScript包含一种原型链特性,允许对象继承另一个对象的属性.正确的使用它能减少对象初始化时小号的时间和内存. 对象字面量包围在一对花括号中的0~N个键值对即为对象字面量。 123456var empoty = &#123;&#125;;var xiaoming = &#123; name : &quot;小明&quot;, age : 18&#125; 对象字面量还可以嵌套使用 12345678var xiaoming = &#123; name : &quot;小明&quot;, age : 18 chengji: &#123; yuwen: 99, shuxu: 100 &#125;&#125; 检索对象里的值我们可以使用[]括住一个字符串表达式来索引某个值 1xiaoming[&quot;name&quot;] 如果该字符串是一个合法的标识符且不是保留关键字，那么也可以使用.进行索引 1xiaoming.name 如果我们索引hair这个属性的话,会得到一个undefined值,因此我们也可以使用||指定一个默认值 1xiaoming.hair || &quot;red&quot; 这样我们获得的结果就是red这个字符串,可是如果我们向一个undefined值继续索引的话会得到一个TypeError异常,我们可以使用&amp;&amp;来避免 1xiaoming.cars &amp;&amp; xiaoming.cars.changcheng 我们通过这种方式获得小明拥有的汽车中长城汽车的属性值. 更新对象的值我们可以通过=对对象进行赋值. 1234567xiaoming.name = &quot;zhangxiaoming&quot;// 或者赋值某个新的对象xiaoming.chengji: &#123; yuwen: 99, shuxu: 100 &#125; 引用对象对象通过引用来传递 1var chengji = xiaoming.chengji 创建对象Object 模式12345678var o1 = &#123;&#125;;//字面量的表现形式var o2 = new Object;var o3 = new Object();var o4 = new Object(null);var o5 = new Object(undefined);var o6 = Object.create(Object.prototype);//等价于 var o = &#123;&#125;;//即以 Object.prototype 对象为一个原型模板,新建一个以这个原型模板为原型的对象// 区别var o7 = Object.create(null);//创建一个原型为 null 的对象 构造器模式12345function Car(sColor)&#123; this.color = sColor; &#125;var car = new Car(&quot;red&quot;); 原型链每个对象都会连接到一个原型对象,并且从中继承属性. 对象字面量会连接到Object.prototype 需要指出的是原型连接在对象更新时是不起作用的(如果我们对某个对象做出改变是不会触及该对象的原型).原型连接只有在索引值的时候才会被用到. 委托如果我们尝试去索引某个对象A的值,但该对象没有此属性名,那么JavaScript会试着从A的原型B中进行查找,如果B中也没有的话,会继续向B的原型C中查找,一直找到Object.prototype,如果都没有找到那么值就是undefined. 指定对象的原型1 反射我们可以使用typeof来观察我们的对象中是否包含某个属性 12typeof xiaoming.name // 值为stringtypeof xiaoming.address // 值为undefined 这样我们可以通过undefined来判断某个对象中是否包含某个值,但是有一点需要说明的是typeof也会在原型链进行索引判断。 那么我们可以使用hasOwnProperty方法进行判断，它不对原型链进行检查同时它的返回值只有布尔值 1xiaoming.hasOwnProperty(&quot;address&quot;) // 值为false 删除delete运算符可以用来删除对象的属性.它不会触及原型链中的任何对象. 如果我们自定义的对象属性覆盖了原型中的属性,我们可以通过删除对象的属性而让原型中的属性显露出来","categories":[{"name":"前端","slug":"前端","permalink":"https://wangmingco.github.io/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://wangmingco.github.io/tags/JavaScript/"}]},{"title":"Vertx 3 Data Access","slug":"vertx/vertx3_data_access","date":"2015-08-27T13:10:00.000Z","updated":"2021-11-18T02:35:57.498Z","comments":true,"path":"2015/08/27/vertx/vertx3_data_access/","link":"","permalink":"https://wangmingco.github.io/2015/08/27/vertx/vertx3_data_access/","excerpt":"","text":"JDBC client这个客户端允许你在Vertx应用中使用异步API与JDBC数据库相交互. JDBCClient接口定义了异步方式的JDBC API Creating a the client下面的几种方式介绍了如何创建一个客户端： Using default shared data source在大多数情景中,你可能需要在不同的客户端实例(client instances)中共享同一个data source. 例如,你想要通过部署多个verticle实例来拓展应用的规模,然而每个verticle都共享相同的datasource,这样你就避免了多个datasource pool了。 如下： 1JDBCClient client = JDBCClient.createShared(vertx, config); 当第一次调用JDBCClient.createShared的时候,确实会根据传进的配置创建出data source. 但是当接下来再次调用这个方法的时候,也会创建一个新的客户端,但是它却没有创建新的data source,因此第二次传进的配置也没有生效. Specifying a data source name在创建JDBCClient实例的时候也可以指定data source的名字 1JDBCClient client = JDBCClient.createShared(vertx, config, &quot;MyDataSource&quot;); 如果使用相同的Vertx实例和相同的data source名字创建出不同的客户端,那这些客户端会使用相同的data source. 使用这种创建方式你可以在不同的客户端上使用不同的datasource, 例如和不同的数据库进行交互. Creating a client with a non shared data source虽然在大部分情况下不同的客户端实例需要共享相同的data source,但是有时候也可能客户端需要一个非共享的data source, 你可以使用JDBCClient.createNonShared方法. 1JDBCClient client = JDBCClient.createNonShared(vertx, config); 这种方式和调用JDBCClient.createShared时传递一个唯一的data source名字达到相同的效果. Specifying a data source如果你想使用一个已经存在的data source, 那么你也可以直接使用那个data source创建一个客户端. 1JDBCClient client = JDBCClient.create(vertx, dataSource); Closing the client你可以在整个verticle生命周期之内都持有客户端的引用,但是一旦你使用完该客户端你就应该主动关闭它. 由于data source内部持有一个引用计数器,每当客户端关闭一次,data source内部的技术器就会减1,当计数器为0的时候,data source就会关闭自己. Getting a connection当你成功创建出客户端之后,你可以使用getConnection方法来获得一个连接. 当连接池中有了可用连接之后,handler会获得一个可用连接 12345678910111213141516client.getConnection(res -&gt; &#123; if (res.succeeded()) &#123; SQLConnection connection = res.result(); connection.query(&quot;SELECT * FROM some_table&quot;, res2 -&gt; &#123; if (res2.succeeded()) &#123; ResultSet rs = res2.result(); // Do something with results &#125; &#125;); &#125; else &#123; // Failed to get connection - deal with it &#125;&#125;); 获得的连接是一个SQLConnection实例, SQLConnection接口更多的是被Vert.x sql service使用. Configuration当我们创建客户端时,向其传递了一个配置,该配置包含下面属性： provider_class : 用于管理数据库连接的类名. 默认的类名是io.vertx.ext.jdbc.spi.impl.C3P0DataSourceProvider, 但是如果你想要使用其他连接池,那么你可以使用你自己的实现覆盖该属性. 因为我们使用了C3P0的连接池,因此我们还可以使用下列属性 url : 数据库的JDBC连接URL地址 driver_class : JDBCdirver名称 user : 数据库名称 password : 数据库密码 max_pool_size : 连接池最大数量(默认是15) initial_pool_size : 连接池初始大小(默认是3) min_pool_size : 连接池最小值 max_statements : 缓存prepared statements的最大值(默认是0) max_statements_per_connection : 每个连接缓存prepared statements的最大值(默认是0) max_idle_time : 该值表示一个闲置连接多少秒后会被关闭(默认是0, 从不关闭). 如果你还想要配置其他C3P0的配置,那么你可以在classpath上添加一个c3p0.properties文件 下面给出了一个配置示例： 123456JsonObject config = new JsonObject() .put(&quot;url&quot;, &quot;jdbc:hsqldb:mem:test?shutdown=true&quot;) .put(&quot;driver_class&quot;, &quot;org.hsqldb.jdbcDriver&quot;) .put(&quot;max_pool_size&quot;, 30);JDBCClient client = JDBCClient.createShared(vertx, config); Vert.x MySQL - PostgreSQL clientMySQL / PostgreSQL客户端为Vert.x应用提供了一个与MySQL / PostgreSQL数据库交互的接口. 它使用Mauricio Linhares开源驱动与MySQL / PostgreSQL数据库进行非阻塞交互. Creating a the client下面给出了几种创建方式： Using default shared pool在大多数情况下,我们需要在多个客户端实例中共享同一个连接池 例如你通过部署多个verticle实例的方式进行程序拓展,但是可以每个verticle可以共享同一个连接池. 1234567JsonObject mySQLClientConfig = new JsonObject().put(&quot;host&quot;, &quot;mymysqldb.mycompany&quot;);AsyncSQLClient mySQLClient = MySQLClient.createShared(vertx, mySQLClientConfig);// To create a PostgreSQL client:JsonObject postgreSQLClientConfig = new JsonObject().put(&quot;host&quot;, &quot;mypostgresqldb.mycompany&quot;);AsyncSQLClient postgreSQLClient = PostgreSQLClient.createShared(vertx, postgreSQLClientConfig); MySQLClient.createShared或者PostgreSQLClient.createShared会根据指定的配置创建一个连接池. 随后再调用这俩个方式时会使用同一个连接池,同时新的配置不会被采用. Specifying a pool name你也可以像下面这样指定一个连接池的名字. 1234567JsonObject mySQLClientConfig = new JsonObject().put(&quot;host&quot;, &quot;mymysqldb.mycompany&quot;);AsyncSQLClient mySQLClient = MySQLClient.createShared(vertx, mySQLClientConfig, &quot;MySQLPool1&quot;);// To create a PostgreSQL client:JsonObject postgreSQLClientConfig = new JsonObject().put(&quot;host&quot;, &quot;mypostgresqldb.mycompany&quot;);AsyncSQLClient postgreSQLClient = PostgreSQLClient.createShared(vertx, postgreSQLClientConfig, &quot;PostgreSQLPool1&quot;); 如果不同的客户端使用相同的Vertx实例和相同的连接池名字,那么他们将使用同一个连接池. 使用这种创建方式你可以在不同的客户端上使用不同的datasource, 例如和不同的数据库进行交互. Creating a client with a non shared data source虽然在大部分情况下不同的客户端实例需要共享相同的data source,但是有时候也可能客户端需要一个非共享的data source, 你可以使用MySQLClient.createNonShared或者PostgreSQLClient.createNonShared方法. 1234567JsonObject mySQLClientConfig = new JsonObject().put(&quot;host&quot;, &quot;mymysqldb.mycompany&quot;);AsyncSQLClient mySQLClient = MySQLClient.createNonShared(vertx, mySQLClientConfig);// To create a PostgreSQL client:JsonObject postgreSQLClientConfig = new JsonObject().put(&quot;host&quot;, &quot;mypostgresqldb.mycompany&quot;);AsyncSQLClient postgreSQLClient = PostgreSQLClient.createNonShared(vertx, postgreSQLClientConfig); 这种方式和调用MySQLClient.createNonShared或者PostgreSQLClient.createNonShared时传递一个唯一的data source名字达到相同的效果. Closing the client你可以在整个verticle生命周期之内都持有客户端的引用,但是一旦你使用完该客户端你就应该调用close关闭它. Getting a connection当你成功创建出客户端之后,你可以使用getConnection方法来获得一个连接. 当连接池中有了可用连接之后,handler会获得一个可用连接 1234567891011client.getConnection(res -&gt; &#123; if (res.succeeded()) &#123; SQLConnection connection = res.result(); // Got a connection &#125; else &#123; // Failed to get connection - deal with it &#125;&#125;); 连接是SQLConnection的一个实例, SQLConnection是一个被Sql客户端使用的公共接口. 需要注意的是date和timestamps类型. 无论何时从数据库中获取date时, 客户端会将它转换成ISO 8601形式的字符串(yyyy-MM-ddTHH:mm:ss.SSS).Mysql会忽略毫秒数. ConfigurationPostgreSql和MySql使用了下面相同的配置： 12345678&#123; &quot;host&quot; : &lt;your-host&gt;, &quot;port&quot; : &lt;your-port&gt;, &quot;maxPoolSize&quot; : &lt;maximum-number-of-open-connections&gt;, &quot;username&quot; : &lt;your-username&gt;, &quot;password&quot; : &lt;your-password&gt;, &quot;database&quot; : &lt;name-of-your-database&gt;&#125; host : 数据库主机地址(默认是localhost) port : 数据库端口(PostgreSQL默认是5432. MySQL默认是3306) maxPoolSize : 连接池保持开启的最大数量,默认是10. username : 连接数据库使用的用户名.(PostgreSQL的默认值是postgres, MySQL的默认值是root) password : 连接数据库使用的密码(默认没有设置密码). database : 连接的数据库名称.(默认值是test) Common SQL interface通用SQL接口是用来和VertxSQL服务交互的. 通过指定的SQL服务接口我们可以获取一个指定的连接. The SQL Connection我们使用SQLConnection表示与一个数据库的连接. Auto-commit当连接的auto commit被设置为true. 这意味着每个操作都会在连接自己的事务中被高效地执行. 如果你想要在一个单独的事务中执行多个操作,你应该使用setAutoCommit方法将auto commit被设置为false. 当操作完成之后,我们设置的handler会自动地被调用. 1234567connection.setAutoCommit(false, res -&gt; &#123; if (res.succeeded()) &#123; // OK! &#125; else &#123; // Failed! &#125;&#125;); Executing queries我们使用query来执行查询操作 query方法的参数是原生SQL语句, 我们不必使用针对不同的数据库使用不同的SQL方言. 当查询完成之后,我们设置的handler会自动地被调用. query的结果使用ResultSet表示. 12345678connection.query(&quot;SELECT ID, FNAME, LNAME, SHOE_SIZE from PEOPLE&quot;, res -&gt; &#123; if (res.succeeded()) &#123; // Get the result set ResultSet resultSet = res.result(); &#125; else &#123; // Failed! &#125;&#125;); ResultSet实例中的getColumnNames方法可以获得可用列名, getResults可以获得查询真实的结果. 实际上,查询的结果是一个JsonArray的List实例,每一个元素都代表一行结果. 123456789101112List&lt;String&gt; columnNames = resultSet.getColumnNames();List&lt;JsonArray&gt; results = resultSet.getResults();for (JsonArray row: results) &#123; String id = row.getString(0); String fName = row.getString(1); String lName = row.getString(2); int shoeSize = row.getInteger(3);&#125; 另外你还可以使用getRows获取一个Json对象实例的List, 这种方式简化了刚才的方式,但是有一点需要注意的是,SQL结果可能包含重复的列名, 如果你的情景是这种情况,你应该使用getResults. 下面给出了一种使用getRows获取结果的示例： 12345678910List&lt;JsonObject&gt; rows = resultSet.getRows();for (JsonObject row: rows) &#123; String id = row.getString(&quot;ID&quot;); String fName = row.getString(&quot;FNAME&quot;); String lName = row.getString(&quot;LNAME&quot;); int shoeSize = row.getInteger(&quot;SHOE_SIZE&quot;);&#125; Prepared statement queries我们可以使用queryWithParams来执行prepared statement查询. 下例中,演示了使用方法： 123456789101112String query = &quot;SELECT ID, FNAME, LNAME, SHOE_SIZE from PEOPLE WHERE LNAME=? AND SHOE_SIZE &gt; ?&quot;;JsonArray params = new JsonArray().add(&quot;Fox&quot;).add(9);connection.queryWithParams(query, params, res -&gt; &#123; if (res.succeeded()) &#123; // Get the result set ResultSet resultSet = res.result(); &#125; else &#123; // Failed! &#125;&#125;); Executing INSERT, UPDATE or DELETE我们可以直接使用update方法进行数据更新操作. 同样update方法的参数同样是原生SQL语句,不必使用SQL方言. 当更新完成之后,我们会获得一个更新结果UpdateResult。 我们可以调用更新结果的getUpdated方法获得有多少行发生了改变, 而且如果更新时生成了一些key,那么我们可以通过getKeys获得 123456789101112List&lt;String&gt; columnNames = resultSet.getColumnNames();List&lt;JsonArray&gt; results = resultSet.getResults();for (JsonArray row: results) &#123; String id = row.getString(0); String fName = row.getString(1); String lName = row.getString(2); int shoeSize = row.getInteger(3);&#125; Prepared statement updates如果想要执行prepared statement更新操作,我们可以使用updateWithParams. 如下例： 1234567891011121314151617String update = &quot;UPDATE PEOPLE SET SHOE_SIZE = 10 WHERE LNAME=?&quot;;JsonArray params = new JsonArray().add(&quot;Fox&quot;);connection.updateWithParams(update, params, res -&gt; &#123; if (res.succeeded()) &#123; UpdateResult updateResult = res.result(); System.out.println(&quot;No. of rows updated: &quot; + updateResult.getUpdated()); &#125; else &#123; // Failed! &#125;&#125;); Executing other operations如果想要执行其他数据库操作,例如创建数据库,你可以使用execute方法. 同样execute执行的语句也是原生SQL语句.当操作执行完之后,我们设置的handler会被调用. 12345678910String sql = &quot;CREATE TABLE PEOPLE (ID int generated by default as identity (start with 1 increment by 1) not null,&quot; + &quot;FNAME varchar(255), LNAME varchar(255), SHOE_SIZE int);&quot;;connection.execute(sql, execute -&gt; &#123; if (execute.succeeded()) &#123; System.out.println(&quot;Table created !&quot;); &#125; else &#123; // Failed! &#125;&#125;); Using transactions如果想要使用事务,那么首先要调用setAutoCommit将auto-commit设置为false. 接下来你就可以进行事务操作, 例如提交时使用commit, 回滚时使用rollback. 一旦commit/rollback完成之后, 我们设置的handler会被调用, 然后下一个事务会自动开始. 1234567connection.commit(res -&gt; &#123; if (res.succeeded()) &#123; // Committed OK! &#125; else &#123; // Failed! &#125;&#125;); Closing connections当你执行完全部的操作之后,你应该使用close将连接资源还给连接池.","categories":[{"name":"vertx","slug":"vertx","permalink":"https://wangmingco.github.io/categories/vertx/"}],"tags":[{"name":"vertx3","slug":"vertx3","permalink":"https://wangmingco.github.io/tags/vertx3/"}]},{"title":"Vertx 3 Metrics And Monitoring","slug":"vertx/vertx3_metrics_and_monitoring","date":"2015-08-15T09:22:00.000Z","updated":"2021-11-18T02:35:58.448Z","comments":true,"path":"2015/08/15/vertx/vertx3_metrics_and_monitoring/","link":"","permalink":"https://wangmingco.github.io/2015/08/15/vertx/vertx3_metrics_and_monitoring/","excerpt":"","text":"FeaturesMeasured接口提供一套简单的API来检索metrics,很多Vert.x组件都实现了这个接口,例如 HttpServer, NetServer,甚至Vertx实例自身. 我们基于Dropwizard接口配置JMX报告,这个接口将Vert.x像JMX MBeans那样暴露出来. Getting started想要使用metrics,首先我们在pom文件里依赖下面的仓库： 12345&lt;dependency&gt; &lt;groupId&gt;io.vertx&lt;/groupId&gt; &lt;artifactId&gt;vertx-metrics&lt;/artifactId&gt; &lt;version&gt;$&#123;vertx.metrics.version&#125;&lt;/version&gt;&lt;/dependency&gt; 然后我们使用DropwizardMetricsOptions对Vertx实例开启metrics. 123Vertx vertx = Vertx.vertx(new VertxOptions().setMetricsOptions( new DropwizardMetricsOptions().setEnabled(true))); 你也可以开启JMX: 123Vertx vertx = Vertx.vertx(new VertxOptions().setMetricsOptions( new DropwizardMetricsOptions().setJmxEnabled(true))); Metrics serviceNaming下文中列出的每一个测量组件都会被分配一个名字. 每个metric都可以通过全限定名baseName + . + metricName从Vertx实例中获得. 12JsonObject metrics = metricsService.getMetricsSnapshot(vertx);metrics.getJsonObject(&quot;vertx.eventbus.handlers&quot;); 或者使用metric名字获得该自身. 123EventBus eventBus = vertx.eventBus();JsonObject metrics = metricsService.getMetricsSnapshot(eventBus);metrics.getJsonObject(&quot;handlers&quot;); Retrieving metrics一旦开启了metrics功能, MetricsService可以从任意Measured对象中检索出metrics快照, Measured对象提供了一个meteric name和meteric data映射关系的map,这个map通过JsonObject存储。 下面的例子打印出Vertx实例中所有的metrics. 123MetricsService metricsService = MetricsService.create(vertx);JsonObject metrics = metricsService.getMetricsSnapshot(vertx);System.out.println(metrics); 由于HttpServer实现了Measured,你可以轻松地抓取到该http服务器上所有的metrics 1234MetricsService metricsService = MetricsService.create(vertx);HttpServer server = vertx.createHttpServer();// set up serverJsonObject metrics = metricsService.getMetricsSnapshot(server); Data下面列出了每个dropwizard metric在JSON中的表现形式. 对于每个metric详细信息请参考Dropwizard metrics documentation Gauge123&#123; &quot;value&quot; : value // any json value&#125; Counter123&#123; &quot;count&quot; : 1 // number&#125; Histogram12345678910111213&#123; &quot;count&quot; : 1 // long &quot;min&quot; : 1 // long &quot;max&quot; : 1 // long &quot;mean&quot; : 1.0 // double &quot;stddev&quot; : 1.0 // double &quot;median&quot; : 1.0 // double &quot;75%&quot; : 1.0 // double &quot;95%&quot; : 1.0 // double &quot;98%&quot; : 1.0 // double &quot;99%&quot; : 1.0 // double &quot;99.9%&quot; : 1.0 // double&#125; Meter12345678&#123; &quot;count&quot; : 1 // long &quot;meanRate&quot; : 1.0 // double &quot;oneMinuteRate&quot; : 1.0 // double &quot;fiveMinuteRate&quot; : 1.0 // double &quot;fifteenMinuteRate&quot; : 1.0 // double &quot;rate&quot; : &quot;events/second&quot; // string representing rate&#125; ThroughputMeter扩展自Meter,提供即时吞吐量。 123456789&#123; &quot;count&quot; : 40 // long &quot;meanRate&quot; : 2.0 // double &quot;oneSecondRate&quot; : 3 // long - number of occurence for the last second &quot;oneMinuteRate&quot; : 1.0 // double &quot;fiveMinuteRate&quot; : 1.0 // double &quot;fifteenMinuteRate&quot; : 1.0 // double &quot;rate&quot; : &quot;events/second&quot; // string representing rate&#125; TimerHistogram和Meter的组合： 123456789101112131415161718192021&#123; // histogram data &quot;count&quot; : 1 // long &quot;min&quot; : 1 // long &quot;max&quot; : 1 // long &quot;mean&quot; : 1.0 // double &quot;stddev&quot; : 1.0 // double &quot;median&quot; : 1.0 // double &quot;75%&quot; : 1.0 // double &quot;95%&quot; : 1.0 // double &quot;98%&quot; : 1.0 // double &quot;99%&quot; : 1.0 // double &quot;99.9%&quot; : 1.0 // double // meter data &quot;meanRate&quot; : 1.0 // double &quot;oneMinuteRate&quot; : 1.0 // double &quot;fiveMinuteRate&quot; : 1.0 // double &quot;fifteenMinuteRate&quot; : 1.0 // double &quot;rate&quot; : &quot;events/second&quot; // string representing rate&#125; Throughput Timer拓展自Timer,提供即时吞吐量的metric 12345678910111213141516171819202122&#123; // histogram data &quot;count&quot; : 1 // long &quot;min&quot; : 1 // long &quot;max&quot; : 1 // long &quot;mean&quot; : 1.0 // double &quot;stddev&quot; : 1.0 // double &quot;median&quot; : 1.0 // double &quot;75%&quot; : 1.0 // double &quot;95%&quot; : 1.0 // double &quot;98%&quot; : 1.0 // double &quot;99%&quot; : 1.0 // double &quot;99.9%&quot; : 1.0 // double // meter data &quot;meanRate&quot; : 1.0 // double &quot;oneSecondRate&quot; : 3 // long - number of occurence for the last second &quot;oneMinuteRate&quot; : 1.0 // double &quot;fiveMinuteRate&quot; : 1.0 // double &quot;fifteenMinuteRate&quot; : 1.0 // double &quot;rate&quot; : &quot;events/second&quot; // string representing rate&#125; The metrics下面列出了当前支持的metric Vert.x metrics vertx.event-loop-size - event loop pool线程的数量。(Gauge表示) vertx.worker-pool-size - worker pool线程的数量。(Gauge表示) vertx.cluster-host - cluster-host设置。(Gauge表示) vertx.cluster-port - cluster-port设置。(Gauge表示) vertx.verticles - 当前被部署的verticle的数量。(Counter表示) Event bus metricsBase name: vertx.eventbus handlers - event bus里handler的数量.(Counter表示) handlers.myaddress - Timer,表示myaddress的handler接收到消息的比例 messages.bytes-read - Meter, 表示接收到远端消息时读到的字节数的Meter messages.bytes-written - 向远端发送消息时,写入字节的Meter messages.pending - 接收到消息但并没有传递给handller的统计消息数的Counter messages.pending-local - 接收到locally消息但并没有传递给handller的统计消息数的Counter messages.pending-remote - Counter, 表示接收到远端但是并没有传递给handler的消息数量. messages.received - ThroughputMeter,表示接收到消息的比例 messages.received-local - ThroughputMeter,表示接收到本地消息的比例 messages.received-remote - ThroughputMeter, 表示接收到远程消息接收到的比例 messages.delivered - [throughpu_metert], 表示消息传递给handler的比例. messages.delivered-local - ThroughputMeter,表示local消息传递给handler的比例. messages.delivered-remote - ThroughputMeter,表示remote消息传递给handler的比例. messages.sent - [throughput_metert], 表示发送出去的消息的比例. messages.sent-local -ThroughputMeter, 表示本地send出去的消息的比例. messages.sent-remote - ThroughputMeter, 表示远端send出去的消息的比例. messages.published - ThroughputMeter, 表示publish出去的消息的比例. messages.published-local - ThroughputMeter, 表示向本地publish出去的消息的比例. messages.published-remote - ThroughputMeter, 表示给远端publish出去的消息的比例. messages.reply-failures - Meter, 表示reply失败的比例 monitored event bus handlers 通过向handler注册地址上的match来完成配置. 由于Vert.x可以在event bus进行海量的注册,因此比较好的配置是在默认的情况下我们不对任何handler进行监听. monitored handlers可以通过一个指定的address match或者regex match在DropwizardMetricsOptions中完成配置. 12345678Vertx vertx = Vertx.vertx(new VertxOptions().setMetricsOptions( new DropwizardMetricsOptions(). setEnabled(true). addMonitoredEventBusHandler( new Match().setValue(&quot;some-address&quot;)). addMonitoredEventBusHandler( new Match().setValue(&quot;business-.*&quot;).setType(MatchType.REGEX)))); 警告：如果你使用regex match, 当出现错误的regex,那么可能会match出大量的handler Http server metricsBase name: vertx.http.servers.&lt;host&gt;:&lt;port&gt; Http server除了包含Net Server的metrics之外还包含下面这些： requests - 请求的Throughput Timer和该请求出现的比例 &lt;http-method&gt;-requests - 指定的http method请求的Throughput Timer和该http method请求的出现的比例 Examples: get-requests, post-requests &lt;http-method&gt;-requests./&lt;uri&gt; - 指定的http method &amp; URI请求的Throughput Timer和该请求的出现的比例 Examples: get-requests./some/uri, post-requests./some/uri?foo=bar responses-1xx - 回应状态码为1xx的ThroughputMeter responses-2xx - 回应状态码为2xx的ThroughputMeter responses-3xx - 回应状态码为3xx的ThroughputMeter responses-4xx - 回应状态码为4xx的ThroughputMeter responses-5xx - 回应状态码为5xx的ThroughputMeter open-websockets - 统计开启的web socket连接数的Counter open-websockets.&lt;remote-host&gt; - 统计对某个指定的remote host开启的web socket连接数的Counter 不管是exact match还是regex match,Http URI metrics必须在DropwizardMetricsOptions中显式地配置. 12345678Vertx vertx = Vertx.vertx(new VertxOptions().setMetricsOptions( new DropwizardMetricsOptions(). setEnabled(true). addMonitoredHttpServerUri( new Match().setValue(&quot;/&quot;)). addMonitoredHttpServerUri( new Match().setValue(&quot;/foo/.*&quot;).setType(MatchType.REGEX)))); For bytes-read and bytes-written the bytes represent the body of the request/response, so headers, etc are ignored. Http client metricsBase name: vertx.http.clients.@&lt;id&gt; Http client除了包含Http Server全部的metrics之外,还包含下面这些. connections.max-pool-size - 表示最大连接池大小的Gauge connections.pool-ratio - 表示open connections / max connection pool size的比例Gauge responses-1xx - 回应状态码为1xx的Meter responses-2xx - 回应状态码为2xx的Meter responses-3xx - 回应状态码为3xx的Meter responses-4xx - 回应状态码为4xx的Meter responses-5xx - 回应状态码为5xx的Meter Net server metricsBase name: vertx.net.servers.&lt;host&gt;:&lt;port&gt; open-netsockets - 开启的socket连接数的Counter open-netsockets.&lt;remote-host&gt; - 统计对于某个指定remote host开启的socket连接数的Counter connections - 某个连接的Timer和该连接出现的比例 exceptions - 出现异常次数的Counter bytes-read - 已读字节数的Histogram. bytes-written - 写出字节数的Histogram. Net client metricsBase name: vertx.net.clients.@&lt;id&gt; Net client包含全部的Net Server的metrics Datagram socket metricsBase name: vertx.datagram sockets - 统计datagram sockets数的Counter exceptions - 统计异常出现次数的Counter bytes-written - 写出字节数的Histogram. &lt;host&gt;:&lt;port&gt;.bytes-read - 已读字节数的Histogram. 只有当datagram socket被监听的时候上面的统计才有效。 JMXJMX is disabled by default. JMX是被默认不开启的. 如果你想要开启JMX,你需要像下面那样开启它. 123Vertx vertx = Vertx.vertx(new VertxOptions().setMetricsOptions( new DropwizardMetricsOptions().setJmxEnabled(true))); 如果你是从命令行中运行Vert.x想要开启JMX, 你可以在vertx或者vertx.bat脚本中将JMX_OPTS那一行取消掉注释. 1JMX_OPTS=&quot;-Dcom.sun.management.jmxremote -Dvertx.options.jmxEnabled=true&quot; 你可以配置MBeans创建时是处于哪个域名下的: 12345Vertx vertx = Vertx.vertx(new VertxOptions().setMetricsOptions( new DropwizardMetricsOptions(). setJmxEnabled(true). setJmxDomain(&quot;mydomain&quot;))); Enabling remote JMX如果你想metrics远程被JMX暴露，最少你需要设置下面这个系统属性: 1com.sun.management.jmxremote 如果你是通过命令行运行Vert.x，那么你需要在vertx or vertx.bat文件中将JMX_OPTS的注释去掉。 如果你在公共服务器上运行Vert.x，那么你需要小心对JMX的远程访问了。 Please see the Oracle JMX documentation for more information on configuring JMX Accessing Dropwizard RegistryWhen configuring the metrics service, an optional registry name can be specified for registering the underlying Dropwizard Registry in the the Dropwizard Shared Registry so you can retrieve this registry and use according to your needs. 123456789VertxOptions options = new VertxOptions().setMetricsOptions( new MetricsServiceOptions().setEnabled(true).setRegistryName(&quot;the_name&quot;));Vertx vertx = Vertx.vertxt(options);// Get the registryMetricRegistry registry = SharedMetricRegistries.getOrCreate(&quot;the_name&quot;);// Do whatever you need with the registry","categories":[{"name":"vertx","slug":"vertx","permalink":"https://wangmingco.github.io/categories/vertx/"}],"tags":[{"name":"vertx3","slug":"vertx3","permalink":"https://wangmingco.github.io/tags/vertx3/"}]},{"title":"Vertx 3 Web","slug":"vertx/vertx3_web","date":"2015-08-10T09:10:00.000Z","updated":"2021-11-18T02:35:43.658Z","comments":true,"path":"2015/08/10/vertx/vertx3_web/","link":"","permalink":"https://wangmingco.github.io/2015/08/10/vertx/vertx3_web/","excerpt":"","text":"Basic Vert.x-Web conceptsHere’s the 10000 foot view: Router是Vert.x-Web最核心的概念. Router是一个持有零到多个Routes的对象 Router会将HTTP request发送到第一个匹配该请求的route身上. route持有一个与HTTP request相匹配的handler, 然后该handler接受该请求. 然后执行具体任务, 当执行完任务之后你可以选择结束该请求或者将它传递给下一个匹配的handler. 下面是一个简单的示例： 123456789101112131415HttpServer server = vertx.createHttpServer();Router router = Router.router(vertx);router.route().handler(routingContext -&gt; &#123; // This handler will be called for every request HttpServerResponse response = routingContext.response(); response.putHeader(&quot;content-type&quot;, &quot;text/plain&quot;); // Write to the response and end it response.end(&quot;Hello World from Vert.x-Web!&quot;);&#125;);server.requestHandler(router::accept).listen(8080); 我们创建了一个HTTP Server服务器, 接着创建了一个router. 我们没有对这个route指定匹配规则,因此它会匹配所有的HTTP request. 然后我们在该route上设置了一个handler, 这个handler会处理该服务器上所有的HTTP request. 传递给handler的是一个RoutingContext对象, 该对象包含一个一个标准的Vert.x HttpServerRequest和Vert.x HttpServerResponse,但是还包含了很多其他的Vert.x-Web里的特性. 对于每一个HTTP request都会生成一个唯一的RoutingContext实例, 但是给实例会传递给所有匹配该请求的handler. Handling requests and calling the next handler当Vert.x-Web``route一个HTTP Request到一个与之匹配的route，它会向该route的handler传递一个RoutingContext实例. 如果在当前handler里,你不想结束response, 那么你应该调用下一个相匹配的route继续处理该请求. 你没有必要在当前handler执行完之前调用下一个route, 你可以稍后再做这件事. 12345678910111213141516171819202122232425262728293031Route route1 = router.route(&quot;/some/path/&quot;).handler(routingContext -&gt; &#123; HttpServerResponse response = routingContext.response(); // enable chunked responses because we will be adding data as // we execute over other handlers. This is only required once and // only if several handlers do output. response.setChunked(true); response.write(&quot;route1\\n&quot;); // Call the next matching route after a 5 second delay routingContext.vertx().setTimer(5000, tid -&gt; routingContext.next());&#125;);Route route2 = router.route(&quot;/some/path/&quot;).handler(routingContext -&gt; &#123; HttpServerResponse response = routingContext.response(); response.write(&quot;route2\\n&quot;); // Call the next matching route after a 5 second delay routingContext.vertx().setTimer(5000, tid -&gt; routingContext.next());&#125;);Route route3 = router.route(&quot;/some/path/&quot;).handler(routingContext -&gt; &#123; HttpServerResponse response = routingContext.response(); response.write(&quot;route3&quot;); // Now end the response routingContext.response().end();&#125;); 在上面的例子中, route1被写到response的5秒钟之后,route2被写到response,在过了5秒钟之后,route3被写到response,然后结束掉response. 注意这一切的发生都是非阻塞的, Using blocking handlers在某些环境下,你也许想要在handler执行时,将event loop阻塞住, 例如调用一个阻塞API或者执行一些密集型计算. 这种情况下,你不能在普通handler中进行操作,我们为route提供了一个阻塞的handler. 阻塞式和非阻塞式handler非常像,只不过阻塞式是由Vert.x从worker pool中借出一个线程进行任务执行,而非是从event loop中. 下例进行了说明： 123456789router.route().blockingHandler(routingContext -&gt; &#123; // Do something that might take some time synchronously service.doSomethingThatBlocks(); // Now call the next handler routingContext.next();&#125;); 在默认情况下, Vert.x中任何的阻塞handler都是在相同的上下文中(例如verticle实例中)顺序执行的,这意味着当前一个handler未完成之前,下一个handler是不会执行的. 如果你不关心任务的执行顺序,而且不介意阻塞handler并行执行,你可以在调用blockingHandler方法时传递一个false的参数,让其不按照任务的指定顺序进行执行. Routing by exact pathroute可以被设定为匹配特定的URI. 在这种情况下,它就可以指定路径的请求了. 在下面的例子中,handler会被路径为/some/path/的请求调用. 但是我们会忽略末尾斜杠,因此当路径为/some/path和/some/path//该handler都会被调用. 123456789101112Route route = router.route().path(&quot;/some/path/&quot;);route.handler(routingContext -&gt; &#123; // This handler will be called for the following request paths: // `/some/path` // `/some/path/` // `/some/path//` // // but not: // `/some/path/subdir`&#125;); Routing by paths that begin with something通常情况下,你会想设置一个通用的前置路径. 如果是这种情况你可以使用正则表达式, 但是一个比较简单的实现方式是在route path的末尾加上一个*. 在下面的例子中,当请求路径前缀为/some/path/的时候,我们设置的handler都会被执行. (例如/some/path/foo.html和/some/path/otherdir/blah.css都是匹配的) 1234567891011121314Route route = router.route().path(&quot;/some/path/*&quot;);route.handler(routingContext -&gt; &#123; // This handler will be called for any path that starts with // `/some/path/`, e.g. // `/some/path` // `/some/path/` // `/some/path/subdir` // `/some/path/subdir/blah.html` // // but not: // `/some/bath`&#125;); 你还可以将路径参数放在route()方法里 12345Route route = router.route(&quot;/some/path/*&quot;);route.handler(routingContext -&gt; &#123; // This handler will be called same as previous example&#125;); Capturing path parameters我们可以在请求参数上使用通配符进行匹配路径 123456789Route route = router.route(HttpMethod.POST, &quot;/catalogue/products/:productype/:productid/&quot;);route.handler(routingContext -&gt; &#123; String productType = routingContext.request().getParam(&quot;producttype&quot;); String productID = routingContext.request().getParam(&quot;productid&quot;); // Do something with them...&#125;); 通配符由:组成,将其放在参数名后面. 参数名由字母和数字下划线组成. 在上面的例子中,如果一个POST请求地址是/catalogue/products/tools/drill123/, 那么上面的route会被匹配到, productType接收到tools值, productID会接收到drill123值. Capturing path parameters with regular expressions当使用正则表达式的时候,你还可以捕获路径参数： 123456789101112Route route = router.routeWithRegex(&quot;.*foo&quot;);// This regular expression matches paths that start with something like:// &quot;/foo/bar&quot; - where the &quot;foo&quot; is captured into param0 and the &quot;bar&quot; is captured into// param1route.pathRegex(&quot;\\\\/([^\\\\/]+)\\\\/([^\\\\/]+)&quot;).handler(routingContext -&gt; &#123; String productType = routingContext.request().getParam(&quot;param0&quot;); String productID = routingContext.request().getParam(&quot;param1&quot;); // Do something with them...&#125;); 在上面的例子中,如果请求路径是/tools/drill123/, 那么我们设置的route会被匹配到, 然后productType会接收到参数值tools, productID会接收到参数值drill123. Captures are denoted in regular expressions with capture groups (i.e. surrounding the capture with round brackets) Routing with regular expressions正则还可以被使用在URI路径的匹配上： 1234567891011121314Route route = router.route().pathRegex(&quot;.*foo&quot;);route.handler(routingContext -&gt; &#123; // This handler will be called for: // /some/path/foo // /foo // /foo/bar/wibble/foo // /foo/bar // But not: // /bar/wibble&#125;); 还有一种做法是,正则可以在创建route时进行指定. 1234567Route route = router.routeWithRegex(&quot;.*foo&quot;);route.handler(routingContext -&gt; &#123; // This handler will be called same as previous example&#125;); Routing by HTTP method在默认的情况下route会匹配所有的HTTP methods. 如果你想要某个route只匹配特定的HTTP method,你可以像下面这样做： 1234567Route route = router.route().method(HttpMethod.POST);route.handler(routingContext -&gt; &#123; // This handler will be called for any POST request&#125;); 或者你在创建route时直接指定： 1234567Route route = router.route(HttpMethod.POST, &quot;/some/path/&quot;);route.handler(routingContext -&gt; &#123; // This handler will be called for any POST request to a URI path starting with /some/path/&#125;); 当然还有其他方式可用,你可以直接调用get(), post, put等方法调用 12345678910111213141516171819router.get().handler(routingContext -&gt; &#123; // Will be called for any GET request&#125;);router.get(&quot;/some/path/&quot;).handler(routingContext -&gt; &#123; // Will be called for any GET request to a path // starting with /some/path&#125;);router.getWithRegex(&quot;.*foo&quot;).handler(routingContext -&gt; &#123; // Will be called for any GET request to a path // ending with `foo`&#125;); 如果你想要对某个route指定多个HTTP method,你可以像下面这样做： 1234567Route route = router.route().method(HttpMethod.POST).method(HttpMethod.PUT);route.handler(routingContext -&gt; &#123; // This handler will be called for any POST or PUT request&#125;); Route order在默认情况下routes的排序是按照添加添加进router的顺序进行排序的. 当router接受到一个请求时, router会遍历自身的每一个route查看是否与请求匹配,如果匹配的话,该route的handler就会被调用. 如果handler随后调用了下一个handler, 那么下一个与之匹配的route也会被调用. 12345678910111213141516171819202122232425262728293031Route route1 = router.route(&quot;/some/path/&quot;).handler(routingContext -&gt; &#123; HttpServerResponse response = routingContext.response(); // enable chunked responses because we will be adding data as // we execute over other handlers. This is only required once and // only if several handlers do output. response.setChunked(true); response.write(&quot;route1\\n&quot;); // Now call the next matching route routingContext.next();&#125;);Route route2 = router.route(&quot;/some/path/&quot;).handler(routingContext -&gt; &#123; HttpServerResponse response = routingContext.response(); response.write(&quot;route2\\n&quot;); // Now call the next matching route routingContext.next();&#125;);Route route3 = router.route(&quot;/some/path/&quot;).handler(routingContext -&gt; &#123; HttpServerResponse response = routingContext.response(); response.write(&quot;route3&quot;); // Now end the response routingContext.response().end();&#125;); 在上面的例子中，输出结果为： 123route1route2route3 /some/path开头的请求都是按照刚才的那个顺序进行route调用的. 如果你想要改变route的调用顺序,你可以使用order()方法,向其指定一个指定值. Routes在router中的位置是按照他们添加进去的时间顺序进行排序的, 而且他们的位置是从0开始的. 当然像上文所说的,你还可以调用order()方法改变这个排序. 需要注意的是序号可以是负数, 例如你想要某个route在序号0的route之前执行,你就可以将某个route序号指定为-1. 下例中我们改变了route2的序号,确保他在route1之前执行. 12345678910111213141516171819202122232425262728293031323334Route route1 = router.route(&quot;/some/path/&quot;).handler(routingContext -&gt; &#123; HttpServerResponse response = routingContext.response(); response.write(&quot;route1\\n&quot;); // Now call the next matching route routingContext.next();&#125;);Route route2 = router.route(&quot;/some/path/&quot;).handler(routingContext -&gt; &#123; HttpServerResponse response = routingContext.response(); // enable chunked responses because we will be adding data as // we execute over other handlers. This is only required once and // only if several handlers do output. response.setChunked(true); response.write(&quot;route2\\n&quot;); // Now call the next matching route routingContext.next();&#125;);Route route3 = router.route(&quot;/some/path/&quot;).handler(routingContext -&gt; &#123; HttpServerResponse response = routingContext.response(); response.write(&quot;route3&quot;); // Now end the response routingContext.response().end();&#125;);// Change the order of route2 so it runs before route1route2.order(-1); 接下来我们就看到了我们所期望的结果 123route2route1route3 如果俩个route有相同的序号,那么他们会按照添加的顺序进行执行. 你还可以通过调用last()方法将某个route放到最后一个. Routing based on MIME type of request你可以通过consumes方法指定route需要匹配请求的MIME类型. 这下面的例子中, 请求包含了一个content-type请求头,该值指定了请求体的MINE类型. 这个值会和consumes方法里的值进行匹配. MINE类型的匹配可以做到精确匹配. 123456router.route().consumes(&quot;text/html&quot;).handler(routingContext -&gt; &#123; // This handler will be called for any request with // content-type header set to `text/html`&#125;); 同样我们还可以进行多个MINE类型的匹配 123456router.route().consumes(&quot;text/html&quot;).consumes(&quot;text/plain&quot;).handler(routingContext -&gt; &#123; // This handler will be called for any request with // content-type header set to `text/html` or `text/plain`.&#125;); 我们还可以通过通配符对子类型进行匹配 123456router.route().consumes(&quot;text/*&quot;).handler(routingContext -&gt; &#123; // This handler will be called for any request with top level type `text` // e.g. content-type header set to `text/html` or `text/plain` will both match&#125;); 我们还可以通过通配符对父类型进行匹配 123456router.route().consumes(&quot;*/json&quot;).handler(routingContext -&gt; &#123; // This handler will be called for any request with sub-type json // e.g. content-type header set to `text/json` or `application/json` will both match&#125;); 如果你在consumers不指定/, 它会假定你指的是子类型. Routing based on MIME types acceptable by the client HTTP accept header常常用于表示客户端接收到的服务器响应的MIME类型. accept header可以带有多个MIME类型,他们之间通过&#39;,&#39;分割. MIME类型还可以有一个q值,MIME types can also have a q value appended to them* which signifies a weighting to apply if more than one response MIME type is available matching the accept header. The q value is a number between 0 and 1.0. If omitted it defaults to 1.0. 例如,下面的accept header表示只会接受text/plain的MIME类型. 1Accept: text/plain 下面的accept header会接受text/plain和text/html的MIME类型,这俩者直接并没有优先级. 1Accept: text/plain, text/html 但是下面的客户端会会接受text/plain和text/html的MIME类型,但是text/html的优先级高于text/plain, 因为text/html有一个更高的q值. (默认情况下q=1) 1Accept: text/plain; q=0.9, text/html 如果服务器能够同时提供text/plain和text/html, 那么在这个例子中,他就应该提供text/html. 通过使用produces方法设置了route产生的MIME类型, 例如下面的handler设置了一个MIME类型为application/json的响应 1234567router.route().produces(&quot;application/json&quot;).handler(routingContext -&gt; &#123; HttpServerResponse response = routingContext.response(); response.putHeader(&quot;content-type&quot;, &quot;application/json&quot;); response.write(someJSON).end();&#125;); 在这个例子中,route会匹配到所有的 accept header为application/json的请求. 下面是该accept headers的匹配值: 1234Accept: application/jsonAccept: application/*Accept: application/json, text/htmlAccept: application/json;q=0.7, text/html;q=0.8, text/plain 你还可以设置你的routeproduce多个MIME类型. 在这种情况中, 你可以使用getAcceptableContentType()方法找到实际接受到的MIME类型 12345678910router.route().produces(&quot;application/json&quot;).produces(&quot;text/html&quot;).handler(routingContext -&gt; &#123; HttpServerResponse response = routingContext.response(); // Get the actual MIME type acceptable String acceptableContentType = routingContext.getAcceptableContentType(); response.putHeader(&quot;content-type&quot;, acceptableContentType); response.write(whatever).end();&#125;); 在上面的例子中，如果你发送下面的accept header 1Accept: application/json; q=0.7, text/html Then the route would match and acceptableContentType would contain text/html as both are acceptable but that has a higher q value. Combining routing criteria你可以将很多route规则组合到一起, 例如： 1234567891011Route route = router.route(HttpMethod.PUT, &quot;myapi/orders&quot;) .consumes(&quot;application/json&quot;) .produces(&quot;application/json&quot;);route.handler(routingContext -&gt; &#123; // This would be match for any PUT method to paths starting with &quot;myapi/orders&quot; with a // content-type of &quot;application/json&quot; // and an accept header matching &quot;application/json&quot;&#125;); Enabling and disabling routes你可以通过调用disable()方法手动的关闭某个route, 被关闭的route会忽略所有的匹配. 你还可以通过调用enable重新打开被关闭的route Context data在一个请求的生命周期之内, 你可以将想要在handler之间共享的数据放在RoutingContext中进行传递. 下面的例子中,使用put添加数据, 使用get检索数据. 1234567891011121314router.get(&quot;/some/path&quot;).handler(routingContext -&gt; &#123; routingContext.put(&quot;foo&quot;, &quot;bar&quot;); routingContext.next();&#125;);router.get(&quot;/some/path/other&quot;).handler(routingContext -&gt; &#123; String bar = routingContext.get(&quot;foo&quot;); // Do something with bar routingContext.response().end();&#125;); Sub-routers有时候你也许会有很多handler来处理请求, 在这种情况下将这些handler分配到多个route中是非常有好处的. 另外如果你想在不同的应用程序中通过不同的root路径来复用这些handler, 这种做法同样是很有帮助的. 为了能达到这种效果, 你可以 Sometimes if you have a lot of handlers it can make sense to split them up into multiple routers. This is also useful if you want to reuse a set of handlers in a different application, rooted at a different path root. To do this you can mount a router at a mount point in another router. The router that is mounted is called a sub-router. Sub routers can mount other sub routers so you can have several levels of sub-routers if you like. Let’s look at a simple example of a sub-router mounted with another router. This sub-router will maintain the set of handlers that corresponds to a simple fictional REST API. We will mount that on another router. The full implementation of the REST API is not shown. Here’s the sub-router: 12345678910111213141516171819202122Router restAPI = Router.router(vertx);restAPI.get(&quot;/products/:productID&quot;).handler(rc -&gt; &#123; // TODO Handle the lookup of the product.... rc.response().write(productJSON);&#125;);restAPI.put(&quot;/products/:productID&quot;).handler(rc -&gt; &#123; // TODO Add a new product... rc.response().end();&#125;);restAPI.delete(&quot;/products/:productID&quot;).handler(rc -&gt; &#123; // TODO delete the product... rc.response().end();&#125;); If this router was used as a top level router, then GET/PUT/DELETE requests to urls like /products/product1234 would invoke the API. However, let’s say we already have a web-site as described by another router: 123456Router mainRouter = Router.router(vertx);// Handle static resourcesmainRouter.route(&quot;/static/*&quot;).handler(myStaticHandler);mainRouter.route(&quot;.*\\\\.templ&quot;).handler(myTemplateHandler); We can now mount the sub router on the main router, against a mount point, in this case /productsAPI mainRouter.mountSubRouter(“/productsAPI”, restAPI);This means the REST API is now accessible via paths like: /productsAPI/products/product1234 Default 404 Handling如果没有route匹配到客户端的请求,那么Vert.x-Web会发送一个404的信号错误. 你可以自行手动设置error handler, 或者选择我们提供的error handler, 如果没有设置error handler，Vert.x-Web会返回一个基本的404回应 Error handling我们可以设置handler来处理请求,同样我们还可以设置handler处理route中的失败情况. Failure handlers 通常是和处理普通handler的route一起工作. 例如,你可以提供一个failure handler只是用来处理某种特定路径下的或者某种特定HTTP method的失败. 这种机制就为你向应用程序的不同部分设置不同的failure handler了. 下面的例子演示了我们向/somepath/开始的路径和GET请求才会被调用的failure handler. 123456789Route route = router.get(&quot;/somepath/*&quot;);route.failureHandler(frc -&gt; &#123; // This will be called for failures that occur // when routing requests to paths starting with // &#x27;/somepath/&#x27;&#125;); 如果handler中抛出异常Failure routing就会发生作用, 或者handler调用失败,向客户端发送一个失败的HTTP状态码信号. 如果我们从handler中捕获一个异常, 我们将会向客户端返回500的状态码. 在处理失败的时候, failure handler会被传递给routing context, 我们可以在该context中检索出当前的错误, 因此failure handler可以用于生成failure response。 1234567891011121314151617181920212223242526272829303132Route route1 = router.get(&quot;/somepath/path1/&quot;);route1.handler(routingContext -&gt; &#123; // Let&#x27;s say this throws a RuntimeException throw new RuntimeException(&quot;something happened!&quot;);&#125;);Route route2 = router.get(&quot;/somepath/path2&quot;);route2.handler(routingContext -&gt; &#123; // This one deliberately fails the request passing in the status code // E.g. 403 - Forbidden routingContext.fail(403);&#125;);// Define a failure handler// This will get called for any failures in the above handlersRoute route3 = router.get(&quot;/somepath/*&quot;);route3.failureHandler(failureRoutingContext -&gt; &#123; int statusCode = failureRoutingContext.statusCode(); // Status code will be 500 for the RuntimeException or 403 for the other failure HttpServerResponse response = failureRoutingContext.response(); response.setStatusCode(statusCode).end(&quot;Sorry! Not today&quot;);&#125;); Request body handlingThe BodyHandler allows you to retrieve request bodies, limit body sizes and handle file uploads. You should make sure a body handler is on a matching route for any requests that require this functionality. 1router.route().handler(BodyHandler.create()); Getting the request bodyIf you know the request body is JSON, then you can use getBodyAsJson, if you know it’s a string you can use getBodyAsString, or to retrieve it as a buffer use getBody. Limiting body sizeTo limit the size of a request body, create the body handler then use setBodyLimit to specifying the maximum body size, in bytes. This is useful to avoid running out of memory with very large bodies. If an attempt to send a body greater than the maximum size is made, an HTTP status code of 413 - Request Entity Too Large, will be sent. There is no body limit by default. Merging form attributesBy default, the body handler will merge any form attributes into the request parameters. If you don’t want this behaviour you can use disable it with setMergeFormAttributes. Handling file uploadsBody handler is also used to handle multi-part file uploads. If a body handler is on a matching route for the request, any file uploads will be automatically streamed to the uploads directory, which is file-uploads by default. Each file will be given an automatically generated file name, and the file uploads will be available on the routing context with fileUploads. Here’s an example: 12345678router.route().handler(BodyHandler.create());router.post(&quot;/some/path/uploads&quot;).handler(routingContext -&gt; &#123; Set&lt;FileUpload&gt; uploads = routingContext.fileUploads(); // Do something with uploads....&#125;); Each file upload is described by a FileUpload instance, which allows various properties such as the name, file-name and size to be accessed. Handling cookiesVert.x-Web使用CookieHandler来支持cookies. 你必须确保当请求需要cookies支持的时候,你已经设置上了cookie handler。 1router.route().handler(CookieHandler.create()); Manipulating cookies你可以向getCookie()方法, 或者通过cookies()方法检索出cookie集合. getCookie(), 传递一个cookie name的参数来检索出一个cookie cookies(), 检索出cookie集合 removeCookie, 删除一个cookie addCookie, 添加一个cookie 当response headers被写回的时候, cookies集合会自动的被写入到response中. Cookies是通过Cookie实例进行描述的. 你可以通过该实例检索出cookie中的name, value, domain, path 或者其他的cookie属性. 下面的例子演示了如何检索和添加cookie 123456789101112router.route().handler(CookieHandler.create());router.route(&quot;some/path/&quot;).handler(routingContext -&gt; &#123; Cookie someCookie = routingContext.getCookie(&quot;mycookie&quot;); String cookieValue = someCookie.getValue(); // Do something with cookie... // Add a cookie - this will get written back in the response automatically routingContext.addCookie(Cookie.cookie(&quot;othercookie&quot;, &quot;somevalue&quot;));&#125;); Handling sessionsVert.x-Web 同样提供了对于session的支持. Sessions last between HTTP requests for the length of a browser session and give you a place where you can add session-scope information, such as a shopping basket. Vert.x-Web uses session cookies to identify a session. The session cookie is temporary and will be deleted by your browser when it’s closed. We don’t put the actual data of your session in the session cookie - the cookie simply uses an identifier to look-up the actual session on the server. The identifier is a random UUID generated using a secure random, so it should be effectively unguessable. Cookies are passed across the wire in HTTP requests and responses so it’s always wise to make sure you are using HTTPS when sessions are being used. Vert.x will warn you if you attempt to use sessions over straight HTTP. To enable sessions in your application you must have a SessionHandler on a matching route before your application logic. The session handler handles the creation of session cookies and the lookup of the session so you don’t have to do that yourself. Session storesTo create a session handler you need to have a session store instance. The session store is the object that holds the actual sessions for your application. Vert.x-Web comes with two session store implementations out of the box, and you can also write your own if you prefer. Local session storeWith this store, sessions are stored locally in memory and only available in this instance. This store is appropriate if you have just a single Vert.x instance of you are using sticky sessions in your application and have configured your load balancer to always route HTTP requests to the same Vert.x instance. If you can’t ensure your requests will all terminate on the same server then don’t use this store as your requests might end up on a server which doesn’t know about your session. Local session stores are implemented by using a shared local map, and have a reaper which clears out expired sessions. The reaper interval can be configured with LocalSessionStore.create. Here are some examples of creating a LocalSessionStore SessionStore store1 = LocalSessionStore.create(vertx); // Create a local session store specifying the local shared map name to use// This might be useful if you have more than one application in the same// Vert.x instance and want to use different maps for different applicationsSessionStore store2 = LocalSessionStore.create(vertx, “myapp3.sessionmap”); // Create a local session store specifying the local shared map name to use and// setting the reaper interval for expired sessions to 10 secondsSessionStore store3 = LocalSessionStore.create(vertx, “myapp3.sessionmap”, 10000); Clustered session storeWith this store, sessions are stored in a distributed map which is accessible across the Vert.x cluster. This store is appropriate if you’re not using sticky sessions, i.e. your load balancer is distributing different requests from the same browser to different servers. Your session is accessible from any node in the cluster using this store. To you use a clustered session store you should make sure your Vert.x instance is clustered. Here are some examples of creating a ClusteredSessionStore Vertx.clusteredVertx(new VertxOptions().setClustered(true), res -&gt; { Vertx vertx = res.result(); // Create a clustered session store using defaults SessionStore store1 = ClusteredSessionStore.create(vertx); // Create a clustered session store specifying the distributed map name to use // This might be useful if you have more than one application in the cluster // and want to use different maps for different applications SessionStore store2 = ClusteredSessionStore.create(vertx, “myclusteredapp3.sessionmap”);}); Creating the session handlerOnce you’ve created a session store you can create a session handler, and add it to a route. You should make sure your session handler is routed to before your application handlers. You’ll also need to include a CookieHandler as the session handler uses cookies to lookup the session. The cookie handler should be before the session handler when routing. Here’s an example: Router router = Router.router(vertx); // We need a cookie handler firstrouter.route().handler(CookieHandler.create()); // Create a clustered session store using defaultsSessionStore store = ClusteredSessionStore.create(vertx); SessionHandler sessionHandler = SessionHandler.create(store); // Make sure all requests are routed through the session handler toorouter.route().handler(sessionHandler); // Now your application handlersrouter.route(“/somepath/blah/“).handler(routingContext -&gt; { Session session = routingContext.session(); session.put(“foo”, “bar”); // etc });The session handler will ensure that your session is automatically looked up (or created if no session exists) from the session store and set on the routing context before it gets to your application handlers. Using the sessionIn your handlers you an access the session instance with session. You put data into the session with put, you get data from the session with get, and you remove data from the session with remove. The keys for items in the session are always strings. The values can be any type for a local session store, and for a clustered session store they can be any basic type, or Buffer, JsonObject, JsonArray or a serializable object, as the values have to serialized across the cluster. Here’s an example of manipulating session data: router.route().handler(CookieHandler.create());router.route().handler(sessionHandler); // Now your application handlersrouter.route(“/somepath/blah”).handler(routingContext -&gt; { Session session = routingContext.session(); // Put some data from the session session.put(“foo”, “bar”); // Retrieve some data from a session int age = session.get(“age”); // Remove some data from a session JsonObject obj = session.remove(“myobj”); });Sessions are automatically written back to the store after after responses are complete. You can manually destroy a session using destroy. This will remove the session from the context and the session store. Note that if there is no session a new one will be automatically created for the next request from the browser that’s routed through the session handler. Session timeoutSessions will be automatically timed out if they are not accessed for a time greater than the timeout period. When a session is timed out, it is removed from the store. Sessions are automatically marked as accessed when a request arrives and the session is looked up and and when the response is complete and the session is stored back in the store. You can also use setAccessed to manually mark a session as accessed. The session timeout can be configured when creating the session handler. Default timeout is 30 minutes. AuthenticationServing static resourcesCORS handlingCross Origin Resource Sharing是一个安全的资源请求途径(AJAX跨域问题的解决方案) Vert.x-Web包含了一个CorsHandler, 用于处理CORS协议. 例如 1234567router.route().handler(CorsHandler.create(&quot;vertx\\\\.io&quot;).allowedMethod(HttpMethod.GET));router.route().handler(routingContext -&gt; &#123; // Your app handlers&#125;); TODO more CORS docs TemplatesError handler你可以自己提供一个ErrorHandler用于处理error异常,否则的话Vert.x-Web会包含一个包装好的pretty error handler用于响应错误页面. 如果你自己想要设置一个ErrorHandler, 那么你只需要将其设置成failure handler就可以了. Request loggerVert.x-Web内嵌了LoggerHandler,使用它你可以将HTTP requests通过日志形式记录下来. 默认情况下,请求是Vert.x logger进行记录的,我们可以将其配置成JUL logging, log4j or SLF4J Serving faviconsVert.x-Web包含一个FaviconHandler来响应favicons. Favicons可以被指定为文件系统里的一个路径,或者Vert.x-Web会默认的在classpath搜索名为favicon.ico的文件.这意味着你需要在你的应用程序的jar包绑定该favicon Timeout handlerVert.x-Web包含一个超时handler,你可以使用它应付某些操作执行时间太长的请求. 我们通过一个TimeoutHandler实例来配置它. 如果一个请求在写回之前超时了，那么4.8响应将会写回个给客户端. 下面的例子使用了一个超时handler: 1router.route(&quot;/foo/&quot;).handler(TimeoutHandler.create(5000)); Response time handler这个handler设置了x-response-time响应头, 该响应头包含了请求从接受到响应所耗费的时间,单位是ms: 1x-response-time: 1456ms SockJSSockJS event bus bridge","categories":[{"name":"vertx","slug":"vertx","permalink":"https://wangmingco.github.io/categories/vertx/"}],"tags":[{"name":"vertx3","slug":"vertx3","permalink":"https://wangmingco.github.io/tags/vertx3/"}]},{"title":"PYTHON2 第三方库","slug":"编程语言/python2 第三方库","date":"2015-08-08T16:00:00.000Z","updated":"2021-11-18T02:28:43.573Z","comments":true,"path":"2015/08/09/编程语言/python2 第三方库/","link":"","permalink":"https://wangmingco.github.io/2015/08/09/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/python2%20%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/","excerpt":"","text":"json使用dump()方法将对象序列化成json,然后使用load()将字符串反序列化成对象 123456789101112131415161718192021222324252627282930313233343536#-*- coding=utf-8 -*-import jsonlist = [123, &quot;ad&quot;]listJson = json.dumps(list)listR = json.loads(listJson)print &quot;列表序列化 : &quot; + listJsonprint &quot;列表反序列化 : &quot; + str(listR[0])tumple = (123, &quot;adf&quot;)tumpleJson = json.dumps(tumple)tumpleR = json.loads(tumpleJson)print &quot;元组序列化 : &quot; + tumpleJsonprint &quot;元组反序列化 : &quot; + str(tumpleR[1])map = &#123; &quot;key1&quot;:&quot;value1&quot;, &quot;key2&quot;:&quot;value2&quot;, &quot;key3&quot;:&quot;value3&quot;, &#125;mapJson = json.dumps(map)mapR = json.loads(mapJson)print &quot;字典序列化 : &quot; + mapJsonprint &quot;字典反序列化 : &quot; + str(mapR[&quot;key1&quot;])seq = [&#x27;apple&#x27;, &#x27;mango&#x27;, &#x27;carrot&#x27;, &#x27;banana&#x27;]seqJson = json.dumps(seq)seqR = json.loads(seqJson)print &quot;序列序列化 : &quot; + seqJsonprint &quot;序列反序列化 : &quot; + str(seqR[1])type tumpleR[1]type mapR[&quot;key1&quot;]type seqR[1] redis1234567891011121314151617181920212223242526272829303132333435363738#!/usr/bin/python# -*- coding: utf-8 -*-import sysreload(sys)sys.setdefaultencoding(&#x27;utf-8&#x27;)import redisimport json_REDIS_HOST = &#x27;localhost&#x27;_REDIS_PORT = 6379_REDIS_DB = 1_PASSWORD = &quot;2016&quot;def getRedisCli() : redisCli = redis.Redis(host=_REDIS_HOST, port=_REDIS_PORT, db=_REDIS_DB, password=_PASSWORD) return redisClidef info() : redisCli = getRedisCli() return redisCli.info()def slowlog_get() : redisCli = getRedisCli() return redisCli.slowlog_get()def client_list() : redisCli = getRedisCli() return redisCli.client_list()def dbsize() : redisCli = getRedisCli() return redisCli.dbsize()info = info()slowlog_get = slowlog_get()dbsize = dbsize()print info mysql12345678910111213141516171819202122232425262728293031#!/usr/bin/python# -*- coding: utf-8 -*-import sysimport mysql.connectormysql_host = &quot;localhost&quot;mysql_database = &quot;test&quot;mysql_user = &quot;root&quot;mysql_passwrold = &quot;root&quot;reload(sys)sys.setdefaultencoding(&#x27;utf-8&#x27;)def exec_sqls(exec_sql): cnx = mysql.connector.connect(user=mysql_user, password=mysql_passwrold, host=mysql_host, database=mysql_database) cursor = cnx.cursor() exec_sql(cursor) cnx.commit() cursor.close() cnx.close()def query_max_connections(cursor): print &quot;连接数信息&quot; max_connections = exec_sql_query(cursor, &quot;show variables like &#x27;max_connections&#x27;&quot;) max_connections_num = float(max_connections[0][1]) print(&quot;max_connections : &quot; + str(max_connections_num)) exec_sqls(query_max_connections) Fabric安装 1pip install fabric 如果已经安装过了则进行更新, 我现在基于的是1.12.0版本 1pip install --upgrade fabric 执行本地命令 12345678910111213#!/usr/bin/python# -*- coding: utf-8 -*-import sysreload(sys)sys.setdefaultencoding(&#x27;utf-8&#x27;)from fabric.api import localdef echo_helloworld(): local(&quot;ECHO helloworld&quot;)echo_helloworld() 如果命令报错的话,我们进行错误处理 1234567891011121314151617#!/usr/bin/python# -*- coding: utf-8 -*-import sysreload(sys)sys.setdefaultencoding(&#x27;utf-8&#x27;)from fabric.api import local, settingsdef cd_test_dir(): # 首先我们设置只是警告, 而不是发生错误时直接Abort with settings(warn_only=True): result = local(&quot;cd ./test&quot;, capture=True) if result.failed: local(&quot;mkdir ./test&quot;) local(&quot;cd ./test&quot;, capture=True)cd_test_dir() 安装失败最近在mac上使用pip安装插件，总是提示 1234567Exception:Traceback (most recent call last): File &quot;/Library/Python/2.7/site-packages/pip/basecommand.py&quot;, line 215, in .........OSError: [Errno 1] Operation not permitted: &#x27;/tmp/pip-qo8UFu-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/six-1.4.1-py2.7.egg-info&#x27; 各种su, sudo都不行, 在百度上找到一种解决方案 1pip install scrapy --user -U 基于用户的权限来安装模块包, 成功安装","categories":[{"name":"PYTHON2","slug":"PYTHON2","permalink":"https://wangmingco.github.io/categories/PYTHON2/"}],"tags":[]},{"title":"PYTHON2 文件和网络操作","slug":"编程语言/python2 文件和网络操作","date":"2015-08-07T16:00:00.000Z","updated":"2021-11-18T02:28:53.342Z","comments":true,"path":"2015/08/08/编程语言/python2 文件和网络操作/","link":"","permalink":"https://wangmingco.github.io/2015/08/08/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/python2%20%E6%96%87%E4%BB%B6%E5%92%8C%E7%BD%91%E7%BB%9C%E6%93%8D%E4%BD%9C/","excerpt":"","text":"文件打开一个文件 1f = open(name, [mode], [size]) name: 文件名 mode: 打开方式 size: 操作的字节数 mode值: r: 只读方式打开(文件必须存在) w: 只写方式打开(文件不存在创建文件,文件存在清空文件) a: 追加方式打开(文件不存在创建文件) r+/w+: 读写方式打开 a+: 读写方式打开 rb,wb,ab,rb+,wb+,ab+: 二进制方式打开 注意:如果我们使用非二进制模式输出时\\n(0A)会被自动替换为\\r\\n(0D 0A),因此在文件输出时,我们要注意这个问题. 对象常用方法 read([size]) : 读取文件(size有值则读取size个字节),如果不填写size则读取全部 readline([size]) : 每次读取一行(size值为当前行的长度,但是如果每次读取不完的话,下次再调用readline时会继续在当前行读取) readlines([size]) : 读取多行,返回每一行组成的列表. 如果不填写size则读取全部内容(不推荐使用这种方式读取所有行) write(str) : 将字符串直接写入文件中 writelines(lines): 将字符串或者字符串列表写入文件中. close(): 关闭文件操作 我们可以使用for循环遍历整个文件 123file = open(&quot;demo.txt&quot;)for line in file: print(line) OS模块文件操作1fd = os.open(filename, flag, [mode]) filename和mode我们通过上面的描述都知道了,现在我们看一下flag属性值(文件打开方式) os.O_CREAT : 创建文件 os.O_RDONLY : 只读方式打开 os.O_WRONLY : 只写方式打开 os.O_RDWR : 读写方式打开 示例 12fd = os.open(&quot;test.txt&quot;, os.O_CREAT | os.O_RDWR)os.write(fd, &quot;helloworld&quot;) 遍历目录文件1234567891011121314151617181920#!/usr/bin/python# -*- coding: utf-8 -*-import sysreload(sys)sys.setdefaultencoding(&#x27;utf-8&#x27;)import os.pathrootdir = &quot;C:\\\\Users\\\\wangming\\\\Documents&quot;for parent, dirnames, filenames in os.walk(rootdir): for filename in filenames: fullname = os.path.join(parent, filename) # print &quot;the full name of the file is:&quot; + fullname #输出文件路径信息 file = open(fullname) for line in file: if line.find(&quot;)[&quot;) &gt; 0: print(str(fullname) + &quot; -&gt; &quot; + str(line)) 中文乱码写入文件时,如果输出中文,我们经常会遇到乱码的问题.只需要在python文件顶部加上以下内容就可以了 1#-*- coding=utf-8 -*- 网络Socket服务器12345678910111213141516171819import socketsock=socket.socket(socket.AF_INET,socket.SOCK_STREAM)sock.bind((&#x27;localhost&#x27;,8089))sock.listen(5)print(&#x27;tcpServer listen at: %s:%s\\n\\r&#x27; %(&#x27;localhost&#x27;,8089))while True: client_sock,client_addr=sock.accept() print(&#x27;%s:%s connect&#x27; %client_addr) while True: recv=client_sock.recv(4096) if not recv: client_sock.close() break print(&#x27;[Client %s:%s said]:%s&#x27; % (client_addr[0],client_addr[1],recv)) client_sock.send(&#x27;tcpServer has received your message&#x27;) sock.close() HttpServer12345678910import BaseHTTPServerimport urlparseclass WebRequestHandler(BaseHTTPServer.BaseHTTPRequestHandler): def do_GET(self): &quot;&quot;&quot; &quot;&quot;&quot; print &quot;8090&quot;server = BaseHTTPServer.HTTPServer((&#x27;0.0.0.0&#x27;,8090), WebRequestHandler)server.serve_forever() self 还有如下参数 self.path self.client_address self.address_string() self.command self.path self.request_version self.server_version self.sys_version self.protocol_version self.headers self.send_response(200) self.end_headers() Socket客户端123456client=socket.socket(socket.AF_INET,socket.SOCK_STREAM)client.connect((&#x27;localhost&#x27;,8880))client.send(&#x27;2&#x27;)recvData=client.recv(1024)print recvData","categories":[{"name":"PYTHON2","slug":"PYTHON2","permalink":"https://wangmingco.github.io/categories/PYTHON2/"}],"tags":[]},{"title":"PYTHON2 函数","slug":"编程语言/python2 函数","date":"2015-08-06T16:00:00.000Z","updated":"2021-11-18T02:28:46.614Z","comments":true,"path":"2015/08/07/编程语言/python2 函数/","link":"","permalink":"https://wangmingco.github.io/2015/08/07/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/python2%20%E5%87%BD%E6%95%B0/","excerpt":"","text":"定义一个不带参数的函数123456# 定义一个不带参数的函数def printHelloworld(): print(&quot;hello world&quot;)## 调用函数printHelloworld() 定义一个带参数的函数123456# 定义一个带参数的函数def printHelloworld(saywhat): print(saywhat)## 调用函数printHelloworld(&quot;hello world&quot;) 函数中的局部变量1234567# 定义一个带参数的函数def printHelloworld(saywhat): value = saywhat print(value)## 调用函数printHelloworld(&quot;hello world&quot;) 当在函数内部修改了局部变量之后,并不会影响脚本中的变量 12345678910# 定义一个带参数的函数def printHelloworld(saywhat): print(saywhat) saywhat = &quot;new value&quot; print(saywhat)# 调用函数str = &quot;hello world&quot;printHelloworld(str)print(str) 使用global语句123456789# 定义一个带参数的函数def printHelloworld(): global saywhat ## 此处不可进行初始化 saywhat = &quot;new value&quot; print(saywhat)# 调用函数printHelloworld()print(saywhat) 默认参数值我们也可以给函数参数指定默认值 12345def printHelloworld(str, str1=&quot;str1 value&quot;, str2=&quot;str2 value&quot;): print(str + &quot; &quot; + str1 + &quot; &quot; + str2)# 调用函数printHelloworld(&quot;123&quot;, str2=&quot;789&quot;) 可变参数python函数也可以接受不定参数 12345def f(*args): print(args)f(1)f(1, 2) 输出为 12(1,)(1, 2) return返回值12345678910111213def printHelloworld(str, str1=&quot;str1 value&quot;, str2=&quot;str2 value&quot;): print(str) if str1==&quot;str1 value&quot; : return &quot;nil value&quot; print(str1) print(str2)# 调用函数result = printHelloworld(&quot;123&quot;, str2=&quot;789&quot;)print(result)result = printHelloworld(&quot;123&quot;, str1=&quot;789&quot;)print(result) 高阶函数如果函数A里的参数或者返回值是另一个函数,那么函数A就是高阶函数. 1234567def add5(v1): return v1 + 5;def add(v1, v2, add5): return add5(v1) + add5(v2)print(add(2, 4, add5)) 内置高阶函数map()函数：它接受一个函数和一个列表,然后遍历列表中的每个元素作用在函数参数中 1234print(map(add5, [1, 2, 3]))// 结果为[6, 7, 8] reduce()函数 1 filter()函数 1 闭包在2.7版本中必须要如下声明一个闭包 12345678910def outerF(): count = [10] def innerF(): print(count[0]) count[0] = 20 return innerFf = outerF()f()f() 匿名函数python通过lambda表达式完成匿名函数 12345def nonameF(f, v1): return f(v1)value = nonameF(lambda x: x + 1, 5)print(value) 不过python只是有限的支持匿名函数, 匿名函数只能是一个表达式,而且不能拥有return,表达式的结果就是返回值 偏函数偏函数就是通过functools.partial函数将函数A中的参数指定一个值然后返回一个新的函数 12345678import functoolsdef fa(var1, var2, var3): print(var1 + var2 + var3)fb = functools.partial(fa, var2=2, var3=3)fa(1, 2, 3)fb(1) 最后我们看到了相同的结果 重定义我们可以对一个已经存在的函数重新定义行为 1234567891011121314def f(*args): print(args)f = lambda : 15print(f())n = fdef f(): return 20print(n())print(f()) 从这一点可以验证在python中函数也是对象. 装饰器装饰器本质上就是一个高阶函数，它接收一个函数作为参数，然后，返回一个新函数。 python通过@语法内置实现装饰器 123456789def fb(f): print(&quot;fb&quot;) return f@fbdef fa(var1, var2, var3): print(var1 + var2 + var3)fa(1, 2, 3) 上面这个例子每次在调用fa方法时都会输出一个fb字符串","categories":[{"name":"PYTHON2","slug":"PYTHON2","permalink":"https://wangmingco.github.io/categories/PYTHON2/"}],"tags":[]},{"title":"PYTHON2 基础语法","slug":"编程语言/python2 基础语法","date":"2015-08-05T16:00:00.000Z","updated":"2021-11-18T02:28:50.083Z","comments":true,"path":"2015/08/06/编程语言/python2 基础语法/","link":"","permalink":"https://wangmingco.github.io/2015/08/06/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/python2%20%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/","excerpt":"","text":"控制流程if1234567tmp = 0if tmp &gt; 0 : print(&quot;&gt;&quot;)elif tmp &lt; 0 : print(&quot;&lt;&quot;)else : print(&quot;=&quot;) while123456tmp = 0while tmp &lt; 3 : print(tmp) tmp +=1else : print(&quot;over&quot;) for12345678910for i in [0,1,2,3,4]: print(i) if i &gt; 2 : break else : continueelse: print(&#x27;loop over&#x27;) 或者 123# 从0开始步增到10for i in range(0, 10, 1) print(i) 模块模块是一个包含函数和变量的文件。为了在其他程序中重用模块，模块的文件名必须以.py为扩展名。 使用sys模块1234import sysfor argv in sys.argv : print(argv) 使用from..import.., import可以使用* 1234from sys import argvfor argvtmp in argv : print(argvtmp) 模块的name,下面的语法输出当前模块的name 1print(__name__) 自定义模块 建立mymodule.py文件1234# Filename: mymodule.pydef printModuleName(): print(__name__) 建立test_mymodule.py文件123import mymodulemymodule.printModuleName() 需要注意的是mymodule.py文件的Filename必须和文件名相同 如果module的name是__main__说明这个module是由用户启动的 集合列表 声明一个列表 list = [123, &quot;ad&quot;] 索引第一个元素 list[0] 在尾部添加一个元素 list.append(2.56) 对第一个元素重新赋值 list[0] = &quot;0&quot; 获取列表长度 len(list) 删除第一个元素 del list[0] 元组元组和列表十分类似，只不过元组和字符串一样是 不可变的 即你不能修改元组 123tumple = (123, &quot;adf&quot;)print(tumple[0])print(len(tumple)) 字典1234567891011121314151617map = &#123; &quot;key1&quot;:&quot;value1&quot;, &quot;key2&quot;:&quot;value2&quot;, &quot;key3&quot;:&quot;value3&quot;, &#125;print(map)print(len(map))print(map[&quot;key1&quot;])del map[&quot;key1&quot;]print(map)for key in map: print(key + &quot; &quot; + map[key])if &quot;key2&quot; in map: print(&quot;map contains key2&quot;)help(dict) 序列序列的两个主要特点是索引操作符和切片操作符 1234567891011121314151617shoplist = [&#x27;apple&#x27;, &#x27;mango&#x27;, &#x27;carrot&#x27;, &#x27;banana&#x27;]print(&#x27;Item 0 is&#x27;, shoplist[0])print(&#x27;Item -1 is&#x27;, shoplist[-1])### Slicing on a listprint(&#x27;Item 1 to 3 is&#x27;, shoplist[1:3])print(&#x27;Item 2 to end is&#x27;, shoplist[2:])print(&#x27;Item 1 to -1 is&#x27;, shoplist[1:-1])print(&#x27;Item start to end is&#x27;, shoplist[:])### Slicing on a stringname = &#x27;swaroop&#x27;print(&#x27;characters 1 to 3 is&#x27;, name[1:3])print(&#x27;characters 2 to end is&#x27;, name[2:])print(&#x27;characters 1 to -1 is&#x27;, name[1:-1])print(&#x27;characters start to end is&#x27;, name[:]) 多线程123456789101112131415161718import socketimport threadingimport timecount = 0def socketSendData(): client=socket.socket(socket.AF_INET,socket.SOCK_STREAM) client.connect((&#x27;www.baidu.com&#x27;,80)) time.sleep(1)for i in range(0, 20000, 1): try: t = threading.Thread(target=socketSendData) info = t.start() except: count += 1 print &quot;Error: unable to start thread &quot; + str(count) 异常捕获异常 1234567try: fh = open(&quot;test&quot;, &quot;w&quot;)except IOError: print &quot;Error: open error&quot;else: print &quot;hava open file&quot; fh.close() 抛出异常raise [Exception [, args [, traceback]]]例如 12if(num &lt; 100): raise RuntimeError(&quot;num is greater than 100!&quot;) 面向对象self类的方法与普通的函数只有一个特别的区别——它们必须有一个额外的第一个参数名称self 1 创建一个类12345class Person: passp = Person()print p 对象的方法123456class Person: def run(self): print(&quot;run&quot;)p = Person()p.run() __init__方法__init__方法在类的一个对象被建立时，马上运行 12345678class Person: def run(self): print(&quot;run&quot;) def __init__(self): print(&quot;init&quot;)p = Person()p.run() __del__方法1234567class Person: def __init__(self): print(&quot;init&quot;) def __del__(self): print(&quot;__destory__&quot;)p = Person() 变量 类的变量: 由一个类的所有对象（实例）共享使用。只有一个类变量的拷贝，所以当某个对象对类的变量做了改动的时候，这个改动会反映到所有其他的实例上。 对象的变量: 由类的每个对象/实例拥有。因此每个对象有自己对这个域的一份拷贝，即它们不是共享的，在同一个类的不同实例中，虽然对象的变量有相同的名称，但是是互不相关的。通过一个例子会使这个易于理解。 12345678class Father: age = 0father = Father()father.age = 10Father.age = 20print(father.age)print(Father.age) 权限控制对象的属性(变量和方法)如果名字以__开头则不能被外部访问,但是如果名称构成形式为__xxx__则被称为特殊属性,是可以被外界访问的. 继承123456789101112class Father: name = &quot;Tom&quot; def run(self): print(&quot;run&quot;)class Son(Father): passson = Son()print(son.name)son.run() __init__, __del__在继承中的使用Python不会自动调用父类的constructor 123456789101112131415161718192021class Mother: passclass Father: name = &quot;Tom&quot; def run(self): print(&quot;run&quot;) def __init__(self): print(&quot;Father init&quot;) def __del__(self): print(&quot;Father del&quot;)class Son(Father, Mother): def __init__(self): print(&quot;Son init&quot;) def __del__(self): print(&quot;Son del&quot;)son = Son()print(son.name)son.run() 字符串函数修改 capitalize(...) : Python capitalize()将字符串的第一个字母变成大写,其他字母变小写。print &quot;abc&quot;.capitalize() center(...) : 返回一个原字符串居中,并使用空格填充至长度 width 的新字符串。默认填充字符为空格。print &quot;abc&quot;.center(10, &quot;1&quot;)结果为111abc1111 expandtabs(...) : S.expandtabs(tabsize=8) -&gt; str 把字符串中的 tab 符号(‘\\t’)转为空格，默认的空格数 tabsize 是 8。 format(...) : &quot;abcd&#123;0&#125;fg&quot;.format(&quot;sdf&quot;) {0}被替换成sdf join(...) : S.join(iterable) -&gt; str 用于将序列中的元素以指定的字符连接生成一个新的字符串。 ljust(...) : S.ljust(width[, fillchar]) -&gt; str 返回一个原字符串左对齐,并使用空格填充至指定长度的新字符串。如果指定的长度小于原字符串的长度则返回原字符串。 rjust(...) : S.rjust(width[, fillchar]) -&gt; str 返回一个原字符串右对齐,并使用空格填充至长度 width 的新字符串。如果指定的长度小于字符串的长度则返回原字符串。 lower(...) : S.lower() -&gt; str 转换字符串中所有大写字符为小写。 lstrip(...) : S.lstrip([chars]) -&gt; str 用于截掉字符串左边的空格或指定字符。 replace(...) : S.replace(old, new[, count]) -&gt; str 把字符串中的 old（旧字符串） 替换成 new(新字符串)，如果指定第三个参数max，则替换不超过 max 次。 split(...) : S.split(sep=None, maxsplit=-1) -&gt; list of strings 通过指定分隔符对字符串进行切片，如果参数num 有指定值，则仅分隔 num 个子字符串. 另外参考rsplit(...) strip(...) : S.strip([chars]) -&gt; str 用于移除字符串头尾指定的字符（默认为空格）。 rstrip(...) : S.rstrip([chars]) -&gt; str 删除 string 字符串末尾的指定字符（默认为空格）. swapcase(...) : S.swapcase() -&gt; str 用于对字符串的大小写字母进行转换。 translate(...) : S.translate(table) -&gt; str 根据参数table给出的表(包含 256 个字符)转换字符串的字符, 要过滤掉的字符放到 del 参数中。 upper(...) : S.upper() -&gt; str 将字符串中的小写字母转为大写字母。 zfill(...) : S.zfill(width) -&gt; str 返回指定长度的字符串，原字符串右对齐，前面填充0。 title(...) : S.title() -&gt; str 返回”标题化”的字符串,就是说所有单词都是以大写开始，其余字母均为小写(见 istitle())。 查找 count(...) : 用于统计字符串里某个字符出现的次数。可选参数为在字符串搜索的开始与结束位置。&quot;abcdefg&quot;.count(&quot;c&quot;, 2, 4)结果为1 find(...) : S.find(sub[, start[, end]]) -&gt; int 检测字符串中是否包含子字符串 str ，如果指定 beg（开始） 和 end（结束） 范围，则检查是否包含在指定范围内，如果包含子字符串返回开始的索引值，否则返回-1。 rfind(...) : S.rfind(sub[, start[, end]]) -&gt; int 返回字符串最后一次出现的位置，如果没有匹配项则返回-1。 endswith(...) : 用于判断字符串是否以指定后缀结尾，如果以指定后缀结尾返回True，否则返回False。可选参数”start”与”end”为检索字符串的开始与结束位置。&quot;abcdefg&quot;.endswith(&quot;d&quot;, 2, 4)结果为true index(...) : S.index(sub[, start[, end]]) -&gt; int检测字符串中是否包含子字符串 str ，如果指定 beg（开始） 和 end（结束） 范围，则检查是否包含在指定范围内，该方法与 python find()方法一样，只不过如果str不在 string中会报一个异常。 rindex(...) : S.rindex(sub[, start[, end]]) -&gt; int 返回子字符串 str 在字符串中最后出现的位置，如果没有匹配的字符串会报异常，你可以指定可选参数[beg:end]设置查找的区间。 partition(...) : S.partition(sep) -&gt; (head, sep, tail) Search for the separator sep in S, and return the part before it,the separator itself, and the part after it. If the separator is not found, return S and two empty strings. rpartition(...) : S.rpartition(sep) -&gt; (head, sep, tail) 类似于 partition()函数,不过是从右边开始查找. startswith(...) : S.startswith(prefix[, start[, end]]) -&gt; bool 用于检查字符串是否是以指定子字符串开头，如果是则返回 True，否则返回 False。如果参数 beg 和 end 指定值，则在指定范围内检查。 检测 isalnum(...) : S.isalnum() -&gt; bool 判断字符串是否包含字母数字。 isalpha(...) : S.isalpha() -&gt; bool 检测字符串是否只由字母组成。 isdecimal(...) : S.isdecimal() -&gt; bool 检查字符串是否只包含十进制字符。这种方法只存在于unicode对象。 isdigit(...) : S.isdigit() -&gt; bool 检测字符串是否只由数字组成。 islower(...) : S.islower() -&gt; bool 检测字符串是否由小写字母组成。 isnumeric(...) : S.isnumeric() -&gt; bool 检查是否只有数字字符组成的字符串。这种方法目前只对unicode对象。 isspace(...) : S.isspace() -&gt; bool 是否只由空格组成。 istitle(...) : S.istitle() -&gt; bool 检测字符串中所有的单词拼写首字母是否为大写，且其他字母为小写。 isupper(...) : S.isupper() -&gt; bool 检测字符串中所有的字母是否都为大写。 编码 encode(...) : encoding 指定的编码格式编码字符串。errors参数可以指定不同的错误处理方案。S.encode(encoding=&#39;utf-8&#39;, errors=&#39;strict&#39;) -&gt; bytes 遍历 splitlines(...) : S.splitlines([keepends]) -&gt; list of strings 返回一个字符串的所有行，可选包括换行符列表(如果num提供，则为true)","categories":[{"name":"PYTHON2","slug":"PYTHON2","permalink":"https://wangmingco.github.io/categories/PYTHON2/"}],"tags":[]},{"title":"Vertx 3 Core","slug":"vertx/vertx3_core","date":"2015-08-05T12:15:00.000Z","updated":"2021-11-18T02:35:33.395Z","comments":true,"path":"2015/08/05/vertx/vertx3_core/","link":"","permalink":"https://wangmingco.github.io/2015/08/05/vertx/vertx3_core/","excerpt":"","text":"In the beginning there was Vert.x NOTEMuch of this is Java specific - need someway of swapping in language specific parts 在Vert.x里，如果你不使用Vertx对象，你几乎是寸步难行。 Vertx对象扮演着Vert.x控制中心的角色，同时它也提供了大量的功能，例如： 创建客户端和服务器 获得event bus引用 设置定时器 … 如果你将Vert.x嵌入到你的应用程序中，你可以向下面这样获得一个Vertx对象的引用 1Vertx vertx = Vertx.vertx(); If you’re using Verticles 注意： 在绝大多数应用程序中，你只需要一个Vert.x实例，但是如果你想要创建多个Vert.x实例，这也是可以的，例如你想要将event bus或者服务器与客户端进行隔离 Specifying options when creating a Vertx object当你实例化Vertx对象时，如果你感觉默认的参数不符合你的需求，你可以指定实例化时的参数： 1Vertx vertx = Vertx.vertx(new VertxOptions().setWorkerPoolSize(40)); VertxOptions对象拥有N多设置，例如配置集群，高可用设置，线程池大小以及等等其他参数 Are you fluent?流式API(fluent API)是一种将方法进行链式调用的方式： 1request.response().putHeader(&quot;Content-Type&quot;, &quot;text/plain&quot;).write(&quot;some text&quot;).end(); 在Vert.x APIs中，你都可以使用这种方式 进行链式调用可以避免你的代码看起来罗哩罗嗦的。当然，这并不是强制的，你也可以像下面这样书写你的代码。 1234HttpServerResponse response = request.response();response.putHeader(&quot;Content-Type&quot;, &quot;text/plain&quot;);response.write(&quot;some text&quot;);response.end(); Don’t call us, we’ll call you.Vert.x APIs大多数是基于事件驱动的。这意味着，在Vert.x中，当你关注的事件发生时，Vert.x会自动通知你。 例如当下面这些事件发生时，Vert.x就会自动通知你 定时器被触发 socket中接收到数据 从磁盘中读取数据已经就绪 异常发生 HTTP服务器接受到一个请求 我们需要通过向Vert.x APIs提供handler来处理Vert.x通知给我们的事件，例如下例中演示了我们每秒从定时器中接受一个事件 1234vertx.setPeriodic(1000, id -&gt; &#123; // This handler will get called every second System.out.println(&quot;timer fired!&quot;);&#125;); 或者接受一个HTTP请求 1234server.requestHandler(request -&gt; &#123; // This handler will be called every time an HTTP request is received at the server request.response().end(&quot;hello world!&quot;);&#125;); 当Vert.x中产生一个事件之后，它会异步地将这个事件传递到你设置的handler中 This leads us to some important concepts in Vert.x: TODO Don’t block me!With very few exceptions (i.e. some file system operations ending in ‘Sync’), Vert.x中的API方法都不会阻塞该该方法的执行线程。 如果结果能够直接返回的话，那么你可以直接获得该结果进行后续处理，否则你需要提供一个handler，等结果正式产生之后再处理该结果。 因为Vert.x API不会阻塞任何线程，因此你可以使用少量的线程来处理非常大的并发量 在传统的阻塞API中，下面的操作会阻塞住当前的调用线程 从socket中读取数据 向磁盘中写入数据 向远端发送一条消息，同时等待消息返回 … Many other situations 在上面的例子中，当你的线程等待一个结果时，这个线程就不能再做其他的任何事，这是非常低效的。 译者注： 也许你会说这个线程被阻塞了，但是还有其他的线程可以工作啊，但是首先我们的目标是用少量地线程做大量的工作，当我们引入更多线程首先与我们的目标不符合，再有更多的线程会消耗更多的内存和更多的线程上下文切换操作 这意味着，如果你想要使用阻塞API进行大量并发操作，你需要非常多的线程以避免你的应用程序慢慢停止掉。 For the levels of concurrency required in many modern applications, a blocking approach just doesn’t scale. Reactor and Multi-Reactor我们在前文中提到过Vert.x是基于事件驱动的，当Vert.x事件准备好之后，就会向事件传递给被设置的handler上 在大多数情况下，Vert.x会使用一个称为event loop的线程来调用你的handler 鉴于Vert.x以及你的应用程序不会产生任何阻塞操作，event loop会快速地将事件分发到不同的handler上 因为我们的任何操作都不会带来任何阻塞，因此一个event loop就可以在非常短的时间内，分发出去居多的事件。例如一个event loop就可以非常快速地处理数千个HTTP请求。 我们把这种模式称为Reactor Pattern. 你也许以前就听说过这种模式，例如Node.js就是这种模式的一种实现 在一个标准reactor实现中,会有一个单独的event loop线程进行可用事件轮询，只要有事件接听到，就将它发送到全部的handler上 但是这种实现有个小缺点，在任一时刻，它都会只运行在一个核心上，因此如果你想要你的单线程reactor应用程序在多核心服务器上进行拓展，那么你就需要启动并管理多个不同的reactor应用程序进程 但是Vert.x的工作模式与之不同。相比单线程event loop,每个Vertx实例都包含数个event loop. 在默认情况下,我们会根据所在机器的可用核心数来设置event loop数量,当然你也可以自己指定这个数量 我们把这种模式称为Multi-Reactor Pattern 注意：尽管Vertx实例会持有多个event loop,但是每一个handler都不会被并发执行, 而且在大多数情况下(工作者verticle除外),handler会被同一个event loop执行 The Golden Rule - Don’t Block the Event Loop我们已经知道Vert.x API不会有任何阻塞操作,也不会阻塞住event loop. 但是如果在你自己处理handler时阻塞住了当前线程(工作者vertile除外)，那么同样会影响Vert.x性能 如果你确实在handler处理时，阻塞住了event loop,那么event loop会一直等待你的操作完成，在等待的时候它只是傻傻地干等着。如果你讲Vertx对象中的所有event loop都阻塞住了话，那么你的应用程序不久就会挂掉了。 我们下面举出一些常见的阻塞操作： Thread.sleep() 等待锁 Waiting on a mutex or monitor (e.g. synchronized section) 执行一个长时间的数据库操作，并同步等待结果的返回 执行耗时较长的复杂计算 在循环中进行自旋 如果某个操作耗费大量时间引发了上述问题,从而阻塞了event loop,那么你应该直接跳过当前操作. 那么多长的时长才能被称为大量时间呢? 这完全取决于你的应用的并发数量。 如果只在一个event loop中，你想要每秒处理10000个http请求，那么处理每个请求不能超过0.1ms，因此在event loop中每次处理过程中的阻塞时间不能超过0.1ms The maths is not hard and shall be left as an exercise for the reader. 如果你的应用程序没有应答，也许是因为在某些地方阻塞住了event loop.为了能够帮你确定那个问题，当在一定时间内event loop都没有返回的话，Vert.x会自动对此产生警告日志。如果你在日志中见到了像那样的警告，你就需要好好研究一下问题出在哪里了。 例如vertx-eventloop-thread-3线程已经被阻塞了20458 ms，Vert.x会提供堆栈信息帮你找到阻塞发生的具体位置。 如果你想要关闭那么警告信息或者改变一些其他设置，那么你可以在创建Vertx对象之前，在VertxOptions中进行设置 Running blocking code在一个完美的世界里，那么没有战争和饥饿，全部的API也都会被书写成异步形式的， But.. the real world is not like that. (Have you watched the news lately?)Fact is, many, if not most libraries, especially in the JVM ecosystem have synchronous APIs and many of the methods are likely to block. A good example is the JDBC API - it’s inherently asynchronous, and no matter how hard it tries, Vert.x cannot sprinkle magic pixie dust on it to make it asynchronous. 但事实上，许多类库，尤其是在JVM生态系统中拥有大量同步API而且许多方法都会产生阻塞。一个非常著名的例子就是JDBC API,它被设计出来就是同步的，Vert.x无论怎么优化都不能将它变成异步的。 我们并不准备将所有的东西都重写成异步的，因此我们提供了一种方式，以便你可以在Vert.x应用程序中使用传统的阻塞API 正如像在前面讨论的那样，你不能在event loop直接调用阻塞操作,那么你要如何去执行一个阻塞操作呢？ 我们可以通过调用executeBlocking方法来执行阻塞代码, 同样当这个方法执行完阻塞代码之后，会异步地调用result handler. 1234567vertx.executeBlocking(future -&gt; &#123; // Call some blocking API that takes a significant amount of time to return String result = someAPI.blockingMethod(&quot;hello&quot;); future.complete(result);&#125;, res -&gt; &#123; System.out.println(&quot;The result is: &quot; + res.result());&#125;); 还有一种执行阻塞代码的方式，那就是使用worker verticle VerticlesVert.x引入了一个简单的可扩展的类actor的部署和并发模型. 这个模型是可选的, 如果你不想要采取该模型也可以不实现它,vertx并不强制要求你实现它.这个模型并不是actor-model的严格实现, 但是该模型在并发处理,拓展模式和开发模式上确实和actor-model非常像。 其实当我们在verticle中开始实现逻辑代码时，就已经开始使用这个开发模型了。 verticle简而言之就是一个代码块,然后你通过Vert.x部署和运行它. 我们可以使用Vert.x支持的不同语言实现verticle,而且一个单独的应用程序中可以包含多种语言实现的verticle. 你可以把verticle理解成Actor模型中的actor. 一般来说,一个Vert.x应用应该只是由verticle实例构成.不同的 verticle可以在event bus上通过发送消息进行交互. Writing VerticlesJavaverticle必须实现Verticle接口。 当然如果你不想实现这个接口，还有一种其他定义方法，那就是继承AbstractVerticle抽象类 1234567891011public class MyVerticle extends AbstractVerticle &#123; // Called when verticle is deployed public void start() &#123; &#125; // Optional - called when verticle is undeployed public void stop() &#123; &#125;&#125; verticle在被Vert.x部署的过程中,verticle的start方法会被调用,当start方法被调用完之后,verticle就被认为部署完成. verticle实现中像例子中start方法是必须要实现的,但是stop方法可以选择不实现. stop方法是当verticle被undeployed进行调用的,当stop方法调用完成之后,verticle就被认为停止运行了 Asynchronous Verticle start and stop有时你想要在verticle开始部署阶段(start方法中)完成一些耗时的操作,但是当这些操作完成之前,你不希望当前verticle处于部署完成状态.例如你想要在start方法中部署其他verticle，但是由于部署是异步进行的,因此可能主verticle都已经返回了,但是其他verticle的部署工作还没有完成,那么你就不想让主verticle处于完成状态. 但是你也不能在start方法中进行阻塞等待其他verticle部署完成,在event loop无论何时你都不应该把它阻塞掉。 那么该怎么办呢？我们的办法是你实现一个asynchronous的start方法,这个方法会传入一个Future对象作为参数.即使当start方法返回了,该verticle也不会被认为已经完成部署了。 当你在start方法里所有的工作都完成之后,通过调用Future对象的complete方法,在外部获得一个通知,部署工作真正完成了. 1234567891011121314public class MyVerticle extends AbstractVerticle &#123; public void start(Future&lt;Void&gt; startFuture) &#123; // Now deploy some other verticle: vertx.deployVerticle(&quot;com.foo.OtherVerticle&quot;, res -&gt; &#123; if (res.succeeded()) &#123; startFuture.complete(); &#125; else &#123; startFuture.fail(); &#125; &#125;); &#125;&#125; 同样的,stop方法也有一个asynchronous版本的. 12345678910111213141516public class MyVerticle extends AbstractVerticle &#123; public void start() &#123; // Do something &#125; public void stop(Future&lt;Void&gt; startFuture) &#123; obj.doSomethingThatTakesTime(res -&gt; &#123; if (res.succeeded()) &#123; startFuture.complete(); &#125; else &#123; startFuture.fail(); &#125; &#125;); &#125;&#125; 注意,通过verticle部署的vertcle，这俩种vertcle会构成一种”父子”关系，当父verticle被undeploy后,子verticle会自动被Vert.x进行undeploy Verticle Types在Vert.x中有三种不同类型的verticle Standard Verticles : 这是最常用的一种. 这种verticle通过event loop线程执行.接下来我们会详细讨论这种verticle. Worker Verticles : 这种verticle通过worker pool中的线程执行。该verticle在同一时刻永远不会被多个线程并发执行 Multi-threaded worker verticles : 该verticle同样通过worker pool中的线程执行.但是这种verticle可能会被多个线程并发执行. Standard verticlesStandard Verticles当被创建的时候会被分配到一个event loop上, 同时Standard Verticles的start()会被该event loop进行调用. 当你在event loop中,通过核心API以及带有handler参数的的方式调用其他方法时,Vert.x确保那些handler回调时是被刚才那个event loop进行调用的. 这意味着,我们能保证vertcle实例里全部代码总是能被相同的event loop进行调用(当然这是在你不故意自己创建线程调用他们的前提下). 这意味着,当你基于Vert.x开发应用程序时,vert.x会帮你完成那些并发操作,你自己完全不需要考虑多线程和并发情况,只需要像在单线程中那样写代码就好了. 从此你的生活就远离了synchronized, volatile, 条件竞争, 死锁等等.. Worker verticlesworker verticle和standard verticle相比,worker verticle并不是运行在event loop中,而是在worker thread pool中的某个线程中运行. worker verticle是被设计成专门用来调用阻塞代码的,他们不会阻塞掉任何的event loop. 如果你不想在worker verticle中运行阻塞代码, 你也可以在event loop中执行运行内联的阻塞代码. 如果你想要部署worker verticle时, 你可以使用setWorker(). 12DeploymentOptions options = new DeploymentOptions().setWorker(true);vertx.deployVerticle(&quot;com.mycompany.MyOrderProcessorVerticle&quot;, options); Worker verticle实例永远不会被多线程同一时间并发执行,但是却可以在不同的时间被不同的线程执行. ###Multi-threaded worker verticles multi-threaded worker verticle和worker verticle很像,只不过这种multi-threaded worker verticle可以被多个不同线程并发执行. 注意:multi-threaded worker verticle是一个非常高级的特性,而且大部分的应用程序并不会需要使用到它. 因为在这种verticle中的并发操作,你需要非常小心通过使用传统的多线程编程技术保持verticle的状态一致性. Deploying verticles programmatically你可以通过deployVerticle()方法部署一个verticle, 使用这种方式你需要指定该verticle的名字或者传递一个你已经创建好的该verticle的实例. 注意: 只有在java中才可以部署Verticle实例 12Verticle myVerticle = new MyVerticle();vertx.deployVerticle(myVerticle); verticle名字用来查找特定的VerticleFactory, 我们使用VerticleFactory来实例化出实际的verticle实例. 不同的VerticleFactory用于在不同的语言实现中对verticle进行实例化, 除此之外不同的VerticleFactory也用于加载service或者在Maven运行时获得verticle. 这种特性可以让你在某种语言中部署其他语言实现的verticle. 下面的例子演示了在Java中部署不同语言类型的verticle 1234567vertx.deployVerticle(&quot;com.mycompany.MyOrderProcessorVerticle&quot;);// Deploy a JavaScript verticlevertx.deployVerticle(&quot;verticles/myverticle.js&quot;);// Deploy a Ruby verticle verticlevertx.deployVerticle(&quot;verticles/my_verticle.rb&quot;); Rules for mapping a verticle name to a verticle factory当使用verticle名称部署verticle时,这个名字被用来找到实际的VerticleFactory,对verticle进行实例化 verticle名称还可以有一个前缀(随后跟一个冒号),当该前缀被指定后,会使用该前缀来查找VerticleFactory. 123js:foo.js // Use the JavaScript verticle factorygroovy:com.mycompany.SomeGroovyCompiledVerticle // Use the Groovy verticle factoryservice:com.mycompany:myorderservice // Uses the service verticle factory 如果我们并没有指定前缀,那么Vert.x会去名称中找到后缀(文件类型),然后使用该后缀找到VerticleFactory. 12foo.js // Will also use the JavaScript verticle factorySomeScript.groovy // Will use the Groovy verticle factory 但是如果既没有前缀，也没有后缀被找到,那么Vert.x会认为这个名称是个Java类的全限定名,使用使用这个全限定名进行实例化 How are Verticle Factories located?在Vert.x启动时,它会在classpath中对大多数的VerticleFactory加载和注册. 当然如果你想在程序中通过编程的方式对VerticleFactory进行注册和解除注册到话,你可以使用registerVerticleFactory和unregisterVerticleFactory方法 Waiting for deployment to complete同样verticle的部署也是异步进行的, 当调用部署方法进行返回的时候也许部署操作并没有真正的,可能要等到过一段时间才能真正完成, 如果你想当部署操作真正完成的时候捕获一个通知,你可以在部署方法里添加一个completion handler,用于处理完成时候你想进行的特定操作. 1234567vertx.deployVerticle(&quot;com.mycompany.MyOrderProcessorVerticle&quot;, res -&gt; &#123; if (res.succeeded()) &#123; System.out.println(&quot;Deployment id is: &quot; + res.result()); &#125; else &#123; System.out.println(&quot;Deployment failed!&quot;); &#125;&#125;); 如果部署成功了,handler会捕获一个result(内含一个字符串形式的部署ID). 当你后期想要对verticle进行undeploy操作时,你就需要使用刚才的那个部署成功时获得的字符串形式的部署ID了. Undeploying verticle deployments当verticle被部署成功之后,我们也可以通过调用undeploy方法对其进行undeploy操作. 当然undeploy一样是异步进行的,如果你想当undeploy操作完成时同样捕获通知,你也可以对undeploy方法设置一个completion handler. 1234567vertx.undeploy(deploymentID, res -&gt; &#123; if (res.succeeded()) &#123; System.out.println(&quot;Undeployed ok&quot;); &#125; else &#123; System.out.println(&quot;Undeploy failed!&quot;); &#125;&#125;); Specifying number of verticle instances当你使用verticle名字对某个verticle进行部署时,你也可以指定该verticle部署成功后的实例数量: 12DeploymentOptions options = new DeploymentOptions().setInstances(16);vertx.deployVerticle(&quot;com.mycompany.MyOrderProcessorVerticle&quot;, options); 当我们想在多核主机上对应用进行拓展时,通过这种方式就可以轻松实现了. 假设,你现在要在一个多核主机上部署一个web-server verticle,因此你想要对该verticle部署多个实例以便能使用上所有核心. Passing configuration to a verticle当verticle被部署时,我们还可以向其指定一个JSON形式的配置: 123JsonObject config = new JsonObject().put(&quot;name&quot;, &quot;tim&quot;).put(&quot;directory&quot;, &quot;/blah&quot;);DeploymentOptions options = new DeploymentOptions().setConfig(config);vertx.deployVerticle(&quot;com.mycompany.MyOrderProcessorVerticle&quot;, options); 稍后我们就可以通过Context对象来操作Configuration配置了 TODO Accessing environment variables in a VerticleTODO Verticle Isolation GroupsBy default, Vert.x has a flat classpath. I.e, it does everything, including deploying verticles without messing with class-loaders. In the majority of cases this is the simplest, clearest and sanest thing to do. Vert.x默认有一个flat classpath,它会实现N多功能,包括在部署verticle时不会干扰类加载的工作. 在大多数情况下,这是最简单，清晰，明智的事情。 However, in some cases you may want to deploy a verticle so the classes of that verticle are isolated from others in your application. This might be the case, for example, if you want to deploy two different versions of a verticle with the same class name in the same Vert.x instance, or if you have two different verticles which use different versions of the same jar library. WARNINGUse this feature with caution. Class-loaders can be a can of worms, and can make debugging difficult, amongst other things.Here’s an example of using an isolation group to isolate a verticle deployment. 123DeploymentOptions options = new DeploymentOptions().setIsolationGroup(&quot;mygroup&quot;);options.setExtraClasspath(Arrays.asList(&quot;lib/jars/some-library.jar&quot;));vertx.deployVerticle(&quot;com.mycompany.MyIsolatedVerticle&quot;, options); Isolation groups are identified by a name, and the name can be used between different deployments if you want them to share an isolated class-loader. Extra classpath entries can also be provided with setExtraClasspath so they can locate resources that are isolated to them. High AvailabilityVerticles can be deployed with High Availability (HA) enabled. TODO Running Verticles from the command line通常做法是你可以在Maven或者Gradle项目中添加一个Vert.x core library引用,你就可以直接运行Vert.x了. 然而,你如果不习惯那种做法,你还可以直接在命令行中执行运行Vert.x verticle. 在命令行中运行Vert.x你需要下载Vert.x的分发版本,然后将安装好的bin目录添加到Path环境变量中,同时要确保在PATH中你也添加上了JDK8. 下例演示了如何直接在命令中运行verticle 123456789# Run a JavaScript verticlevertx run my_verticle.js# Run a Ruby verticlevertx run a_n_other_verticle.rb# Run a Groovy script verticle, clusteredvertx run FooVerticle.groovy -cluster 令人惊喜的是,你可以在命令行中直接运行java源文件. 1vertx run SomeJavaSourceFile.java Vert.x会在运行该java源文件之前自己去编译它. 这对于quickly prototyping verticle和写verticle demo是非常有用的. Causing Vert.x to exitThreads maintained by Vert.x instances are not daemon threads so they will prevent the JVM from exiting. 如果你将Vert.x嵌入在了你的应用程序中,而且当你的应用程序已经使用完了Vert.x的功能,你需要关闭掉Vert.x的时候,你可以直接调用close将其关闭掉. 这个操作会关闭Vert.x内部所有的线程池和其他的资源,但是并不会让JVM也跟着关闭掉. The Context objectTODO Executing periodic and delayed actionsIt’s very common in Vert.x to want to perform an action after a delay, or periodically. 在standard verticle中,你不能因为想要得到一个延迟的效果就将线程sleep掉,因为这个操作会将event loop线程阻塞掉. 取而代之的是,你可以使用Vert.x timers,Vert.x timers既可以执行一次也可以周期性执行. One-shot Timersone shot timer会在一个特定的延迟后(单位毫秒)调用一个event handler. 设置one shot timer是非常简单的,调用setTimer方法然后设置一个延迟和一个handler就ok了. 12345long timerID = vertx.setTimer(1000, id -&gt; &#123; System.out.println(&quot;And one second later this is printed&quot;);&#125;);System.out.println(&quot;First this is printed&quot;); 这个返回的返回值是一个唯一的timer id,如果你想在后期取消掉这个timer,就需要使用这个id了. Periodic Timers你可以通过调用setPeriodic方法设置一个周期性的定时器. There will be an initial delay equal to the period. The return value of setPeriodic is a unique timer id (long). This can be later used if the timer needs to be cancelled. The argument passed into the timer event handler is also the unique timer id: 12345long timerID = vertx.setPeriodic(1000, id -&gt; &#123; System.out.println(&quot;And every second this is printed&quot;);&#125;);System.out.println(&quot;First this is printed&quot;); Cancelling timersTo cancel a periodic timer, call cancelTimer specifying the timer id. For example: 1vertx.cancelTimer(timerID); Automatic clean-up in verticlesIf you’re creating timers from inside verticles, those timers will be automatically closed when the verticle is undeployed. The Event Busevent bus是Vert.x的神经系统。 每一个Vertx对象内部都有一个唯一的event bus实例，我们可以通过eventBus这个方法获取它的引用。 event bus可以让你的应用程序的不同组件进行交互, 但是强大的是进行交互的组件可以自由选择实现语言，而且并不局限于仅仅只有在相同的Vertx实例内的组件才能交互。 event bus构成了一个在多个服务器节点和多个浏览器间的分布式端对端消息系统。 event bus还支持以下三种消息模式：publish/subscribe, point to point, request-response messaging event busAPI是非常简单的,你基本只需要调用registering handlers, unregistering handlers 以及sending messages, publishing messages The TheoryAddressing我们通过event bus向一个地址发送Message. 在Vert.x中不需要担心是否会使用到复杂的寻址方案. 在Vert.x中，地址就是一个简单的合法字符串。Vert.x的地址还使用了一些scheme,例如使用.分割命名空间区间。 一些合法的地址例如：europe.news.feed1, acme.games.pacman, sausages, and X Handlers我们使用handler从event bus中接收消息,因此你只需向一个address注册一个handler。 handler和address是一种多对多的关系,这意味着,一个handler可以向很多个address注册,同时多个handler可以向同一个address注册 Publish / subscribe messagingevent bus也支持publishing messages:消息会被发布到某一个地址上.这意味着：某一消息会发布给在某个地址上注册的全部handler。这和publish/subscribe消息模式很像。 Point to point and Request-Response messagingevent bus支持点对点消息传送. 这种模式下消息会被发送到一个地址上。Vert.x然后会在该地址上的N个handler中选择一个,然后将消息传递给被选择的handler。 如果某个地址上注册了多个handler，Vert.x会根据non-strict round-robin算法来选取一个。 在点对点传送消息的情况中，当发送消息时，可以指定一个可选的回复handler。当接受者接受到一个消息后，同时该Message被处理后，接受者可以选择是否回应该消息。如果接受者选择回应该消息，那么reply handler会被调用。 当发送者接收到消息回应后，发送者还可以选择接着回应。这种模式可以永远重复下去，Vert.x还支持在这俩个verticle中创建一个会话。 这种通用的消息模式称为Request-Response模式。 Best-effort deliveryVert.x会尽自己的全力进行消息分发,而且Vert.x保证不会主动抛弃消息,这种模式称为best-effort delivery. 然而,当event bus失效时,可能会发生消息丢失情况.如果你的应用程序不允许出现消息丢失,那么你应该将你的handler编码成idempotent(code your handlers to be idempotent),当event bus恢复正常后,你的消息发送者再次尝试发送消息. Types of messagesVert.x 消息支持所有的原生类型, String, Buffer. 但是在Vert.x中一般是使用JSON作为消息数据格式. 这是因为在Vert.x所支持的所有语言中，都很容易创建,读取和解析JSON。 当然，Vert.x并不强制你必须使用JSON作为消息数据传输格式。 event bus本身是非常灵活的,而且支持发送任意的对象数据,只要你能进行编解码就可以 The Event Bus APILet’s jump into the API Getting the event bus下例我们演示一下如何获得EventBus引用： 1EventBus eb = vertx.eventBus(); 每一个Vertx实例中都有一个event bus实例。 Registering Handlers下例演示了如何在event bus上注册一个handler 12345EventBus eb = vertx.eventBus();eb.consumer(&quot;news.uk.sport&quot;, message -&gt; &#123; System.out.println(&quot;I have received a message: &quot; + message.body());&#125;); 当你的handler收到一条message时, handler会自动被调用. 调用consumer(.., ..)方法的返回值是一个MessageConsumer实例. 我们可以通过MessageConsumer实例来unregister handler,也可以像流一样使用那个handler 或者你可以不向consumer方法中设置handler,那么你同样会获得一个MessageConsumer实例，你可以在MessageConsumer实例上再设置handler 123456EventBus eb = vertx.eventBus();MessageConsumer&lt;String&gt; consumer = eb.consumer(&quot;news.uk.sport&quot;);consumer.handler(message -&gt; &#123; System.out.println(&quot;I have received a message: &quot; + message.body());&#125;); 当向一个集群的event bus上注册一个handler时,那么就需要向集群中的每一个节点上都要注册一个该handler，那这就需要消耗一些时间了。 如果你需要当向集群中所有的节点都注册完成时，捕获一个通知，那么你可以再在MessageConsumer上注册一个&quot;completion&quot; handler. 1234567consumer.completionHandler(res -&gt; &#123; if (res.succeeded()) &#123; System.out.println(&quot;The handler registration has reached all nodes&quot;); &#125; else &#123; System.out.println(&quot;Registration failed!&quot;); &#125;&#125;); Un-registering Handlers想要unregister一个handler只需要调用unregister方法就可以了 如果你当前的环境是一个集群环境, 那么就需要向整个集群中的所有节点都执行unregister操作，这同样需要一些时间等待,当然你也可以注册一个&quot;completion&quot; handler 1234567consumer.unregister(res -&gt; &#123; if (res.succeeded()) &#123; System.out.println(&quot;The handler un-registration has reached all nodes&quot;); &#125; else &#123; System.out.println(&quot;Un-registration failed!&quot;); &#125;&#125;); Publishing messagespublish消息同样是非常简单的,你只需要向目标address上调用publish方法就可以了 1eventBus.publish(&quot;news.uk.sport&quot;, &quot;Yay! Someone kicked a ball&quot;); 这个消息会被分发到在目标地址上注册所有的handler上. Sending messagesSending出来的消息则只会在目的地址上注册的某个handler接受.这是一种point to point消息模式.handler的选择同样采用的是non-strict round-robin算法 下例演示了如何send message 1eventBus.send(&quot;news.uk.sport&quot;, &quot;Yay! Someone kicked a ball&quot;); Setting headers on messages在event bus上传送的消息同样可以带有消息头. 在sending和publishing这俩种模式下,可以通过DeliveryOptions对象指定消息头 123DeliveryOptions options = new DeliveryOptions();options.addHeader(&quot;some-header&quot;, &quot;some-value&quot;);eventBus.send(&quot;news.uk.sport&quot;, &quot;Yay! Someone kicked a ball&quot;, options); The Message object在消息handler上你接受的对象是一个Message实例 Message实例中的body就相当于被sent或者publish的对象. 我们还可以通过headers方法获得message的header. Replying to messages有时候当你send出一个消息之后,你可能期待某些答复. 这种消息模式被称为request-response pattern 想要达到这种效果,你可以在send消息时设置一个reply handler. 当消息接收者收到消息后,可以通过调用消息上的reply方法进行应答 当接收者通过消息的reply方法进行应答时，那么发送者在send时设置的reply handler将会被调用,下面给出了这种应答模式的演示： The receiver: 12345MessageConsumer&lt;String&gt; consumer = eventBus.consumer(&quot;news.uk.sport&quot;);consumer.handler(message -&gt; &#123; System.out.println(&quot;I have received a message: &quot; + message.body()); message.reply(&quot;how interesting!&quot;);&#125;); The sender: 12345eventBus.send(&quot;news.uk.sport&quot;, &quot;Yay! Someone kicked a ball across a patch of grass&quot;, ar -&gt; &#123; if (ar.succeeded()) &#123; System.out.println(&quot;Received reply: &quot; + ar.result().body()); &#125;&#125;); 这种应答可以形成往复的应答模式从而生成一个会话 Sending with timeouts在send发送消息时，如果指定了一个reply handler,那么你还可以通过DeliveryOptions设置一个超时时间(默认是30s)。 当在指定的时间内没有收到对方应答时，reply handler将会以一种失败的状态被调用 Send Failures在消息发送时可能会在下面几种情况下引发失败： There are no handlers available to send the message to The recipient has explicitly failed the message using fail In all cases the reply handler will be called with the specific failure. Message Codecs如果你对在event bus上传送的对象指定一个消息编码器并且在event bus上注册了该消息编码器, 那么无论该对象是何类型，你都可以在event bus上对其进行传递. 当你sending或者publishing一个对象时, 你需要在DeliveryOptions对象里指定该对象所对应的编码器名称. 12345eventBus.registerCodec(myCodec);DeliveryOptions options = new DeliveryOptions().setCodecName(myCodec.name());eventBus.send(&quot;orders&quot;, new MyPOJO(), options); 你也可以在eventBus上指定一个默认的编码器，这样一来，当你再send消息时，就不用每次都手动的设置编码器了 123eventBus.registerDefaultCodec(MyPOJO.class, myCodec);eventBus.send(&quot;orders&quot;, new MyPOJO()); 如果你想要解除一个消息编码器，你只需要使用unregisterCodec就好了 Message codecs don’t always have to encode and decode as the same type. For example you can write a codec that allows a MyPOJO class to be sent, but when that message is sent to a handler it arrives as a MyOtherPOJO class. Clustered Event Busevent bus的作用域并不是单单的在一个单独的Vertx实例里。在集群里，你的局域网中的不同的Vertx实例可以聚合在一起，而每一个Vertx实例里的event bus可以相互聚集形成一个单独的分布式的event bus。 Clustering programmatically如果你通过编程的方式使用集群方法创建Vertx实例,在这种方式下你就得到了一个集群event bus 12345678910VertxOptions options = new VertxOptions();Vertx.clusteredVertx(options, res -&gt; &#123; if (res.succeeded()) &#123; Vertx vertx = res.result(); EventBus eventBus = vertx.eventBus(); System.out.println(&quot;We now have a clustered event bus: &quot; + eventBus); &#125; else &#123; System.out.println(&quot;Failed: &quot; + res.cause()); &#125;&#125;); 你必须确保你已经在classpath上实现了ClusterManager, 例如你也可以使用Vertx的ClusterManager实现 Clustering on the command line你可以通过下面的方式进行命令行的集群配置 1vertx run MyVerticle -cluster ##Automatic clean-up in verticlesIf you’re registering event bus handlers from inside verticles, those handlers will be automatically unregistered when the verticle is undeployed. ExamplesCodec12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849class ClientCodec implements MessageCodec&lt;ClientSource, ClientTarget&gt; &#123; /* * 当把对象s传输网络中时,该方法会被调用. * 会将s写入buffer中 */ @Override public void encodeToWire(Buffer buffer, ClientSource s) &#123; &#125; /* * pos表示从buffer哪里开始读 */ @Override public ClientTarget decodeFromWire(int pos, Buffer buffer) &#123; return null; &#125; /* * 如果message是在本地event bus上传递上传输时, 该方法会被调用, 将ClientSource类型对象改变为ClientTarget */ @Override public ClientTarget transform(ClientSource s) &#123; return null; &#125; /* * 该编码器的名称, 每个编码器都必须有一个唯一的名字. 当发送message或者从event bus上解除编码器的时候,需要使用到该编码器 */ @Override public String name() &#123; return null; &#125; @Override public byte systemCodecID() &#123; return -1; &#125;&#125;class ClientSource &#123; &#125;class ClientTarget &#123; &#125; JSON不像其他语言,JAVA并没有一等类来支持JSON,因此Vert.x提供了下面俩个类让JSON的使用更加简便 JSON objectsJsonObject表示一个JSON对象。 JsonObject基本上只是一个string key和value的一个映射,value可以是JSON支持的数据类型的一种(string, number, boolean) 同时JSON对象还支持null值 ###Creating JSON objects 如果使用默认的JsonObject构造器创建出来的就是一个空JSON对象 You can create a JSON object from a string JSON representation as follows:你也可以使用一个String表示的JSON来创建一个JsonObject对象。 12String jsonString = &quot;&#123;\\&quot;foo\\&quot;:\\&quot;bar\\&quot;&#125;&quot;;JsonObject object = new JsonObject(jsonString); ###Putting entries into a JSON object 我们可以直接使用put方法向JsonObject中添加元素 12JsonObject object = new JsonObject();object.put(&quot;foo&quot;, &quot;bar&quot;).put(&quot;num&quot;, 123).put(&quot;mybool&quot;, true); ###Getting values from a JSON object 我们可以直接使用get...方法从JsonObject中获取某个值。 12String val = jsonObject.getString(&quot;some-key&quot;);int intVal = jsonObject.getInteger(&quot;some-other-key&quot;); ###Encoding the JSON object to a String 你可以直接使用encode方法将某个对象编码成字符串形式 JSON arraysJsonArray表示的是JSON数组 JSON数组就是JSON value的一个序列 JSON数组还可以包含null值 Creating JSON arrays如果使用默认的JsonArray构造器创建出来的就是一个空JSON数组对象 你也可以使用一个String表示的JSON来创建一个JsonArray对象。 12String jsonString = &quot;[\\&quot;foo\\&quot;,\\&quot;bar\\&quot;]&quot;;JsonArray array = new JsonArray(jsonString); 你可以直接使用add方法向一个JsonArray中添加元素 12JsonArray array = new JsonArray();array.add(&quot;foo&quot;).add(123).add(false); ###Getting values from a JSON array 同样的你可以使用get...方法直接从JsonArray获取元素 123String val = array.getString(0);Integer intVal = array.getInteger(1);Boolean boolVal = array.getBoolean(2); Encoding the JSON array to a String你可以直接使用encode方法将JsonArray编码成String Buffers在Vert.x中进行数据传播的大多是org.vertx.java.core.buffer.Buffer实例 Buffer表示的是一个字节序列(size &gt;= 0), 可以向Buffer写入或者读取数据, 当写入数据时，超过其容量最大值时，会自动拓容。 Creating buffers我们可以直接使用一系列Buffer.buffer开头的静态方法来创建一个Buffer. Buffer可以从String或者byte arrays进行初始化,当然我们也可以直接创建出一个空Buffer. 下面给出了一些创建Buffer的示例： 创建一个内容为空的Buffer 1Buffer buff = Buffer.buffer(); 创建一个Buffer,并使用String进行初始化,在Buffer内部该字符串会使用UTF-8进行编码 1Buffer buff = Buffer.buffer(&quot;some string&quot;); 创建一个Buffer,并使用String进行初始化,在Buffer内部该字符串会使用指定的编码方法进行编码 1Buffer buff = Buffer.buffer(&quot;some string&quot;, &quot;UTF-16&quot;); 创建一个Buffer,并使用byte[]进行初始化 12byte[] bytes = new byte[] &#123;1, 3, 5&#125;;Buffer buff = Buffer.buffer(bytes); 我们还可以在创建Buffer时指定其初始化大小。如果你能确定向Buffer写入数据的大小，那么你可以在创建Buffer指定其初始化大小。当Buffer创建成功之后，Buffer就会被分配出所指定的内存，一般来说这种方式适用于你的Buffer在不断地自动拓容的情况下。 需要注意的是，使用指定大小的方式创建一个Buffer，它本身是空的，只是分配了那么多内存而已。它并不会使用0来填充整个Buffer。 1Buffer buff = Buffer.buffer(10000); Writing to a Buffer有俩种方式向Buffer中添加数据：appending和random access. 不管使用哪种方式,Buffer都会当容量不足时进行自动拓容。 Appending to a BufferBuffer提供了多种append方法，向Buffer中追加不同类型的数据。而且append方法返回的都是Buffer自身，因此我们可以使用链式调用append方法 12345Buffer buff = Buffer.buffer();buff.appendInt(123).appendString(&quot;hello\\n&quot;);socket.write(buff); Random access buffer writes你也可以通过一系列set方法在某个合法的索引位置上写入数据。在set方法中第一个参数是要开始写入数据的索引位置,第二个参数是要写入的数据 1234Buffer buff = Buffer.buffer();buff.setInt(1000, 123);buff.setString(0, &quot;hello&quot;); Reading from a Buffer我们通过一系列get方法从Buffer中读取数据,第一个参数是要开始读取的索引位置。 1234Buffer buff = Buffer.buffer();for (int i = 0; i &lt; buff.length(); i += 4) &#123; System.out.println(&quot;int value at &quot; + i + &quot; is &quot; + buff.getInt(i));&#125; Buffer length使用length方法来获得Buffer的长度, length的取值方式是最大的索引值+1 Copying buffers使用copy可以直接对Buffer进行数据拷贝 拷贝之后的俩个Buffer是否使用同一个缓冲区 Slicing buffers我们使用slice方法创建一个sliced buffer,它与原Buffer共享一个数据缓冲区。 ##Buffer re-use当Buffer被写入到socket中，或者其他的一些类似的地方，他们就不能被复用了 TCP ServerCreating a TCP server我们使用默认的选项(HttpServerOptions)来创建一个最简单的TCP服务器. 1NetServer server = vertx.createNetServer(); Configuring a TCP server如果想要对创建的服务器进行特殊配置,可以使用HttpServerOptions来创建服务器。 12NetServerOptions options = new NetServerOptions().setPort(4321);NetServer server = vertx.createNetServer(options); Start the Server Listening我们提供了众多的listen方法,下面我们选择一个不带参数的listen方法(端口和主机地址已经在刚才的HttpServerOptions中指定了) 12NetServer server = vertx.createNetServer();server.listen(); 下面我们在listen方法中显式地指定监听的端口和网卡地址(这时候会忽略掉HttpServerOptions中设置的端口号) 12NetServer server = vertx.createNetServer();server.listen(1234, &quot;localhost&quot;); listen方法默认监听的地址是0.0.0.0(所有可用地址),默认的端口是0(这种情况下会随机选择一个可用的端口). 需要注意的是绑定操作(listen)是异步进行的,所以当listen方法返回之后并不保证绑定操作已经成功.在示例中我们添加了一个handler用于接受绑定成功之后的通知. 12345678NetServer server = vertx.createNetServer();server.listen(1234, &quot;localhost&quot;, res -&gt; &#123; if (res.succeeded()) &#123; System.out.println(&quot;Server is now listening!&quot;); &#125; else &#123; System.out.println(&quot;Failed to bind!&quot;); &#125;&#125;); Listening on a random port当我们监听端口号为0时,系统会自动随机选择一个实际可用的端口进行监听,如果想要获取真实监听端口可以调用actualPort方法. 12345678NetServer server = vertx.createNetServer();server.listen(0, &quot;localhost&quot;, res -&gt; &#123; if (res.succeeded()) &#123; System.out.println(&quot;Server is now listening on actual port: &quot; + server.actualPort()); &#125; else &#123; System.out.println(&quot;Failed to bind!&quot;); &#125;&#125;); Getting notified of incoming connections下例中我们设置了一个connectHandler,用于处理服务器接受到的网络连接 1234NetServer server = vertx.createNetServer();server.connectHandler(socket -&gt; &#123; // Handle the connection in here&#125;); 当网络连接建立成功之后,handler就会自动被调用(同时会带有一个NetSocket对象作为参数) NetSocket是对实际网络连接的一个类Socket接口抽象(socket-like interface),你可以在这个接口进行读写数据,或者直接关闭Socket等操作. Reading data from the socketTo read data from the socket you set the handler on the socket. 想要读取Socket中的数据,那你就需要调用NetSocket的handler方法,设置一个handler,用于处理数据. 当Socket流中有数据到达时,服务器就会将接受到的数据封装成一个Buffer对象,然后刚刚在NetSocket上设置的那个handler就会被调用. 考虑半包处理 123456NetServer server = vertx.createNetServer();server.connectHandler(socket -&gt; &#123; socket.handler(buffer -&gt; &#123; System.out.println(&quot;I received some bytes: &quot; + buffer.length()); &#125;);&#125;); Writing data to a socket你可以直接调用NetSocket的write方法进行写回数据 12345678Buffer buffer = Buffer.buffer().appendFloat(12.34f).appendInt(123);socket.write(buffer);// Write a string in UTF-8 encodingsocket.write(&quot;some data&quot;);// Write a string using the specified encodingsocket.write(&quot;some data&quot;, &quot;UTF-16&quot;); 注意，write方法一样是异步进行的,当write方法返回后,并不保证数据已经完全写入到Socket流中,也不保证数据能够写入成功 Closed handler下例中我们设置了一个closeHandler用于当Socket关闭时,获得一些通知 123socket.closeHandler(v -&gt; &#123; System.out.println(&quot;The socket has been closed&quot;);&#125;); Handling exceptions如果你想当socket操作发生异常时获得通知,你可以设置一个exceptionHandler Event bus write handler每一个Socket都会在event bus上自动注册一个handler,一旦该handler接受到Buffer, handler会将Buffer写到Socket上. 利用这种特性你可以在不同的verticle甚至不同的Vertx实例里对同一个socket写数据. 这种功能的实现方式是handler身上有一个writeHandlerID,这个ID是handler在event bus上的注册地址,不同的verticle甚至不同的Vertx实例就可以通过该地址向Socket写入数据。 Local and remote addresses我们可以通过localAddress获得NetSocket的本地地址. 通过remoteAddress获得网络对等端地址. Sending files我们可以通过sendFile直接向Socket中写入一个文件. 这是一种非常高效发送文件的方式,如果操作操作系统支持的话,这还可以被OS内核支持 1socket.sendFile(&quot;myfile.dat&quot;); Streaming socketsInstances of NetSocket are also ReadStream and WriteStream instances so they can be used to pump data to or from other read and write streams. See the chapter on streams and pumps for more information. NetSocket实例还是ReadStream和WriteStream的实例,因此 Upgrading connections to SSL/TLS我们可以使用upgradeToSsl方法将一个不支持SSL/TLS的连接改为支持SSL/TLS的连接,具体参考相关章节 Closing a TCP Server我们可以调用close方法关闭服务器,close方法会关闭所有打开的连接和所有的服务器资源. 一样一样的,关闭操作同样是异步的,你懂得,想要关闭完成时进行某些操作,设置handler吧. 1234567server.close(res -&gt; &#123; if (res.succeeded()) &#123; System.out.println(&quot;Server is now closed&quot;); &#125; else &#123; System.out.println(&quot;close failed&quot;); &#125;&#125;); Automatic clean-up in verticles如果你是在verticle中创建的TCP服务器和客户端,那么当宿主verticle被undeployed时,宿主身上的服务器和客户端也会被自动的关闭掉 Scaling - sharing TCP serversTCP服务器上的所有handler都只会被相同的event loop执行. 这意味着如果你的服务器是运行在一个多核心的主机上,但是你在该主机上只部署了一个服务器实例,那么你最多也就是利用了主机上的一个核心. 为了能使用更多的核心,你需要在该主机上部署多个服务器实例. 下面的示例演示了如何通过编程的方式部署多个服务器实例： 12345678910for (int i = 0; i &lt; 10; i++) &#123; NetServer server = vertx.createNetServer(); server.connectHandler(socket -&gt; &#123; socket.handler(buffer -&gt; &#123; // Just echo back the data socket.write(buffer); &#125;); &#125;); server.listen(1234, &quot;localhost&quot;);&#125; 或者如果你的服务器是在verticle内实现的,那么你也可以在命令行中通过-instances部署多个服务器实例. 1vertx run com.mycompany.MyVerticle -instances 10 以及通过编程的方式部署多个服务器verticle实例 12DeploymentOptions options = new DeploymentOptions().setInstances(10);vertx.deployVerticle(&quot;com.mycompany.MyVerticle&quot;, options); Once you do this you will find the echo server works functionally identically to before, but all your cores on your server can be utilised and more work can be handled. At this point you might be asking yourself ‘How can you have more than one server listening on the same host and port? Surely you will get port conflicts as soon as you try and deploy more than one instance?’ Vert.x does a little magic here.* When you deploy another server on the same host and port as an existing server it doesn’t actually try and create a new server listening on the same host/port. Instead it internally maintains just a single server, and, as incoming connections arrive it distributes them in a round-robin fashion to any of the connect handlers. Consequently Vert.x TCP servers can scale over available cores while each instance remains single threaded. TCP ClientCreating a TCP client最简单的创建TCP客户端的方式是使用默认的NetClientOptions： 1NetClient client = vertx.createNetClient(); Configuring a TCP client如果你不想要使用默认的NetClientOptions配置,那么你可以创建一个NetClientOptions实例进行TCP客户端创建： 12NetClientOptions options = new NetClientOptions().setConnectTimeout(10000);NetClient client = vertx.createNetClient(options); Making connections为了和服务器创建一个连接,你需要使用connect方法,在该方法中需要指定hsot和port,同时需要设置一个handler,当连接成功或者失败之后,handler会获得一个NetSocket的参数. 12345678910NetClientOptions options = new NetClientOptions().setConnectTimeout(10000);NetClient client = vertx.createNetClient(options);client.connect(4321, &quot;localhost&quot;, res -&gt; &#123; if (res.succeeded()) &#123; System.out.println(&quot;Connected!&quot;); NetSocket socket = res.result(); &#125; else &#123; System.out.println(&quot;Failed to connect: &quot; + res.cause().getMessage()); &#125;&#125;); Configuring connection attemptsA client can be configured to automatically retry connecting to the server in the event that it cannot connect. This is configured with setReconnectInterval and setReconnectAttempts.客户端可以被配制成当连接不成功的时候在event里自动响应服务器的应答. 通过setReconnectInterval和setReconnectAttempts来设置这种机制. NOTECurrently Vert.x will not attempt to reconnect if a connection fails, reconnect attempts and interval only apply to creating initial connections.注意：当连接失败之后,Vertx不会尝试自动重连, 1234NetClientOptions options = new NetClientOptions();options.setReconnectAttempts(10).setReconnectInterval(500);NetClient client = vertx.createNetClient(options); 在默认情况下,创建多个连接是会失败的. HTTP ServerCreating an HTTP Server我们使用全部默认选项创建一个非常简单的HTTP服务器： 1HttpServer server = vertx.createHttpServer(); Configuring an HTTP server如果想创建一个自配置的HTTP服务器也很简单,你只需要在创建的时候,创建一个HttpServerOptions参数就可以了： 123HttpServerOptions options = new HttpServerOptions().setMaxWebsocketFrameSize(1000000);HttpServer server = vertx.createHttpServer(options); Start the Server Listening接下来我们使用listen()方法,让服务器开始监听客户端的请求. 12HttpServer server = vertx.createHttpServer();server.listen(); 或者我们指定要监听的端口和主机地址(这种方式会忽略掉在HttpServerOptions中配置的端口和主机地址) 12HttpServer server = vertx.createHttpServer();server.listen(8080, &quot;myhost.com&quot;); 如果不指定主机和端口的话,默认监听的主机地址是0.0.0.0(这意味着在所有可用的主机地址上进行绑定),默认的端口是80 The actual bind is asynchronous so the server might not actually be listening until some time after the call to listen has returned. 实际上这个绑定操作(listen())是异步进行着,这意味着可能要等到 If you want to be notified when the server is actually listening you can provide a handler to the listen call. For example: 12345678HttpServer server = vertx.createHttpServer();server.listen(8080, &quot;myhost.com&quot;, res -&gt; &#123; if (res.succeeded()) &#123; System.out.println(&quot;Server is now listening!&quot;); &#125; else &#123; System.out.println(&quot;Failed to bind!&quot;); &#125;&#125;); Getting notified of incoming requestsTo be notified when a request arrives you need to set a requestHandler: 1234HttpServer server = vertx.createHttpServer();server.requestHandler(request -&gt; &#123; // Handle the request in here&#125;); Handling requestsWhen a request arrives, the request handler is called passing in an instance of HttpServerRequest. This object represents the server side HTTP request. The handler is called when the headers of the request have been fully read. If the request contains a body, that body will arrive at the server some time after the request handler has been called. The server request object allows you to retrieve the uri, path, params and headers, amongst other things. Each server request object is associated with one server response object. You use response to get a reference to the HttpServerResponse object. Here’s a simple example of a server handling a request and replying with “hello world” to it. 123vertx.createHttpServer().requestHandler(request -&gt; &#123; request.response().end(&quot;Hello world&quot;);&#125;).listen(8080); Request versionThe version of HTTP specified in the request can be retrieved with version Request methodUse method to retrieve the HTTP method of the request. (i.e. whether it’s GET, POST, PUT, DELETE, HEAD, OPTIONS, etc). Request URIUse uri to retrieve the URI of the request. Note that this is the actual URI as passed in the HTTP request, and it’s almost always a relative URI. The URI is as defined in Section 5.1.2 of the HTTP specification - Request-URI Request pathUse path to return the path part of the URI For example, if the request URI was: a/b/c/page.html?param1=abc&amp;param2=xyzThen the path would be /a/b/c/page.html Request queryUse query to return the query part of the URI For example, if the request URI was: a/b/c/page.html?param1=abc&amp;param2=xyzThen the query would be param1=abc&amp;param2=xyz Request headersUse headers to return the headers of the HTTP request. This returns an instance of MultiMap - which is like a normal Map or Hash but allows multiple values for the same key - this is because HTTP allows multiple header values with the same key. It also has case-insensitive keys, that means you can do the following: MultiMap headers = request.headers(); // Get the User-Agent:System.out.println(“User agent is “ + headers.get(“user-agent”)); // You can also do this and get the same result:System.out.println(“User agent is “ + headers.get(“User-Agent”)); Request parametersUse params to return the parameters of the HTTP request. Just like headers this returns an instance of MultiMap as there can be more than one parameter with the same name. Request parameters are sent on the request URI, after the path. For example if the URI was: /page.html?param1=abc&amp;param2=xyzThen the parameters would contain the following: param1: ‘abc’param2: ‘xyzNote that these request parameters are retrieved from the URL of the request. If you have form attributes that have been sent as part of the submission of an HTML form submitted in the body of a multi-part/form-data request then they will not appear in the params here. Remote addressThe address of the sender of the request can be retrieved with remoteAddress. Absolute URIThe URI passed in an HTTP request is usually relative. If you wish to retrieve the absolute URI corresponding to the request, you can get it with absoluteURI End handlerThe endHandler of the request is invoked when the entire request, including any body has been fully read. Reading Data from the Request BodyOften an HTTP request contains a body that we want to read. As previously mentioned the request handler is called when just the headers of the request have arrived so the request object does not have a body at that point. This is because the body may be very large (e.g. a file upload) and we don’t generally want to buffer the entire body in memory before handing it to you, as that could cause the server to exhaust available memory. To receive the body, you can use the handler on the request, this will get called every time a chunk of the request body arrives. Here’s an example: 123request.handler(buffer -&gt; &#123; System.out.println(&quot;I have received a chunk of the body of length &quot; + buffer.length());&#125;); The object passed into the handler is a Buffer, and the handler can be called multiple times as data arrives from the network, depending on the size of the body. In some cases (e.g. if the body is small) you will want to aggregate the entire body in memory, so you could do the aggregation yourself as follows: 12345678910Buffer totalBuffer = Buffer.buffer();request.handler(buffer -&gt; &#123; System.out.println(&quot;I have received a chunk of the body of length &quot; + buffer.length()); totalBuffer.appendBuffer(buffer);&#125;);request.endHandler(v -&gt; &#123; System.out.println(&quot;Full body received, length = &quot; + totalBuffer.length());&#125;); This is such a common case, that Vert.x provides a bodyHandler to do this for you. The body handler is called once when all the body has been received: 123request.bodyHandler(totalBuffer -&gt; &#123; System.out.println(&quot;Full body received, length = &quot; + totalBuffer.length());&#125;); Pumping requestsThe request object is a ReadStream so you can pump the request body to any WriteStream instance. See the chapter on streams and pumps for a detailed explanation. Handling HTML formsHTML forms can be submitted with either a content type of application/x-www-form-urlencoded or multipart/form-data. For url encoded forms, the form attributes are encoded in the url, just like normal query parameters. For multi-part forms they are encoded in the request body, and as such are not available until the entire body has been read from the wire. Multi-part forms can also contain file uploads. If you want to retrieve the attributes of a multi-part form you should tell Vert.x that you expect to receive such a form before any of the body is read by calling setExpectMultipart with true, and then you should retrieve the actual attributes using formAttributes once the entire body has been read: 1234567server.requestHandler(request -&gt; &#123; request.setExpectMultipart(true); request.endHandler(v -&gt; &#123; // The body has now been fully read, so retrieve the form attributes MultiMap formAttributes = request.formAttributes(); &#125;);&#125;); Handling form file uploadsVert.x can also handle file uploads which are encoded in a multi-part request body. To receive file uploads you tell Vert.x to expect a multi-part form and set an uploadHandler on the request. This handler will be called once for every upload that arrives on the server. The object passed into the handler is a HttpServerFileUpload instance. 123456server.requestHandler(request -&gt; &#123; request.setExpectMultipart(true); request.uploadHandler(upload -&gt; &#123; System.out.println(&quot;Got a file upload &quot; + upload.name()); &#125;);&#125;); File uploads can be large we don’t provide the entire upload in a single buffer as that might result in memory exhaustion, instead, the upload data is received in chunks: 12345request.uploadHandler(upload -&gt; &#123; upload.handler(chunk -&gt; &#123; System.out.println(&quot;Received a chunk of the upload of length &quot; + chunk.length()); &#125;);&#125;); The upload object is a ReadStream so you can pump the request body to any WriteStream instance. See the chapter on streams and pumps for a detailed explanation. If you just want to upload the file to disk somewhere you can use streamToFileSystem: 123456789101112131415161718192021222324252627282930313233request.uploadHandler(upload -&gt; &#123; upload.streamToFileSystem(&quot;myuploads_directory/&quot; + upload.filename());&#125;);```javaWARNINGMake sure you check the filename in a production system to avoid malicious clients uploading files to arbitrary places on your filesystem. See security notes for more information.## Sending back responsesThe server response object is an instance of HttpServerResponse and is obtained from the request with response.You use the response object to write a response back to the HTTP client.#### Setting status code and messageThe default HTTP status code for a response is 200, representing OK.Use setStatusCode to set a different code.You can also specify a custom status message with setStatusMessage.If you don’t specify a status message, the default one corresponding to the status code will be used.#### Writing HTTP responsesTo write data to an HTTP response, you use one the write operations.These can be invoked multiple times before the response is ended. They can be invoked in a few ways:With a single buffer:```javaHttpServerResponse response = request.response();response.write(buffer); With a string. In this case the string will encoded using UTF-8 and the result written to the wire. HttpServerResponse response = request.response();response.write(“hello world!”);With a string and an encoding. In this case the string will encoded using the specified encoding and the result written to the wire. 12HttpServerResponse response = request.response();response.write(&quot;hello world!&quot;, &quot;UTF-16&quot;); Writing to a response is asynchronous and always returns immediately after the write has been queued. If you are just writing a single string or buffer to the HTTP response you can write it and end the response in a single call to the end The first call to write results in the response header being being written to the response. Consequently, if you are not using HTTP chunking then you must set the Content-Length header before writing to the response, since it will be too late otherwise. If you are using HTTP chunking you do not have to worry. Ending HTTP responsesOnce you have finished with the HTTP response you should end it. This can be done in several ways: With no arguments, the response is simply ended. 123HttpServerResponse response = request.response();response.write(&quot;hello world!&quot;);response.end(); It can also be called with a string or buffer in the same way write is called. In this case it’s just the same as calling write with a string or buffer followed by calling end with no arguments. For example: 1234567891011121314151617181920HttpServerResponse response = request.response();response.end(&quot;hello world!&quot;);```java#### Closing the underlying connectionYou can close the underlying TCP connection with close.Non keep-alive connections will be automatically closed by Vert.x when the response is ended.Keep-alive connections are not automatically closed by Vert.x by default. If you want keep-alive connections to be closed after an idle time, then you configure setIdleTimeout.#### Setting response headersHTTP response headers can be added to the response by adding them directly to the headers:```javaHttpServerResponse response = request.response();MultiMap headers = response.headers();headers.set(&quot;content-type&quot;, &quot;text/html&quot;);headers.set(&quot;other-header&quot;, &quot;wibble&quot;); Or you can use putHeader 12HttpServerResponse response = request.response();response.putHeader(&quot;content-type&quot;, &quot;text/html&quot;).putHeader(&quot;other-header&quot;, &quot;wibble&quot;); Headers must all be added before any parts of the response body are written. Chunked HTTP responses and trailersVert.x supports HTTP Chunked Transfer Encoding. This allows the HTTP response body to be written in chunks, and is normally used when a large response body is being streamed to a client and the total size is not known in advance. You put the HTTP response into chunked mode as follows: 12HttpServerResponse response = request.response();response.setChunked(true); Default is non-chunked. When in chunked mode, each call to one of the write methods will result in a new HTTP chunk being written out. When in chunked mode you can also write HTTP response trailers to the response. These are actually written in the final chunk of the response. To add trailers to the response, add them directly to the trailers. 1234HttpServerResponse response = request.response();response.setChunked(true);MultiMap trailers = response.trailers();trailers.set(&quot;X-wibble&quot;, &quot;woobble&quot;).set(&quot;X-quux&quot;, &quot;flooble&quot;); Or use putTrailer. 123HttpServerResponse response = request.response();response.setChunked(true);response.putTrailer(&quot;X-wibble&quot;, &quot;woobble&quot;).putTrailer(&quot;X-quux&quot;, &quot;flooble&quot;); Serving files directly from diskIf you were writing a web server, one way to serve a file from disk would be to open it as an AsyncFile and pump it to the HTTP response. Or you could load it it one go using readFile and write it straight to the response. Alternatively, Vert.x provides a method which allows you to serve a file from disk to an HTTP response in one operation. Where supported by the underlying operating system this may result in the OS directly transferring bytes from the file to the socket without being copied through user-space at all. This is done by using sendFile, and is usually more efficient for large files, but may be slower for small files. Here’s a very simple web server that serves files from the file system using sendFile: 123456789vertx.createHttpServer().requestHandler(request -&gt; &#123; String file = &quot;&quot;; if (request.path().equals(&quot;/&quot;)) &#123; file = &quot;index.html&quot;; &#125; else if (!request.path().contains(&quot;..&quot;)) &#123; file = request.path(); &#125; request.response().sendFile(&quot;web/&quot; + file);&#125;).listen(8080); Sending a file is asynchronous and may not complete until some time after the call has returned. If you want to be notified when the file has been writen you can use sendFile NOTEIf you use sendFile while using HTTPS it will copy through user-space, since if the kernel is copying data directly from disk to socket it doesn’t give us an opportunity to apply any encryption. WARNINGIf you’re going to write web servers directly using Vert.x be careful that users cannot exploit the path to access files outside the directory from which you want to serve them. It may be safer instead to use Vert.x Apex. Pumping responsesThe server response is a WriteStream instance so you can pump to it from any ReadStream, e.g. AsyncFile, NetSocket, WebSocket or HttpServerRequest. Here’s an example which echoes the request body back in the response for any PUT methods. It uses a pump for the body, so it will work even if the HTTP request body is much larger than can fit in memory at any one time: 12345678910vertx.createHttpServer().requestHandler(request -&gt; &#123; HttpServerResponse response = request.response(); if (request.method() == HttpMethod.PUT) &#123; response.setChunked(true); Pump.pump(request, response).start(); request.endHandler(v -&gt; response.end()); &#125; else &#123; response.setStatusCode(400).end(); &#125;&#125;).listen(8080); HTTP CompressionVert.x comes with support for HTTP Compression out of the box. This means you are able to automatically compress the body of the responses before they are sent back to the client. If the client does not support HTTP compression the responses are sent back without compressing the body. This allows to handle Client that support HTTP Compression and those that not support it at the same time. To enable compression use can configure it with setCompressionSupported. By default compression is not enabled. When HTTP compression is enabled the server will check if the client incldes an Accept-Encoding header which includes the supported compressions. Commonly used are deflate and gzip. Both are supported by Vert.x. If such a header is found the server will automatically compress the body of the response with one of the supported compressions and send it back to the client. Be aware that compression may be able to reduce network traffic but is more CPU-intensive. HTTP clientUsing the file system with Vert.xVert.x FileSystem对象对多个文件系统都提供了很多操作. 每一个Vert.x实例都有一个文件系统对象,你可以通过fileSystem方法获得它. 每一个操作都提供了一个阻塞和一个非阻塞版本. 非阻塞版本会带有一个handler参数,当非阻塞操作完成之后或者错误发生的时候,这个handler就会被调用. 下面的例子演示了一个异步拷贝文件的操作. 12345678910FileSystem fs = vertx.fileSystem();// Copy file from foo.txt to bar.txtfs.copy(&quot;foo.txt&quot;, &quot;bar.txt&quot;, res -&gt; &#123; if (res.succeeded()) &#123; // Copied ok! &#125; else &#123; // Something went wrong &#125;&#125;); 那些阻塞版本操作正如其名,会一直进行阻塞操作直到结果返回或者异常发生. 在许多情况下,基于不同的操作系统和文件系统,那些阻塞操作也可以非常快的返回,这也是我们提供阻塞版本的原因,但是我们还是强烈建议你,在event loop中当你使用一个阻塞操作时,你应该测试一下,它究竟会耗时多少. 下面演示了如何使用阻塞API 1234FileSystem fs = vertx.fileSystem();// Copy file from foo.txt to bar.txt synchronouslyfs.copyBlocking(&quot;foo.txt&quot;, &quot;bar.txt&quot;); 还有很多的其他文件操作(copy, move, truncate, chmod),我们就不在此一一列出的,具体的你可以去查看相关API. Asynchronous filesVert.x提供了一种异步文件概念,你可以使用这种方式在文件系统中操作文件.下面的是一种演示. 12345678OpenOptions options = new OpenOptions();fileSystem.open(&quot;myfile.txt&quot;, options, res -&gt; &#123; if (res.succeeded()) &#123; AsyncFile file = res.result(); &#125; else &#123; // Something went wrong! &#125;&#125;); Datagram sockets (UDP)","categories":[{"name":"vertx","slug":"vertx","permalink":"https://wangmingco.github.io/categories/vertx/"}],"tags":[{"name":"vertx3","slug":"vertx3","permalink":"https://wangmingco.github.io/tags/vertx3/"}]},{"title":"ZooKeeper 原理","slug":"zookeeper/ZooKeeper 原理","date":"2015-07-12T16:00:00.000Z","updated":"2021-11-18T02:43:53.352Z","comments":true,"path":"2015/07/13/zookeeper/ZooKeeper 原理/","link":"","permalink":"https://wangmingco.github.io/2015/07/13/zookeeper/ZooKeeper%20%E5%8E%9F%E7%90%86/","excerpt":"","text":"数据结构Zookeeper 会维护一个类似于标准的文件系统的数据结构 节点类型 PERSISTENT：持久化目录节点，这个目录节点存储的数据不会丢失； PERSISTENT_SEQUENTIAL：顺序自动编号的目录节点，这种目录节点会根据当前已近存在的节点数自动加 1，然后返回给客户端已经成功创建的目录节点名； EPHEMERAL：临时目录节点，一旦创建这个节点的客户端与服务器端口也就是 session 超时，这种节点会被自动删除； EPHEMERAL_SEQUENTIAL：临时自动编号节点 角色ZK中有如下三种角色 Leader：领导者，负责投票的发起和决议，以及更新系统状态 Follower：接受客户端的请求并返回结果给客户端，并参与投票 Observer：接受客户端的请求，将写的请求转发给leader，不参与投票。Observer目的是扩展系统，提高读的速度。 选举","categories":[{"name":"ZooKeeper","slug":"ZooKeeper","permalink":"https://wangmingco.github.io/categories/ZooKeeper/"}],"tags":[]},{"title":"Vertx 2 Java Api Manaual","slug":"vertx/vertx2_java_api_manual","date":"2015-07-08T08:20:00.000Z","updated":"2021-11-18T02:35:59.531Z","comments":true,"path":"2015/07/08/vertx/vertx2_java_api_manual/","link":"","permalink":"https://wangmingco.github.io/2015/07/08/vertx/vertx2_java_api_manual/","excerpt":"","text":"Writing Verticles正如我们在手册里描述的那样,一个verticle是就是一个Vert.x的执行单元 再重复一下，Vert.x是一个Verticle容器，而且Vert.x确保一个verticle实例永远不会被多个线程并发执行。你可以使用Vert.x支持的所有的语言来编写Verticle，同时Vert.x支持并发执行同一个verticle文件实例出多个Verticle实例。 在Vert.x中，你所编写的所有代码其实都是在Verticle实例中运行。 对于一个简单的任务，你可以直接编写原生verticle，然后在命令行中直接运行它们，但是在大部分情况中你都应该将verticle打包成Vert.x module。 原生verticle，指的就是一个单独的没有打包进module的文件或者类,例如verticle1.class, verticle2.java, verticle3.rb, verticle4.groovy 现在让我们编写一个简单的原生verticle： 我们将编写一个简单的TCP echo服务器。这个服务器仅仅接受网络连接，然后将接收到的数据进行输出。 123456789101112131415import org.vertx.java.core.Handler;import org.vertx.java.core.net.NetSocket;import org.vertx.java.core.streams.Pump;import org.vertx.java.platform.Verticle;public class Server extends Verticle &#123; public void start() &#123; vertx.createNetServer().connectHandler(new Handler&lt;NetSocket&gt;() &#123; public void handle(final NetSocket socket) &#123; Pump.createPump(socket, socket).start(); &#125; &#125;).listen(1234); &#125;&#125; 现在运行它 1vertx run Server.java 现在服务器运行起来了，然后通过telnet连接它 1telnet localhost 注意，你通过回车发送出去的数据是如何输出的 现在，你已经编写了第一个verticle。 也许你已经注意到了，你并没有手动将.java文件编译成.class文件。Vert.x知道如何直接”运行”.java文件，其实在Vert.x内部会自动编译该源文件。 每一个java vertivle都必须继承org.vertx.java.deploy.Verticle,然后必须重载start方法，当verticle启动时，Vert.x会自动调用该方法。 Asynchronous start假设现在有一个Verticle——v1不得不在start()方法中，完成一些异步的操作，或者启动一些其他verticle，在这些操作完成之前，v1一直都应该是未完成状态。 在这种情况下，你的verticle可以实现start()方法的异步版本： 123456789101112public void start(final Future&lt;Void&gt; startedResult) &#123; // For example - deploy some other verticle container.deployVerticle(&quot;foo.js&quot;, new AsyncResultHandler&lt;String&gt;() &#123; public void handle(AsyncResult&lt;String&gt; deployResult) &#123; if (deployResult.succeeded()) &#123; startedResult.setResult(null); &#125; else &#123; startedResult.setFailure(deployResult.cause()); &#125; &#125; &#125;);&#125; Verticle clean-up当verticle停止后，其内部的Servers, clients, event bus handlers and timers会自动关闭或者取消掉，当某个verticle停止时，你如果想要进行一些其他的清理逻辑，你可以自己实现stop()方法，那么当该verticle被解除部署时，该方法就会被自动调用 The container object每一个verticle实例都有一个称为container的成员变量。container表示的是它运行所在的Verticle的一个视图。 container对象定义了部署和解除部署verticle和module的方法，同时还允许设置环境变量和一个可访问的logger The vertx object每一个verticle实例都含有一个vertx实例变量。该变量提供了访问Vert.x核心API的能力。在Vert.x中，你要使用该核心API完成大部分工作，例如TCP, HTTP, file system access, event bus, timers等等。 Getting Configuration in a Verticle你可以像下例这样在命令行中通过-conf选项向module或者verticle传递配置 1vertx runmod com.mycompany~my-mod~1.0 -conf myconf.json 或者向一个原生vertile传递 1vertx run foo.js -conf myconf.json -conf参数是一个包含JSON对象的文本文件名字。 通过调用verticle成员变量contailner的config()方法该配置就成功启用了 123JsonObject config = container.config();System.out.println(&quot;Config is &quot; + config); config()返回一个org.vertx.java.core.json.JsonObject实例，该实例代表一个json对象。 无论部署什么语言实现的verticle，对于配置verticle的方式是一致的。 Logging from a Verticle每个verticle实例都有一个属于它自己的logger。可以通过调用container实例的logger()方法获取logger对象的引用。 123Logger logger = container.logger();logger.info(&quot;I am logging something&quot;); The logger is an instance of the class org.vertx.java.core.logging.Logger and has the following methods; logger是org.vertx.java.core.logging.Logger的实例,该实例拥有下列方法： trace debug info warn error fatal logger产生的日志存储到系统临时目录的vertx.log文件中,在linux中的临时目录是\\tmp. 更多关于配置logging方法的信息，参考主手册 Accessing environment variables from a Verticle你可以通过调用container对象的env()方法来访问环境变量 Causing the container to exitcontainer的exit()方法会干净地关闭掉Vert.x实例 Deploying and Undeploying Verticles Programmatically你可以在一个verticle中通过编程方式对其他verticle进行部署和解除部署。任何通过该方式部署的verticle都有能力看见主verticle的资源(classes, scripts 或者其他文件) Deploying a simple verticle如果想要通过程序的方式部署一个verticle，只需要调用container变量里的deployVerticle方法。 下面的例子就部署了一个verticle实例 1container.deployVerticle(main); main是被部署的Verticle的名字(java源文件名称或者类的FQCN) 具体参考主手册的running Vert.x章节 Deploying Worker VerticlesdeployVerticle方法部署的是标准verticle,如果你想要部署工作者verticle,你可以使用deployWorkerVerticle方法，这俩个方法的参数一致。 Deploying a module programmatically你可以采用下面的方式部署一个module： 1container.deployModule(&quot;io.vertx~mod-mailer~2.0.0-beta1&quot;, config); 程序会根据指定的配置部署一个io.vertx~mod-mailer~2.0.0-beta1的module实例。 Passing configuration to a verticle programmatically我们也可以将JSON配置传递给通过程序部署的verticle。在部署的verticle内部，配置可以被config()方法访问。 1234JsonObject config = new JsonObject();config.putString(&quot;foo&quot;, &quot;wibble&quot;);config.putBoolean(&quot;bar&quot;, false);container.deployVerticle(&quot;foo.ChildVerticle&quot;, config); 然后，在ChildVerticle中，你能通过config()方法访问刚才的配置 Using a Verticle to co-ordinate loading of an application如果你的应用程序是由多个verticle组成，并且希望都当应用程序启动的时候，所有的verticle都能启动起来，那么你可以使用一个单独的verticle来管理应用程序的配置，而且由该verticle启动剩余的全部verticle。 下例中，我们创建了一个AppStarterverticle. 12345678910111213141516// Application configJsonObject appConfig = container.config();JsonObject verticle1Config = appConfig.getObject(&quot;verticle1_conf&quot;);JsonObject verticle2Config = appConfig.getObject(&quot;verticle2_conf&quot;);JsonObject verticle3Config = appConfig.getObject(&quot;verticle3_conf&quot;);JsonObject verticle4Config = appConfig.getObject(&quot;verticle4_conf&quot;);JsonObject verticle5Config = appConfig.getObject(&quot;verticle5_conf&quot;);// Start the verticles that make up the appcontainer.deployVerticle(&quot;verticle1.js&quot;, verticle1Config);container.deployVerticle(&quot;verticle2.rb&quot;, verticle2Config);container.deployVerticle(&quot;foo.Verticle3&quot;, verticle3Config);container.deployWorkerVerticle(&quot;foo.Verticle4&quot;, verticle4Config);container.deployWorkerVerticle(&quot;verticle5.js&quot;, verticle5Config, 10 然后我们创建一个config.json配置文件 12345678910111213141516171819&#123; &quot;verticle1_conf&quot;: &#123; &quot;foo&quot;: &quot;wibble&quot; &#125;, &quot;verticle2_conf&quot;: &#123; &quot;age&quot;: 1234, &quot;shoe_size&quot;: 12, &quot;pi&quot;: 3.14159 &#125;, &quot;verticle3_conf&quot;: &#123; &quot;strange&quot;: true &#125;, &quot;verticle4_conf&quot;: &#123; &quot;name&quot;: &quot;george&quot; &#125;, &quot;verticle5_conf&quot;: &#123; &quot;tel_no&quot;: &quot;123123123&quot; &#125;&#125; 然后将AppStarter设置为module里的主要verticle, 接着你就可以通过下面的例子来启动整个应用程序 1vertx runmod com.mycompany~my-mod~1.0 -conf config.json 如果你的应用程序是非常庞大的，而且是由多个module组成，那么你仍然可以使用相同的技术来实现。 通常，你也许会选择一种脚本语言(JavaScript, Groovy, Ruby or Python)作为你的启动verticle实现语言，那些语言通常会比java更好地支持JSON，因此你可以在启动verticle中非常友好地持有整个JSON配置。 Specifying number of instances当你部署一个verticle时，默认地会只部署一个verticle实例。由于verticle实例是单线程执行的，因此这意味着，这种方式只会用到一个服务器核心。 Vert.x通过部署多个verticle实例来达到拓展（并发运行） 如果你想在程序中部署多个verticle或者module，你可以像下面这样，指定部署实例的数量： 1container.deployVerticle(&quot;foo.ChildVerticle&quot;, 10); 或者使用下面这种方式 1container.deployModule(&quot;io.vertx~some-mod~1.0&quot;, 10); Getting Notified when Deployment is completeverticle的部署实际上是以异步方式运行的，也许是在deployVerticle或者deployModule方法返回之后才完成部署.如果你想当部署完成之后获得通知，那么你可以向 deployVerticle或者deployModule方法传递一个handler，以便当部署完成时获得通知。 123456789container.deployVerticle(&quot;foo.ChildVerticle&quot;, new AsyncResultHandler&lt;String&gt;() &#123; public void handle(AsyncResult&lt;String&gt; asyncResult) &#123; if (asyncResult.succeeded()) &#123; System.out.println(&quot;The verticle has been deployed, deployment ID is &quot; + asyncResult.result()); &#125; else &#123; asyncResult.cause().printStackTrace(); &#125; &#125;&#125;); 当部署完成时，handler会获得一个AsyncResult实例. 你可以通过调用AsyncResult对象的succeeded() 和 failed()方法来观察部署是否正确完成了。 result()方法提供异步操作的结果,在这个例子中，部署的结果是部署ID,如果你以后要接触部署verticle或者module的话，你就需要这个部署ID了。 cause()方法提供了失败原因 Undeploying a Verticle or Module如果verticle被解除部署后，那么通过该verticle部署的verticle或者module，以及它们所有子代，都会被自动解除部署，所以在大多数情况下，你不需要手动地去解除部署一个verticle。然而，当你真的需要手动去解除部署verticle或者module时，你可以通过调用undeployVerticle或者undeployModule的方法来实现(这俩个方法需要传递部署ID)。 1container.undeployVerticle(deploymentID); 你也可以向这俩个方法中传递一个handler，那么当解除部署完成后，你就会得到一个通知 Scaling your application一个verticle实例总是单线程的(工作者verticle除外),这意味着一个verticle实例最多使用一个服务器核心 为了能够利用多核优势，你需要部署多个verticle实例。需要部署的具体数量就取决于你的应用程序了，例如有多少个verticle(不是verticle实例)以及verticle的类型都是什么。 你可以通过程序方式部署多个verticle实例，或者在命令行上通过-instances选项指定部署的数量 The Event Busevent bus充当着Vert.x的”神经系统” 它允许vertivle能够相互通信，不管这些verticle是否是同一种语言实现，或者是否是在同一个Vert.x实例里。 It even allows client side JavaScript running in a browser to communicate on the same event bus. (More on that later). 它甚至允许运行在浏览器里的同一个event bus的JavaScript形式的verticle相互交互 event bus形成了一个横跨多个服务器节点以及多个浏览器的分布式的端对端的消息系统, event bus的API是相当简单的. 它基本上只涉及了registering handlers, unregistering handlers 和 sending/publishing messages. The TheoryAddressing我们通过event bus向一个地址发送Message. 在Vert.x中不需要担心是否会使用到复杂的寻址方案. 在Vert.x中，地址就是一个简单的合法字符串。Vert.x的地址还使用了一些scheme,例如使用.分割命名空间区间。 一些合法的地址例如：europe.news.feed1, acme.games.pacman, sausages, and X Handlers我们使用handler从event bus中接收消息——向一个地址注册一个handler。 无论是否是同一个verticle中的handler都可以向相同的地址进行注册。verticle中的同一个handler也可以注册到不同的地址上 Publish / subscribe messagingevent bus也支持消息发布——消息会被发布到某一个地址上.消息发布意味着：将消息发布给在某个地址上注册的全部handler。这和publish/subscribe消息模式很像。 Point to point and Request-Response messagingevent bus支持点对点消息传送.消息会被发送到一个地址上。Vert.x然后会在该地址上的N个handler中选择一个,然后将消息传递给被选择的handler。如果某个地址上注册了多个handler，Vert.x会根据一个不是很严格的循环算法来选取一个。 在点对点传送消息的情况中，当发送消息时，可以指定一个可选的回复handler。当接受者接受到一个消息后，同时该Message被处理后，接受者可以选择是否回应该消息。如果接受者选择回应该消息，那么reply handler会被调用。 当发送者接收到消息回应后，发送者还可以选择接着回应。这种模式可以永远重复下去，Vert.x还支持在这俩个verticle中创建一个会话。这种通用的消息模式称为Request-Response模式。 Transientevent bus消息都具有瞬时性，当event bus全部或者部分失败后，那就有可能丢失一部分消息。如果你的应用程序不允许出现消息丢失，那么你应该将你的handler编码成idempotent，同时当event bus恢复后，你的sender再尝试回应消息。 如果你想要持久有你的消息，你可以使用persistent work queue module Types of messages在event bus上传递的消息可以是一个简单的字符串，一个数字，一个boolean，或者是Vert.x Buffer 或者JSON消息。 但是我们强烈建议你在不同的verticle中通过JSON消息进行通信。JSON可以在Vert.x支持的语言中轻松地创建和解析。 Event Bus APIRegistering and Unregistering Handlers下例展示了如何在test.address上注册一个消息handler。 123456789EventBus eb = vertx.eventBus();Handler&lt;Message&gt; myHandler = new Handler&lt;Message&gt;() &#123; public void handle(Message message) &#123; System.out.println(&quot;I received a message &quot; + message.body); &#125;&#125;;eb.registerHandler(&quot;test.address&quot;, myHandler); myHandler会接受到所有发送到test.address地址上的消息。 Message是一个泛型类，已经指定的消息类型有：Message&lt;Boolean&gt;, Message&lt;Buffer&gt;, Message&lt;byte[]&gt;, Message&lt;Byte&gt;, Message&lt;Character&gt;, Message&lt;Double&gt;, Message&lt;Float&gt;, Message&lt;Integer&gt;, Message&lt;JsonObject&gt;, Message&lt;JsonArray&gt;, Message&lt;Long&gt;, Message&lt;Short&gt; and Message&lt;String&gt; 如果你确定接受到的消息都是同一种类型，那么你可以在handler上使用指定类型 12345Handler&lt;Message&lt;String&gt;&gt; myHandler = new Handler&lt;Message&lt;String&gt;&gt;() &#123; public void handle(Message&lt;String&gt; message) &#123; String body = message.body; &#125;&#125;; registerHandler方法返回的是event bus自身。我们提供了一个流畅的API，因此你可以将多个调用连接在一起。 当你向某个地址中注册一个handler，同时处于一个集群中，那该注册过程就需要耗费一点时间来在整个集群中的进行传播。如果你想handler注册成功后获得通知，那么你可以向registerHandler方法的第三个参数中指定另一个handler。当集群中的所有节点都收到向某个地址注册handler信息之后，那么第三个参数handler就会被调用,然后你就会收到handler注册完成的通知了。 12345eb.registerHandler(&quot;test.address&quot;, myHandler, new AsyncResultHandler&lt;Void&gt;() &#123; public void handle(AsyncResult&lt;Void&gt; asyncResult) &#123; System.out.println(&quot;The handler has been registered across the cluster ok? &quot; + asyncResult.succeeded()); &#125;&#125;); 解除handler注册也是非常简单的，你只需要向unregisterHandler方法传递注册地址和已经注册上的那个handler对象就可以了。 1eb.unregisterHandler(&quot;test.address&quot;, myHandler); 一个handler可以向相同的或者不同的地址上注册多次，因此为了在handler解除注册时，能够确定handler的唯一性，在解除注册时你需要同时指定要被解除的handler对象和注册地址 和注册一样，当你在一个集群环境中解除handler注册，这个过程需要耗费一些时间，以便整个集群都会收到该解除注册通知。同样的你如果想要当解除注册完成之后获得通知，registerHandler给这个函数增加一个第三个参数就可以了 12345eb.unregisterHandler(&quot;test.address&quot;, myHandler, new AsyncResultHandler&lt;Void&gt;() &#123; public void handle(AsyncResult&lt;Void&gt; asyncResult) &#123; System.out.println(&quot;The handler has been unregistered across the cluster ok? &quot; + asyncResult.succeeded()); &#125;&#125;); 如果你想要你的handler存在于整个verticle的生命周期内，那么你就没有必要显式地去对该handler进行解除注册，当verticle停止的时候，Vert.x会自动对其进行解除注册 Publishing messages发布一个消息也是非常简单的，你只需要指定一个发布地址，然后在指定发布的内容就可以了 1eb.publish(&quot;test.address&quot;, &quot;hello world&quot;); 这个消息会发布给在该地址上注册的所有handler。 Sending messages通过send发送消息，那么目标地址上只有一个handler进行消息接受。这是一种点对点的发送消息模式。选取handler同样采用了一种不是很严格的round-robin算法 1eb.send(&quot;test.address&quot;, &quot;hello world&quot;); Replying to messages当你接受到一个消息后，你可能需要对该消息进行回应，这种模式称为request-response 当你send一个消息时，你将一个回应handler作为第三个参数。当接受者接收到消息后，他们可以调用Message的reply方法来回应消息。当reply方法被调用的时候，它会将回复消息发送者。 12345678910111213Handler&lt;Message&lt;String&gt;&gt; myHandler = new Handler&lt;Message&lt;String&gt;&gt;() &#123; public void handle(Message&lt;String&gt; message) &#123; System.out.println(&quot;I received a message &quot; + message.body); // Do some stuff // Now reply to it message.reply(&quot;This is a reply&quot;); &#125;&#125;;eb.registerHandler(&quot;test.address&quot;, myHandler); The sender: 12345eb.send(&quot;test.address&quot;, &quot;This is a message&quot;, new Handler&lt;Message&lt;String&gt;&gt;() &#123; public void handle(Message&lt;String&gt; message) &#123; System.out.println(&quot;I received a reply &quot; + message.body); &#125;&#125;); 发送空的reply或者null reply都是合法的。 The replies themselves can also be replied to so you can create a dialog between two different verticles consisting of multiple rounds. Specifying timeouts for replies如果你在发送消息时指定了一个reply handler, 但是却一直得不到回复响应，那么那么该handler永远都不会被解除注册。 为了解决这个问题，你可以指定一个Handler&lt;AsyncResult&lt;Message&gt;&gt;作为reply handler，然后再设置一个超时时间。如果在超时之前，你收到了消息的reply，那么该AsyncResult的handler方法就会被调用。如果超时前一直都得不到reply，那么该handler就会自动被解除注册，同时new Handler&lt;AsyncResult&lt;Message&lt;String&gt;&gt;&gt;()也会被调用，但是AsyncResult会包含一个失败的状态，你可以在这种状态下做一些特殊处理: 12345678910eb.sendWithTimeout(&quot;test.address&quot;, &quot;This is a message&quot;, 1000, new Handler&lt;AsyncResult&lt;Message&lt;String&gt;&gt;&gt;() &#123; public void handle(AsyncResult&lt;Message&lt;String&gt;&gt; result) &#123; if (result.succeeded()) &#123; System.out.println(&quot;I received a reply &quot; + message.body); &#125; else &#123; System.err.println(&quot;No reply was received before the 1 second timeout!&quot;); &#125; &#125;&#125;); 当send超时之后，我们可以通过AsyncResult的cause()来获得一个ReplyException异常信息。ReplyException上的failureType()值是ReplyFailure.TIMEOUT 你也可以在event bus自身上设置一个超时时间. 如果你在event bus使用带有reply handler的send(...)方法，那这个超时时间就会被使用到。默认的超时时间是-1,这意味着reply handler 永远不会超时 1234567eb.setDefaultReplyTimeout(5000);eb.send(&quot;test.address&quot;, &quot;This is a message&quot;, new Handler&lt;Message&lt;String&gt;&gt;() &#123; public void handle(Message&lt;String&gt; message) &#123; System.out.println(&quot;I received a reply before the timeout of 5 seconds&quot;); &#125;&#125;); 同样，你也可以对reply设置一个超时，然后使用Handler&lt;AsyncResult&lt;Message&gt;&gt;在超时时间内获得reply的reply： 123456789message.replyWithTimeout(&quot;This is a reply&quot;, 1000, new Handler&lt;AsyncResult&lt;Message&lt;String&gt;&gt;&gt;() &#123; public void handle(AsyncResult&lt;Message&lt;String&gt;&gt; result) &#123; if (result.succeeded()) &#123; System.out.println(&quot;I received a reply to the reply&quot; + message.body); &#125; else &#123; System.err.println(&quot;No reply to the reply was received before the 1 second timeout!&quot;); &#125; &#125;&#125;); Getting notified of reply failures如果你使用超时和一个result handler去send一个消息，但是没有可用的handler将消息发送出去，那么result handler将会被调用，AsyncResult会是一个失败的状态,同样cause()会返回一个ReplyException. ReplyException实例的failureType()的返回值是ReplyFailure.NO_HANDLERS 如果你使用超时和一个result handler去send一个消息，但是接受者通过调用Message.fail(..)回应该消息, result handler会被调用，AsyncResult会是一个失败的状态,同样cause()会返回一个ReplyException. ReplyException实例的failureType()的返回值是ReplyFailure.RECIPIENT_FAILURE For example: 123456789101112131415161718eb.registerHandler(&quot;test.address&quot;, new Handler&lt;Message&lt;String&gt;&gt;() &#123; public void handle(Message&lt;String&gt; message) &#123; message.fail(123, &quot;Not enough aardvarks&quot;); &#125;&#125;);eb.sendWithTimeout(&quot;test.address&quot;, &quot;This is a message&quot;, 1000, new Handler&lt;AsyncResult&lt;Message&lt;String&gt;&gt;&gt;() &#123; public void handle(AsyncResult&lt;Message&lt;String&gt;&gt; result) &#123; if (result.succeeded()) &#123; System.out.println(&quot;I received a reply &quot; + message.body); &#125; else &#123; ReplyException ex = (ReplyException)result.cause(); System.err.println(&quot;Failure type: &quot; + ex.failureType(); System.err.println(&quot;Failure code: &quot; + ex.failureCode(); System.err.println(&quot;Failure message: &quot; + ex.message(); &#125; &#125;&#125;); Message types你发送的消息类型可以是以下几种(包括部分包装类型) boolean byte[] byte char double float int long short java.lang.String org.vertx.java.core.json.JsonObject org.vertx.java.core.json.JsonArray org.vertx.java.core.buffer.Buffer 如果Vert.x buffers 和 JSON objects and arrays是在相同的JVM里进行传递，那么在传递之前，他们会被copy一份，因此不同的verticle不能访问相同的对象实例，相同的对象实例会引发条件竞争。 Send some numbers: 12345eb.send(&quot;test.address&quot;, 1234);eb.send(&quot;test.address&quot;, 3.14159);Send a boolean:eb.send(&quot;test.address&quot;, true); Send a JSON object: 123JsonObject obj = new JsonObject();obj.putString(&quot;foo&quot;, &quot;wibble&quot;);eb.send(&quot;test.address&quot;, obj); Null messages can also be sent: 1eb.send(&quot;test.address&quot;, null); 使用JSON作为verticle通信协议是一个不错的约定，这是因为JSON可以被所有Vert.x所支持的语言进行编解码 Distributed event bus如果想要在你的特定网络内每一个Vert.x实例都在相同的event bus里，你只需要在命令行里启动Vert.x实例时添加-cluster参数就好了 一旦你成功启动，集群模式下的Vert.x实例就会合并到一起，组成一个分布式的event bus Shared Data我们可能需要一种安全的方式在不同的verticle间共享数据。 Vert.x允许java.util.concurrent.ConcurrentMap和java.util.Set这俩个数据结构在verticle间共享。 注意：为了避免可变数据带来的问题，Vert.x只允许简单的不可变类型，例如number, boolean and string or Buffer等数据类型用于做数据共享。当共享一个buffer时， 当我们从共享数据获取Buffer数据时，其实我们只是从共享数据里copy了一个Buffer，因此不同的verticle永远不会访问同一个对象。 并发数据只能在同一个Vert.x实例中的verticle实例中进行共享。在以后的版本中，Vert.x会允许数据可以在集群中的所有Vert.x实例间进行共享。 Shared Maps如果想要在不同的verticle中共享一个map。首先我们获得这个map的引用，然后就可以使用java.util.concurrent.ConcurrentMap的共享实例了。 123ConcurrentMap&lt;String, Integer&gt; map = vertx.sharedData().getMap(&quot;demo.mymap&quot;);map.put(&quot;some-key&quot;, 123); 当然你也可以在其他的verticle中访问它 123ConcurrentMap&lt;String, Integer&gt; map = vertx.sharedData().getMap(&quot;demo.mymap&quot;);// etc Shared Sets在不同的verticle中使用一个共享的set和使用一个共享的map，方式基本相同 123Set&lt;String&gt; set = vertx.sharedData().getSet(&quot;demo.myset&quot;);set.add(&quot;some-value&quot;); 然后在不同的verticle中使用它 123Set&lt;String&gt; set = vertx.sharedData().getSet(&quot;demo.myset&quot;);// etc Buffers在Vert.x中进行数据传播的大多是org.vertx.java.core.buffer.Buffer实例 Buffer表示的是一个字节序列(size &gt;= 0), 可以向Buffer写入或者读取数据, 当写入数据时，超过其容量最大值时，会自动拓容。 Creating Buffers创建一个空Buffer 1Buffer buff = new Buffer(); 使用String类型创建一个buffer。这个String在Buffer内部以UTF-8进行编码 1Buffer buff = new Buffer(&quot;some-string&quot;); 指定String编码格式创建一个Buffer实例。 1Buffer buff = new Buffer(&quot;some-string&quot;, &quot;UTF-16&quot;); 使用byte[]创建一个Buffer 12byte[] bytes = new byte[] &#123; ... &#125;;new Buffer(bytes); 在创建Buffer实例时，我们也可以指定其大小。当你确定写入buffer的数据大小时，你可以创建一个指定大小的buffer。当buffer创建成功之后，就会分配出指定大小的内存，这种方式比buffer容量不足时，自动拓容要高效的多，但是要慎用，因为它一开始就可能会非常大的内存。 注意，通过指定大小的方式创建出的Buffer实例，给它分配的内存是空的，并不会用0去填充它。 1Buffer buff = new Buffer(100000); Writing to a Buffer有俩种方式向一个buffer中写入数据： appending random access buffer会随着写入的数据的不断增加自动拓容，因此，Buffer实例的写数据操作不可能产生IndexOutOfBoundsException异常 Appending to a Buffer想要使用append方式向buffer中写入数据,你只需要调用appendXXX方法. Append方法支持追加buffers, byte[], String and all primitive types appendXXX方法会返回Buffer实例自身，所以在也可以直接使用chain模式 12345Buffer buff = new Buffer();buff.appendInt(123).appendString(&quot;hello\\n&quot;);socket.write(buff); Random access buffer writes你也可以通过setXXX方法在一个指定位置上写入数据。 setXXX方法支持buffers, byte[], String and all primitive types.所有的setXXX方法的第一个参数都是个写入位置的索引值。 无论采用什么写数据的方式,Buffer总会当内存不足时，进行自动拓容 1234Buffer buff = new Buffer();buff.setInt(1000, 123);buff.setBytes(0, &quot;hello&quot;); Reading from a Buffer我们通过getXXX方法从Buffer里读数据. getXXX方法支持byte[], String and all primitive types. getXXX方法的第一个值是开始读取的位置索引值 1234Buffer buff = ...;for (int i = 0; i &lt; buff.length(); i += 4) &#123; System.out.println(&quot;int value at &quot; + i + &quot; is &quot; + buff.getInt(i));&#125; Other buffer methods: length(). 获得buffer的大小。buffer的length值是buffer的最大索引值 + 1 copy(). 拷贝整个buffer 更多方法参考javadoc手册。 JSON在javascript中有一等类支持JSON, RUBY中有哈希字面量非常好的支持JSON,但是java并不支持这俩点. 因此,如果你想要在java verticle中使用JSON,我们提供了一些简单的JSON类,这些JSON类可以表示JSON对象或者JSON数组.那些类提供了从一个JSON对象或者数组中set/get JSON支持的所有类型。 JSON对象是org.vertx.java.core.json.JsonObject的实例.JSON数组是org.vertx.java.core.json.JsonArray的实例 下面的例子给出了在java verticle中在从event bus中收发JSON消息 123456789101112131415EventBus eb = vertx.eventBus();JsonObject obj = new JsonObject().putString(&quot;foo&quot;, &quot;wibble&quot;) .putNumber(&quot;age&quot;, 1000);eb.send(&quot;some-address&quot;, obj);// ....// And in a handler somewhere:public void handle(Message&lt;JsonObject&gt; message) &#123; System.out.println(&quot;foo is &quot; + message.body.getString(&quot;foo&quot;); System.out.println(&quot;age is &quot; + message.body.getNumber(&quot;age&quot;);&#125; 我们还提供了对象和JSON格式之间的转化方法 Please see the JavaDoc for the full Java Json API. Delayed and Periodic Tasks在Vert.x中有一种常用操作就是经过一段时间的延迟后执行某种操作 chap.c在标准verticle中,你不能通过让线程sleep的方式来达到延迟的效果,因为这会阻塞event loop线程 你可以使用Vert.x定时器.定时器可以是one-shot 或者 periodic One-shot Timersone shot定时器当延迟时间一到就会调用一个event handler.延迟单位是毫秒 你只需要调用setTimer方法,然后向该方法传递需延迟的时间和一个handler. 1234567long timerID = vertx.setTimer(1000, new Handler&lt;Long&gt;() &#123; public void handle(Long timerID) &#123; log.info(&quot;And one second later this is printed&quot;); &#125;&#125;);log.info(&quot;First this is printed&quot;); 该方法的返回值是一个唯一的定时器ID,我们可以使用该ID取消该定时器 Periodic Timers你还可以使用setPeriodic方法设置一个阶段定时器.这个定时器每隔一段时间就会执行一次.同样该方法的返回值是一个唯一的定时器ID,我们同样可以使用该ID取消定时器. 1234567long timerID = vertx.setPeriodic(1000, new Handler&lt;Long&gt;() &#123; public void handle(Long timerID) &#123; log.info(&quot;And every second this is printed&quot;); &#125;&#125;);log.info(&quot;First this is printed&quot;); Cancelling timers我们调用cancelTimer方法可以取消掉periodic timer 12345678long timerID = vertx.setPeriodic(1000, new Handler&lt;Long&gt;() &#123; public void handle(Long timerID) &#123; &#125;&#125;);// And immediately cancel itvertx.cancelTimer(timerID); 或者你可以在event handler里取消它.下面的例子就是在10秒后取消掉了该定时器 123456789long timerID = vertx.setPeriodic(1000, new Handler&lt;Long&gt;() &#123; int count; public void handle(Long timerID) &#123; log.info(&quot;In event handler &quot; + count); if (++count == 10) &#123; vertx.cancelTimer(timerID); &#125; &#125;&#125;); Writing TCP Servers and Clients通过Vert.x创建TCP的服务器和客户端是非常简单的 Net ServerCreating a Net Server我们可以通过vertx实例的createNetServer方法轻松创建一个TCP服务器 1NetServer server = vertx.createNetServer(); Start the Server Listening接下来我们告诉服务器要监听入站连接的端口号 123NetServer server = vertx.createNetServer();server.listen(1234, &quot;myhost&quot;); 第一个参数是要监听的端口号。如果将要监听的端口号设置为0的话，那服务器会随机出一个可用的端口号。一旦服务器完成监听动作，你可以调用port()方法查看服务器真实监听的端口号。 第二个参数是域名或者IP地址。如果该参数省略不填的话，那么才采取默认值0.0.0.0,这意味着它会监听所有可用的网络接口 实际上的绑定动作是异步的，这意味着，可能你的listen方法已经返回了，但是绑定动作还没有完成。如果你想要开始正式监听时获取一个通知的话，那么你可以在第三个参数上指定一个handler。 12345server.listen(1234, &quot;myhost&quot;, new AsyncResultHandler&lt;Void&gt;() &#123; public void handle(AsyncResult&lt;NetServer&gt; asyncResult) &#123; log.info(&quot;Listen succeeded? &quot; + asyncResult.succeeded()); &#125;&#125;); Getting Notified of Incoming Connections我们需要调用connectHandler来处理到来的网络连接. 123456789NetServer server = vertx.createNetServer();server.connectHandler(new Handler&lt;NetSocket&gt;() &#123; public void handle(NetSocket sock) &#123; log.info(&quot;A client has connected!&quot;); &#125;&#125;);server.listen(1234, &quot;localhost&quot;); connectHandler方法返回值就是服务器自身，因此我们将多个方法调用链式地组合在一起： 1234567NetServer server = vertx.createNetServer();server.connectHandler(new Handler&lt;NetSocket&gt;() &#123; public void handle(NetSocket sock) &#123; log.info(&quot;A client has connected!&quot;); &#125;&#125;).listen(1234, &quot;localhost&quot;); or 12345vertx.createNetServer().connectHandler(new Handler&lt;NetSocket&gt;() &#123; public void handle(NetSocket sock) &#123; log.info(&quot;A client has connected!&quot;); &#125;&#125;).listen(1234, &quot;localhost&quot;); Vert.x API大多数都采用这种模式思想 Closing a Net Server如果想要结束一个net server，我们只需要调用close方法就好了 1server.close(); close方法同样是异步的，因此它也有可能close方法已经返回了，但是close操作其实还没完成。当然你如果想要当close完成时获得通知的话，你也可以选择向close方法指定一个handler 12345server.close(new AsyncResultHandler&lt;Void&gt;() &#123; public void handle(AsyncResult&lt;Void&gt; asyncResult) &#123; log.info(&quot;Close succeeded? &quot; + asyncResult.succeeded()); &#125;&#125;); 如果你想要你的net server的生命周期和verticle保持一致，那么你就没必要显式的调用close方法了，当verticle解除部署时，Vert.x container会自动帮你关闭掉服务器 NetServer PropertiesNetServer有一套属性可以设置，属性可以影响NetServer的行为。首先，这套属性调整的是TCP参数，在大多数情况下，你不需要设置他们。 setTCPNoDelay(tcpNoDelay) If true then Nagle’s Algorithm is disabled. If false then it is enabled. setSendBufferSize(size) Sets the TCP send buffer size in bytes. setReceiveBufferSize(size) Sets the TCP receive buffer size in bytes. setTCPKeepAlive(keepAlive) if keepAlive is true then TCP keep alive is enabled, if false it is disabled. setReuseAddress(reuse) if reuse is true then addresses in TIME_WAIT state can be reused after they have been closed. setSoLinger(linger) setTrafficClass(trafficClass) Handling Data当服务器接受到一个连接，connect handler对象的handler方法会被调用，同时向该方法中传递一个NetSocket对象。NetSocket是一个类Socket接口，该类允许你进行读写数据，甚至还允许你关闭该Socket。 Reading Data from the Socket如果想要从NetSocket读取数据，你需要在NetSocket上调用dataHandler方法设置一个dataHandler。每当在socket上接受到数据后，dataHandler都会被调用,同时向dataHandler方法传递一个org.vertx.java.core.buffer.Buffer对象。你可以使用下面的例子开启一个服务器： 1234567891011NetServer server = vertx.createNetServer();server.connectHandler(new Handler&lt;NetSocket&gt;() &#123; public void handle(NetSocket sock) &#123; sock.dataHandler(new Handler&lt;Buffer&gt;() &#123; public void handle(Buffer buffer) &#123; log.info(&quot;I received &quot; + buffer.length() + &quot; bytes of data&quot;); &#125; &#125;); &#125;&#125;).listen(1234, &quot;localhost&quot;); Writing Data to a Socket如果想要向scoket中写入数据的话，你可以调用write方法，这个方法可以通过下面几种方式进行调用： With a single buffer: 12Buffer myBuffer = new Buffer(...);sock.write(myBuffer); 下面我们使用UTF-8编码的字符串，写入到socket中。 1sock.write(&quot;hello&quot;); 下面我们将指定编码格式化一个字符串，然后写入到socket中 1sock.write(&quot;hello&quot;, &quot;UTF-16&quot;); write方法同样是异步的，当该write方法入栈之后就会立即返回 下面给出了一个TCP 服务器，它将接受到的数据直接返回回去。 1234567891011NetServer server = vertx.createNetServer();server.connectHandler(new Handler&lt;NetSocket&gt;() &#123; public void handle(final NetSocket sock) &#123; sock.dataHandler(new Handler&lt;Buffer&gt;() &#123; public void handle(Buffer buffer) &#123; sock.write(buffer); &#125; &#125;); &#125;&#125;).listen(1234, &quot;localhost&quot;); Socket Remote Address通过remoteAddress()方法你可以获得socket对等端的地址 Socket Local Address通过localAddress()方法你可以获得socket的本地地址 Closing a socketclose方法会关闭一个socket，它会直接关闭底层的TCP连接 Closed Handler如果你想当socket关闭时获得通知，你可以设置一个closedHandler 1234567891011NetServer server = vertx.createNetServer();server.connectHandler(new Handler&lt;NetSocket&gt;() &#123; public void handle(final NetSocket sock) &#123; sock.closedHandler(new VoidHandler() &#123; public void handle() &#123; log.info(&quot;The socket is now closed&quot;); &#125; &#125;); &#125;&#125;).listen(1234, &quot;localhost&quot;); 不管是服务器还是客户端，任何一方关闭连接，close handler都会被调用 Exception handler如果担心通信过程中连接发生异常，你可以设置一个exception handler 1234567891011NetServer server = vertx.createNetServer();server.connectHandler(new Handler&lt;NetSocket&gt;() &#123; public void handle(final NetSocket sock) &#123; sock.exceptionHandler(new Handler&lt;Throwable&gt;() &#123; public void handle(Throwable t) &#123; log.info(&quot;Oops, something went wrong&quot;, t); &#125; &#125;); &#125;&#125;).listen(1234, &quot;localhost&quot;); Event Bus Write Handler每一个NetSocket都会自动向event bus上注册一个handler， 当该handler接受到任何buffer之后，它会将buffer写入到NetSocket上。这样一来，由于我们可以通过从不同的verticle里，甚至从不同的Vert.x实例中向向NetSocket注册的event bus地址上写数据，那么我们实现了不单单从传统socket通信的方式向NetSocket写入数据的方式。 我们可以从netSocket上通过writeHandlerID()方法获取注册在event bus上的地址 下面的例子给出了从不同的verticle中向一个NetSocket中写入数据 123String writeHandlerID = ... // E.g. retrieve the ID from shared datavertx.eventBus().send(writeHandlerID, buffer); Read and Write StreamsNetSocket also implements org.vertx.java.core.streams.ReadStream and org.vertx.java.core.streams.WriteStream. This allows flow control to occur on the connection and the connection data to be pumped to and from other object such as HTTP requests and responses, WebSockets and asynchronous files. NetSocket实现了org.vertx.java.core.streams.ReadStream和org.vertx.java.core.streams.WriteStream接口。 Scaling TCP Servers每一个verticle实例都是纯单线程的。 如果你在一个verticle上创建了一个TCPserver，而且对该verticle只部署了一个实例，那么在该verticle上所有的handler就总是在同一个event loop上执行。 这意味着，如果你在一个多核心主机上上运行一个服务器，同时你只部署了一个服务器verticle实例，那么你的服务器只会使用该机器的一个核心 为了解决这个情况，你可以在同一个机器上部署多个服务器上module实例 1vertx runmod com.mycompany~my-mod~1.0 -instances 20 或者部署原生的verticle 1vertx run foo.MyApp -instances 20 上面的代码在同一个Vert.x实例上运行了20个module/verticle实例 当你这样部署之后，你会发现，服务器和之前运行的一样，但是，令人惊奇的是，你机器上的所有核心都处于使用状态，而且处理任务的能力也大大增强了 这时，你也许会问自己”等等，你怎么能让多个服务器同时监听相同的IP和端口呢？当你部署运行多个实例的时候不会造成端口冲突吗” 当主机上已经存在一个服务器监听某个host/port的时候，当你再部署一个服务器,监听相同的host/port时，Vert.x并不会新建一个server，再在相同的host/port上进行监听 Vert.x内部是这样做的，当你尝试部署多个服务器时监听相同的主机和端口时，Vert.x并不会再创建新的服务器对象对相同的主机和端口号进行监听，但是它会在处理网络连接的地方上再注册一个connetc handler(每个)，这么一来就相当于实现了一个处理网络的”集群” Vert.x内部只会持有一个服务器，当有连接到来时，Vert.x会根据round-robin算法，在众多的connet handler中选择一个，然后将到来的连接转发到被选择出的那个connet handler上 Consequently Vert.x TCP servers can scale over available cores while each Vert.x verticle instance remains strictly single threaded, and you don’t have to do any special tricks like writing load-balancers in order to scale your server on your multi-core machine. 因此，Vert.x TCP server就可以在非常方便地在可用核心上进行水平拓展，每个verticle实例都被分配到一个单线程上，因此你就不需要自己在多核主机上去实现服务器的负载均衡了。 NetClientNetClient常常是用来与服务器进行TCP连接 Creating a Net Client你只需要通过调用vertx的createNetClient方法就可以创建一个TCP客户端 1NetClient client = vertx.createNetClient(); Making a Connection然后调用connect方法就可以连接到服务器 1234567891011NetClient client = vertx.createNetClient();client.connect(1234, &quot;localhost&quot;, new AsyncResultHandler&lt;NetSocket&gt;() &#123; public void handle(AsyncResult&lt;NetSocket&gt; asyncResult) &#123; if (asyncResult.succeeded()) &#123; log.info(&quot;We have connected! Socket is &quot; + asyncResult.result()); &#125; else &#123; asyncResult.cause().printStackTrace(); &#125; &#125;&#125;); connetc方法第一个参数是服务器的端口，第二个参数是服务器绑定的域名或者IP地址。第三个参数是一个connect handler，当连接建立成功之后，这个handler就会被调用 connect handler泛型参数是AsyncResult&lt;NetSocket&gt;,我们可以从这个对象的result()方法中获取NetSocket对象。你可以像在服务器端那样，在socket上进行读写数据。 当然你也可以像在服务器端那样执行close , set the closed handler, set the exception handler操作 Configuring ReconnectionNetClient可以被设置成自动重连或者当它无法连接到服务器/与服务器断开连接后进行断线重连。你可以通过调用setReconnectAttempts和setReconnectInterval方法来实现这样的功能 12345NetClient client = vertx.createNetClient();client.setReconnectAttempts(1000);client.setReconnectInterval(500); ReconnectAttempts:该值设定重连服务器的次数。-1表示无限次。默认值是0 ReconnectInterval:该值设定重连服务器的间隔。单位是毫秒。默认值是1000 NetClient PropertiesNetClient也有一套TCP Properties，这套属性值的含义和NetServer一样，具体使用参考NetServer就好了。 SSL ServersSSL ClientsUser Datagram Protocol (UDP)Flow Control - Streams and PumpsVert.x提供了几个对象用于从Buffer中读取和写入数据。 在Vert.x中，调用写入数据的方法会直接返回，但是这个写入操作会在Vert.x内部入列(Vert.x内部有一个写入队列)。 如果你向一个对象中写入数据的速度快于这个对象向底层资源写入数据的速度的话，那么这个写入队列会无限制增长下去，直到最后将全部的可用内存都消耗掉。 为了解决这种问题，Vert.x API中的某些对象提供了flow control功能 我们可以向org.vertx.java.core.streams.ReadStream的实现类写入任何带有flow control功能对象, 我们可以从org.vertx.java.core.streams.WriteStream的实现类中读取出任何带有flow control功能的对象。 下面我们给出一个向ReadStream中读取数据,向WriteStream中写入数据的例子。 A very simple example would be reading from a NetSocket on a server and writing back to the same NetSocket - since NetSocket implements both ReadStream and WriteStream, but you can do this between any ReadStream and any WriteStream, including HTTP requests and response, async files, WebSockets, etc. 一个非常简单的例子是在服务器中从NetSocket中读取数据，然后将数据再写回到相同的NetSocket中,能这样做是因为NetSocket实现了ReadStream和WriteStream接口, 但是你可以在任何实现了ReadStream和WriteStream接口的类之间进行这样的操作,包括HTTP requests and response, async files, WebSockets, 等等. 对于刚才提到的情况，我们可以可以将接受的数据再直接写回到NetSocket中 1234567891011121314NetServer server = vertx.createNetServer();server.connectHandler(new Handler&lt;NetSocket&gt;() &#123; public void handle(final NetSocket sock) &#123; sock.dataHandler(new Handler&lt;Buffer&gt;() &#123; public void handle(Buffer buffer) &#123; // Write the data straight back sock.write(buffer); &#125; &#125;); &#125;&#125;).listen(1234, &quot;localhost&quot;); 在上述的例子中有一个问题：如果从socket中读取数据的速度快于向socket中写入数据的速度，它会慢慢地增长NetSocket中的写入队列，最终会引发内存溢出。例如，如果socket客户端读取数据不是很快，那么慢慢地该连接会阻塞掉。 由于NetSocket实现了WriteStream, 在写入数据之前我们可以检查WriteStream是否已经满了 123456789101112131415NetServer server = vertx.createNetServer();server.connectHandler(new Handler&lt;NetSocket&gt;() &#123; public void handle(final NetSocket sock) &#123; sock.dataHandler(new Handler&lt;Buffer&gt;() &#123; public void handle(Buffer buffer) &#123; if (!sock.writeQueueFull()) &#123; sock.write(buffer); &#125; &#125; &#125;); &#125;&#125;).listen(1234, &quot;localhost&quot;); 上面的例子中不会引发内存溢出，但是当写入队列写满之后，就会发生丢消息的问题了。我们真的想做的是，当NetSocket的写入队列满了之后，就将NetSocket暂停掉： 12345678910111213141516NetServer server = vertx.createNetServer();server.connectHandler(new Handler&lt;NetSocket&gt;() &#123; public void handle(final NetSocket sock) &#123; sock.dataHandler(new Handler&lt;Buffer&gt;() &#123; public void handle(Buffer buffer) &#123; sock.write(buffer); if (sock.writeQueueFull()) &#123; sock.pause(); &#125; &#125; &#125;); &#125;&#125;).listen(1234, &quot;localhost&quot;); 貌似我们已经完成了需求，但其实不然。当socket句柄满了之后，NetSocket被暂停了，但是当写入队列缓解之后，我们希望还能唤起暂停的NetSocket 123456789101112131415161718192021NetServer server = vertx.createNetServer();server.connectHandler(new Handler&lt;NetSocket&gt;() &#123; public void handle(final NetSocket sock) &#123; sock.dataHandler(new Handler&lt;Buffer&gt;() &#123; public void handle(Buffer buffer) &#123; sock.write(buffer); if (sock.writeQueueFull()) &#123; sock.pause(); sock.drainHandler(new VoidHandler() &#123; public void handle() &#123; sock.resume(); &#125; &#125;); &#125; &#125; &#125;); &#125;&#125;).listen(1234, &quot;localhost&quot;); 当写入队列能够接受新的数据时,drainHandler会被调用, 这个操作会让NetSocket重新读取数据。 在我们开发Vert.x应用程序时，这是一种非常普遍的操作，因此我们提供了一个辅助类Pump, 这个类会完成刚才我们写的那一段代码。你可以将Pump看成ReadStream和WriteStream，Pump会自己知道何时重新读写数据 1234567NetServer server = vertx.createNetServer();server.connectHandler(new Handler&lt;NetSocket&gt;() &#123; public void handle(NetSocket sock) &#123; Pump.create(sock, sock).start(); &#125;&#125;).listen(1234, &quot;localhost&quot;); ReadStreamHttpClientResponse, HttpServerRequest, WebSocket, NetSocket, SockJSSocket and AsyncFile等类都实现了ReadStream接口 ReadStream接口定义如下方法： dataHandler(handler): 设置一个从ReadStream读取数据的handler，当有数据到来时，handler会接受到一个buffer对象. pause(): 暂停dataHandler. 调用该方法之后，dataHandler不会再接受新的数据 resume(): 激活dataHandler. 如果有数据来临时，dataHandler会被调用. exceptionHandler(handler): ReadStream中发生异常时，exceptionHandler会被调用. endHandler(handler): 当流读到结尾时，endHandler会被调用. This might be when EOF is reached if the ReadStream represents a file, or when end of request is reached if it’s an HTTP request, or when the connection is closed if it’s a TCP socket. WriteStream HttpClientRequest, HttpServerResponse, WebSocket, NetSocket, SockJSSocket and AsyncFile实现了WriteStream接口 WriteStream接口定义如下方法： write(buffer): 将Buffer中写入WriteStream.这个方法不会发生阻塞.写入操作在Vert.x内部会向写入队列中入列，写入队列将数据异步地写入底层资源。 setWriteQueueMaxSize(size): set the number of bytes at which the write queue is considered full, and the method * * writeQueueFull() returns true. Note that, even if the write queue is considered full, if write is called the data will still be accepted and queued. writeQueueFull(): 获取write queue是否满了，如果满了，返回true exceptionHandler(handler): 当WriteStream发生异常时，将会调用这个handler drainHandler(handler): The handler will be called if the WriteStream is considered no longer full.当WriteStream PumpPump实例拥有下列方法 start(): 启动pump. stop(): 停止pump. When the pump starts it is in stopped mode. setWriteQueueMaxSize(): 与WriteStream的setWriteQueueMaxSize意义相同. bytesPumped(): 返回pumped的总的字节数 Pump可以多次启动和停止 当Pump第一次创建出来后，并不是started状态，你需要调用start()方法来启动它 Writing HTTP serversVert.x能帮你完成一个全功能的高性能的可扩展的HTTP服务器 Creating an HTTP Server调用vertx对象上的createHttpServer就可以创建一个HTTP服务器 1HttpServer server = vertx.createHttpServer(); Start the Server Listening然后我们调用listen绑定土匪用于监听要接收处理的请求的端口 123HttpServer server = vertx.createHttpServer();server.listen(8080, &quot;myhost&quot;); 第一个参数是绑定的端口号 第二个参数是主机域名或者IP地址。如果忽略该参数，则服务器会采取默认值0.0.0.0,服务器会在所有可用的网络接口中监听绑定的端口号 实际上绑定操作是异步进行的，也就是当listen方法返回之后，并不意味着就绑定成功了。如果你想当绑定真正完成的时候，你可以向listen方法传递一个handler，用以接受绑定成功之后的通知 12345server.listen(8080, &quot;myhost&quot;, new AsyncResultHandler&lt;Void&gt;() &#123; public void handle(AsyncResult&lt;HttpServer&gt; asyncResult) &#123; log.info(&quot;Listen succeeded? &quot; + asyncResult.succeeded()); &#125;&#125;); Getting Notified of Incoming Requests我们还要设置一个request handler,这个handler是为了当请求到来时，我们能收到通知: 12345678910HttpServer server = vertx.createHttpServer();server.requestHandler(new Handler&lt;HttpServerRequest&gt;() &#123; public void handle(HttpServerRequest request) &#123; log.info(&quot;A request has arrived on the server!&quot;); request.response().end(); &#125;&#125;);server.listen(8080, &quot;localhost&quot;); 每当有请求到来时，该handler都会被调用一次，然后向handler方法传递一个org.vertx.java.core.http.HttpServerRequest参数 你可以在verticle中实现一个HTTP 服务器,然后在浏览器里输入http://localhost:8080测试一下 和NetServer一样,requestHandler方法返回的也是它自身,因此我们也可以使用链式调用模式 12345678HttpServer server = vertx.createHttpServer();server.requestHandler(new Handler&lt;HttpServerRequest&gt;() &#123; public void handle(HttpServerRequest request) &#123; log.info(&quot;A request has arrived on the server!&quot;); request.response().end(); &#125;&#125;).listen(8080, &quot;localhost&quot;); Or: 123456vertx.createHttpServer().requestHandler(new Handler&lt;HttpServerRequest&gt;() &#123; public void handle(HttpServerRequest request) &#123; log.info(&quot;A request has arrived on the server!&quot;); request.response().end(); &#125;&#125;).listen(8080, &quot;localhost&quot;); Handling HTTP Requests到目前为止，我们看到了如何创建一个HttpServer以及如何捕获通知,下面让我们看一下如何处理接受到的请求： 当捕获到一个请求时，会将请求封装到一个HttpServerRequest中，接着request handler会被调用。 The handler is called when the headers of the request have been fully read. If the request contains a body, that body may arrive at the server some time after the request handler has been called. 当请求的header被全部读取完之后，该handler就会被调用. 如果请求中包含body，body也许会在request handler被调用之后才达到。 HttpServerRequest包含有get the URI, path, request headers and request parameters等功能。我们还可以通过调用该对象的response()方法来获得一个表示服务器向客户端进行回应的对象。 Request MethodHttpServerRequest的method()表示的是请求使用的HTTP method(该方法的可能返回值有GET, PUT, POST, DELETE, HEAD, OPTIONS, CONNECT, TRACE, PATCH). Request VersionHttpServerRequest的version()方法返回的当前请求使用的HTTP版本号 Request URIHttpServerRequest的rui()方法返回的完整的URI(Uniform Resource Locator)地址，例如： 1/a/b/c/page.html?param1=abc&amp;param2=xyz uri()返回将会返回/a/b/c/page.html?param1=abc&amp;param2=xyz 请求使用的URI地址可以是绝对的，也可以是相对的，这取决于客户端使用的什么,在大多数情况下使用的都是绝对的 Request PathHttpServerRequest的path()方法返回的是请求路径，例如： 1a/b/c/page.html?param1=abc&amp;param2=xyz request.path()将返回/a/b/c/page.html Request QueryHttpServerRequest的query()方法返回的是请求查询内容，例如 1a/b/c/page.html?param1=abc&amp;param2=xyz request.query()将返回param1=abc&amp;param2=xyz Request Headers我们可以在HttpServerRequest的对象上通过headers()方法获取请求的请求头(org.vertx.java.core.MultiMap对象)。MultiMap允许一个key有多个值(这让人想起的guava) 下面的例子对http://localhost:8080请求输出了请求头 123456789101112HttpServer server = vertx.createHttpServer();server.requestHandler(new Handler&lt;HttpServerRequest&gt;() &#123; public void handle(HttpServerRequest request) &#123; StringBuilder sb = new StringBuilder(); for (Map.Entry&lt;String, String&gt; header: request.headers().entries()) &#123; sb.append(header.getKey()).append(&quot;: &quot;).append(header.getValue()).append(&quot;\\n&quot;); &#125; request.response().putHeader(&quot;content-type&quot;, &quot;text/plain&quot;); request.response().end(sb.toString()); &#125;&#125;).listen(8080, &quot;localhost&quot;); Request params我们通过HttpServerRequest的params()方法获得请求的请求参数,同样请求参数也是用org.vertx.java.core.MultiMap存储. 例如： 1/page.html?param1=abc&amp;param2=xyz Then the params multimap would contain the following entries: 12param1: &#x27;abc&#x27;param2: &#x27;xyz Remote AddressHttpServerRequest的remoteAddress()返回的是HTTP连接另一端的地址（也就是客户端） Absolute URIHttpServerRequest的absoluteURI()返回的是请求的相对URI地址 Reading Data from the Request Body有时候我们需要向HTTP body中读取数据。像前面介绍的，当请求头被完整读取出来之后，request handler就会被调用，同时封装一个HttpServerRequest对象传递给该handler，但是该对象并不包含body。这么做是因为，body也许非常大，我们不希望可能因为超过可用内存而引发任何问题。 如果，你想要读取body数据，那么你只需要调用HttpServerRequest的dataHandler方法,通过该方法设置一个data handler，每当接受一次request body块都会调用一次该handler。 123456789101112HttpServer server = vertx.createHttpServer();server.requestHandler(new Handler&lt;HttpServerRequest&gt;() &#123; public void handle(HttpServerRequest request) &#123; request.dataHandler(new Handler&lt;Buffer&gt;() &#123; public void handle(Buffer buffer) &#123; log.info(&#x27;I received &#x27; + buffer.length() + &#x27; bytes&#x27;); &#125; &#125;); &#125;&#125;).listen(8080, &quot;localhost&quot;); dataHandler可能不仅仅被调用一次，调用的次数取决于body的大小 这和NetSocket中去读数据非常像 HttpServerRequest实现了ReadStream接口,因此你可以将body转接到一个WriteStream中。 在大多数情况下，body并不是非常大而且我们想要一次性就接受到整个body数据，那么你可以像下面这样操作： 123456789101112131415161718192021HttpServer server = vertx.createHttpServer();server.requestHandler(new Handler&lt;HttpServerRequest&gt;() &#123; public void handle(HttpServerRequest request) &#123; final Buffer body = new Buffer(0); request.dataHandler(new Handler&lt;Buffer&gt;() &#123; public void handle(Buffer buffer) &#123; body.appendBuffer(buffer); &#125; &#125;); request.endHandler(new VoidHandler() &#123; public void handle() &#123; // The entire body has now been received log.info(&quot;The total body received was &quot; + body.length() + &quot; bytes&quot;); &#125; &#125;); &#125;&#125;).listen(8080, &quot;localhost&quot;); 和任何ReadStream的实现类一样,当stream读到尾之后，end handler就会被调用。 如果HTTP请求使用了HTTP chunking,那么每次接收到body里每个HTTP chunk时都会调用一次data handler。 如果想要接收到完整的body数据再解析它的话，这是一种非常通用的用法，因此Vert.x提供了一个bodyHandler方法 bodyHandler方法设置的handler，只有当整个body数据接受完之后才会被调用 当body数据非常大的时候，vert.x会将整个body数据换存储在内存里 123456789101112HttpServer server = vertx.createHttpServer();server.requestHandler(new Handler&lt;HttpServerRequest&gt;() &#123; public void handle(HttpServerRequest request) &#123; request.bodyHandler(new Handler&lt;Buffer&gt;() &#123; public void handle(Buffer body) &#123; // The entire body has now been received log.info(&quot;The total body received was &quot; + body.length() + &quot; bytes&quot;); &#125; &#125;); &#125;&#125;).listen(8080, &quot;localhost&quot;); Handling Multipart Form UploadsVert.x能够理解HTML表单里的文件上传操作. 为了能处理文件上传，你需要在request对象上设置uploadHandler。表单中每上传一个文件，设置的handler都会被调用一次 123456request.expectMultiPart(true);request.uploadHandler(new Handler&lt;HttpServerFileUpload&gt;() &#123; public void handle(HttpServerFileUpload upload) &#123; &#125;&#125;); HttpServerFileUpload类实现了ReadStream，因此你可以从该类中读取数据,然后将数据再写入任何实现了WriteStream的对象,例如前文一直提到的Pump 你也可以直接使用streamToFileSystem()方法将文件直接输出磁盘上 1234567request.expectMultiPart(true);request.uploadHandler(new Handler&lt;HttpServerFileUpload&gt;() &#123; public void handle(HttpServerFileUpload upload) &#123; upload.streamToFileSystem(&quot;uploads/&quot; + upload.filename()); &#125;&#125;); Handling Multipart Form Attributes如果客户端发送过来的请求是一个HTML表单请求，那么你可以使用formAttributes读取请求属性列表。我们要确保请求的全部内容(包含header和body)都被读取之后，采取调用formAttributes,这是因为表单属性都存储在了body里 1234567request.endHandler(new VoidHandler() &#123; public void handle() &#123; // The request has been all ready so now we can look at the form attributes MultiMap attrs = request.formAttributes(); // Do something with them &#125;&#125;); Setting Status Code and Message我们使用setStatusCode()可以设置返回给客户端的HTTP状态码 1234567HttpServer server = vertx.createHttpServer();server.requestHandler(new Handler&lt;HttpServerRequest&gt;() &#123; public void handle(HttpServerRequest request) &#123; request.response().setStatusCode(739).setStatusMessage(&quot;Too many gerbils&quot;).end(); &#125;&#125;).listen(8080, &quot;localhost&quot;); 你还可以使用setStatusMessage()设置状态消息,如果你不进行手动设置的话，那就会采取默认值 默认的状态码是200 Writing HTTP responses如果你想要向HTTP response写入数据，你直接调用write方法就好了。当response结束之前，你可以多次调用write方法。 12Buffer myBuffer = ...request.response().write(myBuffer); 向response中写入使用UTF-8编码的字符串 1request.response().write(&quot;hello&quot;); 使用指定的编码对字符串进行编码然后写入到response中 1request.response().write(&quot;hello&quot;, &quot;UTF-16&quot;); write方法同样是异步的，当write放入到socket的写入队列之后就直接返回(但是此时并不意味着数据就已经写出了) 如果你只想向HTTP response写入一个String或者一个Buffer，那么当你调用完write方法之后，再调用一次end方法就可以了 The first call to write results in the response header being being written to the response. 因此，如果你没使用HTTP chunking，那么当你向response写入数据之前，必须设置Content-Length header。 Ending HTTP responses当你已经向HTTP response写完数据之后，必须手动调用end()方法 end方法有如下几种调用方式： 1request.response().end(); 下面这种方式和先调用一个write(String)再调用end()方法是一样的 1request.response().end(&quot;That&#x27;s all folks&quot;); Closing the underlying connection你可以通过调用close()方法关闭掉当前请求的底层TCP连接 1request.response().close(); Response headers我们可以通过调用headers()方法获得response header（Multimap），然后通过set方法向其添加response header 12request.response().headers().set(&quot;Cheese&quot;, &quot;Stilton&quot;);request.response().headers().set(&quot;Hat colour&quot;, &quot;Mauve&quot;); 我们还可以通过链式模式调用putHeader方法向HTTP response header添加属性 1request.response().putHeader(&quot;Some-Header&quot;, &quot;elephants&quot;).putHeader(&quot;Pants&quot;, &quot;Absent&quot;); response header必须在写入body动作之前写入 Chunked HTTP Responses and TrailersVert.x支持HTTP Chunked Transfer Encoding, 这种模式会将HTTP response body以chunk的方式写入到socket中，当向clent输出的response body非常大，且其大小未知时，这是非常有用的。 1req.response().setChunked(true); response的默认值是non-chunked,当在chunked模式下，每一次调用response.write(...)都会创建一个新的HTTP chunk写入到socket流中 在chunked模式下，你还可以向response中写入HTTP response trailers,这些数据实际上是被写入到最后一个chunk中。 你可以向下面这样，通过调用trailers()方法向HTTP response trailers中写入数据。 12request.response().trailers().add(&quot;Philosophy&quot;, &quot;Solipsism&quot;);request.response().trailers().add(&quot;Favourite-Shakin-Stevens-Song&quot;, &quot;Behind the Green Door&quot;); Like headers, individual HTTP response trailers can also be written using the putTrailer() method. This allows a fluent API since calls to putTrailer can be chained: 1request.response().putTrailer(&quot;Cat-Food&quot;, &quot;Whiskas&quot;).putTrailer(&quot;Eye-Wear&quot;, &quot;Monocle&quot;); Serving files directly from diskIf you were writing a web server, one way to serve a file from disk would be to open it as an AsyncFile and pump it to the HTTP response. Or you could load it it one go using the file system API and write that to the HTTP response. Alternatively, Vert.x provides a method which allows you to serve a file from disk to an HTTP response in one operation. Where supported by the underlying operating system this may result in the OS directly transferring bytes from the file to the socket without being copied through userspace at all. Using sendFile is usually more efficient for large files, but may be slower for small files than using readFile to manually read the file as a buffer and write it directly to the response. To do this use the sendFile function on the HTTP response. Here’s a simple HTTP web server that serves static files from the local web directory: 12345678910111213HttpServer server = vertx.createHttpServer();server.requestHandler(new Handler&lt;HttpServerRequest&gt;() &#123; public void handle(HttpServerRequest req) &#123; String file = &quot;&quot;; if (req.path().equals(&quot;/&quot;)) &#123; file = &quot;index.html&quot;; &#125; else if (!req.path().contains(&quot;..&quot;)) &#123; file = req.path(); &#125; req.response().sendFile(&quot;web/&quot; + file); &#125;&#125;).listen(8080, &quot;localhost&quot;); There’s also a version of sendFile which takes the name of a file to serve if the specified file cannot be found: 1req.response().sendFile(&quot;web/&quot; + file, &quot;handler_404.html&quot;); Note: If you use sendFile while using HTTPS it will copy through userspace, since if the kernel is copying data directly from disk to socket it doesn’t give us an opportunity to apply any encryption. If you’re going to write web servers using Vert.x be careful that users cannot exploit the path to access files outside the directory from which you want to serve them. Pumping ResponsesSince the HTTP Response implements WriteStream you can pump to it from any ReadStream, e.g. an AsyncFile, NetSocket, WebSocket or HttpServerRequest. Here’s an example which echoes HttpRequest headers and body back in the HttpResponse. It uses a pump for the body, so it will work even if the HTTP request body is much larger than can fit in memory at any one time: 12345678910111213HttpServer server = vertx.createHttpServer();server.requestHandler(new Handler&lt;HttpServerRequest&gt;() &#123; public void handle(final HttpServerRequest req) &#123; req.response().headers().set(req.headers()); Pump.createPump(req, req.response()).start(); req.endHandler(new VoidHandler() &#123; public void handle() &#123; req.response().end(); &#125; &#125;); &#125;&#125;).listen(8080, &quot;localhost&quot;); HTTP CompressionVert.x comes with support for HTTP Compression out of the box. Which means you are able to automatically compress the body of the responses before they are sent back to the Client. If the client does not support HTTP Compression the responses are sent back without compressing the body. This allows to handle Client that support HTTP Compression and those that not support it at the same time. To enable compression you only need to do: 12HttpServer server = vertx.createHttpServer();server.setCompressionSupported(true); The default is false. When HTTP Compression is enabled the HttpServer will check if the client did include an ‘Accept-Encoding’ header which includes the supported compressions. Common used are deflate and gzip. Both are supported by Vert.x. Once such a header is found the HttpServer will automatically compress the body of the response with one of the supported compressions and send it back to the client. Be aware that compression may be able to reduce network traffic but is more cpu-intensive. Writing HTTP ClientsRouting HTTP requests with Pattern MatchingWebSocketsSockJSSockJS - EventBus BridgeFile SystemDNS Client","categories":[{"name":"vertx","slug":"vertx","permalink":"https://wangmingco.github.io/categories/vertx/"}],"tags":[{"name":"vertx2","slug":"vertx2","permalink":"https://wangmingco.github.io/tags/vertx2/"}]},{"title":"Vertx 2 Manual","slug":"vertx/vertx2_manual","date":"2015-07-02T04:10:00.000Z","updated":"2021-11-18T02:35:51.042Z","comments":true,"path":"2015/07/02/vertx/vertx2_manual/","link":"","permalink":"https://wangmingco.github.io/2015/07/02/vertx/vertx2_manual/","excerpt":"","text":"Concepts in Vert.xverticle Vert.x 执行的代码单元称为 verticle. verticle可以由JavaScript, Ruby, Java, Groovy or Python等语言编写(Scala和Clojure支持还在开发中) 许多verticle可以在同一个Vert.x实例中并发执行 应用程序可以由部署同一网络在多个不同的节点上的verticle组成, 然后在``Vert.x event bus上进行消息交换。 在一些不重要的应用程序中, 可以在命令行中直接运行verticle, 但是更加通常的做法是将他们打包进module里，然后运行该module module Vert.x应用程序通常是由一个或者多个module组成. 一个module中可以包含多个verticle(不同的verticles可能由不同的语言编写). module`允许功能性的封装和复用 module可以被放入Maven或者其他Bintray仓库里, 而且也可以注册到Vert.x module registry上. 通过Vert.x社区, Vert.x module系统发展出了一个完整的Vert.x module生态系统 更多关于module的信息,参考[module`s manual](). Vert.x Instancesverticles运行在Vert.x实例中. Vert.x实例运行在它自己的JVM实例里. 在同一时间,一个Vert.x实例中可以运行多个verticles.在同一时刻同一个主机上可以运行多个Vert.x实例, 这些Vert.x实例可以被配制成一个集群, 集群中的Vert.x实例可以在一个分布式的event bus中进行交互. 注：是否每一个Vert.x实例都要启动一个JVM实例？ PolyglotVert.x允许你通过JavaScript, Ruby, Java, Groovy and Python这几种语言编写verticle，而且在未来我们还会支持Clojure and Scala. 不管是采用什么语言编写的verticle，都可以进行无缝交互。 ConcurrencyVert.x保证每一个verticle实例在任一时间点上只会被一个线程执行. 这样一来，在实际的开发过程中，你就不需要考虑你的代码会并发执行了(就好像你的代码永远只会被单线程执行). 如果你曾经使用传统的多线程并发模型进程编程, 那Vert.x的这种做法会将你从那种编程模型中解救出来，从此你不用再同步你的状态访问了. 这意味着条件竞争和OS线程死锁都成为了过去式. 不同的verticle实例可以通过event bus进行消息交换. Vert.x应用程序是并发的，因为Vert.x允许有多个单线程的verticle实例并发执行，以及他们之间相互交换数据，而且单个verticle实例并不会被多个线程并发执行。 因此Vert.x的并发模型和Actor模型非常像(verticle和actor大致是一致的)。但是他们之间还是有一些不同点的，例如，在代码结构单元上，verticle的粒度趋于比actor的要大 Asynchronous Programming ModelVert.x提供了一套异步API,这意味着在Vert.x中你需要做的大部分事情就是设置event handler(进行异步回调). 例如你设置了一个handler从TCP Socket接受数据,当数据来的时候,这个handler就会自动被调用. 你还可以设置handler,让其从event bus接受消息, 或者接受HTTP请求然后回应该请求, 以及当一个连接被关闭时收到通知, 或者当定时器到达时接受通知. 这种设置handler的模式在Vert.x中普遍存在(因为我们要异步，要回调). 由于我们使用异步API,因此我们可以仅仅使用少量的os thread便可以支持多个verticles. 实际上, Vert.x设置的线程数与主机上的可用核心数相等.作为一个非常优秀的非阻塞应用程序,你设置线程数没有必要超过可用核心数. 在传统的异步API中,线程会在API操作中阻塞住, 而线程被阻塞之后, 他们就不能再做其他的工作了.例如,从socket中读取数据. 当该线在Socket上程等待数据到达时,它就不能再做其他事.这意味着,当我们需要支持百万并发连接的时候,那我们需要一百万个线程. 在开发项目的时候，有时异步API会受到些批评,尤其是当你不得不从多个event handler上获取结果的时候 我们可以采取下面的方式缓和这种情况,例如,使用mod-rx-vertxmodule,这个module允许你构建异步事件流.这个module使用了RxJava类库,这个类库受到了.net的Reactive extensions启发. event loop每个Vert.x实例内部都管理着一些线程(线程数与主机上可用核心上的线程数相等). 我们称那些线程为event loop， 因为那些线程都或多或少地进行着循环检查——是否有事件传递过来，如果接受到事件，就将它发送给适当的handler处理。例如，事件可以是已经从socket中读取到的数据，或者一个定时器的时间到了，或者一个HTTP response已经结束。 当一个标准的verticle实例被部署后, 服务器将选择一个event loop指派给该verticle实例。要由那个verticle实例处理的工作，都会调用分配给它的线程转发给它。当然，由于在同一时刻可能存在着好几千个处于运行状态的verticle，一个event loop可能同时会被分配到多个verticle上 我们管这叫做multi-reactor模式。它和reactor pattern很像，但是它却拥有多个event loop The Golden Rule - Don’t block the event loop!一个特定的event loop经常会被用于服务多个verticle实例，所以你千万不能将verticle实例阻塞住。一旦verticle阻塞住，那么分配给他线程就不能将接下来的事件分发给其他的handler了，然后你的应用程序慢慢地就被拖死了。 在verticle中任何占用event loop的事情以及event loop不能继续快速处理其他事件的事情都会造成event loop阻塞。可能阻塞event loop的事件可能包括。 Thread.sleep() Object.wait() CountDownLatch.await() 或者java.util.concurrent中其他的阻塞操作. 在loop中进行自旋 执行一个长时间的计算密集型操作，例如数字计算 调用一个阻塞的第三方库操作，例如JDBC查询 Writing blocking code - introducing Worker verticles在一个标准的verticle中，event loop是不建议阻塞发生的，但是，在实际情况中我们极可能有需要阻塞event loop的场景，或者你确实有计算密集型操作执行。一个典型的例子就是调用像JDBC这样的API。 你也许会想写一些直接的阻塞代码，例如，你打算开发一个简单的webserver，但是你知道自己不会有很大的流量，那么你也就不需要处理很多并发连接了。 像刚才描述的那些场景，Vert.x允许你使用一种特殊的verticle实例——工作者verticle(woker verticle)。工作者verticle与标准verticle的不同之处在于，工作者verticle不会被分配到一个Vert.x event loop线程上，而是在一个称为工作者线程池的内部线程池上运行。 和标准verticle一样，工作者verticle也不会被多个线程同时执行，但和标准verticle不同的是，工作者verticle可以被不同的线程在不同的时刻执行(标准verticle总是被同一个线程执行)。 在一个工作者verticle中阻塞线程是可以被接受的。 为了支持标准非阻塞verticle和阻塞工作者verticle，Vert.x提供了一种混合线程模型，因此你可以在你的应用程序使用合适的verticle书写你的逻辑。这相比于一些其他只要求使用阻塞或者非阻塞的平台更加实用。 但是当你使用工作者verticle时也要小心，如果你想要处理很多的并发网络连接时，阻塞的verticle并不能拓展你的应用程序的并发处理能力 Shared data消息传递是非常有用的，但是它并不适用于所有的应用程序的并发处理。于是我们提供了一种共享数据结构，可以使使同一个Vert.x实例中不同verticle实例直接访问它。 Vert.x提供了一个共享的Map和一个共享的Set。为了避免条件竞争，我们建议所有被存储共享的数据都应该是不可变的。 Vert.x APIsVert.x提供了一个可以在verticle中可以直接调用的小巧的静态API。 Vert.x API不会轻易地发生变动，新功能的添加会通过module的方式添加。 这意味着Vert.x core会一直保持小巧和紧凑，如果你想要使用新功能，只需要添加相关module即可。 Vert.x API被分为container API和core API俩部分。 Container API下面给出了Vert.x container对象的操作列表： 对verticle进行部署和解除部署 对module进行部署和解除部署 恢复verticle配置 Logging Core APIThis API provides functionality for: TCP/SSL 服务器和客户端 HTTP/HTTPS 服务器和客户端 WebSockets服务器和客户端 分布式 event bus Periodic and one-off timers Buffers Flow control File-system access Shared map and sets Accessing configuration SockJS Using Vert.x from the command linevertx命令通过命令行与Vert.x平台进行交互。它的主要作用是运行Vert.x``module和原生verticle。 如果你在命令行中仅仅输入vert，那么命令行中会输出vertx命令会采用哪些选项。 Running verticles directly你可以在命令行中直接通过使用vertx run命令直接运行原生Vert.x verticle实例。 对于快速原型代码(quickly prototyping code)或者简单的应用程序，运行原生verticle是非常有用的，但是一般在正式应用程序中，我们建议将你的应用打包成一个module来运行。打包成的module更加易于运行，封装和复用。 一个最简单的vertx示例，就是传递给它一个verticle名字选项，然后将该verticle运行起来。 如果你的verticle是通过JavaScript, Ruby, Groovy or Python等脚本语言编写的，那么你只需要将脚本的名字传递给它。(例如erver.js, server.rb, or server.groovy.) 如果verticle是通过Java来编写的，那么verticle的名字就是应用程序的主类的全限定名，或者是应用程序的主类的Java源文件名，然后由Vert.x编译该源文件，再运行它。 下面给出俩种运行verticle方式：I. 直接运行 1234567891011vertx run app.jsvertx run server.rbvertx run accounts.pyvertx run MyApp.javavertx run com.mycompany.widgets.Widgetvertx run SomeScript.groovy II. 在verticle名前加上该verticle实现语言。例如你的verticle是一个编译好的Groovy类，如果你指定好前缀为groovy，那么Vert.x就知道它是Groovy class而不是Java class。 1vertx run groovy:com.mycompany.MyGroovyMainClass vertx run命令会使用下面几个选项： -conf &lt;config_file&gt; 对verticle提供一些配置。&lt;config_file&gt;是一个text文件的名称，该文件包含一个json形式的配置说明，该选项是可选的。 -cp &lt;path&gt; 这个路径指定verticle文件和verticle中使用到的其他资源的路径。默认值是.(当前路径)。如果你的verticle引用了其他脚本，类,或者资源(如jar文件)，那么你要确保可以在该路径中找到他们。该路径可以通过:分割，包含多个路径。每一个路径都可以是相对或者是绝对路径。例如：-cp classes:lib/otherscripts:jars/myjar.jar:jars/otherjar.jar.需要注意的是，不要将这些值放到系统类路径中(system classpath),因为这可能会导致在部署应用时，产生不可预期的问题。 -instances &lt;instances&gt; 指定在Vert.x中需要实例化该verticle的数量。每一个verticle实例都必须在单线程中运行，为了能够通过可用核心来扩展你的应用程序，你也许想将同一个verticle文件部署多个实例(这样一来,多个线程就可以运行同一种verticle了)。如果忽略该选项，那么默认的就只会部署一个实例。 -includes &lt;mod_list&gt; 一个通过,分割的module名称列表，这些module都被包含在verticle的classpath中。 -worker 该值用于指定verticle是否是以工作者的形式启动 -cluster 这个选项用于指定该Vert.x实例是否和同一网络下的其他Vert.x实例组成一个集群。集群化的Vert.x实例会将Vert.x和其他节点形成一个分布式事件总线。默认值是false -cluster-port 如果指定了-cluster值为true，-cluster-port指定和其他Vert.x实例组成集群的端口号。默认值是0，则随机一个可用端口。一般你不需要指定这个值，除非你真的需要指定一个特殊的端口。 -cluster-host 如果指定了-cluster值为true，-cluster-host指定和其他Vert.x实例组成集群的域名。默认的它会从可用的网络接口中，随机选择一个。如果你的网卡中有多个网络接口，那么你也可以选择一个自己想用的。 下面给出了一些vertx run示例： 根据默认配置运行一个JavaScript verticle 1vertx run server.js 下面运行10个指定classpath的编译好的Java verticle实例 1vertx run com.acme.Myverticle -cp &quot;classes:lib/myjar.jar&quot; -instances 10 用Java源代码运行10个verticle实例 1vertx run Myverticle.java -instances 10 运行20个ruby工作者verticle实例 1vertx run order_worker.rb -instances 20 -worker 在同一台机器上运行2个JavaScript verticle实例，同时将他们和其他服务器组成一个集群。 12vertx run handler.js -clustervertx run sender.js -cluster 通过指定配置文件运行一个ruby verticle实例 1vertx run my_vert.rb -conf my_vert.conf my_vert.conf 只包含一些简单配置： 1234&#123; &quot;name&quot;: &quot;foo&quot;, &quot;num_widgets&quot;: 46&#125; Forcing language implementation to use在Vert.x的langs.properties配置文件中包含了Vert.x能够识别的语言，然后Vert.x会自动识别出module是通过什么语言编写的。有时候也会有一些模棱两可的情况，例如你想要将一个Groovy类作为一个verticle，那么你就可以将实现语言作为前缀加在verticle前，例如： 1vertx run groovy:com.mycompany.MyGroovyMain`verticle` Running modules from the command line我们高度建议你将任何非实验性的Vert.x功能打包成一个module。至于如何将你的代码打包成一个module，你可以参考[module`s manual]() 想要运行一个module，那你就不能再使用vertx run命令了，而是要使用vertx runmod &lt;module name&gt;. 同样，该命令也带有一些选项： -conf &lt;config_file&gt; - 与vertx run意义相同 -instances &lt;instances&gt; - 与vertx run意义相同 -cluster - 与vertx run意义相同 -cluster-host - 与vertx run意义相同 -cp 如果该选项被赋值，那么它将覆盖标准module classpath，然后Vert.x将会在指定的路径搜索mod.json文件和其他module资源。这在某些情况下非常有用，例如，你在IDE中开发了一个module，你可以在不同的classpath中运行该module，然后你就能找到存储项目资源的实际classpath，然后再指定classpath 如果你想要运行一个本地没有安装的module，Vert.x会自动尝试从仓库(仓库可配置)中安装它。一般Vert.x会被配置到从Maven Central, Sonatype Nexus, Bintray 以及你本地仓库安装module。你也可以在Vert.x conf directory中的repos.txt中配置其他Maven仓库。 下面是一些直接运行module的示例： 运行一个名为com.acme~my-mod~2.1的实例 1vertx runmod com.acme~my-mod~2.1 运行一个名为com.acme~other-mod~1.0.beta1的module，我们指定配置，同时运行10实例 1vertx runmod com.acme~other-mod~1.0.beta1 -instances 10 -conf other-mod.conf Running modules directory from .zip filesvertx runzip命令能直接从一个modulezip文件中直接运行module. 运行的module不要求已经安装在本地或者已经安装在一个module仓库里。 1vertx runzip &lt;zip_file_name&gt; zipmodule运行示例 1vertx runzip my-mod~2.0.1.zip 实际上，Vert.x会解压zip文件，将module解压到系统临时目录里，然后从该目录里运行该module。 Running modules as executable jars (fat jars)Vert.x还支持装配fat jars. fat jars都是可运行jar包，它们同时包含着Vert.x的二进制文件，这样你就可以直接通过运行fat jars来运行里面module。 1java -jar my`module`-1.0-fat.jar 这意味着，当你想要通过运行fat jars的module时，你的机器上可以不安装Vert.x，因为jar包中已经包含了所需的Vert.x的二进制文件。 你也可以在命令行中向fat jars中传递Vert.x平台参数 1java -jar my`module`-1.0-fat.jar -cluster -conf myconf.json 你也可以向fat jars传递-cp参数，该参数同样作用于Vert.x平台。下面的例子就在运行module时，指定了一个自定制的cluster.xml 1java -jar my`module`-1.0-fat.jar -cluster -conf myconf.json -cp path/to/dir/containiner/cluster_xml 可以使用下面的命令创建一个fat jar 1vertx fatjar &lt;module_name&gt; Or you can use the Gradle task in the standard Gradle build or the Maven plugin to build them. If you want to override any Vert.x platform configuration, e.g. langs.properties, cluster.xml or logging configuration, you can add those files to the directory platform_lib inside your module that you’re making into a fat jar. When executing your fat jar Vert.x will recognise this directory and use it to configure Vert.x with. Displaying version of Vert.x使用下面的命令查看当前安装的Vert.x的版本 1vertx version Installing and uninstalling modules参考 [module`s manual](). High availability with Vert.xVert.x同样支持对module的高可用(high availability (HA))运行. Automatic failover假设一个module与HA一起运行，如果module所在的Vert.x实例运行失败了，那么该module会自动在集群中其他的节点上重新启动，那我们称该module为fail-over 想要module与HA一起运行，那么只需要在命令行上加上-ha参数 1vertx runmod com.acme~my-mod~2.1 -ha 但是想要HA正常工作，你就需要在集群中添加多个Vert.x实例，也就是说必须存在一个已经启动的Vert.x实例 (该实例是否也需要加-ha参数呢？应该是不需要的，要不然就自我矛盾了) 1vertx runmod com.acme~my-other-mod~1.1 -ha 如果现在运行着com.acme~my-mod~2.1的module的Vert.x实例挂掉了(你可以通过kill -9这个命令进行测试)，那么运行着com.acme~my-mod~1.1的Vert.x实例会自动开始部署com.acme~my-mod~2.1``module，因此，运行着com.acme~my-mod~1.1的Vert.x实例接下来会运行那俩个module。 注意：干净地关闭一个Vert.x实例并不会引起failover,例如使用CTRL-C或者kill -SIGINT 你也可以以bare模式运行Vert.x实例。这种模式下运行的Vert.x实例启动时并不会自动运行任何module，they will also failover for nodes in the cluster. 可以通过下面的命令开启一个bare 实例 1vertx -ha 当你使用ha选项时，你就不需要指定-cluster选项了，因为当Vert.x实例与HA一起运行时，cluster就默认开启了。 HA groups当你与HA运行一个Vert.x实例时，你也可以选择指定一个HA group。 HA group是在逻辑上将集群中一组节点进行分组。只有同一个HA group组内的节点才能相互failover,也就是说failover是不同横跨HA group的. 如果你不显式指定HA group，那么就会将其分配进默认的__DEFAULT__组里. 当运行module时，通过-hgroup选项指定HA group 1vertx runmod com.acme~my-mod~2.1 -ha -hagroup somegroup 下面展示了一些示例： In console 1: 1vertx runmod com.mycompany~my-mod1~1.0 -ha -hagroup g1 In console 2: 1vertx runmod com.mycompany~my-mod2~1.0 -ha -hagroup g1 In console 3: 1vertx runmod com.mycompany~my-mod3~1.0 -ha -hagroup g2 如果我们把console 1中的实例kill掉，那么该实例会向console 2中的实例进行fail over，但不会向console 3中的实例进行fail over，因为他们没有在一个共同的HA group。 如果我们将console 3中的实例kill掉之后，就不会发生fail over了，因为该组中只有一个Vert.x实例 Dealing with network partitions - QuoraHA实现还支持quora When starting a Vert.x instance you can instruct it that it requires a “quorum” before any HA deployments will be deployed. A quorum is a minimum number of nodes for a particular group in the cluster. Typically you chose your quorum size to Q = 1 + N/2 where N is the number of nodes in the group. 当你开启一个Vert.x实例时，你可以在它进行HA部署之前，引导它进行quorum。quorum指的是集群中某个HA group中的最小节点数。一般你可将qurom设定为Q = 1 + N / 2，其中N是HA group中节点的数量。 If there are less than Q nodes in the cluster the HA deployments will undeploy. They will redeploy again if/when a quorum is re-attained. By doing this you can prevent against network partitions, a.k.a. split brain. 如果集群中的节点数小于Q，那么HA部署会undeploy。 如果quorum重新获得后，那么HA会进行重新部署。By doing this you can prevent against network partitions, a.k.a. split brain. 更多信息参考quora 如果想要使用quorum运行Vert.x实例，你只需要在命令行中指定-quorum选项就好： In console 1: 1vertx runmod com.mycompany~my-mod1~1.0 -ha -quorum 3 在console 1中Vert.x实例会启动成功但是，它并不会部署module，因为在集群中只有一个节点 In console 2: 1vertx runmod com.mycompany~my-mod2~1.0 -ha -quorum 3 在console 1中Vert.x实例会启动成功但是，它并不会部署module，因为在集群中只有俩个节点 In console 3: 1vertx runmod com.mycompany~my-mod3~1.0 -ha -quorum 3 现在，我们有三个节点了，quorum条件达到了。现在module就会自动地部署到他们所在的Vert.x实例上 如果我们close或者kill掉三个节点中的一个，其他节点上所有的module都会自动的解除部署，因为现在quorum不再满足条件。 Quora也可以和HA group一起结合使用。 Logging每一个verticle实例都可以从它内部检索出属于它自己的logger，至于如何检索就要参考具体语言实现的API了。 默认的log日志是存储在系统临时目录的vertx.log文件中，在Linux中是\\tmp. 默认实现使用JUL纪录日志。但是我们可以通过$VERTX_HOME\\conf\\logging.properties这个属性文件进行修改。 如果你想要使用其他的日志框架，例如log4j，你可以在启动Vert.x的时候，通过系统参数的方式进行指定。 1-Dorg.vertx.logger-delegate-factory-class-name=org.vertx.java.core.logging.impl.Log4jLogDelegateFactory or 1-Dorg.vertx.logger-delegate-factory-class-name=org.vertx.java.core.logging.impl.SLF4JLogDelegateFactory 如果你不想要使用Vert.x提供的日志功能也可以，你只需要像平常那样使用你喜欢的日志框架，同时引用相关日志jar包，同时你还要在module里进行配置。 Configuring thread pool sizesVert.x主要包含俩个线程池： event loop池 后台(工作者)线程池 The event loop poolevent loop池 用于向标准verticle提供event loop。默认大小是根据你机器上的核心决定的，通过Runtime.getRuntime().availableProcessors()的方法获取你机器上的可用核心. 如果你想要进行优化，改变线程池的大小，你可以重新设置系统属性值——vertx.pool.eventloop.size. The background pool这个线程池是用于提供工作者verticle使用的线程，以及用于其他阻塞任务。由于工作者线程提供阻塞功能，我们往往会比event loop线程池使用的更多。默认的工作者线程池的最大值是20. 如果你想要修改工作者线程池的最大,只需要修改系统属性vertx.pool.worker.size就好了 Configuring clustering在分布式环境中可以使用conf/cluster.xml文件配置集群。 如果你想要采集集群配置过程中的信息，可以修改conf/logging.properties文件，设置com.hazelcast.level=INFO 当运行一个集群时，如果你有多个网络接口选择，那么你可以通过修改interfaces-enabled元素，确保Hazelcast使用的上古当前网络接口 如果你的网络不支持多播(组播)，那么你可以在配置文件中将multicast关闭掉，然后开启tcp-ip Performance TuningImproving connection timeIf you’re creating a lot of connections to a Vert.x server in a short period of time, you may need to tweak some settings in order to avoid the TCP accept queue getting full. This can result in connections being refused or packets being dropped during the handshake which can then cause the client to retry. 如果短时间内Vert.x服务器接受到了大量的连接，你可以通过修改一些配置来避免TCP接收队列饱和。这些设置可以作用于连接复用或者握手期间的丢包情况 出现这种情况的典型例子就是，你的客户端出现了有超过3000ms的长连接 How to tune this is operating system specific but in Linux you need to increase a couple of settings in the TCP / Net config (10000 is an arbitrarily large number) 一般是操作系统来调整TCP接收，但是在Linux中，你可能需要将TCP / Net设置进行翻倍。 12sudo sysctl -w net.core.somaxconn=10000sudo sysctl -w net.ipv4.tcp_max_syn_backlog=10000 对于其他的系统，你就要参考具体系统的配置手册了。 同时，你还要对服务器端的accept backlog参数进行设置 12HttpServer server = vertx.createHttpServer();server.setAcceptBacklog(10000); ###Handling large numbers of connections Increase number of available file handles为了使服务器能够处理大量的网络链接，你也许需要提升你系统的最大文件句柄数(每一个socket都需要一个文件句柄)，至于如何进行设置就看具体操作操作系统了。 Tune TCP buffer size每一个TCP连接的都会为它自己的buffer分配一块内存，因此为了能够支持在固定大小的内存限制下，结构更多的网络连接，我们就需要削减每个TCP buffer的大小了。 123HttpServer server = vertx.createHttpServer();server.setSendBufferSize(4 * 1024);server.setReceiveBufferSize(4 * 1024);","categories":[{"name":"vertx","slug":"vertx","permalink":"https://wangmingco.github.io/categories/vertx/"}],"tags":[{"name":"vertx2","slug":"vertx2","permalink":"https://wangmingco.github.io/tags/vertx2/"}]},{"title":"Java equals和hashcode","slug":"JavaSE/Java equals hashcode","date":"2015-06-07T16:00:00.000Z","updated":"2021-11-18T02:39:43.498Z","comments":true,"path":"2015/06/08/JavaSE/Java equals hashcode/","link":"","permalink":"https://wangmingco.github.io/2015/06/08/JavaSE/Java%20equals%20hashcode/","excerpt":"","text":"Effective Java学习总结 euqals如果类不具有自己的逻辑相等概念，那么就没有必要自己去覆盖euqals()方法. 在这种情况下,每个类的实例都和自身相等. 但是如果程序里也关心逻辑上是否是相等,那么在实现equals()时就要考虑它的通用约定： 自反性: 对于任何非null的引用值x,x.equals(x)必须返回true. 这一点保证的是对象的自身必须等于其自身. 对称性: 对于任何非null的引用值x和y,当且仅当y.equals(x)返回true时,x.equals(y)必须返回true. 传递性: 对于任何非null的引用值x，y和z,如果y.equals(x)返回true且y.equals(z)返回true,则z.equals(x)也必须返回true 一致性: 对于任何非null的引用值x和y,只要equals的比较操作在对象中的信息没有被修改,多次调用x.equals(y)则一致地返回true或者返回false. 这也就是说如果俩个对象相等,那么他们就应该始终保持着相等. 非空性: 对于任何非null的引用值,x.euqals(null)都必须返回false 下面依次是违反上面几个特性的例子： 违反自反性: 1234@Overridepublic boolean equals(Object obj) &#123; return !super.equals(obj);&#125; 违反对称性 123456789101112131415161718192021public static void main(String str1[]) &#123; N n1 = new N(); n1.id = 123; Integer id = 123; System.out.println(n1.equals(id)); System.out.println(id.equals(n1));&#125;class N&#123; public Integer id; @Override public boolean equals(Object obj) &#123; if (obj instanceof Integer) &#123; return obj.equals(id); &#125; return super.equals(obj); &#125;&#125; 违反传递性 1 违反一致性 12345678910111213141516171819202122public static void main(String str1[]) &#123; N n1 = new N(); n1.id = 123; N n2 = new N(); n2.id = 123; System.out.println(n1.equals(n2)); n2.id = 12; System.out.println(n1.equals(n2)); &#125;&#125;class N&#123; public int id; @Override public boolean equals(Object obj) &#123; if (!(obj instanceof N)) &#123; return false; &#125; return ((N) obj).id == id; &#125;&#125; 违反非空性： 这个一般我们不会犯错，因为我们一般都有下面这样的语法,当obj为null时,就会自动返回false 123if (obj instanceof N) &#123; return false;&#125; 一般在实现equals方法时,我们要做到以下几点 1234567891011121314151617181920212223class N&#123; public int id; @Override public boolean equals(Object obj) &#123; // 检查参数是否是这个对象的引用,当equals操作代价昂贵时,这么做会达到性能的提升 if (obj == this) &#123; return true; &#125; // 检查是否是正确的类型 if (!(obj instanceof N)) &#123; return false; &#125; // 把参数转换为正确的类型 N target = (N)obj; // 对于该类中的每个关键域都对其进行匹配 return target.id == id; &#125;&#125; 对于对每个关键域进行判断的时候,除了float和double都可使用==进行判断 float采用Float.compare()进行判断 double采用Double.compare()进行判断如果是数组可以使用Arrays.equals()进行判断. 当equals完成了上述之后,还要对其进行对称性,传递性,一致性进行单元测试. hashCode当覆盖equals()时总要覆盖hashCode(). 对于hashCode的通俗约定： 在运行期,如果对象的equals()方法的用到的关键域没有被修改，那么多次调用对象的hashCode方法每次必须都返回同一个整数。 如果俩个对象调用equals()方法比较是相等的,那么调用这俩个对象的hashCode()方法,它们返回的整数也必须相等 如果俩个对象调用equals()方法比较是不相等的,那么调用这俩个对象的hashCode()方法,它们返回的整数也可能是相等的. 下面给出了一个计算散列值的一个规则：将equals()方法中涉及到的每个关键域f进行如下计算,然后得出一个散列值c： 如果域是boolean，则计算f ? 1 : 0 如果域是byte,char,short,int，则计算(int)f 如果域是long，则计算(int)(f^(f&gt;&gt;32)) 如果域是float，则计算Float.floatToIntBits(f) 如果域是double，则计算Double.doubleToLongBits(f),接着调用long类型的计算 如果域是引用类型，则按照equals()递归方式,依次递归调用hashCode(),如果引用是个null,则返回0计算完每个关键域的散列值之后,依次进行如下计算12int result = 17;result = 31 * result + c;","categories":[{"name":"Java","slug":"Java","permalink":"https://wangmingco.github.io/categories/Java/"}],"tags":[]},{"title":"java泛型","slug":"JavaSE/Java 泛型","date":"2015-06-07T16:00:00.000Z","updated":"2021-11-18T02:39:41.564Z","comments":true,"path":"2015/06/08/JavaSE/Java 泛型/","link":"","permalink":"https://wangmingco.github.io/2015/06/08/JavaSE/Java%20%E6%B3%9B%E5%9E%8B/","excerpt":"","text":"泛型（Generic type 或者 generics）是对 Java 语言的类型系统的一种扩展，以支持创建可以按类型进行参数化的类. 泛型类我们定义一个简单的泛型类, T称为泛型参数, G被称为泛型化了 123class G&lt;T&gt; &#123;&#125; 接着我们在内部定义一个泛型变量 123class G&lt;T&gt; &#123; T t;&#125; 然后我们再添加一个泛型方法泛型方法 1234567class G&lt;T&gt; &#123; T t; public void setValue(T t) &#123; this.t = t; &#125;&#125; 下来我们来使用一下这个泛型类 12G&lt;String&gt; g = new G&lt;&gt;();g.setValue(&quot;value&quot;); 泛型方法在一个非泛化的类中我们也可以直接定义泛化的方法 类型擦除说到java中的泛型就不得不提泛型参数的类型擦除. 当java源码文件被编译成class文件的时候,编译器会将泛型中的类型参数擦除掉(其实class文件中还是会保留部分的泛型信息, 具体参考java虚拟机规范). 类定义的泛型参数T会被替换成具体类型, 一般为Object. 而&lt;T&gt;信息则会被擦除掉, 例如G就会替换成 1234567class G &#123; Object t; public void setValue(Object t) &#123; this.t = t; &#125;&#125; 而在引用该类型的时候则会擦除成 12G g = new G();g.setValue(&quot;value&quot;); 因此，java里的泛型类型安全是由编译器保证的, 在运行期是无法保证类型的安全的. 泛型类的继承关系如果类被泛型化之后, 会对类本身的继承关系造成影响 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879public class TestGeneric &#123; public static void main(String[] args) &#123; SuperParam superParam = new SuperParam(); G&lt;SuperParam&gt; g = new G&lt;&gt;(); g.setValue(superParam); SubG1 subG1 = new SubG1(); subG1.setValue(1); subG1.printValue(&quot;SubG1 printValue&quot;); subG1.print(); SubG2 subG2 = new SubG2(); subG2.setValue(&quot;SubG2 setValue&quot;); subG2.printValue(&quot;SubG2 printValue&quot;); subG2.print(); SubG3&lt;Integer&gt; subG3 = new SubG3&lt;&gt;(); subG3.setValue(&quot;SubG3 setValue&quot;); subG3.printValue(&quot;SubG3 printValue&quot;); subG3.print(3); SubG4&lt;Integer&gt; subG4 = new SubG4(); subG4.setValue(&quot;SubG4 setValue&quot;); subG4.printValue(&quot;SubG4 printValue&quot;); subG4.print(4); &#125;&#125;class G&lt;T&gt; &#123; T t; public void setValue(T t) &#123; this.t = t; &#125; public void printValue(T t) &#123; System.out.println(t); &#125; public T getT() &#123; return t; &#125;&#125;// SubG1继承了G的泛型参数. 但是SubG1本身是没有泛化的class SubG1 extends G &#123; public void print() &#123; System.out.println(t); &#125;&#125;// 强制指定继承过来的T的类型为Stringclass SubG2 extends G&lt;String&gt; &#123; public void print() &#123; System.out.println(&quot;Super:&quot; + t); &#125;&#125;// G的类型由继承过来的方法指定, SubG3则再次由本类自己指定类型class SubG3&lt;T&gt; extends G &#123; public void print(T t1) &#123; System.out.println(&quot;Super:&quot; + t + &quot;. this:&quot; + t1); &#125;&#125;// 指定G的类型为String, SubG4则仍然由本类进行泛型化class SubG4&lt;T&gt; extends G&lt;String&gt; &#123; public void print(T t1) &#123; System.out.println(&quot;Super:&quot; + t + &quot;. this:&quot; + t1); &#125;&#125;class SuperParam &#123; public String toString() &#123; return &quot;SuperParam&quot;; &#125;&#125; 结果为 12345678SubG1 printValue1SubG2 printValueSuper:SubG2 setValueSubG3 printValueSuper:SubG3 setValue. this:3SubG4 printValueSuper:SubG4 setValue. this:4 需要特别指出的是, 在SubG1对象分别调用setValue()和printValue()方法时分别使用了Integer和String俩个类型, 但是却没有产生任何异常信息. 泛型参数的继承关系1234567891011121314151617181920212223242526272829303132333435363738public class TestGeneric &#123; public static void main(String[] args) &#123; SuperParam superParam = new SuperParam(); Param param = new Param(); G&lt;SuperParam&gt; gSuperParam = new G&lt;&gt;(); gSuperParam.setValue(superParam); gSuperParam.setValue(param); SuperParam t = gSuperParam.getT(); G&lt;Param&gt; gParam = new G&lt;&gt;(); gParam.setValue(param); gParam.setValue(superParam); // compile error SubParam subParam = new SubParam(); gParam.setValue(subParam); &#125;&#125;class G&lt;T&gt; &#123; T t; public void setValue(T t) &#123; this.t = t; &#125; public T getT() &#123; return t; &#125;&#125;class SuperParam &#123;&#125;class Param extends SuperParam &#123;&#125;class SubParam extends Param &#123;&#125; 从这一行gParam.setValue(subParam);我们可以看到类型参数的继承结构和普通类型的继承结构的规则是一样的. 泛化在方法中的应用12345678910111213141516171819202122public class TestGeneric &#123; public static void main(String[] args) &#123; print(new G&lt;&gt;()); print(new G&lt;SuperParam&gt;()); // compile Error print(new SubG1()); print(new SubG2()); print(new SubG3()); print(new SubG3&lt;SuperParam&gt;()); print(new SubG4()); print(new SubG4&lt;SuperParam&gt;()); printSuperParam(new G&lt;&gt;()); printSuperParam(new G&lt;SuperParam&gt;()); printSuperParam(new G&lt;Param&gt;()); // compile Error &#125; public static void print(G&lt;String&gt; gs) &#123;&#125; public static void printSuperParam(G&lt;SuperParam&gt; gs) &#123;&#125;&#125; 从上面的例子中我们可以看出, 泛化的类的泛型参数并没有对其类型判断造成影响, 子类化的参数仍然是编译通过的. 但是类型参数的继承再传递到方法时, 却被认为不是相同的类型. 通配符?在泛型参数中作为通配符存在, 它一般和extends和super关键字一起使用. 它表示不确定的一组类型, 例如和extends关键字一起使用就是表示继承自某个类的所有类型 extendsextends关键字是用来定义泛型参数的继承关系. 它表示我们的泛型参数继承自某个类型, 也被我们称为上界符. 我们修改一下G的类型定义,我们引入extends关键字 1234567891011121314151617181920212223242526272829303132public class TestGeneric &#123; public static void main(String[] args) &#123; SuperParam superParam = new SuperParam(); G&lt;SuperParam&gt; g = new G&lt;&gt;(); g.setValue(superParam); SubG1 subG1 = new SubG1(); subG1.setValue(1); subG1.printValue(&quot;SubG1 printValue&quot;); subG1.print(); &#125;&#125;class G&lt;T extends SuperParam&gt; &#123; T t; public void setValue(T t) &#123; this.t = t; &#125; public void printValue(T t) &#123; System.out.println(t); &#125; public T getT() &#123; return t; &#125;&#125; 当使用extends关键字之后, 我们就将这个类的泛化信息固定了下来, 在实例化的时候, 其类型参数必须是继承自某类的子类型 如果我们在实例化的时候指定extends会发生什么呢? 1234567891011121314151617181920212223public class TestGeneric &#123; public static void main(String[] args) &#123; SuperParam superParam = new SuperParam(); G&lt;? extends SuperParam&gt; g = new G&lt;&gt;(); g.setValue(superParam); // compile error g.setValue(new Param()); // compile error &#125;&#125;class G&lt;T&gt; &#123; T t; public void setValue(T t) &#123; this.t = t; &#125;&#125;class SuperParam &#123;&#125;class Param extends SuperParam &#123;&#125;class Param1 extends SuperParam &#123;&#125; 不推荐这种用法, 因为这种情况下如果我们可以对其使用Param或者Param1的类型, 那么这就和不使用泛型是一样的, 会引起类型转化异常. 但是我们却可以在另外一种情况下使用这个关键字 1234567891011121314151617181920212223242526272829public class TestGeneric &#123; public static void main(String[] args) &#123; SuperParam superParam = new SuperParam(); print(new G&lt;&gt;()); // 默认的是SuperParam类型 print(new G&lt;Param&gt;()); &#125; public static void print(G&lt;? extends SuperParam&gt; g) &#123; SuperParam t = g.getT(); &#125;&#125;class G&lt;T&gt; &#123; T t; public void setValue(T t) &#123; this.t = t; &#125; public T getT() &#123; return t; &#125;&#125;class SuperParam &#123;&#125;class Param extends SuperParam &#123;&#125; supersuper作为一种下界符存在. 也就在具体使用时的参数都必须是泛型参数的父类才行. 123G&lt;? super SuperParam&gt; g = new G&lt;&gt;();g.setValue(new SuperParam());g.setValue(new Param()); 同样我们可以在方法中如此使用 123456789101112131415161718192021222324252627public class TestGeneric &#123; public static void main(String[] args) &#123; print(new G&lt;SuperParam&gt;()); print(new G&lt;&gt;()); // 默认是Param &#125; public static void print(G&lt;? super Param&gt; g) &#123; Object t = g.getT(); &#125;&#125;class G&lt;T&gt; &#123; T t; public void setValue(T t) &#123; this.t = t; &#125; public T getT() &#123; return t; &#125;&#125;class SuperParam &#123;&#125;class Param extends SuperParam &#123;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://wangmingco.github.io/categories/Java/"}],"tags":[]},{"title":"Dropwizard 初探","slug":"JavaLibrary/dropwizard","date":"2015-04-07T16:00:00.000Z","updated":"2021-11-18T02:46:29.363Z","comments":true,"path":"2015/04/08/JavaLibrary/dropwizard/","link":"","permalink":"https://wangmingco.github.io/2015/04/08/JavaLibrary/dropwizard/","excerpt":"","text":"Setting Up Maven在MAVEN的dependency里添加metrics-core库 1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.dropwizard.metrics&lt;/groupId&gt; &lt;artifactId&gt;metrics-core&lt;/artifactId&gt; &lt;version&gt;$&#123;metrics.version&#125;&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 注意，使用上面依赖你需要在pom文件里声明了metrics.version属性,并且该属性值是3.1.0 Metersmeter表示的是单位时间内事件数的比例(例如每秒请求数). 除了平均速率之外, meter仍然会追踪1-,5-,15-分钟的移动平均数. 123456private final Meter requests = metrics.meter(&quot;requests&quot;);public void handleRequest(Request request, Response response) &#123; requests.mark(); // etc&#125; 上面的meter表示每秒请求数的比例。 Console ReporterConsole Reporter正如其名,向控制台进行输出日志,下面的示例将每秒进行输出一次. 12345ConsoleReporter reporter = ConsoleReporter.forRegistry(metrics) .convertRatesTo(TimeUnit.SECONDS) .convertDurationsTo(TimeUnit.MILLISECONDS) .build(); reporter.start(1, TimeUnit.SECONDS); Complete getting started下面是一个完整的示例： 12345678910111213141516171819202122232425262728 package sample; import com.codahale.metrics.*; import java.util.concurrent.TimeUnit; public class GetStarted &#123; static final MetricRegistry metrics = new MetricRegistry(); public static void main(String args[]) &#123; startReport(); Meter requests = metrics.meter(&quot;requests&quot;); requests.mark(); wait5Seconds(); &#125; static void startReport() &#123; ConsoleReporter reporter = ConsoleReporter.forRegistry(metrics) .convertRatesTo(TimeUnit.SECONDS) .convertDurationsTo(TimeUnit.MILLISECONDS) .build(); reporter.start(1, TimeUnit.SECONDS); &#125; static void wait5Seconds() &#123; try &#123; Thread.sleep(5*1000); &#125; catch(InterruptedException e) &#123;&#125; &#125;&#125; 1234567891011121314151617&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;somegroup&lt;/groupId&gt; &lt;artifactId&gt;sample&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;Example project for Metrics&lt;/name&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;io.dropwizard.metrics&lt;/groupId&gt; &lt;artifactId&gt;metrics-core&lt;/artifactId&gt; &lt;version&gt;$&#123;metrics.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 注意：使用上面依赖你需要在pom文件里声明了metrics.version属性,并且该属性值是3.1.0 1mvn package exec:java -Dexec.mainClass=sample.First The RegistryMetrics的核心部分是MetricRegistry类,这个类是应用程序中所有的metrics的容器. 下面的示例创建一个新的MetricRegistry: 1final MetricRegistry metrics = new MetricRegistry(); 如果你在应用程序中嵌入一个自己创建的MetricRegistry实例，你应该将这个属性置为静态的. Gaugesgauge表示的是一个瞬时值. 例如我们获取队列里待执行的任务数 1234567891011121314public class QueueManager &#123; private final Queue queue; public QueueManager(MetricRegistry metrics, String name) &#123; this.queue = new Queue(); metrics.register(MetricRegistry.name(QueueManager.class, name, &quot;size&quot;), new Gauge&lt;Integer&gt;() &#123; @Override public Integer getValue() &#123; return queue.size(); &#125; &#125;); &#125;&#125; 当完成计算之后,它将会返回队列里的任务数。 在registry里的每个metric都有一个唯一的名字,其命名规范为用.分割的字符串,例如things.count或者com.example.Thing.latency. MetricRegistry类提供了一个静态方法来构建这些名字. 1MetricRegistry.name(QueueManager.class, &quot;jobs&quot;, &quot;size&quot;) 上面的调用会返回com.example.QueueManager.jobs.size。 对于大多数队列或者类队列结构,你也许仅想要获得queue.size()这个值. 大多数java.util和java.util.concurrent包都实现了size()方法,它的复杂度是O(n),这意味着你的gauge也许会很慢(也许还会持有锁) Counterscounter是一个内部采用AtomicLong计数器的gauge实现. 你可以增加或者减少这个值.例如,我们想要一种更加高效的计算队列大小的方式: 1234567891011private final Counter pendingJobs = metrics.counter(name(QueueManager.class, &quot;pending-jobs&quot;));public void addJob(Job job) &#123; pendingJobs.inc(); queue.offer(job);&#125;public Job takeJob() &#123; pendingJobs.dec(); return queue.take();&#125; 每一次业务逻辑的调用，counter都会被计算一次,它会返回队列中的任务数. 正如你看到的,counter的API是非常不同的是,counter(String)取代了register(String, Metric)，然而你可以仍然可以使用register方法创建你自己的Counter实例,实际上counter(String)在内部里已经将这些工作都为你做好了,还允许你使用相同的名字对metric进行复用 还需要说明一点,在上例中,我们静态引入了MetricRegistry的name方法. Histogramshistogram表示的是流中数据值的静态分布. 除了计算minimum, maximum, mean, etc等值,它还计算中间值或者75th, 90th, 95th, 98th, 99th, 99.9th等百分比. 123456private final Histogram responseSizes = metrics.histogram(name(RequestHandler.class, &quot;response-sizes&quot;));public void handleRequest(Request request, Response response) &#123; // etc responseSizes.update(response.getContent().length);&#125; 上面的histogram统计了响应中的字节数. Timerstimer可以计算某个代码段的调用比例,和调用期间的分布状况. 1234567891011private final Timer responses = metrics.timer(name(RequestHandler.class, &quot;responses&quot;));public String handleRequest(Request request, Response response) &#123; final Timer.Context context = responses.time(); try &#123; // etc; return &quot;OK&quot;; &#125; finally &#123; context.stop(); &#125;&#125; This timer will measure the amount of time it takes to process each request in nanoseconds and provide a rate of requests in requests per second. Health ChecksMetrics还可以通过metrics-healthchecks模块集中检查你的服务的健康. 首先创建一个新的HealthCheckRegistry实例 12345678910111213141516171819final HealthCheckRegistry healthChecks = new HealthCheckRegistry();Second, implement a HealthCheck subclass:public class DatabaseHealthCheck extends HealthCheck &#123; private final Database database; public DatabaseHealthCheck(Database database) &#123; this.database = database; &#125; @Override public HealthCheck.Result check() throws Exception &#123; if (database.isConnected()) &#123; return HealthCheck.Result.healthy(); &#125; else &#123; return HealthCheck.Result.unhealthy(&quot;Cannot connect to &quot; + database.getUrl()); &#125; &#125;&#125; 然后将Metrics注册到它身上： 1healthChecks.register(&quot;postgres&quot;, new DatabaseHealthCheck(database)); 接下来运行所有的health checks: 123456789101112final Map&lt;String, HealthCheck.Resultresults = healthChecks.runHealthChecks();for (Entry&lt;String, HealthCheck.Resultentry : results.entrySet()) &#123; if (entry.getValue().isHealthy()) &#123; System.out.println(entry.getKey() + &quot; is healthy&quot;); &#125; else &#123; System.err.println(entry.getKey() + &quot; is UNHEALTHY: &quot; + entry.getValue().getMessage()); final Throwable e = entry.getValue().getError(); if (e != null) &#123; e.printStackTrace(); &#125; &#125;&#125; Metrics内置了一种health check：ThreadDeadlockHealthCheck,它使用了java内置的线程死锁检测来查找死锁线程. Reporting Via JMX通过JMX报告metrics： 12final JmxReporter reporter = JmxReporter.forRegistry(registry).build();reporter.start(); 一旦reporter启动了,registry中的所有的metrics都可以通过JConsole或者VisualVM看到. Metrics被包装成JMX MBeans,可以在VisualVM&#39;s MBeans browser查看Metrics. 注意：在VisualVM中，你双击任一metric属性,VisualVM将会将这些属性数据通过图形化的方式展示给你. Reporting Via HTTPMetrics仍然可以通过servlet(AdminServlet)展示给你, 提供JSON形式的数据. 它可以报告health checks,打印thread dump,或者提供一个负载均衡的简单响应. (它还提供了其他的servlets–MetricsServlet,例如HealthCheckServlet, ThreadDumpServlet或者PingServlet.) 如果想要使用servlet你必须在pom文件中依赖metrics-servlets. 12345&lt;dependency&gt; &lt;groupId&gt;io.dropwizard.metrics&lt;/groupId&gt; &lt;artifactId&gt;metrics-servlets&lt;/artifactId&gt; &lt;version&gt;$&#123;metrics.version&#125;&lt;/version&gt;&lt;/dependency&gt; Other Reporting除了JMX和HTTP以外,Metrics还提供了下面的报告方式 STDOUT: 使用metrics-core的ConsoleReporter报告 CSV files, 使用metrics-core的CsvReporter报告 SLF4J loggers, 使用metrics-core的Slf4jReporter报告 Ganglia, 使用metrics-ganglia的GangliaReporter报告 Graphite, 使用metrics-graphite的GraphiteReporter报告","categories":[{"name":"Java 类库","slug":"Java-类库","permalink":"https://wangmingco.github.io/categories/Java-%E7%B1%BB%E5%BA%93/"}],"tags":[{"name":"Dropwizard","slug":"Dropwizard","permalink":"https://wangmingco.github.io/tags/Dropwizard/"}]},{"title":"haskell 类型系统","slug":"编程语言/haskell","date":"2015-04-07T16:00:00.000Z","updated":"2021-11-18T02:28:15.100Z","comments":true,"path":"2015/04/08/编程语言/haskell/","link":"","permalink":"https://wangmingco.github.io/2015/04/08/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/haskell/","excerpt":"","text":"数据类型在Haskell中数据只是函数的一种方言,他们并没有本质上的区别.在Haskell中所有的数据类型都必须首字母都必须大写. 在GHCI中我们可以通过::t命令来查看一个数据类型或者函数类型. 我们可以通过下面的语法声明一个数据 12var :: 数据类型var = 数据初始值 或者我们可以将这俩行并为一行 1var = 数据初始值 :: 数据类型 Bool类型我们声明一个bool类型的数据,并将其初始化为True 1true = True :: Bool Char类型单字符类型 12345char = &#x27;a&#x27; :: Charchar = &#x27;\\100&#x27; :: Charchar = &#x27;\\n&#x27; :: Char Int类型有符号整数,其范围和OS与GHC的位数有关.在32位系统中,其范围就是-2^31~2^31-1 1int = -1 :: Int Word类型有符号整数类型,其范围和OS与GHC的位数有关.在32位系统中,其范围就是0~2^32-1 123import Data.Wordword = 1 :: Word Integer类型任意精度类型. 可以表示任意整数的大小, 限制它的因素只和OS有关. 当数据不指明类型时,Integer是整数的默认类型 1integer = 199999 :: Integer Float类型单精度浮点小数 1float = 1.1 :: Float Double类型双精度浮点小数 1double = 1.11111 :: Double Rational类型有理数类型 1rational = 1 / 500 :: Rational String类型String的类型为[Char] 1string = &quot;char array&quot; :: String 元组类型元祖用(,)表示,其中的内容称为元件. 元件的个数并不限制(如有俩个元件的称为2元元组). 一旦确定了元件的个数和元件的类型,那他们就是不可再变的. 1tuple = (123, &quot;abc&quot;) :: (Int, [Char]) 列表类型列表本身就是一个容器,内存可以存放各种类型的数据(包括函数),但是一旦类型确定了,就不可再变. 1list = [123, 8, 9] :: [Int] 拼接列表采用x:xs的形式进行拼接列表, x代表一个元素, xs代表一个列表. 123list = [123, 8, 9]newList = 1 : list 多维列表123mulList = [[]] -- 列表中套有一个列表,类似于2维数组mulList = [[[]]] 类型别名我们可以使用type关键字将复杂类型起一个简单的名字 1type NewType = (Int, Int) 接下来我们就可以使用这个类型了 12point :: NewTypepoint = (1, 2) type关键字并没有产生新的类型,只是在编译期将新的类型替换为原来的类型. 类型类Haskell提供了以下的类型类 Eq Ord Enum Bounded Num Show 字符串 show 1 read 1 lines 1 unlines 1 word 1 unword 1","categories":[{"name":"haskell","slug":"haskell","permalink":"https://wangmingco.github.io/categories/haskell/"}],"tags":[]},{"title":"haskell函数","slug":"编程语言/haskell函数","date":"2015-04-07T16:00:00.000Z","updated":"2021-11-18T02:28:21.695Z","comments":true,"path":"2015/04/08/编程语言/haskell函数/","link":"","permalink":"https://wangmingco.github.io/2015/04/08/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/haskell%E5%87%BD%E6%95%B0/","excerpt":"","text":"我们采用如下格式定义一个函数 12函数名 :: 参数1的类型 -&gt; 参数2的类型 -&gt; ... -&gt; 结果类型 (1)函数名 参数1 参数2 ... = 函数体 (2) 定义函数签名 定义函数 下面我们举例出多种函数定义变体形式: 带有类型类的函数定义12add :: Num t =&gt; t -&gt; t -&gt; tadd x y = x + y 带有多个类型的函数定义12add :: (Show t, Int t) =&gt; t -&gt; t -&gt; tadd x y = x + y 不带有类型类的函数定义12add :: Int -&gt; Int -&gt; Intadd x y = x + y 函数定义1add x y = x + y :: Int 类型自动推断的函数定义1add x y = x + y 函数后跟’在函数名后加一个&#39;,与原函数这代表着俩个函数. 123456add&#x27; :: Num t =&gt; t -&gt; t -&gt; tadd&#x27; x y = x + yadd :: Num t =&gt; t -&gt; t -&gt; tadd x y = x + y 函数类型柯里化函数当调用一个N参数的函数时, 传递M个参数(N &lt; M),那么该参数返回的结果也是一个函数.这个过程称为柯里化. 但是并不是每种函数都可以这么调用,只有下面形式的函数才可以这么调用. 12add :: Num t =&gt; t -&gt; t -&gt; tadd x y = x + y 当我们只向add函数传递一个参数5的时候,我们会得到下面一个这样子的函数: 1234add 5 y = 5 + y函数类型为:add :: Num t =&gt; t -&gt; t 偏函数如果调用函数时,参数列表不完整,这时就称为函数的不完全应用,也称为偏函数. 非柯里化函数非柯里化的函数,必须在调用的时候,将所有参数都放到元组中,然后传递给函数. 12add :: Num t =&gt; (t ,t) -&gt; tadd (x, y) = x + y 多态函数1 重载类型函数1 参数绑定let…in…let里定义的部分会在函数体中进行替换 替换表达式1234s :: Double -&gt; Double -&gt; Double -&gt; Doubles a b c = let p = (a + b + c) / 2 in sqrt (p * (p - a) * (p - b) * (p - c)) 替换多个表达式1 替换函数 where123s :: Double -&gt; Double -&gt; Double -&gt; Doubles a b c = sqrt (p * (p - a) * (p - b) * (p - c)) where p = (a + b + c) / 2 常用函数 恒值函数id 1 常数函数const 1 参数反置函数flip 1 错误函数error 1 undifine函数 1 min/max函数1 列表函数 null 1 length 1 !! 1 reverse 1 head 1 last 1 tail 1 init 1 map 1 filter 1 take 1 drop 1 span 1 break 1 takeWhile 1 dropWhile 1 spiltAt 1 repeat 1 replicate 1 any 1 all 1 elem 1 notelem 1 iterate 1 until 1 zip 1 concat 1 concatMap","categories":[{"name":"haskell","slug":"haskell","permalink":"https://wangmingco.github.io/categories/haskell/"}],"tags":[]},{"title":"haskell表达式","slug":"编程语言/haskell表达式","date":"2015-04-07T16:00:00.000Z","updated":"2021-11-18T02:28:18.199Z","comments":true,"path":"2015/04/08/编程语言/haskell表达式/","link":"","permalink":"https://wangmingco.github.io/2015/04/08/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/haskell%E8%A1%A8%E8%BE%BE%E5%BC%8F/","excerpt":"","text":"条件表达式1234isOne :: Int -&gt; BoolisOne arg = if arg == 1 then True else False 情况分析表达式与switch case类似,只不过情况分析表达式没有break, 使用_作为通配符. 123456month :: Int -&gt; Intmonth n = case n of 1 -&gt; 31 2 -&gt; 28 12 -&gt; 31 _ -&gt; error &quot;error&quot; 守卫表达式123abs :: Num a =&gt; a -&gt; aabs n | n &gt; 0 = n | otherwise = -n 匹配模式表达式123456month :: Int -&gt; Intmonth 1 = 31month 2 = 28month 3 = 21month 12 = 31month _ = error &quot;error&quot; 运算符12345678910优先级9 : !!, .优先级8 : ^, ^^, **优先级7 : *, /, div, mod, rem, quot优先级6 : +, -优先级5 : :, ++优先级4 : ==, /=, &lt;, &lt;=, &gt;, &gt;=, elem, notElem优先级3 : &amp;&amp;优先级2 : ||优先级1 : &gt;&gt;, &gt;&gt;=优先级0 : $, $!, $!!seq 凡是英文运算符,其前后都必须带有`标点","categories":[{"name":"haskell","slug":"haskell","permalink":"https://wangmingco.github.io/categories/haskell/"}],"tags":[]},{"title":"Redis 部署","slug":"nosql/Redis部署","date":"2015-04-01T16:00:00.000Z","updated":"2021-11-18T02:43:49.051Z","comments":true,"path":"2015/04/02/nosql/Redis部署/","link":"","permalink":"https://wangmingco.github.io/2015/04/02/nosql/Redis%E9%83%A8%E7%BD%B2/","excerpt":"","text":"Redis安装 使用 下载，解压和安装： 1234$ wget http://download.redis.io/releases/redis-2.8.19.tar.gz$ tar xzf redis-2.8.19.tar.gz$ cd redis-2.8.19$ make 编译后的可执行文件在src目录中，可以使用下面的命令运行Redis: 1$ src/redis-server 你可以使用内置的客户端连接Redis: 12345$ src/redis-cliredis&gt; set foo barOKredis&gt; get foo&quot;bar&quot; 启动redis服务器123#!/bin/bashcd redis-2.8.19src/redis-server","categories":[{"name":"NoSql","slug":"NoSql","permalink":"https://wangmingco.github.io/categories/NoSql/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://wangmingco.github.io/tags/Redis/"}]},{"title":"线程 状态管理","slug":"JavaSE/并发 线程管理","date":"2015-03-08T16:00:00.000Z","updated":"2021-11-18T02:38:32.770Z","comments":true,"path":"2015/03/09/JavaSE/并发 线程管理/","link":"","permalink":"https://wangmingco.github.io/2015/03/09/JavaSE/%E5%B9%B6%E5%8F%91%20%E7%BA%BF%E7%A8%8B%E7%AE%A1%E7%90%86/","excerpt":"","text":"从Oracle官方文档中我们知道Java线程有如下几种状态 NEW : Thread对象已经创建出来但是还没有运行. RUNNABLE : 线程正在执行. BLOCKED : 线程等待锁 WAITING : 线程正在等待另一个线程来对自己执行某个特定的行为. TIMED_WAITING: 线程正在等待(在超时范围内)另一个线程来对自己执行某个特定的行为. TERMINATED : 线程退出. 从google上找了俩张线程图 我们重点看一下BLOCKED, WAITING, TIMED_WAITING BLOCKED当等待锁的时候,会引发线程的等待状态 1234567891011121314151617181920212223242526public class TestLock &#123; private static final Object lock = new Object(); public static void main(String[] args) &#123; ThreadUtil.printThreadState(&quot;thread1&quot;, &quot;thread2&quot;); Runnable runnable = () -&gt; &#123; synchronized (lock) &#123; System.out.println(Thread.currentThread().getName() + &quot; Sleep&quot;); long now = System.currentTimeMillis(); while (true) &#123; if (System.currentTimeMillis() - now &gt; 5000) &#123; break; &#125; &#125; System.out.println(Thread.currentThread().getName() + &quot; Sleep Finshed&quot;); &#125; &#125;; Thread thread1 = new Thread(runnable, &quot;thread1&quot;); Thread thread2 = new Thread(runnable, &quot;thread2&quot;); thread1.start(); thread2.start(); &#125;&#125; 结果为 1234567891011121314151617thread1 Sleep2016-09-22T17:05:37.064 thread2 -&gt; BLOCKED2016-09-22T17:05:37.064 thread1 -&gt; RUNNABLE2016-09-22T17:05:38.029 thread2 -&gt; BLOCKED2016-09-22T17:05:38.029 thread1 -&gt; RUNNABLE2016-09-22T17:05:39.030 thread2 -&gt; BLOCKED2016-09-22T17:05:39.030 thread1 -&gt; RUNNABLE2016-09-22T17:05:40.031 thread2 -&gt; BLOCKED2016-09-22T17:05:40.031 thread1 -&gt; RUNNABLEthread1 Sleep Finshedthread2 Sleep2016-09-22T17:05:41.032 thread2 -&gt; RUNNABLE2016-09-22T17:05:42.033 thread2 -&gt; RUNNABLE2016-09-22T17:05:43.034 thread2 -&gt; RUNNABLE2016-09-22T17:05:44.035 thread2 -&gt; RUNNABLE2016-09-22T17:05:45.037 thread2 -&gt; RUNNABLEthread2 Sleep Finshed 我们看到thread2就进入了BLOCKED状态. WAITING调用下面三个方法,线程会进入WAITING状态 Object.wait with no timeout Thread.join with no timeout LockSupport.park 注意在调用 Object.wait 和 Thread.join 方法时, 不能传参, 否则线程不会进入到WAITING状态, 我在join中做了个实现 wait123456789101112131415161718192021222324252627282930313233343536373839public class TestWait &#123; private static final Object lock = new Object(); public static void main(String[] args) throws InterruptedException &#123; ThreadUtil.printThreadState(&quot;User&quot;); Thread thread = new Thread(() -&gt; &#123; long now = System.currentTimeMillis(); while (true) &#123; if (System.currentTimeMillis() - now &gt; 2000) &#123; break; &#125; &#125; synchronized (lock) &#123; try &#123; lock.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;, &quot;User&quot;); thread.start(); Thread notify = new Thread(() -&gt; &#123; long now = System.currentTimeMillis(); while (true) &#123; if (System.currentTimeMillis() - now &gt; 5000) &#123; break; &#125; &#125; synchronized (lock) &#123; lock.notify(); &#125; &#125;, &quot;notify&quot;); notify.start(); &#125;&#125; 结果为 123452016-09-22T17:18:12.745 User -&gt; RUNNABLE2016-09-22T17:18:13.747 User -&gt; WAITING2016-09-22T17:18:14.729 User -&gt; WAITING2016-09-22T17:18:15.712 User -&gt; WAITING2016-09-22T17:18:16.713 User -&gt; WAITING joinThreead类的join()方法被调用时,调用它的线程将被挂起,直到这个线程对象完成它的任务join(long millseconds)如果使用这种方法,被挂起的线程只要满足指定的毫秒数到,或者join线程运行完,被挂起线程恢复运行 12345678910111213141516171819202122232425262728293031323334353637383940import java.time.LocalDateTime;public class TestJoin &#123; public static void main(String[] args) throws InterruptedException &#123; ThreadUtil.printThreadState(&quot;main&quot;, &quot;car&quot;, &quot;dog&quot;); Thread carThread = new Thread(() -&gt; &#123; System.out.println(LocalDateTime.now() + &quot; Car run&quot;); long now = System.currentTimeMillis(); while (true) &#123; if (System.currentTimeMillis() - now &gt; 3000) &#123; break; &#125; &#125; System.out.println(LocalDateTime.now() + &quot; Car Stop&quot;); &#125;, &quot;car&quot;); Thread dogThread = new Thread(() -&gt; &#123; System.out.println(LocalDateTime.now() + &quot; Dog run&quot;); long now = System.currentTimeMillis(); while (true) &#123; if (System.currentTimeMillis() - now &gt; 3000) &#123; break; &#125; &#125; System.out.println(LocalDateTime.now() + &quot; Dog Stop&quot;); &#125;, &quot;dog&quot;); try &#123; dogThread.start(); carThread.start(); System.out.println(&quot;Begin join&quot;); carThread.join(); System.out.println(&quot;Started join&quot;); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 结果为 123456789101112131415Begin join2016-09-22T17:17:04.053 Car run2016-09-22T17:17:04.053 Dog run2016-09-22T17:17:05.011 car -&gt; RUNNABLE2016-09-22T17:17:05.011 main -&gt; WAITING2016-09-22T17:17:05.011 dog -&gt; RUNNABLE2016-09-22T17:17:06.013 car -&gt; RUNNABLE2016-09-22T17:17:06.013 main -&gt; WAITING2016-09-22T17:17:06.013 dog -&gt; RUNNABLE2016-09-22T17:17:07.011 car -&gt; RUNNABLE2016-09-22T17:17:07.011 main -&gt; WAITING2016-09-22T17:17:07.011 dog -&gt; RUNNABLE2016-09-22T17:17:07.055 Car StopStarted join2016-09-22T17:17:07.060 Dog Stop 当我调用carThread.join(3);结果为 123456789101112Begin joinStarted join2016-09-22T17:19:26.029 Car run2016-09-22T17:19:26.036 Dog run2016-09-22T17:19:27.004 dog -&gt; RUNNABLE2016-09-22T17:19:27.005 car -&gt; RUNNABLE2016-09-22T17:19:28.004 dog -&gt; RUNNABLE2016-09-22T17:19:28.004 car -&gt; RUNNABLE2016-09-22T17:19:29.005 dog -&gt; RUNNABLE2016-09-22T17:19:29.005 car -&gt; RUNNABLE2016-09-22T17:19:29.030 Car Stop2016-09-22T17:19:29.037 Dog Stop TIMED_WAITING调用下列方法线程会进入TIMED_WAITING状态 Thread.sleep Object.wait with timeout Thread.join with timeout LockSupport.parkNanos LockSupport.parkUntil sleep使用sleep()方法中断线程的运行. sleep()中断线程后,直到CPU时钟来临JVM选中它继续执行的这段期间, 该线程不会占用任何资源 yield()方法通知JVM该线程对象可以释放CPU了 1234567891011121314151617181920212223242526import java.util.concurrent.TimeUnit;public class TestSleep &#123; public static void main(String[] args) &#123; ThreadUtil.printThreadState(&quot;User&quot;); Thread thread = new Thread(() -&gt; &#123; long now = System.currentTimeMillis(); while (true) &#123; if (System.currentTimeMillis() - now &gt; 2000) &#123; break; &#125; &#125; System.out.println(&quot;User Sleep&quot;); try &#123; TimeUnit.SECONDS.sleep(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;User Sleep Finshed&quot;); &#125;, &quot;User&quot;); thread.start(); &#125;&#125; 结果为 1234562016-09-22T17:29:12.378 User -&gt; RUNNABLE2016-09-22T17:29:13.345 User -&gt; RUNNABLEUser Sleep2016-09-22T17:29:14.346 User -&gt; TIMED_WAITING2016-09-22T17:29:15.347 User -&gt; TIMED_WAITINGUser Sleep Finshed join1234567891011121314151617181920212223242526272829303132333435363738394041import java.time.LocalDateTime;public class TestJoin &#123; public static void main(String[] args) throws InterruptedException &#123; ThreadUtil.printThreadState(&quot;main&quot;, &quot;car&quot;, &quot;dog&quot;); Thread carThread = new Thread(() -&gt; &#123; System.out.println(LocalDateTime.now() + &quot; Car run&quot;); long now = System.currentTimeMillis(); while (true) &#123; if (System.currentTimeMillis() - now &gt; 3000) &#123; break; &#125; &#125; System.out.println(LocalDateTime.now() + &quot; Car Stop&quot;); &#125;, &quot;car&quot;); Thread dogThread = new Thread(() -&gt; &#123; System.out.println(LocalDateTime.now() + &quot; Dog run&quot;); long now = System.currentTimeMillis(); while (true) &#123; if (System.currentTimeMillis() - now &gt; 3000) &#123; break; &#125; &#125; System.out.println(LocalDateTime.now() + &quot; Dog Stop&quot;); &#125;, &quot;dog&quot;); try &#123; dogThread.start(); carThread.start(); System.out.println(&quot;Begin join&quot;); carThread.join(3000); System.out.println(&quot;end join&quot;); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 结果为 1234567891011121314Begin join2016-09-22T18:23:56.591 Dog run2016-09-22T18:23:56.601 Car run2016-09-22T18:23:57.646 main -&gt; TIMED_WAITING2016-09-22T18:23:57.647 dog -&gt; RUNNABLE2016-09-22T18:23:57.647 car -&gt; RUNNABLE2016-09-22T18:23:58.582 main -&gt; TIMED_WAITING2016-09-22T18:23:58.582 dog -&gt; RUNNABLE2016-09-22T18:23:58.582 car -&gt; RUNNABLEend join2016-09-22T18:23:59.583 dog -&gt; RUNNABLE2016-09-22T18:23:59.583 car -&gt; RUNNABLE2016-09-22T18:23:59.592 Dog Stop2016-09-22T18:23:59.602 Car Stop wait参考join 守护线程的创建和运行守护线程的优先级很低,通常来说,同一个应用程序中没有其他的线程运行,守护线程才运行. 当守护线程运行结束后,JVM也就结束了这个应用程序 守护线程通常用来作为同一程序中普通线程的服务提供者,因为没有办法确定守护线程什么时候才能获取CPU时钟, 而且在没有其他线程运行的时候,守护线程随时可能会结束 一个典型的守护线程就是java的垃圾回收器 setDeamon()方法只能在start()方法之前被调用,一旦线程开始运行,将不能再修改其状态 注: 需要注意的是,只有在没有用户线程运行的时候,而不是没有用户线程存在的时候守护线程才运行. 例如当所有用户线程多沉睡后,也会被视为没有用户线程执行 Thread.setDaemon(true)必须在thread.start()之前设置，否则会跑出一个IllegalThreadStateException异常。你不能把正在运行的常规线程设置为守护线程。 在Daemon线程中产生的新线程也是Daemon的 不是所有的应用都可以分配给Daemon线程来进行服务，比如读写操作或者计算逻辑。因为在Daemon Thread还没来的及进行操作时，虚拟机可能已经退出了。 当用户线程都运行完后,守护线程也就跟着结束了 12345678910111213141516171819202122232425262728293031public class Main &#123; public static void main(String[] args) &#123; DeameanThread dt = new DeameanThread(); NormalThread nt = new NormalThread(); nt.start(); dt.start(); System.out.println(&quot;main&quot;); &#125;&#125;class NormalThread extends Thread &#123; NormalThread() &#123; setDaemon(false); &#125; @Override public void run() &#123; long old = System.currentTimeMillis(); while((System.currentTimeMillis() - old) &lt; 3000) &#123;&#125; System.out.println(&quot;NormalThread&quot;); &#125;&#125;class DeameanThread extends Thread &#123; DeameanThread() &#123; setDaemon(true); &#125; @Override public void run() &#123; while(true)&#123;&#125; &#125;&#125; ThreadUtil在上面的例子中用到的输出线程状态信息的工具类 1234567891011121314151617181920212223import java.time.LocalDateTime;public class ThreadUtil &#123; public static void printThreadState(String... filter) &#123; Thread print = new Thread(() -&gt; &#123; long now = System.currentTimeMillis(); while (true) &#123; if (System.currentTimeMillis() - now &gt; 1000) &#123; now = System.currentTimeMillis(); Thread.getAllStackTraces().forEach((key, thread) -&gt; &#123; for (int i = 0; i &lt; filter.length; i++) &#123; if (key.getName().equals(filter[i])) &#123; System.out.println(LocalDateTime.now() + &quot; &quot; +key.getName() + &quot; -&gt; &quot; + key.getState()); &#125; &#125; &#125;); &#125; &#125; &#125;, &quot;Print&quot;); print.start(); &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://wangmingco.github.io/categories/Java/"}],"tags":[]},{"title":"MongoDB Replica","slug":"nosql/MongoDB Replica","date":"2015-03-07T16:00:00.000Z","updated":"2021-11-18T02:43:42.987Z","comments":true,"path":"2015/03/08/nosql/MongoDB Replica/","link":"","permalink":"https://wangmingco.github.io/2015/03/08/nosql/MongoDB%20Replica/","excerpt":"","text":"Deploy a Replica Set这篇教程讲述的是如何基于正在运行的不进行控制访问的mongod创建三个replica set. 如果想要创建带有控制访问功能的replica set,参考Deploy Replica Set and Configure Authentication and Authorization. 如果你想要在一个单独的MongoDB上部署replica set, 可以参考Convert a Standalone to a Replica Set. 关于更多的replica set部署信息,参考Replication和Replica Set Deployment Architectures Overview带有三个成员的replica sets就足够应付网络切分和其他类型的系统失败. 那些sets有足够的能力来应付分布式类型的读操作. Replica sets应该保证它的成员数量维持在一个奇数上. 这条规则能够保证正常的elections. 更多关于对replica sets的设计,参考Replication overview 基本的步骤是: 首先启动要成为replica set成员的mongod, 然后配置replica set, 最后将mongod添加到replica set上. Requirements在生产部署阶段, 你应该尽量在不同的主机上部署代理mongod的成员. 当使用虚拟主机进行生产部署时, 你应该在不同的主机服务器上都部署一个’mongod’. 在你创建replica set之前, 你必须先检查你的网络配置能够允许每一个成员都能够相互连接上. 一个成功的replica set部署, 每一个成员都能够连接得上其他成员. 关于如何检查连接,参考Test Connections Between all Members Considerations When Deploying a Replica SetArchitecture在生产阶段, 将replica set和它的成员部署到同一台机器上. 如果可能的话, 绑定到MongoDB标准端口27017上. 使用bind_ip选项确保MongoDB会根据配置好的地址监听来自应用程序的连接. 如果replica set在不同的机房内部署, 那么应该确保大多数的mongod实例部署在第一站点上.参考Replica Set Deployment Architectures Connectivity确保网络中所有的replica set成员和客户端的流量能够安全和高效地传输: 创建一个虚拟的私有网络. 确保该网络上一个单独站点可以路由不同成员间 间所有的流量. 配置访问控制能够阻止未知的客户端连接到 replica set上 配置网络和防火墙规则以便进站和出站的网络包仅仅是在MongoDB的默认端口和你的配置上. 最终确保replica set中每个成员都可以通过可解析的DNS或者hostname访问到. 你应该恰当地设置上DNS名称或者通过/etc/hosts文件来映射这个配置 ConfigurationSpecify the run time configuration on each system in a configuration file stored in /etc/mongodb.conf or a related location. Create the directory where MongoDB stores data files before deploying MongoDB. For more information about the run time options used above and other configuration options, see Configuration File Options. Procedure下面的步骤概括了在access control失效的情况下如何部署replica set Start each member of the replica set with the appropriate options.启动mongod然后通过replSet选项设定replica set名字, 向replica set中添加一个成员. 如果想要配置其他特有参数,参考Replication Options 如果你的应用程序连接了多个replica set, 每一个replica set都应该有一个独立的名字. 某些驱动会根据replica set名称将replica set连接进行分组. 下面是一个示例： 1mongod --replSet &quot;rs0&quot; 你也通过配置文件设置replica set名字. 如果想要通过配置文件启动mongod, 那么你需要--config选项指定配置文件 1mongod --config $HOME/.mongodb/config 在生产部署阶段, 你可以通过配置一个控制脚本来管理这个进程. 但是控制脚本的使用超过了该教程的介绍范围. 注意: 如果你的c盘没有创建C:/data/db, 那么会抛出 ：Hotfix KB2731284 or later update is not installed. 以及 C:\\data\\db not found 的字样. 那么你就需要在命令上加上 –dbpath 选项了 Connect a mongo shell to a replica set member.下例展示了如何连接到在localhost:27017上运行的mongod: 1mongo Initiate the replica set.接着这mongoshell里使用rs.initiate()设置成员. 1rs.initiate() MongoDB使用replica set默认配置启动了一个包含当前成员的replica set 注意: 这个过程大概需要几分钟的时间, 所以需要耐心的稍等一下. Verify the initial replica set configuration.在mongoshell中使用rs.conf()输出replica set配置: 1rs.conf() 输出的replica set配置类似于下面的结构 12345678910&#123; &quot;_id&quot; : &quot;rs0&quot;, &quot;version&quot; : 1, &quot;members&quot; : [ &#123; &quot;_id&quot; : 1, &quot;host&quot; : &quot;mongodb0.example.net:27017&quot; &#125; ]&#125; Add the remaining members to the replica set.在mongoshell中使用rs.add()方法添加俩个成员: 12rs.add(&quot;mongodb1.example.net&quot;)rs.add(&quot;mongodb2.example.net&quot;) 完成这一步之后,你就获得了一个拥有完整功能的replica set. 新的replica set会选出一个主要的来. Check the status of the replica set.在mongoshell中使用rs.status()方法查看replica set状态. 1rs.status() Replication IntroductionReplication 是用于多台服务器间数据同步的一个进程.","categories":[{"name":"NoSql","slug":"NoSql","permalink":"https://wangmingco.github.io/categories/NoSql/"}],"tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"https://wangmingco.github.io/tags/MongoDB/"}]},{"title":"运行MongoDB","slug":"nosql/MongoDB","date":"2015-03-07T16:00:00.000Z","updated":"2021-11-18T02:43:44.455Z","comments":true,"path":"2015/03/08/nosql/MongoDB/","link":"","permalink":"https://wangmingco.github.io/2015/03/08/nosql/MongoDB/","excerpt":"","text":"Run MongoDB On Windows如果在没有进行auth设置且在Secure Mode运行, 那么就不要使 mongod.exe在公共网络上可见. 设置MOngoDB环境设置环境变量在环境变量里添加环境变量 D:\\Program Files\\MongoDB\\Server\\3.0\\ 然后在Path里添加： %MONGODB_HOME%\\bin data directoryMongoDB 需要一个data directory来存储全部的数据. MongoDB默认的data directory路径是\\data\\db,所以我们需要创建一个data directory. 假设我们在D盘创建了一个这样的目录: D:\\mongodb\\data\\db. 你可以通过–dbpath选项给mongod.exe设置另一个data directory. 1mongod.exe --dbpath D:\\mongodb\\data\\db 如果你的data directory包含空格的话,那么就需要使用””将他们包含起来： 1mongod.exe --dbpath &quot;d:\\test\\mongo db data&quot; 启动MongoDB使用mongod.exe命令启动mongoDB1mongod.exe 启动日志最后我们在启动日志里看到 1waiting for connections on port 27017 命令行方式启动MongoDB 默认存储数据目录为/data/db/ (或者 c:/data/db), 默认端口 27017,默认 HTTP 端口 28017. 1mongod --dbpath=/data/db 配置文件方式启动MongoDB 也支持同 mysql 一样的读取启动配置文件的方式来启动数据库,配置文件的内容如下: 1cat /etc/mongodb.cnf 启动时加上”-f”参数,并指向配置文件即可: 1mongod -f /etc/mongodb.cnf Daemon 方式启动MongoDB 提供了一种后台 Daemon 方式启动的选择,只需加上一个” –fork”参数即可,,但如果用到了 ” –fork”参数就必须也启用 ”–logpath”参数,这是强制的 1mongod --dbpath=/data/db --logpath=/data/log/r3.log --fork mongod 参数说明mongod 的参数分为一般参数, windows 参数, replication 参数, replica set 参数,以及隐含参数.上面列举的都是一般参数 mongod 的参数中,没有设置内存大小相关的参数,是的, MongoDB 使用 os mmap 机制来缓存数据文件数据,自身目前不提供缓存机制.这样好处是代码简单,mmap 在数据量不超过内存时效率很高.但是数据量超过系统可用内存后,则写入的性能可能不太稳定,容易出现大起大落,不过在最新的 1.8 版本中,这个情况相对以前的版本已经有了一定程度的改善. mongod 的主要参数有： dbpath —— 数据文件存放路径,每个数据库会在其中创建一个子目录,用于防止同一个实例多次运行的 mongod.lock 也保存在此目录中. logpath —— 错误日志文件 logappend —— 错误日志采用追加模式（默认是覆写模式） bind_ip —— 对外服务的绑定 ip,一般设置为空,及绑定在本机所有可用 ip 上,如有需要可以单独指定 port —— 对外服务端口 . Web 管理端口在这个 port 的基础上+1000 fork —— 以后台 Daemon 形式运行服务 journal —— 开启日志功能,通过保存操作日志来降低单机故障的恢复时间,在 1.8 版本后正式加入,取代在 1.7.5 版本中的 dur 参数. syncdelay —— 系统同步刷新磁盘的时间,单位为秒,默认是 60 秒. directoryperdb —— 每个 db 存放在单独的目录中,建议设置该参数.与 MySQL 的独立表空间类似 maxConns —— 最大连接数 repairpath —— 执行 repair 时的临时目录.在如果没有开启 journal,异常 down 机后重启 ,必须执行 repair操作. 停止数据库 Control-C shutdownServer()指令123mongo --port 28013use admindb.shutdownServer() 常用工具集MongoDB 在 bin 目录下提供了一系列有用的工具,这些工具提供了 MongoDB 在运维管理上的方便。 bsondump: 将 bson 格式的文件转储为 json 格式的数据 mongo: 客户端命令行工具,其实也是一个 js 解释器,支持 js 语法 mongod: 数据库服务端,每个实例启动一个进程,可以 fork 为后台运行 mongodump/ mongorestore: 数据库备份和恢复工具 mongoexport/ mongoimport: 数据导出和导入工具 mongofiles: GridFS 管理工具,可实现二制文件的存取 mongos: 分片路由,如果使用了 sharding 功能,则应用程序连接的是 mongos 而不是mongod mongosniff: 这一工具的作用类似于 tcpdump,不同的是他只监控 MongoDB 相关的包请求,并且是以指定的可读性的形式输出 mongostat: 实时性能监控工具 部署 Replica Sets 创建数据文件存储路径123mkdir E:/mongoData/data/r0mkdir E:/mongoData/data/r1mkdir E:/mongoData/data/r2 创建日志文件路径1mkdir E:/mongoData/log 创建主从 key 文件，用于标识集群的私钥的完整路径，如果各个实例的 key file 内容不一致，程序将不能正常用。1234mkdir E:/mongoData/keyecho &quot;this is rs1 super secret key&quot; &gt; E:/mongoData/key/r0echo &quot;this is rs1 super secret key&quot; &gt; E:/mongoData/key/r1echo &quot;this is rs1 super secret key&quot; &gt; E:/mongoData/key/r2 启动 3 个实例123mongod --replSet rs1 --keyFile E:/mongoData/key/r0 -fork --port 28010 --dbpath E:/mongoData/data/r0 --logpath=E:/mongoData/log/r0.log --logappendmongod --replSet rs1 --keyFile E:/mongoData/key/r1 -fork --port 28011 --dbpath E:/mongoData/data/r1 --logpath=E:/mongoData/log/r1.log --logappendmongod --replSet rs1 --keyFile E:/mongoData/key/r2 -fork --port 28012 --dbpath E:/mongoData/data/r2 --logpath=E:/mongoData/log/r2.log --logappend 配置及初始化 Replica Sets1mongo -port 28010","categories":[{"name":"NoSql","slug":"NoSql","permalink":"https://wangmingco.github.io/categories/NoSql/"}],"tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"https://wangmingco.github.io/tags/MongoDB/"}]},{"title":"MongoDB客户端","slug":"nosql/MongoDB客户端","date":"2015-03-07T16:00:00.000Z","updated":"2021-11-18T02:43:46.638Z","comments":true,"path":"2015/03/08/nosql/MongoDB客户端/","link":"","permalink":"https://wangmingco.github.io/2015/03/08/nosql/MongoDB%E5%AE%A2%E6%88%B7%E7%AB%AF/","excerpt":"","text":"A Quick Tour使用java 驱动开发是非常简单的,首先你要确保你的classpath中包含mongo.jar Making a Connection为了能够连接上MongoDB,最低的要求也是你要知道连接的database的名称. 这个数据库可以不存在,如果不存在的话,MongoDB会自动创建这个数据库 另外,你可以指定连接的服务器的地址和端口,下面的例子展示了三种连接本地mydb数据库的方式 123456789101112131415161718192021222324252627282930import com.mongodb.BasicDBObject;import com.mongodb.BulkWriteOperation;import com.mongodb.BulkWriteResult;import com.mongodb.Cursor;import com.mongodb.DB;import com.mongodb.DBCollection;import com.mongodb.DBCursor;import com.mongodb.DBObject;import com.mongodb.MongoClient;import com.mongodb.ParallelScanOptions;import com.mongodb.ServerAddress;import java.util.List;import java.util.Set;import static java.util.concurrent.TimeUnit.SECONDS;// To directly connect to a single MongoDB server (note that this will not auto-discover the primary even// if it&#x27;s a member of a replica set:MongoClient mongoClient = new MongoClient();// orMongoClient mongoClient = new MongoClient( &quot;localhost&quot; );// orMongoClient mongoClient = new MongoClient( &quot;localhost&quot; , 27017 );// or, to connect to a replica set, with auto-discovery of the primary, supply a seed list of membersMongoClient mongoClient = new MongoClient(Arrays.asList(new ServerAddress(&quot;localhost&quot;, 27017), new ServerAddress(&quot;localhost&quot;, 27018), new ServerAddress(&quot;localhost&quot;, 27019)));DB db = mongoClient.getDB( &quot;mydb&quot; ); 在这个例子中db对象保持着一个对MongoDB服务器指定数据库的一个连接. 通过这个对象你可以做很多其他操作 Note: MongoClient实例实际上维持着对这个数据库的一个连接池. 即使在多线程的情况下,你也只需要一个MongoClient实例, 参考concurrency doc page MongoClient被设计成一个线程安全且线程共享的类. 一个典型例子是,你对一个数据库集群仅仅创建了一个MongoClient实例,然后在你的整个应用程序中都使用这一个实例. 如果出于一些特殊原因你不得不创建多个MongoClient实例,那么你需要注意下面俩点： all resource usage limits (max connections, etc) apply per MongoClient instance 当关闭一个实例时,你必须确保你调用了MongoClient.close()清理掉了全部的资源 New in version 2.10.0: The MongoClient class is new in version 2.10.0. For releases prior to that, please use the Mongo class instead. Authentication (Optional)MongoDB可以在安全模式下运行, 这种模式下,需要通过验证才能访问数据库. 当在这种模式下运行的时候, 任何客户端都必须提供一组证书.在java Driver中,你只需要在创建MongoClient实例时提供一下证书. 12MongoCredential credential = MongoCredential.createMongoCRCredential(userName, database, password);MongoClient mongoClient = new MongoClient(new ServerAddress(), Arrays.asList(credential)); MongoDB支持不同的认证机制,具体参考the access control tutorials Getting a Collection如果想要使用一个collection,那么你仅仅需要调用getCollection(String collectionName)方法,然后指定该collection名称就好 1DBCollection coll = db.getCollection(&quot;testCollection&quot;); 一旦你有了collection对象,那你就可以执行例如插入数据,查询数据等等的操作了 Setting Write Concern在2.10.0这个版本里,默认的write concern是WriteConcern.ACKNOWLEDGED不过你可以通过下面的方法轻松改变它 1mongoClient.setWriteConcern(WriteConcern.JOURNALED); 对应write concern提供了很多种选项. 另外,这个默认的write concern分别可以在数据库,collection,以及单独的更新操作上重载. Inserting a Document一旦你拥有了collection对象,你就可以向该collection中插入document. 例如,我们可以插入一个像下面这样的一个json文档 123456789&#123; &quot;name&quot; : &quot;MongoDB&quot;, &quot;type&quot; : &quot;database&quot;, &quot;count&quot; : 1, &quot;info&quot; : &#123; x : 203, y : 102 &#125;&#125; 注意,上面的例子中我们有一个内嵌的文档.想要插入这样一个文档,我们可以使用BasicDBObject类来实现： 12345BasicDBObject doc = new BasicDBObject(&quot;name&quot;, &quot;MongoDB&quot;) .append(&quot;type&quot;, &quot;database&quot;) .append(&quot;count&quot;, 1) .append(&quot;info&quot;, new BasicDBObject(&quot;x&quot;, 203).append(&quot;y&quot;, 102));coll.insert(doc); findOne()如果想要查看刚才插入的文档,我们可以简单地调用findOne(),这个操作会获得该collection中的第一个文档.这个方法只是返回一个文档对象(而find()会返回一个DBCursor对象),当collection中只有一个文档的时候,这是非常有用的. 12DBObject myDoc = coll.findOne();System.out.println(myDoc); 结果如下： 123456&#123; &quot;_id&quot; : &quot;49902cde5162504500b45c2c&quot; , &quot;name&quot; : &quot;MongoDB&quot; , &quot;type&quot; : &quot;database&quot; , &quot;count&quot; : 1 , &quot;info&quot; : &#123; &quot;x&quot; : 203 , &quot;y&quot; : 102&#125;&#125; Note: _id元素是MongoDB自动添加到你的文档中的. 记住,MongoDB内部以“_”/”$”开头储存元素名称 Adding Multiple Documents当测试一些其他查询的时候,我们需要大量的数据,让我们添加一些简单的文档到collection中. 123&#123; &quot;i&quot; : value&#125; 我们可以在一个循环中不断地插入数据 123for (int i=0; i &lt; 100; i++) &#123; coll.insert(new BasicDBObject(&quot;i&quot;, i));&#125; 注意：我们可以向同一个collection中插入包含不同元素的文档.所以MongoDB也被称为schema-free Counting Documents in A Collection通过以上的操作我们已经插入了101个文档,我们通过getCount()方法来检查一下. 1System.out.println(coll.getCount()); Using a Cursor to Get All the Documents如果想要获得collection中的全部文档,我们可以使用find()方法. find()返回一个DBCursor对象,我们可以通过遍历该对象获取所有匹配我们需求的文档. 12345678DBCursor cursor = coll.find();try &#123; while(cursor.hasNext()) &#123; System.out.println(cursor.next()); &#125;&#125; finally &#123; cursor.close();&#125; Getting A Single Document with A Query我们可以向find()方法传递一个查询参数, 通过该参数找到集合中符合需求的文档子集. 下例中展示了我们想要找到i是7的所有文档. 1234567891011BasicDBObject query = new BasicDBObject(&quot;i&quot;, 71);cursor = coll.find(query);try &#123; while(cursor.hasNext()) &#123; System.out.println(cursor.next()); &#125;&#125; finally &#123; cursor.close();&#125; 该代码只会输出一个文档 1&#123; &quot;_id&quot; : &quot;49903677516250c1008d624e&quot; , &quot;i&quot; : 71 &#125; 你也可以从其他的实例和文档中查看$操作符的用法： 1db.things.find(&#123;j: &#123;$ne: 3&#125;, k: &#123;$gt: 10&#125; &#125;); 使用内嵌的DBObject,$可以看作是正则表达式字串 123456789101112query = new BasicDBObject(&quot;j&quot;, new BasicDBObject(&quot;$ne&quot;, 3)) .append(&quot;k&quot;, new BasicDBObject(&quot;$gt&quot;, 10));cursor = coll.find(query);try &#123; while(cursor.hasNext()) &#123; System.out.println(cursor.next()); &#125;&#125; finally &#123; cursor.close();&#125; Getting A Set of Documents With a Query我们可以使用查询来获得collection中的一个文档集合.例如,我们使用下面的语法来获取所有i &gt; 50的文档 1234567891011// find all where i &gt; 50query = new BasicDBObject(&quot;i&quot;, new BasicDBObject(&quot;$gt&quot;, 50));cursor = coll.find(query);try &#123; while (cursor.hasNext()) &#123; System.out.println(cursor.next()); &#125;&#125; finally &#123; cursor.close();&#125; 我们还可以获得一个区间(20 &lt; i &lt;= 30)文档集合 12345678910query = new BasicDBObject(&quot;i&quot;, new BasicDBObject(&quot;$gt&quot;, 20).append(&quot;$lte&quot;, 30));cursor = coll.find(query);try &#123; while (cursor.hasNext()) &#123; System.out.println(cursor.next()); &#125;&#125; finally &#123; cursor.close();&#125; MaxTimeMongoDB2.6 添加查询超时的能力 1coll.find().maxTime(1, SECONDS).count(); 在上面的例子中将maxTime设置为1s,当时间到后查询将被打断 Bulk operationsUnder the covers MongoDB is moving away from the combination of a write operation followed by get last error (GLE) and towards a write commands API. These new commands allow for the execution of bulk insert/update/remove operations. There are two types of bulk operations: Ordered bulk operations. 按顺序执行全部的操作,当遇到第一个写失败的时候,退出 Unordered bulk operations. 并行执行全部操作, 同时收集全部错误.该操作不保证按照顺序执行 下面展示了上面所说的俩个示例 123456789101112131415161718// 1. Ordered bulk operationBulkWriteOperation builder = coll.initializeOrderedBulkOperation();builder.insert(new BasicDBObject(&quot;_id&quot;, 1));builder.insert(new BasicDBObject(&quot;_id&quot;, 2));builder.insert(new BasicDBObject(&quot;_id&quot;, 3));builder.find(new BasicDBObject(&quot;_id&quot;, 1)).updateOne(new BasicDBObject(&quot;$set&quot;, new BasicDBObject(&quot;x&quot;, 2)));builder.find(new BasicDBObject(&quot;_id&quot;, 2)).removeOne();builder.find(new BasicDBObject(&quot;_id&quot;, 3)).replaceOne(new BasicDBObject(&quot;_id&quot;, 3).append(&quot;x&quot;, 4));BulkWriteResult result = builder.execute();// 2. Unordered bulk operation - no guarantee of order of operationbuilder = coll.initializeUnorderedBulkOperation();builder.find(new BasicDBObject(&quot;_id&quot;, 1)).removeOne();builder.find(new BasicDBObject(&quot;_id&quot;, 2)).removeOne();result = builder.execute(); Note: For servers older than 2.6 the API will down convert the operations. To support the correct semantics for BulkWriteResult and BulkWriteException, the operations have to be done one at a time. It’s not possible to down convert 100% so there might be slight edge cases where it cannot correctly report the right numbers. parallelScanMongoDB 2.6 增加了parallelCollectionScan命令, 该命令通过使用多个游标读取整个collection. 123456789101112ParallelScanOptions parallelScanOptions = ParallelScanOptions .builder() .numCursors(3) .batchSize(300) .build();List&lt;Cursor&gt; cursors = coll.parallelScan(parallelScanOptions);for (Cursor pCursor: cursors) &#123; while (pCursor.hasNext()) &#123; System.out.println((pCursor.next())); &#125;&#125; 其对collection进行IO吞吐量的优化. Note: ParallelScan不能通过mongos运行 Quick Tour of the Administrative FunctionsGetting A List of Databases通过下面的代码你可以获取一个可用数据库列表 12345MongoClient mongoClient = new MongoClient();for (String s : mongoClient.getDatabaseNames()) &#123; System.out.println(s);&#125; 调用mongoClient.getDB()并不会创建一个数据库. 仅仅当尝试向数据库写入数据时,该数据库才会被创建. 例如尝试创建一个所以或者一个collection或者插入一个文档. Dropping A Database通过MongoClient实例你也可以drop掉一个数据库 12MongoClient mongoClient = new MongoClient();mongoClient.dropDatabase(&quot;databaseToBeDropped&quot;); Creating A Collection有俩种方式创建collection： 如果向一个不存在的collection中尝试插入一个文档,那么该collection会被创建出来 或者直接调用createCollection命令 下面的例子展示了创建1M大小的collection 123db = mongoClient.getDB(&quot;mydb&quot;);db.createCollection(&quot;testCollection&quot;, new BasicDBObject(&quot;capped&quot;, true) .append(&quot;size&quot;, 1048576)); Getting A List of Collections你可以通过下面的方式获得一个数据库当中可用collection列表 123for (String s : db.getCollectionNames()) &#123; System.out.println(s);&#125; 上面的例子会输出： 12system.indexestestCollection Note: system.indexes collection是自动创建的, 它里面是数据库中所有的索引, 所以不应该直接访问它 Dropping A Collection你可以通过drop()方法直接drop掉一个collection 123DBCollection coll = db.getCollection(&quot;testCollection&quot;);coll.drop();System.out.println(db.getCollectionNames()); Getting a List of Indexes on a Collection下例展示了如何获得一个collection中索引的列表 12345List&lt;DBObject&gt; list = coll.getIndexInfo();for (DBObject o : list) &#123; System.out.println(o.get(&quot;key&quot;));&#125; 上面的实例会进行下面的输出： 1234&#123; &quot;v&quot; : 1 , &quot;key&quot; : &#123; &quot;_id&quot; : 1&#125; , &quot;name&quot; : &quot;_id_&quot; , &quot;ns&quot; : &quot;mydb.testCollection&quot;&#125;&#123; &quot;v&quot; : 1 , &quot;key&quot; : &#123; &quot;i&quot; : 1&#125; , &quot;name&quot; : &quot;i_1&quot; , &quot;ns&quot; : &quot;mydb.testCollection&quot;&#125;&#123; &quot;v&quot; : 1 , &quot;key&quot; : &#123; &quot;loc&quot; : &quot;2dsphere&quot;&#125; , &quot;name&quot; : &quot;loc_2dsphere&quot; , ... &#125;&#123; &quot;v&quot; : 1 , &quot;key&quot; : &#123; &quot;_fts&quot; : &quot;text&quot; , &quot;_ftsx&quot; : 1&#125; , &quot;name&quot; : &quot;content_text&quot; , ... &#125; Creating An IndexMongoDB支持索引,而且它们可以轻松地插入到一个集合中.创建索引的过程非常简单,你只需要指定被索引的字段,你还可以指定该索引是上升的(1)还是下降的(-1). 1coll.createIndex(new BasicDBObject(&quot;i&quot;, 1)); // create index on &quot;i&quot;, ascending Geo indexesMongoDB支持不同的地理空间索引,在下面的例子中,我们将窗口一个2dsphere索引, 我们可以通过标准GeoJson标记进行查询. 想要创建一个2dsphere索引,我们需要在索引文档中指定2dsphere这个字面量. 1coll.createIndex(new BasicDBObject(&quot;loc&quot;, &quot;2dsphere&quot;)); 有不同的方式去查询2dsphere索引,下面的例子中找到了500m以内的位置. 1234567891011121314151617181920212223242526272829BasicDBList coordinates = new BasicDBList();coordinates.put(0, -73.97);coordinates.put(1, 40.77);coll.insert(new BasicDBObject(&quot;name&quot;, &quot;Central Park&quot;) .append(&quot;loc&quot;, new BasicDBObject(&quot;type&quot;, &quot;Point&quot;).append(&quot;coordinates&quot;, coordinates)) .append(&quot;category&quot;, &quot;Parks&quot;));coordinates.put(0, -73.88);coordinates.put(1, 40.78);coll.insert(new BasicDBObject(&quot;name&quot;, &quot;La Guardia Airport&quot;) .append(&quot;loc&quot;, new BasicDBObject(&quot;type&quot;, &quot;Point&quot;).append(&quot;coordinates&quot;, coordinates)) .append(&quot;category&quot;, &quot;Airport&quot;));// Find whats within 500m of my locationBasicDBList myLocation = new BasicDBList();myLocation.put(0, -73.965);myLocation.put(1, 40.769);myDoc = coll.findOne( new BasicDBObject(&quot;loc&quot;, new BasicDBObject(&quot;$near&quot;, new BasicDBObject(&quot;$geometry&quot;, new BasicDBObject(&quot;type&quot;, &quot;Point&quot;) .append(&quot;coordinates&quot;, myLocation)) .append(&quot;$maxDistance&quot;, 500) ) ) );System.out.println(myDoc.get(&quot;name&quot;)); 更多参考geospatial文档 Text indexesMongoDB还支持text索引,该索引用来支持从String中搜索文本. text索引可以包含任何字段,但是该字段的值必须是String或者String数组.想要创建一个text索引,只需要在索引文档中指定text字面量. 12// create a text index on the &quot;content&quot; fieldcoll.createIndex(new BasicDBObject(&quot;content&quot;, &quot;text&quot;)); MongoDB2.6 以后text索引融进了主要的查询语言中,并且成为了一种默认的方式. 1234567891011121314151617181920// Insert some documentscoll.insert(new BasicDBObject(&quot;_id&quot;, 0).append(&quot;content&quot;, &quot;textual content&quot;));coll.insert(new BasicDBObject(&quot;_id&quot;, 1).append(&quot;content&quot;, &quot;additional content&quot;));coll.insert(new BasicDBObject(&quot;_id&quot;, 2).append(&quot;content&quot;, &quot;irrelevant content&quot;));// Find using the text indexBasicDBObject search = new BasicDBObject(&quot;$search&quot;, &quot;textual content -irrelevant&quot;);BasicDBObject textSearch = new BasicDBObject(&quot;$text&quot;, search);int matchCount = coll.find(textSearch).count();System.out.println(&quot;Text search matches: &quot;+ matchCount);// Find using the $language operatortextSearch = new BasicDBObject(&quot;$text&quot;, search.append(&quot;$language&quot;, &quot;english&quot;));matchCount = coll.find(textSearch).count();System.out.println(&quot;Text search matches (english): &quot;+ matchCount);// Find the highest scoring matchBasicDBObject projection = new BasicDBObject(&quot;score&quot;, new BasicDBObject(&quot;$meta&quot;, &quot;textScore&quot;));myDoc = coll.findOne(textSearch, projection);System.out.println(&quot;Highest scoring document: &quot;+ myDoc); 上面的代码应该输出： 123Text search matches: 2Text search matches (english): 2Highest scoring document: &#123; &quot;_id&quot; : 1 , &quot;content&quot; : &quot;additional content&quot; , &quot;score&quot; : 0.75&#125; 更多关于text search,参考text index and $text query operator","categories":[{"name":"NoSql","slug":"NoSql","permalink":"https://wangmingco.github.io/categories/NoSql/"}],"tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"https://wangmingco.github.io/tags/MongoDB/"}]},{"title":"JAVA钩子程序","slug":"JavaSE/Java hook","date":"2015-03-07T16:00:00.000Z","updated":"2021-11-18T02:39:44.465Z","comments":true,"path":"2015/03/08/JavaSE/Java hook/","link":"","permalink":"https://wangmingco.github.io/2015/03/08/JavaSE/Java%20hook/","excerpt":"","text":"简介触发的时机有： 当所有的非deamon线程(守护线程)结束, 或者调用了Systrem.exit()方法 而导致的程序正常的退出 JVM收到需要关闭自己的信号（比如SIGINT、SIGTERM等，但像SIGKILL，JVM就没有机会去处理了），也或者发生如系统关闭这种不可阻挡的事件。 对于addShutdownHook中的钩子代码，也是有一些要注意的地方，下面列举几点： 关闭钩子可以注册多个，在关闭JVM时就会起多个线程来运行钩子。通常来说，一个钩子就足够了，但如果需要启用多个钩子，就需要注意并发带来的问题。 钩子里也要注意对异常的处理，如果不幸抛出了异常，那么钩子的执行序列就会被终止。 在钩子运行期间，工作线程也在运行，需要考虑到工作线程是否会对钩子的执行带来影响 钩子里的代码尽可能简洁，否则当像系统关闭等情景可能钩子来不及运行完JVM就被退出了。 信号触发使信号触发JVM的钩子程序 123456789101112131415public class HookTest &#123; public static void main(String[] args) &#123; Runtime.getRuntime().addShutdownHook(new Hook()); while(true)&#123;&#125; &#125; static class Hook extends Thread&#123; @Override public void run() &#123; System.out.println(&quot;Hook execute!!!&quot;); &#125; &#125;&#125; 运行钩子程序 1nohup java HookTest &amp; 关闭程序 1kill HookTest_PID 我们可以在nohup程序中看到Hook execute!!!输出 我从JVMs and kill signals看到一篇博客, 这个上面总结了哪些信号会导致JVM运行Hook 12345678910111213141516171819202122232425262728293031323334signal shutdown runs hook exit code commentdefault (15) yes yes 143 SIGTERM is the default unix kill signal0 no - - 1 (SIGHUP) yes yes 129 2 (SIGINT) yes yes 130 SIGINT is the signal sent on ^C3 (SIGQUIT) no - - 触发 JVM dump threads / stack-traces4 (SIGILL) yes no 134 触发 JVM 输出一个 core dump 文件, 同时abort on trap 65 yes no 133 Makes the JVM exit with &quot;Trace/BPT trap: 5&quot;6 (SIGABRT) yes no 134 Makes the JVM exit with &quot;Abort trap: 6&quot;7 yes no 135 Makes the JVM exit with &quot;EMT trap: 7&quot;8 (SIGFPE) yes no 134 Makes the JVM write a core dump and abort on trap 69 (SIGKILL) yes no 137 The JVM is forcibly killed (exits with &quot;Killed: 9&quot;)10 (SIGBUS) yes no 134 Emulates a &quot;Bus Error&quot;11 (SIGSEGV) yes no 134 Emulates a &quot;Segmentation fault&quot;12 yes no 140 Makes the JVM exit with &quot;Bad system call: 12&quot;13 no - - 14 yes no 142 Makes the JVM exit with &quot;Alarm clock: 14&quot;15 (SIGTERM) yes yes 143 This is the default unix kill signal16 no - - 17 no - 145 Stops the application (sends it to the background), same as ^Z18 no - 146 Stops the application (sends it to the background), same as ^Z19 no - - 20 no - - 21 no - 149 Stops the application (sends it to the background), same as ^Z22 no - 150 Stops the application (sends it to the background), same as ^Z23 no - - 24 yes no 152 Makes the JVM exit with &quot;Cputime limit exceeded: 24&quot;25 no - - 26 yes no 154 Makes the JVM exit with &quot;Virtual timer expired: 26&quot;27 yes no 155 Makes the JVM exit with &quot;Profiling timer expired: 27&quot;28 no - - 29 no - - 30 yes no 158 Makes the JVM exit with &quot;User defined signal 1: 30&quot;31 yes no 134 Makes the JVM exit on Segmentation fault 内存溢出触发测试JVM栈溢出后调用钩子程序 12345678910111213141516171819public class HookTest &#123; public static void main(String[] args) &#123; Runtime.getRuntime().addShutdownHook(new Hook()); exec(); &#125; public static void exec() &#123; exec(); &#125; static class Hook extends Thread&#123; @Override public void run() &#123; System.out.println(&quot;Hook execute!!!&quot;); &#125; &#125;&#125; 运行后输出为 123456789101112131415161718192021D:\\testOOM&gt;java HookTestException in thread &quot;main&quot; java.lang.StackOverflowError at HookTest.exec(HookTest.java:9) at HookTest.exec(HookTest.java:9) at HookTest.exec(HookTest.java:9) at HookTest.exec(HookTest.java:9) ... at HookTest.exec(HookTest.java:9) at HookTest.exec(HookTest.java:9) at HookTest.exec(HookTest.java:9) at HookTest.exec(HookTest.java:9) at HookTest.exec(HookTest.java:9) at HookTest.exec(HookTest.java:9) at HookTest.exec(HookTest.java:9) at HookTest.exec(HookTest.java:9) at HookTest.exec(HookTest.java:9) at HookTest.exec(HookTest.java:9) at HookTest.exec(HookTest.java:9)Hook execute!!!D:\\testOOM&gt; 为了测试在更加复杂的环境下, Hook的使用情况, 看下面的测试代码 1234567891011121314151617181920212223242526272829303132333435363738import java.time.LocalDateTime;import java.util.HashMap;import java.util.Map;import java.util.concurrent.TimeUnit;public class HookTest &#123; private static Map&lt;String, String&gt; cache = new HashMap&lt;&gt;(); public static void main(String[] args) &#123; cache.put(&quot;abc&quot;, &quot;abc&quot;); Runtime.getRuntime().addShutdownHook(new Hook()); byte[] bytes = new byte[1024 * 1024 *1024 * 1024]; &#125; static class Hook extends Thread&#123; @Override public void run() &#123; for (int i = 0; i &lt; 100; i++) &#123; System.out.println(LocalDateTime.now()); System.out.println(&quot; freeMemory ： &quot; + Runtime.getRuntime().freeMemory()); System.out.println(&quot; maxMemory ： &quot; + Runtime.getRuntime().maxMemory()); System.out.println(&quot; totalMemory ： &quot; + Runtime.getRuntime().totalMemory()); System.out.println(&quot; currentThread name : &quot; + Thread.currentThread().getName()); System.out.println(&quot; cache size : &quot; + cache.size()); cache.put(LocalDateTime.now().toString(), LocalDateTime.now().toString()); try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125;&#125; 运行后的输出结果为 1234567891011121314151617181920212223242526ζ java HookTest2016-07-09T16:12:12.479 freeMemory : 155922512 maxMemory : 2375024640 totalMemory : 160956416 currentThread name : Thread-0 cache size : 12016-07-09T16:12:13.480 freeMemory : 155922512 maxMemory : 2375024640 totalMemory : 160956416 currentThread name : Thread-0 cache size : 22016-07-09T16:12:14.480 freeMemory : 155922512 maxMemory : 2375024640 totalMemory : 160956416 currentThread name : Thread-0 cache size : 32016-07-09T16:12:15.480 freeMemory : 155922512 maxMemory : 2375024640 totalMemory : 160956416 currentThread name : Thread-0 cache size : 4... 正常结束触发测试程序正常结束后也会调用钩子程序 1234567891011121314public class HookTest &#123; public static void main(String[] args) &#123; Runtime.getRuntime().addShutdownHook(new Hook()); &#125; static class Hook extends Thread&#123; @Override public void run() &#123; System.out.println(&quot;Hook execute!!!&quot;); &#125; &#125;&#125; 运行结果为 1234D:\\testOOM&gt;java HookTestHook execute!!!D:\\testOOM&gt; 调用exit()触发1234567891011121314151617public class HookTest &#123; public static void main(String[] args) &#123; Runtime.getRuntime().addShutdownHook(new Hook()); System.exit(0); System.out.println(&quot;Main over&quot;); &#125; static class Hook extends Thread&#123; @Override public void run() &#123; System.out.println(&quot;Hook execute!!!&quot;); &#125; &#125;&#125; 运行结果为 1234D:\\testOOM&gt;java HookTestHook execute!!!D:\\testOOM&gt; 不被触发再google上找到了一篇这样的文章Know the JVM Series: Shutdown Hooks里面介绍了钩子程序在什么情况下不会执行尽管上面列举出了N多触发钩子程序的示例, 但是并不保证这个钩子程序总是能被触发执行的, 例如 JVM内部发生错误, 可能还没有来得及触发钩子程序, JVM就挂掉了(JVM 发生内部错误, 有没有日志呢?) 还有上面我们给出的那个信号表, 如果操作系统发送出上面的信号的话, 同样的, JVM没有执行钩子程序就退出了 还有调用Runime.halt()函数也不会执行钩子程序 还有一种情况是, 当操作系统向进程发送一个SIGTERM信号之后, 如果进程没有在指定的时间之内关闭, 那么操作系统会强制将该进程杀掉, 如此一来钩子程序也不会得到完整的执行(因为钩子程序可能执行到一半就被操作系统杀死了). 因此不管是这篇文章还是JDK API都推荐不要在钩子程序里写复杂的业务逻辑, 避免产生死锁或者产生长时间的IO操作, 尽可能快地让钩子程序执行完毕. 在oracle上的Design of the Shutdown Hooks API同样见到这样一句话, 12Will shutdown hooks be run if the VM crashes? If the VM crashes due to an error in native code then no guarantee can be made about whether or not the hooks will be run. 哎,, 怎么着才能监控JVM挂掉的信息呢？","categories":[{"name":"Java","slug":"Java","permalink":"https://wangmingco.github.io/categories/Java/"}],"tags":[]},{"title":"类加载机制","slug":"jvm/JVM 类加载机制","date":"2014-09-08T16:00:00.000Z","updated":"2021-11-18T02:43:31.935Z","comments":true,"path":"2014/09/09/jvm/JVM 类加载机制/","link":"","permalink":"https://wangmingco.github.io/2014/09/09/jvm/JVM%20%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/","excerpt":"","text":"类的生命周期类从被加载进虚拟机内存开始到卸载出内存的生命周期: 加载 验证 准备 解析 初始化 使用 卸载 特殊说明2.验证, 3.准备, 4.解析 又称为连接阶段1.加载, 2.验证, 3.准备, 4.解析, 5. 初始化 被称为类加载 加载加载的过程就是JVM读取class文件, 然后将其转换成方法区的数据结构存储在方法区中, 接着在JVM堆中对其实例化一个java.lang.Class对象, 然后应用程序就可以通过该Class对象访问方法区中的数据了。 整个类的加载过程如下 通过类的全限定名来获取此类的二进制流. 将这个字节流所代表的静态存储结构转化为方法区的运行时结构 在java堆中生成一个代表这个类的java.class.Class对象. 在上面的三个过程中, 唯一开发人员可控的就是如何实现加载过程, 也就是从哪里获取以及如何获取类的字节码. 一般情况而言我们都是使用系统提供的类加载器, 或者自己实现一个加载器. 实现参考使用Classloader加载类 我们还可以使用Class.forName(..) 为我们加载类 验证这个阶段主要是用来检测java文件编译后的class文件是符合虚拟机规范的. 如果我们在java源码中将一个对象强转为一个没有被定义的类, 那么javac在编译的时候, 会给我们提示编译错误. 但是我们可以通过ASM这类的工具修改一个class字节流达到刚才我们描述的那个非法的功能. 这样子一来如果不对加载进虚拟机的字节码流做校验的话, 很可能会对虚拟机产生很大的危害, 因此验证阶段就是做这个事情用的.下面我们看一下校验过程: 首先是class文件格式验证, 保证输入的字节流能正确地解析并存储于方法区之内. 是否以魔术0xCAFEBABY 开头 主次版本号是否在当前虚拟机处理范围内. 常量池中是否有不被支持的常量类型(检查常量tag标志) … 还有很多其他校验 然后是基于方法区的数据结构进行元数据验证, 基本上就是在检验数据类型 这个类是否是父类. 这个类是否继承了不允许继承的类(被final修饰的类) 如果这个类不是抽象类,是否实现了其父类或接口中所要求实现的所有方法 … 还有很多其他校验 紧接着同样基于方法区的数据结构对方法体进行验证.(主要是针对数据流和控制流进行分析.) 保证任意时刻操作数栈的数据类型与指令代码序列都能配合工作.例如操作数栈放置一个int类型的数据,不会按照long类型加载到本地变量表. 保证跳转指令不会跳转到方法体以外的字节码指令上 … 还有很多其他校验 最后是符号引用验证.符号校验可以看作是对类自身以外(常量池中的各种符号引用)的信息进行匹配性的校验 符号引用通过字符串描述的全限定名是否能找到对应的类 在指定类中是否存在符号方法的字段描述及简单名称所描述的方法和字段 … 还有很多其他的校验 符号引用的校验是确保解析动作能正常执行.最后一个阶段校验发生在虚拟机将符号引用转化为直接引用的时候,这个转化动作将在连接的第三阶段-解析阶段中发生 准备准备阶段为类变量在方法区中进行内存分配以及初始值设置. 我们看下面的一个类变量value 1public static int value = 123; value在准备阶段初始值为0而不是123.因为把value赋值为123的putstatic指令是在类构造器&lt;clinit&gt;()方法中执行的,而类构造器只有在初始化阶段才会执行. 但是在一些特殊情况下,如果类字段的字段属性表中存在ConstantValue属性,那么在准备阶段value值就会被初始化为ConstantValue指定的属性值. 解析解析阶段是虚拟机将常量池符号引用替换为直接引用的过程(符号引用以CONSTANT_Class_info,CONSTANT_Field_info等类型常量) 符号引用: 以一组符号来描述所引用的目标,符号可以是任何形式的字面量,只要使用时能无歧义地定位到目标即可.符号引用与内存实现的布局无关,引用的目标不一定已经加载到内存中. 直接引用:可以是直接指向目标的指针,相对偏移量或是一个能间接定位到目标的句柄.直接引用是与虚拟机实现的内存布局相关的,同一个符号引用在不同的虚拟机实例上翻译出来的直接引用一般不会相同.如果有了直接引用,那引用的目标一定已经在内存中存在. 虚拟机只规定了在anewarray,checkcast,getfield,getstatic,instanceof,invokeinterface,invokespecial,invokestatic,invokevirtual,mutianewarray,new,putfield,putstatic这13个用于操作符号引用的字节码指令之前,先对他们所使用的符号引用进行解析. 因此有可能是在类被加载时进行解析，也有可能是该符号被使用的时候才会被解析，这个要看具体的虚拟机实现。但是不管是采用哪种方式，都可能发生多次解析的现象，因此虚拟机对此有一个缓存策略，只要一次解析成功，那么后续再接受到解析请求时就会从缓存里面拿，如果第一次解析失败，则以后的解析请求也是失败的 CONSTANT_Class_info结构体解析假设类D引用了一个符号引用N, 第一次将符号引用N解析为类或接口C的直接引用时需要以下步骤 如果C不是一个数组类型,D的类加载器会根据N的全限定名将类C加载进虚拟机. 加载过程中由于上述验证步骤的需要,又可能触发加载C类的父类或实现的接口.一旦这个加载过程出现了任何异常,解析过程将失败. 如果C是一个数组类型,并且数组的元素类型为对象,也就是N的描述符会是类似”[Ljava.lang.Integer”的形式.那将会按照第一点的规则加载数组元素类型,如果N的描述符如前面所假设的形式,需要加载的元素类型就是”java.lang.Integer”,接着由虚拟机生成一个代表此数组维度和元素的数组对象 如果上述步骤没有出现任何异常,那么C在虚拟机中实际已经称为一个有效的类或接口了,但在解析完成之前还要进行符号引用验证,确认C是否具备对D的访问权限,如果不具备访问权限,抛出”java.lang.IllegalAccessError”异常 CONSTANT_Fieldref_info结构体解析要解析一个从未被解析过的字段符号引用,首先会对字段表内class_index项中索引的CONSTANT_Class_info符号引用进行解析,也就是字段所属的类或接口的符号引用.如果在解析这个类或接口符号引用的过程中出现了任何异常,都会导致字段解析失败,如果解析成功,那将这个字段所属的类或接口用C表示. 如果C本身就包含了简单名称和字段描述符都与目标相匹配的字段,则返回了这个字段的直接引用,查找结束 否则,如果在C中实现了接口,将会按照继承关系从上往下递归搜索各个接口和它的父接口,如果接口中包含了简单名称和字段描述符都与目标相匹配的字段,则返回这个字段的直接引用,查找结束. 否则,如果C不是java.lang.Object的话,将会按照继承关系从上往下递归搜索其父类,如果父类中不包含了简单名称和字段描述符都与目标相匹配的字段,则返回这个字段的直接引用,查找结束. 否则,查找失败,抛出java.lang.NoSuchFieldError异常 如果查找过程成功返回了引用,将会对这个字段进行权限验证,如果发现不具备对其字段的访问权限,则抛出”java.lang.IllegalAccessError”异常.尝试在父类和子类中都出现相同的字段,看看编译器是否会编译 CONSTANT_Methodref_info结构体解析类方法解析的第一个步骤与字段解析一样,也是需要解析类方法表的class_index项中索引的方法所属的类或接口的符号引用,如果解析成功,依然使用C表示这个类. 类方法和接口方法符号引用的常量类型定义是分开的,如果在类方法表中发现class_index中索引的C是个接口,那就直接抛出java,lang.IncompatibleClassChangeError. 通过第一步,在类C中查找是否有简单名称和描述符都与目标相匹配的方法,如果有则直接返回这个方法的引用,查找结束. 否则在类C的父类中递归查找是否有简单名称和描述符都与目标相匹配的方法,如果有则返回这个方法的直接引用,查找结束 否则在类C实现的接口列表及它们的父接口之中递归查找是否有简单名称和描述符都与目标相匹配的方法,如果存在匹配的方法.说明类C是一个抽象类,这时候查找结束,抛出java.lang.AbstractMethodError异常 否则,宣告查找失败,抛出java.lang.NoSuchMethodError. 最后如果查找过程中成功返回了直接引用,将会对这个方法进行权限验证:如果发现不具备对此方法的权限访问,将抛出java.lang.IllegalAccessError CONSTANT_InterfaceMethodref_info结构体解析接口方法也需要先解析出接口方法表的class_index项中索引的方法所属的类或接口的符号引用,如果解析成功,依然用C表示这个接口: 与类方法解析相反,如果在接口方法表中发现class_index中的索引C是个类而不是接口,就将直接抛出java.lang.IncompatibleClassChangeError异常. 否则在接口C中查找是否有简单名称和描述符都与目标相匹配的方法,如果有则返回这个方法的直接引用,查找结束. 否则在接口C的父接口中递归查找,知道java.lang.Object类为止,看是否有简单名称和描述符都与目标相匹配的方法,如果有则返回这个方法的直接引用,查找结束. 否则,宣告方法查找失败,抛出java.lang.NoSuchMethodError异常 由于接口中的所有方法都默认是public的,所以不存在访问权限的问题,因为接口方法的符号引用解析都应当不会抛出”java.lang.IllegalAccessError”异常 类的初始化类初始化阶段是类加载过程中最后一步,开始执行类构造器方法. &lt;clinit&gt;方法执行过程可能会影响程序运行行为的一些特点和细节 &lt;clinit&gt;方法由编译器将类变量的赋值动作和静态语句块(static{}块)中的语句合并产生的.编译器收集的顺序是由语句在源文件中出现的顺序决定的,静态语句块只能访问到定义在静态语句块之前的变量,定义在它之后的变量,在前面的静态语句块中可以赋值但是不能访问. &lt;clinit&gt;()方法和实例的构造函数()不同,他不需要显式地调用父类构造器,虚拟机会保证在子类的()方法执行之前,父类的&lt;clinit&gt;方法已经执行完毕,因此虚拟机中第一个被执行的&lt;clinit&gt;()方法的类肯定是java.lang.Object 由于父类的&lt;clinit&gt;()方法先执行,也就意味着父类中定义的静态语句块要优先于子类的变量赋值操作 &lt;clinit&gt;()方法对于对类或者接口来说并不是必须的,如果一个类中没有静态语句块,也没有对变量的赋值操作,那么编译器可以不为这个类生成&lt;clinit&gt;()方法. 接口中不能使用静态语句块,但仍然有变量初始化的赋值操作,因此接口与类一样会生成()方法.但接口与类不同的是,执行接口&lt;clinit&gt;()不需要先执行父接口&lt;clinit&gt;().只有当父接口中定义的变量被使用时,父接口才会被初始化.另外,接口的实现类在初始化时也一样不会执行接口的()方法. 虚拟机会保证一个类的&lt;clinit&gt;()方法在多线程环境中被正确地加锁和同步,如果多个线程同时去初始化一个类,那么只会有一个线程去执行这个类的&lt;clinit&gt;()方法,其他线程都需要阻塞等待,直到活动线程执行&lt;clinit&gt;()方法完毕. 如果,在一个类的()方法中有耗时很长的操作,那就很可能造成多个进程阻塞. &lt;clinit&gt;()方法执行顺序 1234567891011121314151617 public class NewClass &#123; static class Parent &#123; public static int A = 1; static &#123; A = 2; &#125; &#125; static class Sub extends Parent &#123; public static int B = A; &#125; public static void main(String[] args) &#123; System.out.println(Sub.B); &#125;&#125; 字段解析 123456789101112131415161718192021222324252627public class DeadLoopClass &#123; static &#123; if(true) &#123; System.out.println(Thread.currentThread() + &quot; init DeadLoopClass &quot;); while(true)&#123;&#125; &#125; &#125; public static void main(String[] args) &#123; Runnable script = new Runnable() &#123; @Override public void run() &#123; System.out.println(Thread.currentThread() + &quot; start&quot;); DeadLoopClass dlc = new DeadLoopClass(); System.out.println(Thread.currentThread() + &quot; run over&quot;); &#125; &#125;; Thread t1 = new Thread(script); Thread t2 = new Thread(script); t1.start(); t2.start(); &#125;&#125; 类初始化的四种情况 遇到new, getstatic, putstatic, invokestatic, 这四条字节码指令时, 如果类没有进行过初始化,则必须先触发初始化 使用java.lang.reflect包的方法进行反射调用的时候,如果类没有进行过初始化,则需要先触发其初始化 当初始化一个类的时候,如果发现其父类还没有进行过初始化,则需要先触发其父类的初始化. 当虚拟机启动的时候,用户需要指定一个要执行的主类,虚拟机会先初始化这个主类. 通过子类引用父类的静态字段,不会导致子类的类初始化 12345678910111213141516171819202122class SuperClass &#123; static &#123; System.out.println(&quot;SuperClass init&quot;); &#125; public static int value = 123;&#125;class SubClass extends SuperClass &#123; static &#123; System.out.println(&quot;SubClass init&quot;); &#125;&#125;public class NotInitialization &#123; public static void main(String[] args) &#123; System.out.println(SubClass.value); &#125;&#125; 通过数组定义来引用类,不会触发此类的初始化 1234567891011121314class SuperClass &#123; static &#123; System.out.println(&quot;SuperClass init&quot;); &#125; public static int value = 123;&#125;public class NotInitialization &#123; public static void main(String[] args) &#123; SuperClass[] sca = new SuperClass[10]; &#125;&#125; 常量在编译阶段会存入调用类的常量池中,本质上没有直接引用到定义常量的类,因此不会触发定义常量的类的初始化 123456789101112class ConstClass &#123; static &#123; System.out.println(&quot;ConstClass init&quot;); &#125; public static final String HELLOWORLD = &quot;hello world&quot;;&#125;public class NotInitialization &#123; public static void main(String[] args) &#123; System.out.println(ConstClass.HELLOWORLD); &#125;&#125;","categories":[{"name":"JVM","slug":"JVM","permalink":"https://wangmingco.github.io/categories/JVM/"}],"tags":[]},{"title":"JVM内存溢出","slug":"jvm/JVM内存溢出","date":"2014-09-05T16:00:00.000Z","updated":"2021-11-18T02:43:33.785Z","comments":true,"path":"2014/09/06/jvm/JVM内存溢出/","link":"","permalink":"https://wangmingco.github.io/2014/09/06/jvm/JVM%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA/","excerpt":"","text":"ConstantPool OOM溢出代码 12345678910111213141516/** * 运行时常量溢出 * VM Args: -XX:PermSize=10M -XX:MaxPermSize=10M * @author mingwang * */public class RuntimeConstantPoolOOM &#123; public static void main(String[] args) &#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(); int i = 0; while(true) &#123; list.add(String.valueOf(i++).intern()); &#125; &#125;&#125; 如果想运行时常量池添加内容最简单的方式就是String.intern()这个native方法.该方法的作用是:如果池中已经包含一个等于此String对象的字符串,则返回池中这个字符串的String对象.否则将次String对象包含的字符串添加到常量池中,并返回次String对象音乐. Stack OOM溢出代码 12345678910111213141516public class TestStackSOF &#123; private static int stackLength = 1; public static void stackLeak() &#123; stackLength ++; stackLeak(); &#125; public static void main(String[] args) &#123; try &#123; stackLeak(); &#125; catch(Throwable e) &#123; System.out.println(&quot;stack length:&quot; + stackLength + &quot;. &quot; + e.getMessage()); &#125; &#125;&#125; 运行上面的程序 12D:\\testOOM&gt;java -XX:+HeapDumpOnOutOfMemoryError -Xss1M TestStackSOFstack length:22427. null 1M的栈空间大概能执行以上那个简单方法的22427次. 这个次数并不是在编译期就决定的,而是在运行时根据具体的内存使用情况而变化的. 下面的代码 123456789public class Test &#123; public static void stackLeak() &#123; stackLeak(); &#125; public static void main(String[] args) &#123; stackLeak(); &#125;&#125; 使用-XX:+HeapDumpOnOutOfMemoryError并不能产生堆内存溢出错误, 也没有产生类似于java_pid19212.hprof文件的文件.使用java -XX:ErrorFile=./error.log -Xss1M Test 也没有产生错误文件上面的并没有产生 1234567891011121314151617181920212223public class JavaVMStackOOM &#123; private void dontStop() &#123; while(true) &#123; &#125; &#125; public void stackLeakByThread() &#123; while(true) &#123; Thread t = new Thread(new Runnable()&#123; @Override public void run() &#123; dontStop(); &#125; &#125;); &#125; &#125; public static void main(String[] args) &#123; JavaVMStackOM om = new JavaVMStackOM(); om.stackLeakByThread(); &#125;&#125; 以上俩个实现都都无法让虚拟机产生OutOfMemoryError异常,只能产生StackOverflowError.实验结果表明: 单个线程下,无论由于栈帧太大还是虚拟机容量太小,当内存无法分配时,虚拟机抛出的都是StackOverflowError.如果测试时不是限于单线程,通过不断建立新线程的方式倒是可以产生内存溢出异常. 但是这样产生的内存溢出异常与栈空间是否足够大并不存在任何联系,或者准确说,在这种情况下,给每个线程的栈分配的内存越大,反而越容易产生内存溢出异常. 当开发多线程应用时应该特别注意的是,出现StackOverflowError异常时有错误堆栈可以阅读,相对来说比较容易找到问题.如果使用虚拟机默认参数,栈深度在大多数情况下达到1000-2000完全没有问题,对于正常的方法调用(包括递归),这个深度应该够用了,但是如果建立过多的线程导致的内存溢出,在不能减少线程数或者更换64位虚拟机的情况下,就只能通过减少最大堆和减少栈容量来换取更多的线程. Metadata OOM1234567891011121314151617181920public class JavaMethodAreaOOM &#123; public static void main(String[] args) &#123; while(true) &#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(OOMObject.class); enhancer.setUseCache(false); enhancer.setCallBack(new MethodInterceptor()&#123; public Object intercept(Object obj, Method method, Object[] objs, MethodProxy proxy) throws Throwable &#123; return proxy.invokeSuper(obj, args); &#125; &#125;); &#125; &#125; static class OOMObject &#123; &#125;&#125; 执行代码 12javac JavaMethodAreaOOMRun.javajava -XX:PermSize10M -XX:MaxPermSize10M JavaMethodAreaOOMRun 方法区用于存放Class信息,为了测试这个区域,基本思路是产生大量的类去填充方法区,直到溢出.本例中使用的是CGLib, 还可以使用ASM等框架进行测试.方法区溢出也是一种常见的内存溢出异常.一个类如果被垃圾收集器回收,其条件是非常苛刻的. 在经常动态生成大量Class的应用中,需要特别注意类的回收状况. (基于OSGI的应用即使是同一个类文件被不同的加载器加载也会视为不同的类) Heap OOM我们首先看一段内存溢出的代码 123456789public class TestHeapOOM &#123; public static void main(String[] args) &#123; for(int i = 0; i &lt; 10; i ++) &#123; System.out.println(&quot;Allocate : &quot; + i); byte[] bytes = new byte[1324 * 1124 * i * 2]; &#125; &#125;&#125; 接下来我们运行一下上面的那个程序 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106D:\\testOOM&gt;java -XX:+HeapDumpOnOutOfMemoryError -XX:+PrintHeapAtGC -Xms10M -Xmx10M -Xmn4M TestHeapOOMAllocate : 1Allocate : 2Allocate : 3&#123;Heap before GC invocations=1 (full 0): PSYoungGen total 3584K, used 3002K [0x00000000ffc00000, 0x0000000100000000, 0x0000000100000000) eden space 3072K, 97% used [0x00000000ffc00000,0x00000000ffeee8c0,0x00000000fff00000) from space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000) to space 512K, 0% used [0x00000000fff00000,0x00000000fff00000,0x00000000fff80000) ParOldGen total 6144K, used 4096K [0x00000000ff600000, 0x00000000ffc00000, 0x00000000ffc00000) object space 6144K, 66% used [0x00000000ff600000,0x00000000ffa00010,0x00000000ffc00000) Metaspace used 2580K, capacity 4486K, committed 4864K, reserved 1056768K class space used 287K, capacity 386K, committed 512K, reserved 1048576KHeap after GC invocations=1 (full 0): PSYoungGen total 3584K, used 488K [0x00000000ffc00000, 0x0000000100000000, 0x0000000100000000) eden space 3072K, 0% used [0x00000000ffc00000,0x00000000ffc00000,0x00000000fff00000) from space 512K, 95% used [0x00000000fff00000,0x00000000fff7a020,0x00000000fff80000) to space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000) ParOldGen total 6144K, used 4312K [0x00000000ff600000, 0x00000000ffc00000, 0x00000000ffc00000) object space 6144K, 70% used [0x00000000ff600000,0x00000000ffa36020,0x00000000ffc00000) Metaspace used 2580K, capacity 4486K, committed 4864K, reserved 1056768K class space used 287K, capacity 386K, committed 512K, reserved 1048576K&#125;&#123;Heap before GC invocations=2 (full 0): PSYoungGen total 3584K, used 488K [0x00000000ffc00000, 0x0000000100000000, 0x0000000100000000) eden space 3072K, 0% used [0x00000000ffc00000,0x00000000ffc00000,0x00000000fff00000) from space 512K, 95% used [0x00000000fff00000,0x00000000fff7a020,0x00000000fff80000) to space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000) ParOldGen total 6144K, used 4312K [0x00000000ff600000, 0x00000000ffc00000, 0x00000000ffc00000) object space 6144K, 70% used [0x00000000ff600000,0x00000000ffa36020,0x00000000ffc00000) Metaspace used 2580K, capacity 4486K, committed 4864K, reserved 1056768K class space used 287K, capacity 386K, committed 512K, reserved 1048576KHeap after GC invocations=2 (full 0): PSYoungGen total 3584K, used 488K [0x00000000ffc00000, 0x0000000100000000, 0x0000000100000000) eden space 3072K, 0% used [0x00000000ffc00000,0x00000000ffc00000,0x00000000fff00000) from space 512K, 95% used [0x00000000fff80000,0x00000000ffffa020,0x0000000100000000) to space 512K, 0% used [0x00000000fff00000,0x00000000fff00000,0x00000000fff80000) ParOldGen total 6144K, used 4312K [0x00000000ff600000, 0x00000000ffc00000, 0x00000000ffc00000) object space 6144K, 70% used [0x00000000ff600000,0x00000000ffa36020,0x00000000ffc00000) Metaspace used 2580K, capacity 4486K, committed 4864K, reserved 1056768K class space used 287K, capacity 386K, committed 512K, reserved 1048576K&#125;&#123;Heap before GC invocations=3 (full 1): PSYoungGen total 3584K, used 488K [0x00000000ffc00000, 0x0000000100000000, 0x0000000100000000) eden space 3072K, 0% used [0x00000000ffc00000,0x00000000ffc00000,0x00000000fff00000) from space 512K, 95% used [0x00000000fff80000,0x00000000ffffa020,0x0000000100000000) to space 512K, 0% used [0x00000000fff00000,0x00000000fff00000,0x00000000fff80000) ParOldGen total 6144K, used 4312K [0x00000000ff600000, 0x00000000ffc00000, 0x00000000ffc00000) object space 6144K, 70% used [0x00000000ff600000,0x00000000ffa36020,0x00000000ffc00000) Metaspace used 2580K, capacity 4486K, committed 4864K, reserved 1056768K class space used 287K, capacity 386K, committed 512K, reserved 1048576KHeap after GC invocations=3 (full 1): PSYoungGen total 3584K, used 0K [0x00000000ffc00000, 0x0000000100000000, 0x0000000100000000) eden space 3072K, 0% used [0x00000000ffc00000,0x00000000ffc00000,0x00000000fff00000) from space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000) to space 512K, 0% used [0x00000000fff00000,0x00000000fff00000,0x00000000fff80000) ParOldGen total 6144K, used 642K [0x00000000ff600000, 0x00000000ffc00000, 0x00000000ffc00000) object space 6144K, 10% used [0x00000000ff600000,0x00000000ff6a08a0,0x00000000ffc00000) Metaspace used 2580K, capacity 4486K, committed 4864K, reserved 1056768K class space used 287K, capacity 386K, committed 512K, reserved 1048576K&#125;&#123;Heap before GC invocations=4 (full 1): PSYoungGen total 3584K, used 0K [0x00000000ffc00000, 0x0000000100000000, 0x0000000100000000) eden space 3072K, 0% used [0x00000000ffc00000,0x00000000ffc00000,0x00000000fff00000) from space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000) to space 512K, 0% used [0x00000000fff00000,0x00000000fff00000,0x00000000fff80000) ParOldGen total 6144K, used 642K [0x00000000ff600000, 0x00000000ffc00000, 0x00000000ffc00000) object space 6144K, 10% used [0x00000000ff600000,0x00000000ff6a08a0,0x00000000ffc00000) Metaspace used 2580K, capacity 4486K, committed 4864K, reserved 1056768K class space used 287K, capacity 386K, committed 512K, reserved 1048576KHeap after GC invocations=4 (full 1): PSYoungGen total 3584K, used 0K [0x00000000ffc00000, 0x0000000100000000, 0x0000000100000000) eden space 3072K, 0% used [0x00000000ffc00000,0x00000000ffc00000,0x00000000fff00000) from space 512K, 0% used [0x00000000fff00000,0x00000000fff00000,0x00000000fff80000) to space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000) ParOldGen total 6144K, used 642K [0x00000000ff600000, 0x00000000ffc00000, 0x00000000ffc00000) object space 6144K, 10% used [0x00000000ff600000,0x00000000ff6a08a0,0x00000000ffc00000) Metaspace used 2580K, capacity 4486K, committed 4864K, reserved 1056768K class space used 287K, capacity 386K, committed 512K, reserved 1048576K&#125;&#123;Heap before GC invocations=5 (full 2): PSYoungGen total 3584K, used 0K [0x00000000ffc00000, 0x0000000100000000, 0x0000000100000000) eden space 3072K, 0% used [0x00000000ffc00000,0x00000000ffc00000,0x00000000fff00000) from space 512K, 0% used [0x00000000fff00000,0x00000000fff00000,0x00000000fff80000) to space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000) ParOldGen total 6144K, used 642K [0x00000000ff600000, 0x00000000ffc00000, 0x00000000ffc00000) object space 6144K, 10% used [0x00000000ff600000,0x00000000ff6a08a0,0x00000000ffc00000) Metaspace used 2580K, capacity 4486K, committed 4864K, reserved 1056768K class space used 287K, capacity 386K, committed 512K, reserved 1048576KHeap after GC invocations=5 (full 2): PSYoungGen total 3584K, used 0K [0x00000000ffc00000, 0x0000000100000000, 0x0000000100000000) eden space 3072K, 0% used [0x00000000ffc00000,0x00000000ffc00000,0x00000000fff00000) from space 512K, 0% used [0x00000000fff00000,0x00000000fff00000,0x00000000fff80000) to space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000) ParOldGen total 6144K, used 630K [0x00000000ff600000, 0x00000000ffc00000, 0x00000000ffc00000) object space 6144K, 10% used [0x00000000ff600000,0x00000000ff69d8d0,0x00000000ffc00000) Metaspace used 2580K, capacity 4486K, committed 4864K, reserved 1056768K class space used 287K, capacity 386K, committed 512K, reserved 1048576K&#125;java.lang.OutOfMemoryError: Java heap spaceDumping heap to java_pid17676.hprof ...Heap dump file created [1336934 bytes in 0.006 secs]Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space at TestHeapOOM.main(TestHeapOOM.java:6)D:\\testOOM&gt; 我们来分析一下, 我们固定堆内存大小为10M, 新生代为4M. 我们看到PSYoungGen总共为3584K, 分别为eden区3072K, from survivor区为512K, 然后加上to survivor 区的512K, 总共为4096K. 老年代总共为6114K 我们来看一下第一次GC之前的内存分布情况: 此时程序已经进行了俩次内存分配, 在第三次的(分配6M 6114K的byte数组)时候触发了GC. 此时 新生代为3002K, 老年代为4096K, 我们可以推断出，第一次2M的byte数组应该是分配在了新生代, 而第二次的4M byte数组直接分配在了老年代. 而经过一次GC之后, 新生代使用了488K, 而老年代增长到4312K. 经过一次GC之后新生代消耗了3002 - 488 -(4312 - 4096) = 2298, 我们可以推断出第一次分配的那2M的byte数组被回收掉了. 接下来又进行了一次yong GC但是内存并没有发生什么变化,于是就发生了一次full GC. 第一次full GC(也就是invocations=3的时候)之后, 我们看到新生代被清空了, 老年代也只剩下了642K的内存被使用着, 我们推断应该是那个4M的byte数组被回收掉了. 但是此时要分配一个6M的byte数组,显然老年代是不够的. 于是在这次Full GC的时候又进行了一次GC操作, 但是内存仍然不够, 于是又产生了一次Full GC, 也就是full=2的那次. 但是很悲催, 内存仍然是不够用的, 于是就看到了java.lang.OutOfMemoryError: Java heap space, 同时生成了一个java_pid17676.hprof 的文件. 对于*.hprof文件。我们可以通过下列工具分析它 Eclipse Memory Analyzer JProfiler jvisualvm jhat 由于我们从上面的GC日志中分析出了引发内存溢出的原因, 也就不再使用上列的工具分析*.hprof文件了,但是对于复杂的应用程序来说,如果发生了堆内存溢出的话, 使用上列工具分析的话,还是非常有必要的. 在分析这个文件的时候,我们重点确认内存中的对象是否是必要的,也就是弄清楚是引发了内存泄漏还是内存溢出. 如果是内存泄漏可通过工具查看泄漏对象到GC Roots的引用链.于是就能找到泄漏对象是通过怎样的路径与GC Toots相关联,并导致垃圾收集器无法自动回收它们的. 掌握了泄漏对象的类型信息,以及GC Roots引用链信息,就可以比较准确地定位出泄漏代码的位置. 如果不存在泄漏, 换句话说就是内存中的对象确实还都必须存货着, 那就应当检查虚拟机的堆参数,与物理机内存对比查看是否还可以调大,从代码上检查是否存在某些生命周期过长,持有状态时间过长的情况,尝试减少程序运行周期的内存消耗. DirectMemory OOM溢出代码 1234567891011121314/** * VM Args: -Xmx20M -XX:MaxDirectMemorySize=10M */public class DirectMemoryOOM &#123; private static final int _1MB = 1024 * 1024; public static void main(String[] args) throws Exception &#123; Field unsafeField = Unsafe.class.getDeclaredFields()[0]; unsafeField.setAccessible(true); Unsafe unsafe = (Unsafe)unsafeField.get(null); while(true) unsafe.allocateMemory(_1MB); &#125;&#125; 直接通过反射获取Unsafe实例并进行内存分配,Unsafe类的getUnsafe()方法限制了只有引导类加载器才会返回实例,也就是设计者希望只有rt.jar中的类才能使用unsafe的功能. 因为虽然使用DirectbyeBuffer分配内存也会抛出内存异常,但抛出异常时并没有真正向操作系统申请分配内存,而是通过计算得知内存无法分配,于是手动抛出异常,真正申请分配内存的方法是:unsafe.allocateMemory(_1MB);","categories":[{"name":"JVM","slug":"JVM","permalink":"https://wangmingco.github.io/categories/JVM/"}],"tags":[]},{"title":"JVM方法调用","slug":"jvm/JVM 方法调用","date":"2014-09-03T16:00:00.000Z","updated":"2021-11-18T02:43:30.415Z","comments":true,"path":"2014/09/04/jvm/JVM 方法调用/","link":"","permalink":"https://wangmingco.github.io/2014/09/04/jvm/JVM%20%E6%96%B9%E6%B3%95%E8%B0%83%E7%94%A8/","excerpt":"","text":"动态连接每个栈帧内部都包含一个指向运行时常量池的引用来支持当前方法的代码实现动态连接.在Class文件中,描述一个方法调用其他方法,或者访问其他成员变量是通过符号引用来表示的.动态连接就是将这些符号引用所表示的方法转换为实际方法的直接引用.类加载的过程中将要解析尚未被解析的符号引用, 并且将变量访问转换为访问这些变量的存储结构所在的运行时内存位置的正确偏移量.由于动态连接的存在,通过晚期绑定使用的其他类的方法和变量在发生变化时,将不会对调用他们的方法构成影响 每个栈帧都包含一个指向运行时常量池中该栈帧所属的方法引用,持有这个引用是为了支持调用过程中的动态连接.Class文件的常量池中存有大量的符号引用,字节码中的方法调用指令就以常量池中指向方法的符号引用为参数. 这些符号引用一部分会在类加载阶段或第一次使用的时候转化为直接引用,这种转化称为静态解析. 另外一部分将在每一次的运行期间转化为直接引用,这部分称为动态连接 方法正常调用完成当前栈帧承担着恢复调用者状态的责任, 其状态包括调用这的局部变量表, 操作数栈以及被正确增加用来表示执行了该方法调用指令的程序计数器等。使得调用者的代码能在被调用的方法返回并且返回值被压入调用者栈帧的操作数栈后继续正常执行 方法调用非正常完成指的是在方法调用过程了,某些指令导致了虚拟机抛出异常,而且虚拟机抛出的异常在该方法中没办法处理,或者在执行过程中遇到athrow字节码指令抛出的显式异常,同时在方法内部没有捕获异常 方法返回地址当一个方法执行后,有俩个方式退出这个地址.第一种方式是执行引擎遇到任意一个方法返回的字节码指令,这时候可能会有返回值传递给上层的方法调用者(调用当前方法的方法称为调用者),是否有返回值和返回值的类型将根据遇到何种方法返回指令来决定,这种退出方法的方式为正常完成出口. 另一种退出的方法是,在方法执行过程中遇到了异常,并且这个异常没有在方法体内得到处理,无论虚拟机内部产生的异常,还是代码中使用athrow字节码之类产生的异常,只要在本方法的异常表中没有搜索到匹配的异常处理器,就会导致方法退出,这种退出方法的方式称为异常完成出口.一个方法使用异常完成出口的方式退出,是不会给它的上层调用者产生任何返回值的. 无论采用何种退出方法,在方法退出之后,都需要返回到方法被调用的位置,程序才能继续执行,方法返回时可能需要在栈帧中保存一些信息,用来帮助恢复它的上层方法的执行状态.一般来说,方法正常退出时,调用者的PC计数器的值就可以作为返回地址,栈帧中很可能会保存这个计数器值.而方法异常退出时,返回地址是要通过异常处理器表来确定的,栈帧中一般不会保存这部分信息. 方法退出的过程实际上等同于把当前栈帧出栈,因此退出时可能执行的操作有:回复上层方法的局部变量表和操作数栈,把返回值(如果有的话)压入调用者栈帧的操作数栈中,调整PC计数器的值以执行方法调用指令后面的一条指令等. 方法调用方法调用并不等于方法执行,方法调用阶段唯一的任务就是确定方法的版本号(即调用哪个方法),暂时还不涉及方法内部的具体运行过程.在承运运行时,进行方法调用是最普遍,最频繁的的操作,单前面已经讲过,Class文件的编译过程中不包含传统编译的连接步骤,一切方法调用在Class文件里面存储的都只是符号引用,而不是方法在实际运行时内存布局中的入口地址(相当于之前的所说的直接引用).这个特性给java带来了更加强大的动态拓展能力,但也使得java方法的调用过程变得相对复杂起来,需要在类加载期间甚至到运行期间才能确定目标方法的直接引用. 解析继续前面关于方法调用的话题,所有方法调用中的目标方法在Class文件里面都是一个常量池中的符号引用,在类加载的解析极端,会将其中的一部分符号引用转化为直接引用,这种解析能够成立的前提是:方法在程序真正运行之前就有一个可确定的调用版本,并且这个方法在运行期是不可改变的.换句话说,调用目标在程序代码写好,编译器进行编译时就必须确定下来.这类方法的调用称为解析(Resolution). 在java语言中,符合”编译器可知,运行期不可变”这个要求的方法主要是有静态方法和私有方法俩大类,前者与类型直接关联,后者在外部不可被访问,这俩种方法都不可能通过继承或别的方式重写出其他版本,因此他们都适合在类加载阶段进行解析. 与之对应的是,在java虚拟机里面提供了四条方法调用字节码指令: invokestatic: 调用静态方法 invokespecial:调用实例构造器&lt;init&gt;方法,私有方法和父类方法 invokevirtual:调用所有的虚方法 invokeinterface:调用接口方法,会在运行时再确定一个实现此接口的对象 只要能被invokestatic, invokespecial指令调用的方法,都可以在解析阶段确定唯一的版本,符合这个条件的有静态方法,私有方法,实例构造器和父类方法四类,他们在类加载的时候就会把符号引用解析为该方法的直接引用.这些方法可以称为非虚方法,与此相反,其他方法就称为虚方法(除了final方法).下面的例子中最常见的解析调用的例子,此样例中,静态方法sayHello()只可能属于类型StaticResolution,没有任何手段可以覆盖或者隐藏这个方法. 1234567891011public class StaticResolution &#123; public static void sayHello() &#123; System.out.println(&quot;hello&quot;); &#125; public static void main(String[] args) &#123; StaticResolution.sayHello(); &#125;&#125; 通过javap查看字节码: 1234567891011public static void main(java.lang.String[]); descriptor: ([Ljava/lang/String;)V flags: ACC_PUBLIC, ACC_STATIC Code: stack=0, locals=1, args_size=1 0: invokestatic #5 // Method sayHello:()V 3: return LineNumberTable: line 9: 0 line 10: 3 java中的非虚方法除了使用invokestatic和invokespecial调用的方法之外还有一种,就是被final修饰的方法.虽然final方法是使用invokespecial指令来调用的,但是由于它无法被覆盖,没有其他版本,所以也无须对方法接受者进行多态选择,又或者说多态选择的结果是唯一的.在java语言规范中明确说明了final方法是一种非虚方法. 解析调用一定是个静态过程,在编译期间就完全确定,在类装载的解析阶段就会把涉及的符号引用全部转变为可确定的直接引用,不会延迟到运行期再去完成.而分派调用则可能是静态的也可能是动态的,根据分派依据的宗数量可分为单分派和多分派.这俩类分派方式俩俩组合就构成了静态单分派,静态多分派,动态单分派,动态多分派.","categories":[{"name":"JVM","slug":"JVM","permalink":"https://wangmingco.github.io/categories/JVM/"}],"tags":[]},{"title":"JVM 内存分配","slug":"jvm/JVM 内存分配","date":"2014-09-02T16:00:00.000Z","updated":"2021-11-18T02:43:32.799Z","comments":true,"path":"2014/09/03/jvm/JVM 内存分配/","link":"","permalink":"https://wangmingco.github.io/2014/09/03/jvm/JVM%20%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D/","excerpt":"","text":"栈JVM栈和常用的数据结构很相似,都是一种先进后出的数据结构. JVM栈是每个线程私有的内存空间.线程的基本行为就是方法调用, 而方法调用就是通过JVM栈传递的.每当我们创建一个线程对象的的时候, 都会创建一个JVM栈. 它的生命周期与线程相同. JVM栈是由JVM栈帧组成的, 每次方法调用都会有一个JVM栈帧进入JVM栈,也称入栈, 当方法执行完(不管是return还是异常),栈帧都会被弹出JVM栈,也称出栈. 栈帧包含如下结构: PC寄存器 本地方法栈 局部变量表 操作数栈 动态连接 方法出口 在java虚拟机中.对这个区域规定了俩种异常情况: 如果请求的栈深度大于虚拟机所允许的深度,抛出StackOverflowError 如果虚拟机可以动态扩展,当拓展时无法申请到足够的内存时会抛出OutOfMemoryError异常 PC寄存器每当我们创建一个线程的时候, 都会JVM都会附带着创建一个本线程私有的PC寄存器和虚拟机栈. PC寄存器用于存放当前线程执行的字节码指令(线程当前方法)地址. 字节码解释器通过修改寄存器里的值使线程完成下一个指令的执行. 分支,循环,跳转,异常处理,线程恢复等基础功能都需要依赖这个寄存器完成. 在一个单CPU的环境中, 一个多线程的程序通过轮流切换线程完成多线程运行. 那么在切换线程的时候, 被切换的线程对应的寄存器里的值被保存了下来, 当线程再切换回来的时候,线程得以继续运行. PC寄存器是唯一一个在java虚拟机规范中没有规定任何OutOfMemoryError情况的区域. 本地方法栈 用来支持native方法 操作数栈每个栈帧内部都包含一个称为操作数栈的先进后出栈. 同局部变量表一样,操作数栈的最大深度也是在编译的时候被写入到Code属性的max_stacks数据项之中的.操作数栈的每一个元素都可以是任意的java数据类型,包括long和double(一个long或者double类型的数据会占用俩个单位的栈深度, 其他类型占用一个单位的栈深度). 32位的数据类型所占的栈容量为1,64位数据类型所占的栈容量为2.在方法执行的时候,操作数栈的深度都不会超过在max_stacks数据项中设定的最大值. 栈帧在刚创建的时候, 操作数栈是空的, JVM提供了一系列指令从局部变量表或者对象实例的字段中复制常量或变量值到操作数栈中.也提供了一些列指令从操作数栈取走, 操作数据, 以及把结果重新入栈. 也就是入栈和出栈操作.例如:在做算术运算的时候是通过操作数栈来进行的,又或者在调用其他方法的时候是通过操作数栈来进行参数传递的.参考字节码指令 例如,整数加法的字节码指令iadd在运行的时候要求操作数栈中最接近栈顶的俩个元素已经存入了俩个int型的数值,当执行这个指令时,会将这俩个int值出栈并相加,然后将相加的结果入栈. 另外,在概念模型中,俩个栈帧为虚拟机栈的元素,相互之间是完全独立的.但是大多数虚拟机的实现里都会做一些优化处理,令俩个栈帧出现一部分重叠.让下面栈帧的部分操作数栈与上面栈帧的部分局部变量表重叠在一起,这样在进行方法调用时就可以共有一部分数据,而无需进行额外的参数复制传递: 局部变量表局部变量表存放基本类型的数据和对象的引用,但对象本身不存放在栈中,而是存放在堆中. 其长度在编译器决定 一个局部变量称为一个Slot.每个Slot只可以保存一个boolean, byte, char, short, int, float, reference,returnAddress类型的数据.long或者double需要俩个Slot保存. 局部变量表来完成方法调用时的参数传递. (如果是实例方法, 第0个局部变量是用来存储调用实例方法的对象的引用) 局部变量表中的Slot是可重用的, 我们看下面的例子: 123456public class CollectSlot &#123; public static void main(String[] args) &#123; byte[] byes3m = new byte[3 * 1024 * 1024]; System.gc(); &#125;&#125; 运行一下上面的程序, 我们得到下面的结果 1234567891011121314ζ java -XX:+PrintGCDetails -XX:MaxNewSize=1m -Xmx10M -Xms10M CollectSlot[GC (Allocation Failure) [PSYoungGen: 509K-&gt;488K(1024K)] 509K-&gt;504K(9728K), 0.0004559 secs] [Times: user=0.00 sys=0.00, real=0.00 secs][GC (System.gc()) [PSYoungGen: 745K-&gt;488K(1024K)] 3833K-&gt;3656K(9728K), 0.0005722 secs] [Times: user=0.00 sys=0.00, real=0.00 secs][Full GC (System.gc()) [PSYoungGen: 488K-&gt;0K(1024K)] [ParOldGen: 3168K-&gt;3614K(8704K)] 3656K-&gt;3614K(9728K), [Metaspace: 2572K-&gt;2572K(1056768K)], 0.0045062 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]Heap PSYoungGen total 1024K, used 10K [0x00000000ffe80000, 0x0000000100000000, 0x0000000100000000) eden space 512K, 2% used [0x00000000ffe80000,0x00000000ffe82a68,0x00000000fff00000) from space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000) to space 512K, 0% used [0x00000000fff00000,0x00000000fff00000,0x00000000fff80000) ParOldGen total 8704K, used 3614K [0x00000000ff600000, 0x00000000ffe80000, 0x00000000ffe80000) object space 8704K, 41% used [0x00000000ff600000,0x00000000ff987840,0x00000000ffe80000) Metaspace used 2578K, capacity 4486K, committed 4864K, reserved 1056768K class space used 287K, capacity 386K, committed 512K, reserved 1048576KJava HotSpot(TM) 64-Bit Server VM warning: NewSize (1536k) is greater than the MaxNewSize (1024k). A new max generation size of 1536k will be used. 在启动程序的时候, 我们将JVM堆内存设置为10M, 新生代为1M, 当我们在应用程序中分配3M内存的时候, byes3m这个对象就直接分配在了老年代中. 从GC日志的第一条中我们也可以看出, [PSYoungGen: 509K-&gt;488K(1024K)] 新生代已经使用了509k, 回收后488K, 总共1024k. 当调用System.gc()我们发现永久代的内存并没有回收掉，这也正是我们的预期 然后我们修改一下那个程序 12345678public class CollectSlot &#123; public static void main(String[] args) &#123; byte[] byes3m = new byte[3 * 1024 * 1024]; byes3m = null; byte[] byes3m_ = new byte[3 * 1024 * 1024]; System.gc(); &#125;&#125; 我们将byes3m置为null, 看看其占用的内存会不会回收掉 1234567891011121314ζ java -XX:+PrintGCDetails -XX:MaxNewSize=1m -Xmx10M -Xms10M CollectSlot[GC (Allocation Failure) [PSYoungGen: 509K-&gt;496K(1024K)] 509K-&gt;528K(9728K), 0.0005626 secs] [Times: user=0.00 sys=0.00, real=0.00 secs][GC (System.gc()) [PSYoungGen: 753K-&gt;488K(1024K)] 6929K-&gt;6744K(9728K), 0.0006016 secs] [Times: user=0.00 sys=0.00, real=0.00 secs][Full GC (System.gc()) [PSYoungGen: 488K-&gt;0K(1024K)] [ParOldGen: 6256K-&gt;3614K(8704K)] 6744K-&gt;3614K(9728K), [Metaspace: 2572K-&gt;2572K(1056768K)], 0.0045914 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]Heap PSYoungGen total 1024K, used 10K [0x00000000ffe80000, 0x0000000100000000, 0x0000000100000000) eden space 512K, 2% used [0x00000000ffe80000,0x00000000ffe82a68,0x00000000fff00000) from space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000) to space 512K, 0% used [0x00000000fff00000,0x00000000fff00000,0x00000000fff80000) ParOldGen total 8704K, used 3614K [0x00000000ff600000, 0x00000000ffe80000, 0x00000000ffe80000) object space 8704K, 41% used [0x00000000ff600000,0x00000000ff987840,0x00000000ffe80000) Metaspace used 2578K, capacity 4486K, committed 4864K, reserved 1056768K class space used 287K, capacity 386K, committed 512K, reserved 1048576KJava HotSpot(TM) 64-Bit Server VM warning: NewSize (1536k) is greater than the MaxNewSize (1024k). A new max generation size of 1536k will be used. 好，我们看到了ParOldGen: 6256K-&gt;3614K(8704K) 这句话, 说明已经有3M的内存被回收掉了。 赋null值的操作在经过虚拟机JIT编译器优化之后会被消除掉,这时候将变量设置为null实际上是没有意义的.因为我们的方法调用还没有达到JIT编译的次数, 因此在上面的例子中, 赋null值还是管用的, 但是在平时编码时,我们还是尽量不要依赖这种null赋值的操作 下面我们再修改一下程序, 将其放在代码块中，这样placeholder1的slot就会被placeholder2复用, 123456789public class CollectSlot &#123; public static void main(String[] args) &#123; &#123; byte[] byes3m = new byte[3 * 1024 * 1024]; &#125; byte[] byes3m1 = new byte[3 * 1024 * 1024]; System.gc(); &#125;&#125; 运行结果为 1234567891011121314ζ java -XX:+PrintGCDetails -XX:MaxNewSize=1m -Xmx10M -Xms10M CollectSlot[GC (Allocation Failure) [PSYoungGen: 509K-&gt;472K(1024K)] 509K-&gt;472K(9728K), 0.0006416 secs] [Times: user=0.00 sys=0.00, real=0.00 secs][GC (System.gc()) [PSYoungGen: 729K-&gt;488K(1024K)] 6873K-&gt;6752K(9728K), 0.0038950 secs] [Times: user=0.00 sys=0.00, real=0.00 secs][Full GC (System.gc()) [PSYoungGen: 488K-&gt;0K(1024K)] [ParOldGen: 6264K-&gt;3614K(8704K)] 6752K-&gt;3614K(9728K), [Metaspace: 2572K-&gt;2572K(1056768K)], 0.0045731 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]Heap PSYoungGen total 1024K, used 10K [0x00000000ffe80000, 0x0000000100000000, 0x0000000100000000) eden space 512K, 2% used [0x00000000ffe80000,0x00000000ffe82a68,0x00000000fff00000) from space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000) to space 512K, 0% used [0x00000000fff00000,0x00000000fff00000,0x00000000fff80000) ParOldGen total 8704K, used 3614K [0x00000000ff600000, 0x00000000ffe80000, 0x00000000ffe80000) object space 8704K, 41% used [0x00000000ff600000,0x00000000ff987840,0x00000000ffe80000) Metaspace used 2578K, capacity 4486K, committed 4864K, reserved 1056768K class space used 287K, capacity 386K, committed 512K, reserved 1048576KJava HotSpot(TM) 64-Bit Server VM warning: NewSize (1536k) is greater than the MaxNewSize (1024k). A new max generation size of 1536k will be used. 在上面的GC日志中,我们同样看到ParOldGen: 6264K-&gt;3614K(8704K)说明在代码块里面的那3M内存也已经被回收掉了. 这段内存能被回收的关键就是byes3m1复用了byes3m局部变量表中的Slot.因此byes3m原来指向的堆内存就不存在引用了,在GC时,这段内存就被回收掉了.但是如果没有byes3m1这个对象创建的话,byes3m的虽然离开了其作用域,但是由于GCRoots还关联着对其的引用,因此也是不会被回收的. 这种代码在绝大部分情况下影响都非常小, 但是如果一个方法中有一些很耗时的操作, 同时又分配了很大的内存, 将这些不再使用的占大内存的变量放到代码块中就是一个比较好的操作了，所以我们应该以恰当的作用域来控制变量回收时间。 关于局部变量表,还有一点可能会对实际开发产生影响,就是局部变量表不像前面介绍的类变量那样存在”准备阶段”.类变量有俩次赋初始值的过程,一次在准备阶段,赋予系统初始值.另外一次在初始化阶段,赋予程序员定义的初始化. 因此即使在初始化阶段程序员没有为类变量赋值也没关系,类变量仍然具有一个确定的初始值. 但是局部变量就不一样了,如果一个局部变量定义了但没有赋初始值是不能使用的. 堆我们首先看一下JVM堆内存的特点 是供各个线程共享的运行时内存 所有类实例和数组对象分配内存的地方 存储了内存管理系统(GC) 堆内存可以处于物理上不连续的内存空间中,逻辑上是连续的即可. 如果在堆内中没有内存完成实例分配,而且堆无法再拓展时,会抛出OutOfMemoryError 随着JIT编译器的发展和逃逸分析技术的逐渐成熟,栈上分配,标量替换优化技术将会导致一些变化,所有的对象在堆上分配也不是那么绝对了 然后我们看一下堆内存内部分配: 由于现在GC收集器基本都是采用的分代收集算法,所以java堆还可以细分为:新生代和老年代.分的再细一点还有Eden空间,From Survivor空间,To Sruvivor空间. 内存分配 新生代GC(Minor GC)：新生代GC, Java对象大多都朝生夕灭,所以Minor GC非常频繁,回收速度也比较快. 老年代GC(Major GC/Full GC)：老年代GC,出现了Major GC,经常会伴随至少一次的Minor GC. MajorGC的速度一般会比Minor GC慢10倍以上. 引用计数算法引用计数算法很难解决对象之间相互循环引用的问题 1234567891011121314151617public class ReferenceCountingGC &#123; public Object instance = null; private static final int _1MB = 3 * 1024 * 1024; private byte[] bigSize = new byte[_1MB]; public static void main(String[] args) &#123; &#123; ReferenceCountingGC obj1 = new ReferenceCountingGC(); ReferenceCountingGC obj2 = new ReferenceCountingGC(); obj1.instance = obj2; obj2.instance = obj1; &#125; System.gc(); &#125;&#125; 我们运行-XX:+PrintGCDetails -Xmx10M -Xms10M得到结果为 1234567891011[GC (System.gc()) [PSYoungGen: 1650K-&gt;504K(2560K)] 7794K-&gt;7001K(9728K), 0.0029060 secs] [Times: user=0.05 sys=0.00, real=0.00 secs][Full GC (System.gc()) [PSYoungGen: 504K-&gt;0K(2560K)] [ParOldGen: 6497K-&gt;6952K(7168K)] 7001K-&gt;6952K(9728K), [Metaspace: 3051K-&gt;3051K(1056768K)], 0.0104574 secs] [Times: user=0.00 sys=0.00, real=0.01 secs]Heap PSYoungGen total 2560K, used 41K [0x00000000ffd00000, 0x0000000100000000, 0x0000000100000000) eden space 2048K, 2% used [0x00000000ffd00000,0x00000000ffd0a560,0x00000000fff00000) from space 512K, 0% used [0x00000000fff00000,0x00000000fff00000,0x00000000fff80000) to space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000) ParOldGen total 7168K, used 6952K [0x00000000ff600000, 0x00000000ffd00000, 0x00000000ffd00000) object space 7168K, 96% used [0x00000000ff600000,0x00000000ffcca158,0x00000000ffd00000) Metaspace used 3058K, capacity 4494K, committed 4864K, reserved 1056768K class space used 331K, capacity 386K, committed 512K, reserved 1048576K 我们看到GC之后这块内存并没有回收掉 根搜索算法这个算法的基本思想是:通过一系列的名为”GC Roots”的对象作为起始点, 从这些起始点开始向下搜索,搜索所走过的路径称为引用链,当一个对象到GC Roots没有任何引用链时,则证明这个对象是不可到达的. 在java中可作为GC Roots的对象包括以下几种: 虚拟机栈(栈帧中的本地变量表)中的引用对象. 方法区中的类静态属性引用的对象. 方法区中的常量引用对象 本地方法栈中JNI的引用的对象 新生代新生代分为Eden区和Survivor区(Eden有一个, Survivor有俩个). 大多数情况下,对象在新生代Eden区中分配.当Eden区没有足够的空间进行分配时,虚拟机将发起一次Minor GC, 将存活下来的对象移动到一个Survivor区中 123456789101112private static final int _1MB = 1024 * 1024;/** * VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M -XX:SurvivorRatio=8 */public static void testAllocation() &#123; byte[] allocation1, allocation2, allocation3, allocation4; allocation1 = new byte[2 * _1MB]; allocation2 = new byte[2 * _1MB]; allocation3 = new byte[2 * _1MB]; allocation4 = new byte[4 * _1MB]; // 出现一次Minor GC&#125; 分析如下： 首先在堆中分配3个2MB大小和1个4MB大小的byte数组, 在运行时通过-Xms20M、 -Xmx20M和-Xmn10M这3个参数限制Java堆大小为20MB,且不可扩展,其中10MB分配给新生代,剩下的10MB分配给老年代. -XX:SurvivorRatio=8决定了新生代中Eden区与一个Survivor区的空间比例是8比1,从输出的结果也能清晰地看到“eden space 8192K、from space 1024K、to space 1024K”的信息,新生代总可用空间为9216KB(Eden区+1个Survivor区的总容量). 执行testAllocation()中分配allocation4对象的语句时会发生一次Minor GC,这次GC的结果是新生代6651KB变为148KB,而总内存占用量则几乎没有减少(因为allocation1、2、3三个对象都是存活的,虚拟机几乎没有找到可回收的对象). 这次GC发生的原因是给allocation4分配内存的时候,发现Eden已经被占用了6MB,剩余空间已不足以分配allocation4所需的4MB内存,因此发生Minor GC.GC期间虚拟机又发现已有的3个2MB大小的对象全部无法放入Survivor空间(Survivor空间只有1MB大小),所以只好通过分配担保机制提前转移到老年代去. 这次GC结束后,4MB的allocation4对象被顺利分配在Eden中.因此程序执行完的结果是Eden占用4MB(被allocation4占用),Survivor空闲,老年代被占用6MB(被allocation1、2、3占用) 老年代大对象和长期存活的对象会进入老年代。所谓大对象就是指,需要大量连续内存空间的Java对象,最典型的大对象就是那种很长的字符串及数组. 如果连续出现多个大对象, 会导致老年代频繁发生Full GC, 因此在写程序时应该避免频繁出现大对象. 我们可以使用-XX:PretenureSizeThreshold参数令大于这个值的对象直接在老年代中分配. 这样做的目的是避免在Eden区及两个Survivor区之间发生大量的内存拷贝(新生代采用复制算法收集内存). 12345678910private static final int _1MB = 1024 * 1024;/** * VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M -XX:SurvivorRatio=8 * -XX:PretenureSizeThreshold=3145728 */public static void testPretenureSizeThreshold() &#123; byte[] allocation; allocation = new byte[4 * _1MB]; //直接分配在老年代中&#125; 我们看到Eden空间几乎没有被使用,而老年代10MB的空间被使用了40%,也就是4MB的allocation对象直接就分配在老年代中,这是因为PretenureSizeThreshold被设置为3MB(就是3145728B,这个参数不能与-Xmx之类的参数一样直接写3MB),因此超过3MB的对象都会直接在老年代中进行分配. 注意PretenureSizeThreshold参数只对Serial和ParNew两款收集器有效,Parallel Scavenge收集器不认识这个参数,Parallel Scavenge收集器一般并不需要设置.如果遇到必须使用此参数的场合,可以考虑ParNew加CMS的收集器组合. 虚拟机给每个对象定义了一个对象年龄(Age)计数器.如果对象在Eden出生并经过第一次Minor GC后仍然存活, 并且能被Survivor容纳的话,将被移动到Survivor空间中,并将对象年龄设为1.对象在Survivor区中每熬过一次Minor GC,年龄就增加1岁,当它的年龄增加到一定程度(默认为15岁)时,就会被晋升到老年代中.对象晋升老年代的年龄阈值,可以通过参数-XX:MaxTenuringThreshold来设置. 大家可以分别以-XX:MaxTenuringThreshold=1和-XX:MaxTenuringThreshold=15两种设置来执行刚才示例. 例子中allocation1对象需要256KB的内存空间,Survivor空间可以容纳.当MaxTenuringThreshold=1时,allocation1对象在第二次GC发生时进入老年代,新生代已使用的内存GC后会非常干净地变成0KB.而MaxTenuringThreshold=15时,第二次GC发生后,allocation1对象则还留在新生代Survivor空间,这时候新生代仍然有404KB的空间被占用. 实例代码 1234567891011121314151617private static final int _1MB = 1024 * 1024;/** * VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M * -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=1 * -XX:+PrintTenuringDistribution */@SuppressWarnings(&quot;unused&quot;)public static void testTenuringThreshold() &#123; byte[] allocation1, allocation2, allocation3; allocation1 = new byte[_1MB / 4]; // 什么时候进入老年代取决于XX:MaxTenuringThreshold设置 allocation2 = new byte[4 * _1MB]; allocation3 = new byte[4 * _1MB]; allocation3 = null; allocation3 = new byte[4 * _1MB];&#125; 动态年龄判断为了能更好地适应不同程序的内存状况,虚拟机并不总是要求对象的年龄必须达到MaxTenuringThreshold才能晋升老年代,如果在Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半,年龄大于或等于该年龄的对象就可以直接进入老年代,无须等到MaxTenuringThreshold中要求的年龄. 例如下例中设置参数-XX: MaxTenuringThreshold=15,会发现运行结果中Survivor的空间占用仍然为0%,而老年代比预期增加了6%,也就是说allocation1、allocation2对象都直接进入了老年代,而没有等到15岁的临界年龄.因为这两个对象加起来已经达到了512KB,并且它们是同年的,满足同年对象达到Survivor空间的一半规则.我们只要注释掉其中一个对象的new操作,就会发现另外一个不会晋升到老年代中去了. 示例代码 123456789101112131415161718private static final int _1MB = 1024 #### 1024;/** * VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M * -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=15 * -XX:+PrintTenuringDistribution */@SuppressWarnings(&quot;unused&quot;)public static void testTenuringThreshold2() &#123; byte[] allocation1, allocation2, allocation3, allocation4; allocation1 = new byte[_1MB / 4]; // allocation1+allocation2大于survivor空间的一半 allocation2 = new byte[_1MB / 4]; allocation3 = new byte[4 #### _1MB]; allocation4 = new byte[4 #### _1MB]; allocation4 = null; allocation4 = new byte[4 #### _1MB];&#125; 空间分配担保在发生Minor GC时,虚拟机会检测之前每次晋升到老年代的平均大小是否大于老年代的剩余空间大小,如果大于,则改为直接进行一次Full GC.如果小于,则查看HandlePromotionFailure设置是否允许担保失败;如果允许,那只会进行Minor GC;如果不允许,则也要改为进行一次Full GC. 前面提到过,新生代使用复制收集算法,但为了内存利用率,只使用其中一个Survivor空间来作为轮换备份,因此当出现大量对象在Minor GC后仍然存活的情况时(最极端就是内存回收后新生代中所有对象都存活),就需要老年代进行分配担保,让Survivor 无法容纳的对象直接进入老年代.与生活中的贷款担保类似,老年代要进行这样的担保,前提是老年代本身还有容纳这些对象的 剩余空间,一共有多少对象会活下来,在实际完成内存回收之前是无法明确知道的,所以只好取之前每一次回收晋升到老年代对象容量的平均大小值作为经验值,与老年代的剩余空间进行比较,决定是否进行Full GC来让老年代腾出更多空间. 取平均值进行比较其实仍然是一种动态概率的手段,也就是说如果某次Minor GC存活后的对象突增,远远高于平均值的话,依然会导致担保失败(Handle Promotion Failure).如果出现了HandlePromotionFailure失败, 那就只好在失败后重新发起一次Full GC.虽然担保失败时绕的圈子是最大的,但大部分情况下都还是会将 HandlePromotionFailure开关打开,避免Full GC过于频繁, 示例代码 12345678910111213141516171819202122private static final int _1MB = 1024 #### 1024;/** * VM参数：-verbose:gc -Xms20M -Xmx20M -Xmn10M * -XX:SurvivorRatio=8 -XX:-HandlePromotionFailure */@SuppressWarnings(&quot;unused&quot;)public static void testHandlePromotion() &#123; byte[] allocation1, allocation2, allocation3, allocation4, allocation5, allocation6, allocation7; allocation1 = new byte[2 #### _1MB]; allocation2 = new byte[2 #### _1MB]; allocation3 = new byte[2 #### _1MB]; allocation1 = null; allocation4 = new byte[2 #### _1MB]; allocation5 = new byte[2 #### _1MB]; allocation6 = new byte[2 #### _1MB]; allocation4 = null; allocation5 = null; allocation6 = null; allocation7 = new byte[2 #### _1MB];&#125; 直接内存直接内存并不是虚拟机运行时数据区的一部分,也不是java虚拟机规范中定义的内存区域,但是这部分内存也被频繁使用,而且也会导致OutOfMemoryError异常出现 在JDK1.4引入的NIO类,一种基于通道与缓冲区的I/O方式,它可以利用Native函数库直接分配堆外内存,然后通过一个存储在java堆里面的DirectByteBuffer对象作为这块内存的引用进行操作.这样能在一些场景中显著提高性能,因为避免了java堆和Native堆中来回复制数据. 显然本机直接内存的分配不会收到java堆大小的限制,但是既然是内存,则肯定会收到本机总内存(包括RAM及SWAP区或者分页文件)及处理器寻址空间的限制.一般在配置虚拟机参数时,会genuine实际内存设置-Xmx等参数信息,但经常会忽略掉直接内存,使得各个区域的总和大于物理内存限制,从而导致动态拓展时,出现OutOfMemoryError. 方法区 虚拟机启动时创建 供各个线程共享的运行时内存 存储了每个类的结构信息, 运行时常量池, 静态变量,即时编译器编译后的代码, 方法数据, 构造函数, 普通方法的字节码内容 java虚拟机规范对这个区域的限制非常宽松,除了和java堆一样不需要连续的内存外,和可以实现固定大小或者可拓展的之外,还可以选择不实现垃圾收集.(在HotSop虚拟机中一般喜欢称这个区域为永久代)并非数据进入永久代就像其名字一样”永久存在”. 这个区域的回收目标是针对常量池的回收和对类型的卸载. 当方法区无法满足内存分配需求时,将抛出OutOfMemoryError. 运行时常量池是方法区的一部分. Class文件中除了有类的版本,字段,方法,接口等信息外,还有一项信息是常量池,用于存储编译器产生的各种字面量和符号引用.这部分内容将在类加载后存放到方法区的运行时常量池中. 运行时常量池相对于Class文件常量池的另外一个重要特征是具备动态性,java语言并不要求常量一定只能在编译器产生,也就是并非预置入Class文件常量池的内容才能进入方法区运行时常量池,运行期间也可能将新的常量放入常量池,这种特性被用到比较多的便是String#intern()在加载类和接口到虚拟机后就创建对应的常量池,其是Class文件中每个类或者接口常量池表的运行时表示. 它包含了从编译期克制的数值字面量到必须到运行期解析后才能获得的方法或字段引用 java 中的常量池,是为了方便快捷地创建某些对象而出现的,当需要一个对象时,就可以从池中取一个出来(如果池中没有则创建一个)， 则在需要重复创建相等变量时节省了很多时间 . 常量池其实也就是一个内存空间,不同于使用 new 关键字创建的对象所在的堆空间 . 常量池用来存放在编译期间就可以确定的数据,比如字符串等类型 在新生代,常规应用进行一次垃圾收集,一般可以收回70%-95%的空间,而永久代(方法区)远低于此. 永久代的垃圾回收主要是回收俩部分内容: 废弃常量: 回收废弃常量与回收java堆中的对象非常类似.以常量池字面量回收为例,如果一个字符串”ABC”已经进入了常量池,但是当前系统中没有任何一个String对象是叫做”ABC”的,换句话说也就是没有任何String对象引用这个字面量,也没有其他地方引用这个字面量,如果这个时候发生内存回收,而且必要的话,这个”ABC”常量会被清除出常量池.常量池中的其他类(皆苦),方法,字段的符号引用也与此类似. 无用的类 判断一个类是否是无用的类条件要苛刻的多. 要同时满足下面三个条件: 该类的所有实例都已经被回收,也就是java堆中不存在该类的实例.&lt;br.&gt; 加载该类的ClassLoader已经被回收.&lt;br.&gt; 该类对应的java.lang.Class对象没有在任何地方被引用,无法在任何地方通过反射访问该类. 虚拟机可以对满足上面三个条件的类进行回收,这里说的仅仅是可以,而不是和对象一样,不使用了就必然回收.是否对类进行回收HotSpot虚拟机提供了-Xnoclassgc参数进行控制,还可以使用-verbose:Class及-XX:+TraceClassLoading,-XX:+TraceClassUnLoading查看类的加载和卸载信息.-verbose:Class和-XX:+TraceClassLoading可以在Product版的虚拟机中使用,但是-XX:+TraceClassLoading参数需要fastdebug版的虚拟机支持 静态存储里存放程序运行时一直存在的数据 . 可用关键字 static 来标识一个对象的特定元素是静态的,被static 修饰的成员变量和成员方法独立于该类的任何对象,它不依赖类特定的实例,被类的所有实例共享 . 但 JAVA 对象本身不会存放在静态存储空间里,而只是把对象中的一些特殊元素放置这里 .","categories":[{"name":"JVM","slug":"JVM","permalink":"https://wangmingco.github.io/categories/JVM/"}],"tags":[]},{"title":"Groovy JSON","slug":"编程语言/Groovy JSON","date":"2014-04-17T16:00:00.000Z","updated":"2021-11-18T02:27:59.695Z","comments":true,"path":"2014/04/18/编程语言/Groovy JSON/","link":"","permalink":"https://wangmingco.github.io/2014/04/18/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Groovy%20JSON/","excerpt":"","text":"本文是对Groovy部分官方文档进行了翻译 Groovy 原生支持Groovy对象和JSON之间的转换. groovy.json包内的类用于JSON的序列化和解析功能 JsonSlurperJsonSlurper用于将JSON文本或者其他数据内容解析成Groovy里的数据结构,例如maps&lt;/code&gt;, lists, 或者其他原生基本类型 Integer&lt;/code&gt;, Double, Boolean&lt;/code&gt;, String`。 这个类重载了很多方法, 而且还添加了一些特殊的方法, 例如parseText&lt;/code&gt;, parseFile等.下面这个例子中我们使用了parseText 方法, 它会解析一个JSON字符串, 然后递归地将它转换成list, map结构. 一些其他的`parse* 方法和这个方法很类似, 都返回了JSON字符串, 只不过其他的方法接受的参数不一样. 12345def jsonSlurper = new JsonSlurper()def object = jsonSlurper.parseText(&#x27;&#123; &quot;name&quot;: &quot;John Doe&quot; &#125; /* some comment */&#x27;)assert object instanceof Mapassert object.name == &#x27;John Doe&#x27; 需要注意的是, 产生的结果是一个纯map, 可以像一个普通的Groovy对象实例持有它. JsonSlurper根据ECMA-404 JSON Interchange Standard定义来解析JSON, 同时支持JavaScript的注释和时间类型. 除了支持maps之外, JsonSlurper 还支持将JSON数组解析成list的功能 123456def jsonSlurper = new JsonSlurper()def object = jsonSlurper.parseText(&#x27;&#123; &quot;myList&quot;: [4, 8, 15, 16, 23, 42] &#125;&#x27;)assert object instanceof Mapassert object.myList instanceof Listassert object.myList == [4, 8, 15, 16, 23, 42] JSON标准上只支持下面这些原生数据类型：string&lt;/code&gt;, number, object&lt;/code&gt;, true, false&lt;/code&gt;, null. JsonSlurper 将那些JSON类型转换成Groovy类型. 1234567891011def jsonSlurper = new JsonSlurper()def object = jsonSlurper.parseText &#x27;&#x27;&#x27; &#123; &quot;simple&quot;: 123, &quot;fraction&quot;: 123.66, &quot;exponential&quot;: 123e12 &#125;&#x27;&#x27;&#x27;assert object instanceof Mapassert object.simple.class == Integerassert object.fraction.class == BigDecimalassert object.exponential.class == BigDecimal JsonSlurper 生成的结果就是纯Groovy对象实例, 她的内部不会包含任何的JSON相关的类对象, 它的用法是相当透明的. 事实上JsonSlurper的结果遵循GPath表达式. GPath是一个非常强大的表达式语言, 它支持多种不同的数据格式(例如XmlSlurper支持XML 就是其中一个例子) 如果想要了解更多的内容, 你可以直接去GPath expressions看一看.下面给出了JSON类型与Groovy数据类型之间的对应关系. 123456789JSON Groovystring java.lang.Stringnumber java.lang.BigDecimal or java.lang.Integerobject java.util.LinkedHashMaparray java.util.ArrayListtrue truefalse falsenull nulldate java.util.Date based on the yyyy-MM-dd’T’HH:mm:ssZ date format 如果JSON中的一个值是null&lt;/code&gt;, JsonSlurper支持它转换成Groovy中的null.这就与其他JSON解析器形成了对比, 代表一个空值与库提供的单一对象。 Parser VariantsGroovy 有多个JsonSlurper 解析器实现. 每一个解析器都对应着不同的需求, 每一个特定的解析都能很好的处理特定需求, 所以默认的解析器并不是适应于所有的情况. 下面就对各个解析器做个简介: JsonParserCharArray 解析器接受一个JSON字符串, 然后其内部使用一个字节数组进行解析. During value conversion it copies character sub-arrays (a mechanism known as “chopping”) and operates on them. JsonFastParser解析器是JsonParserCharArray解析器的变种, 它是最快的解析器. 尽管它是最快的,但是基于某些原因,它并不是默认的解析器. JsonFastParser解析器也被称为索引覆盖(index-overlay)解析器. 当解析给定JSON字符串的时候,该解析器会极力避免创建新的字节数组或者字符串实例. 它一直指向原生的字节数组。 另外, 它会尽可能的推迟对象的创建. If parsed maps are put into long-term caches care must be taken as the map objects might not be created and still consist of pointer to the original char buffer only. JsonFastParser采取了一种特殊的切割模型, 它会尽早地分割char buffer, 以便能维持一份对原生buffer比较小的拷贝. 如果你想使用JsonFastParser&lt;/code&gt;, 那么给你的建议是保持JsonFastParser`的JSON buffer在2MB左右, 而且时刻要保持长期缓存限制. JsonParserLax 是JsonFastParser的一个变种实现. 它与JsonFastParser 有一些相似的想能特点, 但是不同的是它不是仅仅依靠`ECMA-404 JSON grammar. 例如,在下面例子中它支持不带引号的字符串注释. JsonParserUsingCharacterSource 用于解析非常大的文件. 它使用一种称为\"character windowing\"的技术去解析非常大(超过2MB)的JSON文件,而且性能上也非常稳定 JsonSlurper的默认实现是 JsonParserCharArray&lt;/code&gt;. JsonParserType`包含了解析器种类的枚举类型: 12345Implementation ConstantJsonParserCharArray JsonParserType#CHAR_BUFFERJsonFastParser JsonParserType#INDEX_OVERLAYJsonParserLax JsonParserType#LAXJsonParserUsingCharacterSource JsonParserType#CHARACTER_SOURCE 如果想要改变解析器的实现也非常简单, 只需要通过调用JsonSlurper#setType()&lt;/code&gt;方法给JsonParserType`设置上不同的值就可以了 123456def jsonSlurper = new JsonSlurper(type: JsonParserType.INDEX_OVERLAY)def object = jsonSlurper.parseText(&#x27;&#123; &quot;myList&quot;: [4, 8, 15, 16, 23, 42] &#125;&#x27;)assert object instanceof Mapassert object.myList instanceof Listassert object.myList == [4, 8, 15, 16, 23, 42] JsonOutputJsonOutput用于将Groovy对象序列化成JSON字符串. JsonOutput 重载了toJson静态方法. 每个不同的toJson方法都会接受一个不同的参数类型. toJson方法返回的是一个包含JSOn格式的字符串 123def json = JsonOutput.toJson([name: &#x27;John Doe&#x27;, age: 42])assert json == &#x27;&#123;&quot;name&quot;:&quot;John Doe&quot;,&quot;age&quot;:42&#125;&#x27; JsonOutput不仅支持原生类型, map, list等类型序列化到JSON, 甚至还支持序列化`POGOs(一种比较老的Groovy对象) 12345class Person &#123; String name &#125;def json = JsonOutput.toJson([ new Person(name: &#x27;John&#x27;), new Person(name: &#x27;Max&#x27;) ])assert json == &#x27;[&#123;&quot;name&quot;:&quot;John&quot;&#125;,&#123;&quot;name&quot;:&quot;Max&quot;&#125;]&#x27; 刚才那个例子中, JSON输出默认没有进行pretty输出. 因此JsonSlurper还提供了prettyPrint方法 123456789def json = JsonOutput.toJson([name: &#x27;John Doe&#x27;, age: 42])assert json == &#x27;&#123;&quot;name&quot;:&quot;John Doe&quot;,&quot;age&quot;:42&#125;&#x27;assert JsonOutput.prettyPrint(json) == &#x27;&#x27;&#x27;\\&#123; &quot;name&quot;: &quot;John Doe&quot;, &quot;age&quot;: 42&#125;&#x27;&#x27;&#x27;.stripIndent() prettyPrint方法只接受一个String类型的字符串, 它不能和JsonOutput里其他的方式结合起来使用, it can be applied on arbitrary JSON String instances. 在Groovy中还可以使用JsonBuilder&lt;/code&gt;, StreamingJsonBuilder方式创建JSON. 这俩个构建起都提供了一个DSL, 当构建器生成一个JSON的时候,可以制定一个对象图. 123456789// an inclusive rangedef range = &#x27;a&#x27;..&#x27;d&#x27;assert range.size() == 4assert range.get(2) == &#x27;c&#x27;assert range[2] == &#x27;c&#x27;assert range instanceof java.util.Listassert range.contains(&#x27;a&#x27;)assert range.contains(&#x27;d&#x27;)assert !range.contains(&#x27;e&#x27;) You can iterate on a range using a classic for loop: 123for (i in 1..10) &#123; println &quot;Hello $&#123;i&#125;&quot;&#125; but alternatively you can achieve the same effect in a more Groovy idiomatic style, by iterating a range with each method: 123(1..10).each &#123; i -&gt; println &quot;Hello $&#123;i&#125;&quot;&#125; Ranges can be also used in the switch statement: 12345switch (years) &#123; case 1..10: interestRate = 0.076; break; case 11..25: interestRate = 0.052; break; default: interestRate = 0.037;&#125;","categories":[{"name":"Groovy","slug":"Groovy","permalink":"https://wangmingco.github.io/categories/Groovy/"}],"tags":[]},{"title":"Groovy ANT","slug":"编程语言/Groovy ANT","date":"2014-04-16T16:00:00.000Z","updated":"2021-11-18T02:27:47.812Z","comments":true,"path":"2014/04/17/编程语言/Groovy ANT/","link":"","permalink":"https://wangmingco.github.io/2014/04/17/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Groovy%20ANT/","excerpt":"","text":"本文是对Groovy部分官方文档进行了翻译 虽然Ant只是一个构建工具, 但其提供了例如能够操作文件(包括zip文件), 拷贝, 资源管理等诸多实用功能. 然而如果你不喜欢使用build.xml文件或者Jelly脚本, 而是想要一种清晰简洁的构建方式, 那么你就可以试试使用Groovy编写构建过程. Groovy提供了一个辅助类AntBuilder帮忙编写Ant构建任务. 它看起来很像一个不带尖括号的Ant’s XML的简洁版本. 因此你可以在脚本中混合和匹配标记. Ant本身是一组Jar文件的集合. 将这组jar文件添加到你的classpath上, 你就可以在Groovy中轻轻松松的使用它们. AntBuilder通过便捷的构造器语法直接暴露了Ant task. 下面是一个简单的示例, 它的功能是在标准输出上输出一条消息. 12def ant = new AntBuilder() ant.echo(&#x27;hello from Ant!&#x27;) 创建一个AntBuilder实例 执行AntBuilder实例的echo task 假设,现在你需要创建一个ZIP文件： 12def ant = new AntBuilder()ant.zip(destfile: &#x27;sources.zip&#x27;, basedir: &#x27;src&#x27;) 在下面的例子中, 我们将展示在Groovy中使用传统的Ant 模式通过AntBuilder拷贝一组文件. 12345678910111213141516171819// lets just call one taskant.echo(&quot;hello&quot;)// here is an example of a block of Ant inside GroovyMarkupant.sequential &#123; echo(&quot;inside sequential&quot;) def myDir = &quot;target/AntTest/&quot; mkdir(dir: myDir) copy(todir: myDir) &#123; fileset(dir: &quot;src/test&quot;) &#123; include(name: &quot;**/*.groovy&quot;) &#125; &#125; echo(&quot;done&quot;)&#125;// now lets do some normal Groovy againdef file = new File(ant.project.baseDir,&quot;target/AntTest/groovy/util/AntTest.groovy&quot;)assert file.exists() 下面的例子是遍历一组文件, 然后将每个文件根据特殊模式进行匹配. 12345678910111213141516// lets create a scanner of filesetsdef scanner = ant.fileScanner &#123; fileset(dir:&quot;src/test&quot;) &#123; include(name:&quot;**/Ant*.groovy&quot;) &#125;&#125;// now lets iterate overdef found = falsefor (f in scanner) &#123; println(&quot;Found file $f&quot;) found = true assert f instanceof File assert f.name.endsWith(&quot;.groovy&quot;)&#125;assert found Or execute a JUnit test: 下面我们执行JUnit 1234// lets create a scanner of filesetsant.junit &#123; test(name:&#x27;groovy.util.SomethingThatDoesNotExist&#x27;)&#125; 现在, 让我们的步子迈地更大一点：在Groovy中编译然后执行一个Java文件. 12345678910ant.echo(file:&#x27;Temp.java&#x27;, &#x27;&#x27;&#x27; class Temp &#123; public static void main(String[] args) &#123; System.out.println(&quot;Hello&quot;); &#125; &#125;&#x27;&#x27;&#x27;)ant.javac(srcdir:&#x27;.&#x27;, includes:&#x27;Temp.java&#x27;, fork:&#x27;true&#x27;)ant.java(classpath:&#x27;.&#x27;, classname:&#x27;Temp&#x27;, fork:&#x27;true&#x27;)ant.echo(&#x27;Done&#x27;) 需要提及的是, AntBuilder是内嵌于Gradle中的. 你可以像在Groovy中那样, 在Gradle使用AntBuilder","categories":[{"name":"Groovy","slug":"Groovy","permalink":"https://wangmingco.github.io/categories/Groovy/"}],"tags":[]},{"title":"Groovy 字符串","slug":"编程语言/Groovy 字符串","date":"2014-04-15T16:00:00.000Z","updated":"2021-11-18T02:27:44.863Z","comments":true,"path":"2014/04/16/编程语言/Groovy 字符串/","link":"","permalink":"https://wangmingco.github.io/2014/04/16/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Groovy%20%E5%AD%97%E7%AC%A6%E4%B8%B2/","excerpt":"","text":"本文是对Groovy部分官方文档进行了翻译 在Groovy文本字面量被称为String,这是以字符链的形式出现的. Groovy允许你实例化java.lang.String,像 GStrings (groovy.lang.GString)那样, (GString还被称为插值字符串) 单引号字符单引号字符串是通过单引号括起来的一列字符 1&#x27;a single quoted string&#x27; 单引号字符和java.lang.String是同一个东西, 同时它也不允许插值的出现 字符串连接Groovy里所有的字符串都可以通过 + 连接起来 1assert &#x27;ab&#x27; == &#x27;a&#x27; + &#x27;b&#x27; 三重单引号字符串三重单引号字符串 是通过三个单引号 包围起来的字符序列. 1&#x27;&#x27;&#x27;a triple single quoted string&#x27;&#x27;&#x27; 三重单引号字符串就是纯java.lang.String 而且不允许插值.三重单引号字符串可以多行赋值. 123def aMultilineString = &#x27;&#x27;&#x27;line oneline twoline three&#x27;&#x27;&#x27; 如果你的代码进行了缩进, 例如类中的方法体, 那跨行的三重单引号字符串也会包含缩进. 不过可以调用String#stripIndent() 去除掉缩进. String#stripMargin()方法会通过分割符从字符串的开头 12345def startingAndEndingWithANewline = &#x27;&#x27;&#x27;line oneline twoline three&#x27;&#x27;&#x27; 你也许会注意到最终得到的字符串会包含一个换行符.It is possible to strip that character by escaping the newline with a backslash: 1234567def strippedFirstNewline = &#x27;&#x27;&#x27;\\line oneline twoline three&#x27;&#x27;&#x27;assert !strippedFirstNewline.startsWith(&#x27;\\n&#x27;) 更换特殊字符可以通过\\字符在&#39;&#39;继续引用&#39; 1&#x27;an escaped single quote: \\&#x27; needs a backslash&#x27; 当然也可以通过\\来引用它自身 1&#x27;an escaped escape character: \\\\ needs a double backslash&#x27; 还有一些其他的特殊字符需要\\来引用 123456789Escape sequence Character&#x27;\\t&#x27; tabulation&#x27;\\b&#x27; backspace&#x27;\\n&#x27; newline&#x27;\\r&#x27; carriage return&#x27;\\f&#x27; formfeed&#x27;\\\\&#x27; backslash&#x27;\\&#x27;&#x27; single quote (for single quoted and triple single quoted strings)&#x27;\\&quot;&#x27; double quote (for double quoted and triple double quoted strings) Unicode 转义序列有一些字符并不能通过键盘输出, 那么此时就可以通过Unicode 转义序列来实现. 例如backslash, 在u后跟4个16进制数字即可. 1&#x27;The Euro currency symbol: \\u20AC&#x27; 双引号包含的 string通过双引号包括起来的字符串 1&quot;a double quoted string&quot; 当双引号字符串内没有插值($&#123;&#125;)的时候, 那它就等同于java.lang.String, 当有插值的时候那么双引号字符串就是groovy.lang.GString的实例 String 插值任何表达式都可以嵌入到除了单引号和三引号的所有字符串常量中. 当对字符串求值的时候, 插值会使用他的值来替换掉字符串里的占位符. 占位符表达式通过$&#123;&#125; 或者 $来实现. 占位符里的表达式值会被转换成其字符串表示形式, 转换是通过调用表达式toString()方法,通过传递一个String参数. 下面的例子展示的是字符串里的占位符定位本地变量 1234def name = &#x27;Guillaume&#x27; // a plain stringdef greeting = &quot;Hello $&#123;name&#125;&quot;assert greeting.toString() == &#x27;Hello Guillaume&#x27; 但是并非所有的表达式都是合法的, 像下面我们列举的这个算术表达式 12def sum = &quot;The sum of 2 and 3 equals $&#123;2 + 3&#125;&quot;assert sum.toString() == &#x27;The sum of 2 and 3 equals 5&#x27; 其实并不是只有表达式允许出现在$&#123;&#125;表达式里. Statements 同样可以在$&#123;&#125; 占位符里出现, 但是statement的值会是null. 如果有N个statements出现在$&#123;&#125;里,那么最后一个statement应该返回一个有效值,以便被插入到字符串里. 例如&quot;The sum of 1 and 2 is equal to $&#123;def a = 1; def b = 2; a + b&#125;&quot; 是允许的,而且也会像语法预期的那样执行, 但是习惯上,GString 占位符里应该更多的是使用简单表达式.除了 $&#123;&#125;占位符之外, 我们也可以使用$标记前缀点缀表达式： 12def person = [name: &#x27;Guillaume&#x27;, age: 36]assert &quot;$person.name is $person.age years old&quot; == &#x27;Guillaume is 36 years old&#x27; 但是仅仅一下形式的点缀表达式是合法的：a.b, a.b.c,etc.但是那些包含括号的表达式(例如方法调用,花括号为闭包,算术运算符)是无效的.下面给出了一个定义成数字形式的变量. 1def number = 3.14 下面的 statement 将会抛出一个groovy.lang.MissingPropertyException 异常,因为Groovy认为你正在尝试访问那个数字的不存在的toString属性. 123shouldFail(MissingPropertyException) &#123; println &quot;$number.toString()&quot;&#125; 你可以理解成解析器会将&quot;$number.toString()&quot; 解释成 &quot;$&#123;number.toString&#125;()&quot;.如果你想要在GString中避免$或者$&#123;&#125; 称为插值的话,只需要在它们前面加上\\即可. 1assert &#x27;$&#123;name&#125;&#x27; == &quot;\\$&#123;name&#125;&quot; 特殊插值形式-闭包表达式到目前为止,我们看到可以在${}占位符里插入任何的表达式, 但还有一种特殊的表达式-闭包表达式. 当占位符内好汉一个箭头时$&#123;→&#125;,这个表达式实际上就是一个闭包表达式. 12345def sParameterLessClosure = &quot;1 + 2 == $&#123;-&gt; 3&#125;&quot; (1)assert sParameterLessClosure == &#x27;1 + 2 == 3&#x27;def sOneParamClosure = &quot;1 + 2 == $&#123; w -&gt; w &lt;&lt; 3&#125;&quot; (2)assert sOneParamClosure == &#x27;1 + 2 == 3&#x27; 由于闭包不用声明参数, 所以在使用闭包时,我们不必对其传参 上例中,闭包中使用了一个java.io.StringWriter argument参数, 我们可以使用&lt;&lt;操作符添加内容.不论任何情况, 占位符都被嵌入了闭包. 上面的表达式看起来更像是使用了一个啰嗦的方式去定义插值表达式, 但是闭包有个有趣又高级的特性：惰性计算: 12345678910def number = 1 (1)def eagerGString = &quot;value == $&#123;number&#125;&quot;def lazyGString = &quot;value == $&#123; -&gt; number &#125;&quot;assert eagerGString == &quot;value == 1&quot; (2)assert lazyGString == &quot;value == 1&quot; (3)number = 2 (4)assert eagerGString == &quot;value == 1&quot; (5)assert lazyGString == &quot;value == 2&quot; (6) 我们定义了数值为1的number类型变量, 它稍后会作为插值出现在俩个GString中, 我们希望eagerGString 产生的字符串包含着相同的值 1 同样我们也希望lazyGString 产生的字符串包含着相同的值 1 然后我们将number改变一个值. With a plain interpolated expression, the value was actually bound at the time of creation of the GString. But with a closure expression, the closure is called upon each coercion of the GString into String, resulting in an updated string containing the new number value. An embedded closure expression taking more than one parameter will generate an exception at runtime. Only closures with zero or one parameters are allowed. Inteoperability with Java当一个方法(不管是在Java还是在Groovy中定义的)带有一个java.lang.String参数, 但我们传递一个groovy.lang.GString instance实例, GString会自动调用toString()方法. 1234567891011String takeString(String message) &#123; (4) assert message instanceof String (5) return message&#125;def message = &quot;The message is $&#123;&#x27;hello&#x27;&#125;&quot; (1)assert message instanceof GString (2)def result = takeString(message) (3)assert result instanceof Stringassert result == &#x27;The message is hello&#x27; 首先我们创建一个GString变量 然后我们检查一下声明的变量是否是GString的实例 接着我们向一个方法(参数为String类型)传递GString类型变量 takeString()显式地指出了它唯一的参数为String 我们再次验证所需的参数是String 而不是GString GString and String hashCodes尽管插值字符串能被用来代替Java strings, 但是他们在某些地方并不是完全一样的—— 他们的hashCodes是不同的. Java Strig是immutable, 然而, GString通过它的内插值 生成的字符串是可以改变的. 即使生成完全一样的字符串, GStrings 和 Strings的 hashCode 仍然是不一样的. 1assert &quot;one: $&#123;1&#125;&quot;.hashCode() != &quot;one: 1&quot;.hashCode() GString 和 Strings 拥有不同的hashCode值, 在Map中应该避免使用GString作为key, 特别的,当我们想要检索值的之后应该使用String,而不是GString. 1234def key = &quot;a&quot;def m = [&quot;$&#123;key&#125;&quot;: &quot;letter $&#123;key&#125;&quot;] (1)assert m[&quot;a&quot;] == null (2) map使用一对键值被创建了出来,其key是GString类型 当我们通过一个String类型的key进行检索值的时候,我们会得到一个null的结果, 产生这样的现象正是由于String和GString拥有不同的hashCode Triple double quoted string三重双引号字符串其使用和双引号字符串及其相像, 但与双引号字符串不同的一点是：它们是可以换行的(像三重单引号字符串那样) 123456789101112def name = &#x27;Groovy&#x27;def template = &quot;&quot;&quot; Dear Mr $&#123;name&#125;, You&#x27;re the winner of the lottery! Yours sincerly, Dave&quot;&quot;&quot;assert template.toString().contains(&#x27;Groovy&#x27;) 在三重双引号字符串中,不管是双引号还是单引号都不需要escaped Slashy string除了引号字符串, Groovy还提供了slashy字符串(使用/作为分隔符). Slashy字符串对定义正则表达式和正则模式是非常有用的. 12def fooPattern = /.*foo.*/assert fooPattern == &#x27;.*foo.*&#x27; 只有在/ slashes中需要使用\\ 来escaped 12def escapeSlash = /The character \\/ is a forward slash/assert escapeSlash == &#x27;The character / is a forward slash&#x27; Slashy字符串也可以是多行的 12345def multilineSlashy = /one two three/assert multilineSlashy.contains(&#x27;\\n&#x27;) Slashy字符串也可以插值形式出现(像GString一样) 1234def color = &#x27;blue&#x27;def interpolatedSlashy = /a $&#123;color&#125; car/assert interpolatedSlashy == &#x27;a blue car&#x27; 下面有一些常识方面的东西需要你知道：//不会被解释为空Slashy字符串,这代表着行注释. 1assert &#x27;&#x27; == // Dollar slashy stringDollar slashy字符串 通过$/``/$ 来实现多行GString. 美元符作为转义字符, 而且它还能转义另一个美元符号, 或者一个 forward slash. 除了要实现像GString占位符和闭包美元符slashy的开头美元符之外, 美元符和forward slashes都不需要转义 1234567891011121314151617181920212223242526def name = &quot;Guillaume&quot;def date = &quot;April, 1st&quot;def dollarSlashy = $/ Hello $name, today we&#x27;re $&#123;date&#125;. $ dollar sign $$ escaped dollar sign \\ backslash / forward slash $/ escaped forward slash $/$ escaped dollar slashy string delimiter/$assert [ &#x27;Guillaume&#x27;, &#x27;April, 1st&#x27;, &#x27;$ dollar sign&#x27;, &#x27;$ escaped dollar sign&#x27;, &#x27;\\\\ backslash&#x27;, &#x27;/ forward slash&#x27;, &#x27;$/ escaped forward slash&#x27;, &#x27;/$ escaped dollar slashy string delimiter&#x27; ].each &#123; dollarSlashy.contains(it) &#125; Characters不像java, Groovy里没有显式的字符字面量. 可以通过下面三种方式,显式地生成Groovy 字符变量 12345678char c1 = &#x27;A&#x27; (1)assert c1 instanceof Characterdef c2 = &#x27;B&#x27; as char (2)assert c2 instanceof Characterdef c3 = (char)&#x27;C&#x27; (3)assert c3 instanceof Character 通过指定char类型来显式地声明一个character变量 通过操作符强制转换类型 通过强制转换成指定类型","categories":[{"name":"Groovy","slug":"Groovy","permalink":"https://wangmingco.github.io/categories/Groovy/"}],"tags":[]},{"title":"Groovy 数字","slug":"编程语言/Groovy 数字","date":"2014-04-14T16:00:00.000Z","updated":"2021-11-18T02:27:41.201Z","comments":true,"path":"2014/04/15/编程语言/Groovy 数字/","link":"","permalink":"https://wangmingco.github.io/2014/04/15/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Groovy%20%E6%95%B0%E5%AD%97/","excerpt":"","text":"本文是对Groovy部分官方文档进行了翻译 Groovy支持多种不同的整数字面量和小数字面量 (通过依靠Java数字类型实现) Integral literalsThe integral literal types are the same as in Java: 证书类型变量和Java里的一样 byte char short int long java.lang.BigInteger You can create integral numbers of those types with the following declarations: 可以通过以下声明方式创建整数类型变量 123456789// primitive typesbyte b = 1char c = 2short s = 3int i = 4long l = 5// infinite precisionBigInteger bi = 6 如果使用def关键字, 整型类型会发生改变：它会自动适配成能够存储number类型的类型 123456789101112131415161718def a = 1assert a instanceof Integer// Integer.MAX_VALUEdef b = 2147483647assert b instanceof Integer// Integer.MAX_VALUE + 1def c = 2147483648assert c instanceof Long// Long.MAX_VALUEdef d = 9223372036854775807assert d instanceof Long// Long.MAX_VALUE + 1def e = 9223372036854775808assert e instanceof BigInteger As well as for negative numbers: 123456789101112131415161718def na = -1assert na instanceof Integer// Integer.MIN_VALUEdef nb = -2147483648assert nb instanceof Integer// Integer.MIN_VALUE - 1def nc = -2147483649assert nc instanceof Long// Long.MIN_VALUEdef nd = -9223372036854775808assert nd instanceof Long// Long.MIN_VALUE - 1def ne = -9223372036854775809assert ne instanceof BigInteger Alternative non-base 10 representationsBinary literal在Java6以前和Groovy中,number类型可以是小数, 8进制和16进制. 但是在Java7和Groovy2中,可以使用0b前缀表示二进制数据. 1234567891011121314151617int xInt = 0b10101111assert xInt == 175short xShort = 0b11001001assert xShort == 201 as shortbyte xByte = 0b11assert xByte == 3 as bytelong xLong = 0b101101101101assert xLong == 2925lBigInteger xBigInteger = 0b111100100001assert xBigInteger == 3873gint xNegativeInt = -0b10101111assert xNegativeInt == -175 Octal literal8进制的电话,只需要开头是0后跟要表示的8进制数即可. 1234567891011121314151617int xInt = 077assert xInt == 63short xShort = 011assert xShort == 9 as shortbyte xByte = 032assert xByte == 26 as bytelong xLong = 0246assert xLong == 166lBigInteger xBigInteger = 01111assert xBigInteger == 585gint xNegativeInt = -077assert xNegativeInt == -63 Hexadecimal literalHexadecimal numbers are specified in the typical format of 0x followed by hex digits. 16进制的电话,只需要开头是0x后跟要表示的16进制数即可. 123456789101112131415161718192021int xInt = 0x77assert xInt == 119short xShort = 0xaaassert xShort == 170 as shortbyte xByte = 0x3aassert xByte == 58 as bytelong xLong = 0xffffassert xLong == 65535lBigInteger xBigInteger = 0xaaaaassert xBigInteger == 43690gDouble xDouble = new Double(&#x27;0x1.0p0&#x27;)assert xDouble == 1.0dint xNegativeInt = -0x77assert xNegativeInt == -119 Decimal literals小数字面量和在java 里一样 float double java.lang.BigDecimal 可以通过下面的方式创建小数类型的number 123456// primitive typesfloat f = 1.234double d = 2.345// infinite precisionBigDecimal bd = 3.456 Decimals can use exponents, with the e or E exponent letter, followed by an optional sign, and a integral number representing the exponent: 12345assert 1e3 == 1_000.0assert 2E4 == 20_000.0assert 3e+1 == 30.0assert 4E-2 == 0.04assert 5e-1 == 0.5 Conveniently for exact decimal number calculations, Groovy choses java.lang.BigDecimal as its decimal number type. In addition, both float and double are supported, but require an explicit type declaration, type coercion or suffix. Even if BigDecimal is the default for decimal numbers, such literals are accepted in methods or closures taking float or double as parameter types. Decimal numbers can’t be represented using a binary, octal or hexadecimal representation. Underscore in literalsWhen writing long literal numbers, it’s harder on the eye to figure out how some numbers are grouped together, for example with groups of thousands, of words, etc. By allowing you to place underscore in number literals, it’s easier to spot those groups: 12345678long creditCardNumber = 1234_5678_9012_3456Llong socialSecurityNumbers = 999_99_9999Ldouble monetaryAmount = 12_345_132.12long hexBytes = 0xFF_EC_DE_5Elong hexWords = 0xFFEC_DE5Elong maxLong = 0x7fff_ffff_ffff_ffffLlong alsoMaxLong = 9_223_372_036_854_775_807Llong bytes = 0b11010010_01101001_10010100_10010010 Number type suffixes我们可以通过添加后缀的方式强制指定一个数字的类型(包含二进制,八进制和十六进制) 1234567Type SuffixBigInteger G or gLong L or lInteger I or iBigDecimal G or gDouble D or dFloat F or f 12345678910111213assert 42I == new Integer(&#x27;42&#x27;)assert 42i == new Integer(&#x27;42&#x27;) // lowercase i more readableassert 123L == new Long(&quot;123&quot;) // uppercase L more readableassert 2147483648 == new Long(&#x27;2147483648&#x27;) // Long type used, value too large for an Integerassert 456G == new BigInteger(&#x27;456&#x27;)assert 456g == new BigInteger(&#x27;456&#x27;)assert 123.45 == new BigDecimal(&#x27;123.45&#x27;) // default BigDecimal type usedassert 1.200065D == new Double(&#x27;1.200065&#x27;)assert 1.234F == new Float(&#x27;1.234&#x27;)assert 1.23E23D == new Double(&#x27;1.23E23&#x27;)assert 0b1111L.class == Long // binaryassert 0xFFi.class == Integer // hexadecimalassert 034G.class == BigInteger // octal Math operations尽管接下来我们还要详细讨论操作符, 但是鉴于数学操作符的重要性, 现在我们还是要先讨论其行为和返回类型 byte, char, short 和 int 之间的二进制计算返回的是int类型 byte, char, short 和 int 之间的二进制计算中涉及到long的话, 那么返回的就是long类型 BigInteger 与任何整数类型的二进制计算 返回的结果都是BigInteger类型 float, double 和 BigDecimal 之间的二进制计算返回的结果都是double类型 俩个BigDecimal之间的二进制运算返回的都是BigDecimal类型. 由于Groovy提供了操作符重载功能, BigInteger和BigDecimal之间的算术运算也得以实现, 但是在Java中需要调用一些方法才能计算这些不同类型的数字. The case of the power operatorGroovy 里有一种强大的操作符**, 这个操作符带有base和exponent俩个参数. 这个操作符的结果依赖于它的操作数和操作结果.Groovy使用下面的规则来决定该操作符的返回类型 如果exponent为小数类型1231. 如果结果能表示为Integer类型,那就返回Integer类型2. 否则如果结果能表示为Long类型,那就返回Long类型3. 否则的话就返回Double 如果exponent为整数类型1234561. 如果exponent负数负数, 那就返回Integer, Long 或者Double,2. 如果exponent是正数或者0, 那就要根据base来判断了 A. 如果base是 BigDecimal, 那就返回BigDecimal类型 B. 如果base是 BigInteger, 那就返回BigInteger类型 C. 如果base是 Integer, 那就返回Integer类型, 如果返回的值超过Integer范围的话,就返回BigInteger D. 如果base是 Long, 那就返回Long类型, 如果返回的值超过Long范围的话,就返回BigInteger 示例12345678910111213141516171819202122232425262728293031323334353637// base and exponent are ints and the result can be represented by an Integerassert 2 ** 3 instanceof Integer // 8assert 10 ** 9 instanceof Integer // 1_000_000_000// the base is a long, so fit the result in a Long// (although it could have fit in an Integer)assert 5L ** 2 instanceof Long // 25// the result can&#x27;t be represented as an Integer or Long, so return a BigIntegerassert 100 ** 10 instanceof BigInteger // 10e20assert 1234 ** 123 instanceof BigInteger // 170515806212727042875...// the base is a BigDecimal and the exponent a negative int// but the result can be represented as an Integerassert 0.5 ** -2 instanceof Integer // 4// the base is an int, and the exponent a negative float// but again, the result can be represented as an Integerassert 1 ** -0.3f instanceof Integer // 1// the base is an int, and the exponent a negative int// but the result will be calculated as a Double// (both base and exponent are actually converted to doubles)assert 10 ** -1 instanceof Double // 0.1// the base is a BigDecimal, and the exponent is an int, so return a BigDecimalassert 1.2 ** 10 instanceof BigDecimal // 6.1917364224// the base is a float or double, and the exponent is an int// but the result can only be represented as a Double valueassert 3.4f ** 5 instanceof Double // 454.35430372146965assert 5.6d ** 2 instanceof Double // 31.359999999999996// the exponent is a decimal value// and the result can only be represented as a Double valueassert 7.8 ** 1.9 instanceof Double // 49.542708423868476assert 2 ** 0.1f instanceof Double // 1.0717734636432956 BooleansBoolean是一种特殊的数据类型, 他们的值只有俩种情况：true 和 false. 123def myBooleanVariable = trueboolean untypedBooleanVar = falsebooleanField = true true and false are the only two primitive boolean values. But more complex boolean expressions can be represented using logical operators. In addition, Groovy has special rules (often referred to as Groovy Truth) for coercing non-boolean objects to a boolean value.","categories":[{"name":"Groovy","slug":"Groovy","permalink":"https://wangmingco.github.io/categories/Groovy/"}],"tags":[]},{"title":"Groovy 集合","slug":"编程语言/Groovy 集合","date":"2014-04-10T16:00:00.000Z","updated":"2021-11-18T02:27:50.983Z","comments":true,"path":"2014/04/11/编程语言/Groovy 集合/","link":"","permalink":"https://wangmingco.github.io/2014/04/11/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Groovy%20%E9%9B%86%E5%90%88/","excerpt":"","text":"本文是对Groovy部分官方文档进行了翻译 Groovy 语言层面上就支持多种集合类型,包括list, map, range. 大多数类型集合都是基于java的集合框架,而且Groovy development kit对这些集合内置很多快捷方法. ListsGroovy使用了一种被[]括起来,值通过,分割的语法 定义list. Groovy list 采用的是 JDK里java.util.List的实现, 因为它自身并没有定义自己的集合类.Groovy list 的默认实现是java.util.ArrayList, 在后面我们可以看到其他形式的list 1234def numbers = [1, 2, 3] (1)assert numbers instanceof List (2)assert numbers.size() == 3 (3) 我们定义了一个Number类型的List,然后将这个list分配给一个变量 判断list是 Java’s java.util.List interface 的实例 list的大小可以通过size()来进行查询, 例子中也给我们展示了这个list确实包含3个元素 在上面的list中,我们使用的是同类元素的list, 但其实Groovy list中的数据类型还可以不一样： 1def heterogeneous = [1, &quot;a&quot;, true] (1) 我们定义了一个包含有number,string,boolean 三个类型的list 在上面我们提到过, list实际上是java.util.ArrayList实例, 但其实list还可以是其他不同类型的实例, 下面我们通过操作符或者显式类型声明来强制指定 list使用不同的List实现 12345678def arrayList = [1, 2, 3]assert arrayList instanceof java.util.ArrayListdef linkedList = [2, 3, 4] as LinkedList (1)assert linkedList instanceof java.util.LinkedListLinkedList otherLinked = [3, 4, 5] (2)assert otherLinked instanceof java.util.LinkedList 我们使用操作符强制将类型显式地声明为java.util.LinkedList 我们使用显式声明方式, 将list声明为java.util.LinkedList 我们可以通过[]下标操作符来访问list中的元素(读写都可以). 下标既如果是正数的话,那就从左到右访问元素, 如果下标是负数那就从右到左访问元素. 我们好可以使用&lt;&lt;操作符向list里追加元素 1234567891011121314151617def letters = [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;]assert letters[0] == &#x27;a&#x27; (1)assert letters[1] == &#x27;b&#x27;assert letters[-1] == &#x27;d&#x27; (2)assert letters[-2] == &#x27;c&#x27;letters[2] = &#x27;C&#x27; (3)assert letters[2] == &#x27;C&#x27;letters &lt;&lt; &#x27;e&#x27; (4)assert letters[ 4] == &#x27;e&#x27;assert letters[-1] == &#x27;e&#x27;assert letters[1, 3] == [&#x27;b&#x27;, &#x27;d&#x27;] (5)assert letters[2..4] == [&#x27;C&#x27;, &#x27;d&#x27;, &#x27;e&#x27;] (6) 访问第一个元素(从这可以看出,list的下标是从0开始的) 通过-1 下标访问list中的最后一个元素. 使用下标对list中第三个元素重新赋值 使用&lt;&lt;向list尾部添加一个元素 一次性访问list中俩个元素,这个操作的结果是返回一个包含俩个元素的新的list 使用值域符来访问list中一定范围内的值. 由于list支持多种不同类型的元素, 那么list中也可以包含list,这样就可以制造出多维list 12def multi = [[0, 1], [2, 3]] (1)assert multi[1][0] == 2 (2) 定义了一个包含Number类型list的list 访问外层的第二个元素(第二个list), 然后访问内部list的第一个元素(第二个list的第一个元素) List literals你可以像下面这样创建集合, 注意[]是空集合表达式. 123456789def list = [5, 6, 7, 8]assert list.get(2) == 7assert list[2] == 7assert list instanceof java.util.Listdef emptyList = []assert emptyList.size() == 0emptyList.add(5)assert emptyList.size() == 1 每一个list表达式都是实现自java.util.List 当然list也可以指定其具体的实现类型 123456789def list1 = [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;]//construct a new list, seeded with the same items as in list1def list2 = new ArrayList&lt;String&gt;(list1)assert list2 == list1 // == checks that each corresponding element is the same// clone() can also be calleddef list3 = list1.clone()assert list3 == list1 list本质上是一个有序的对象集合. 12345678910111213141516171819202122232425262728def list = [5, 6, 7, 8]assert list.size() == 4assert list.getClass() == ArrayList // the specific kind of list being usedassert list[2] == 7 // indexing starts at 0assert list.getAt(2) == 7 // equivalent method to subscript operator []assert list.get(2) == 7 // alternative methodlist[2] = 9assert list == [5, 6, 9, 8,] // trailing comma OKlist.putAt(2, 10) // equivalent method to [] when value being changedassert list == [5, 6, 10, 8]assert list.set(2, 11) == 10 // alternative method that returns old valueassert list == [5, 6, 11, 8]assert [&#x27;a&#x27;, 1, &#x27;a&#x27;, &#x27;a&#x27;, 2.5, 2.5f, 2.5d, &#x27;hello&#x27;, 7g, null, 9 as byte]//objects can be of different types; duplicates allowedassert [1, 2, 3, 4, 5][-1] == 5 // use negative indices to count from the endassert [1, 2, 3, 4, 5][-2] == 4assert [1, 2, 3, 4, 5].getAt(-2) == 4 // getAt() available with negative index...try &#123; [1, 2, 3, 4, 5].get(-2) // but negative index not allowed with get() assert false&#125; catch (e) &#123; assert e instanceof ArrayIndexOutOfBoundsException&#125; List as a boolean expressionlist还可以计算出boolean表达式. 1234assert ![] // an empty list evaluates as false//all other lists, irrespective of contents, evaluate as trueassert [1] &amp;&amp; [&#x27;a&#x27;] &amp;&amp; [0] &amp;&amp; [0.0] &amp;&amp; [false] &amp;&amp; [null] Iterating on a list可以通过each, eachWithIndex遍历整个集合. 123456[1, 2, 3].each &#123; println &quot;Item: $it&quot; // `it` is an implicit parameter corresponding to the current element&#125;[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;].eachWithIndex &#123; it, i -&gt; // `it` is the current element, while `i` is the index println &quot;$i: $it&quot;&#125; 在遍历的时候,我们经常需要将遍历出来的值经过某些运算,然后再重新放进一个新的list中. 这种操作经常称为映射(mapping), 这种操作通过collect方法实现. 123456789assert [1, 2, 3].collect &#123; it * 2 &#125; == [2, 4, 6]// shortcut syntax instead of collectassert [1, 2, 3]*.multiply(2) == [1, 2, 3].collect &#123; it.multiply(2) &#125;def list = [0]// it is possible to give `collect` the list which collects the elementsassert [1, 2, 3].collect(list) &#123; it * 2 &#125; == [0, 2, 4, 6]assert list == [0, 2, 4, 6] Manipulating listsFiltering and searchingGroovy development kit提供了许多强大有趣的方法用来强化标准集合: 1234567891011121314151617181920212223242526272829303132333435assert [1, 2, 3].find &#123; it &gt; 1 &#125; == 2 // find 1st element matching criteriaassert [1, 2, 3].findAll &#123; it &gt; 1 &#125; == [2, 3] // find all elements matching critieriaassert [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;, &#x27;e&#x27;].findIndexOf &#123; // find index of 1st element matching criteria it in [&#x27;c&#x27;, &#x27;e&#x27;, &#x27;g&#x27;]&#125; == 2assert [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;, &#x27;c&#x27;].indexOf(&#x27;c&#x27;) == 2 // index returnedassert [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;, &#x27;c&#x27;].indexOf(&#x27;z&#x27;) == -1 // index -1 means value not in listassert [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;, &#x27;c&#x27;].lastIndexOf(&#x27;c&#x27;) == 4assert [1, 2, 3].every &#123; it &lt; 5 &#125; // returns true if all elements match the predicateassert ![1, 2, 3].every &#123; it &lt; 3 &#125;assert [1, 2, 3].any &#123; it &gt; 2 &#125; // returns true if any element matches the predicateassert ![1, 2, 3].any &#123; it &gt; 3 &#125;assert [1, 2, 3, 4, 5, 6].sum() == 21 // sum anything with a plus() methodassert [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;, &#x27;e&#x27;].sum &#123; it == &#x27;a&#x27; ? 1 : it == &#x27;b&#x27; ? 2 : it == &#x27;c&#x27; ? 3 : it == &#x27;d&#x27; ? 4 : it == &#x27;e&#x27; ? 5 : 0 // custom value to use in sum&#125; == 15assert [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;, &#x27;e&#x27;].sum &#123; ((char) it) - ((char) &#x27;a&#x27;) &#125; == 10assert [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;, &#x27;e&#x27;].sum() == &#x27;abcde&#x27;assert [[&#x27;a&#x27;, &#x27;b&#x27;], [&#x27;c&#x27;, &#x27;d&#x27;]].sum() == [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;]// an initial value can be providedassert [].sum(1000) == 1000assert [1, 2, 3].sum(1000) == 1006assert [1, 2, 3].join(&#x27;-&#x27;) == &#x27;1-2-3&#x27; // String joiningassert [1, 2, 3].inject(&#x27;counting: &#x27;) &#123; str, item -&gt; str + item // reduce operation&#125; == &#x27;counting: 123&#x27;assert [1, 2, 3].inject(0) &#123; count, item -&gt; count + item&#125; == 6 下面这段代码是由Groovy语言支撑的在集合中找到最大和最小数的例子: 1234567891011def list = [9, 4, 2, 10, 5]assert list.max() == 10assert list.min() == 2// we can also compare single characters, as anything comparableassert [&#x27;x&#x27;, &#x27;y&#x27;, &#x27;a&#x27;, &#x27;z&#x27;].min() == &#x27;a&#x27;// we can use a closure to specify the sorting behaviourdef list2 = [&#x27;abc&#x27;, &#x27;z&#x27;, &#x27;xyzuvw&#x27;, &#x27;Hello&#x27;, &#x27;321&#x27;]assert list2.max &#123; it.size() &#125; == &#x27;xyzuvw&#x27;assert list2.min &#123; it.size() &#125; == &#x27;z&#x27; 在闭包里,你还可以自定义一个比较规则. 1234567891011121314Comparator mc = &#123; a, b -&gt; a == b ? 0 : (a &lt; b ? -1 : 1) &#125;def list = [7, 4, 9, -6, -1, 11, 2, 3, -9, 5, -13]assert list.max(mc) == 11assert list.min(mc) == -13Comparator mc2 = &#123; a, b -&gt; a == b ? 0 : (Math.abs(a) &lt; Math.abs(b)) ? -1 : 1 &#125;assert list.max(mc2) == -13assert list.min(mc2) == -1assert list.max &#123; a, b -&gt; a.equals(b) ? 0 : Math.abs(a) &lt; Math.abs(b) ? -1 : 1 &#125; == -13assert list.min &#123; a, b -&gt; a.equals(b) ? 0 : Math.abs(a) &lt; Math.abs(b) ? -1 : 1 &#125; == -1 Adding or removing elements我们可以使用[]去声明一个新的空list, 然后使用&lt;&lt;向list追加元素 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849def list = []assert list.emptylist &lt;&lt; 5assert list.size() == 1list &lt;&lt; 7 &lt;&lt; &#x27;i&#x27; &lt;&lt; 11assert list == [5, 7, &#x27;i&#x27;, 11]list &lt;&lt; [&#x27;m&#x27;, &#x27;o&#x27;]assert list == [5, 7, &#x27;i&#x27;, 11, [&#x27;m&#x27;, &#x27;o&#x27;]]//first item in chain of &lt;&lt; is target listassert ([1, 2] &lt;&lt; 3 &lt;&lt; [4, 5] &lt;&lt; 6) == [1, 2, 3, [4, 5], 6]//using leftShift is equivalent to using &lt;&lt;assert ([1, 2, 3] &lt;&lt; 4) == ([1, 2, 3].leftShift(4))```groovyWe can add to a list in many ways:```groovyassert [1, 2] + 3 + [4, 5] + 6 == [1, 2, 3, 4, 5, 6]// equivalent to calling the `plus` methodassert [1, 2].plus(3).plus([4, 5]).plus(6) == [1, 2, 3, 4, 5, 6]def a = [1, 2, 3]a += 4 // creates a new list and assigns it to `a`a += [5, 6]assert a == [1, 2, 3, 4, 5, 6]assert [1, *[222, 333], 456] == [1, 222, 333, 456]assert [*[1, 2, 3]] == [1, 2, 3]assert [1, [2, 3, [4, 5], 6], 7, [8, 9]].flatten() == [1, 2, 3, 4, 5, 6, 7, 8, 9]def list = [1, 2]list.add(3)list.addAll([5, 4])assert list == [1, 2, 3, 5, 4]list = [1, 2]list.add(1, 3) // add 3 just before index 1assert list == [1, 3, 2]list.addAll(2, [5, 4]) //add [5,4] just before index 2assert list == [1, 3, 5, 4, 2]list = [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;z&#x27;, &#x27;e&#x27;, &#x27;u&#x27;, &#x27;v&#x27;, &#x27;g&#x27;]list[8] = &#x27;x&#x27; // the [] operator is growing the list as needed// nulls inserted if requiredassert list == [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;z&#x27;, &#x27;e&#x27;, &#x27;u&#x27;, &#x27;v&#x27;, &#x27;g&#x27;, null, &#x27;x&#x27;] 在list中+的语义并没有发生变化,这是何等的重要啊~~~ 与&lt;&lt;相比, +会创建一个新的list, 但是这个创建的list很可能不是你所预期的, 而且这种方式也可能会导致一些性能问题. Groovy development kit同样提供了很多便捷的方式从list里删除元素: 12345678assert [&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;,&#x27;b&#x27;,&#x27;b&#x27;] - &#x27;c&#x27; == [&#x27;a&#x27;,&#x27;b&#x27;,&#x27;b&#x27;,&#x27;b&#x27;]assert [&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;,&#x27;b&#x27;,&#x27;b&#x27;] - &#x27;b&#x27; == [&#x27;a&#x27;,&#x27;c&#x27;]assert [&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;,&#x27;b&#x27;,&#x27;b&#x27;] - [&#x27;b&#x27;,&#x27;c&#x27;] == [&#x27;a&#x27;]def list = [1,2,3,4,3,2,1]list -= 3 // creates a new list by removing `3` from the original oneassert list == [1,2,4,2,1]assert ( list -= [2,4] ) == [1,1] 同样,你也能通过索引的方式从list里删除元素. 123def list = [1,2,3,4,5,6,2,2,1]assert list.remove(2) == 3 // remove the third element, and return itassert list == [1,2,4,5,6,2,2,1] 假设,你如果从list中删除多个相同元素中的第一个, 那你可以调用remove方法. 123456def list= [&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;,&#x27;b&#x27;,&#x27;b&#x27;]assert list.remove(&#x27;c&#x27;) // remove &#x27;c&#x27;, and return true because element removedassert list.remove(&#x27;b&#x27;) // remove first &#x27;b&#x27;, and return true because element removedassert ! list.remove(&#x27;z&#x27;) // return false because no elements removedassert list == [&#x27;a&#x27;,&#x27;b&#x27;,&#x27;b&#x27;] 如果你想要将list清空的话,只需要调用clear方法即可 123def list= [&#x27;a&#x27;,2,&#x27;c&#x27;,4]list.clear()assert list == [] Set operationsGroovy development kit还包含很多逻辑运算的方法 12345678910111213assert &#x27;a&#x27; in [&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;] // returns true if an element belongs to the listassert [&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;].contains(&#x27;a&#x27;) // equivalent to the `contains` method in Javaassert [1,3,4].containsAll([1,4]) // `containsAll` will check that all elements are foundassert [1,2,3,3,3,3,4,5].count(3) == 4 // count the number of elements which have some valueassert [1,2,3,3,3,3,4,5].count &#123; it%2==0 // count the number of elements which match the predicate&#125; == 2assert [1,2,4,6,8,10,12].intersect([1,3,6,9,12]) == [1,6,12]assert [1,2,3].disjoint( [4,6,9] )assert ![1,2,3].disjoint( [2,4,6] ) SortingGroovy还提供了很多使用闭包比较器的排序操作 123456789101112131415161718192021222324assert [6, 3, 9, 2, 7, 1, 5].sort() == [1, 2, 3, 5, 6, 7, 9]def list = [&#x27;abc&#x27;, &#x27;z&#x27;, &#x27;xyzuvw&#x27;, &#x27;Hello&#x27;, &#x27;321&#x27;]assert list.sort &#123; it.size()&#125; == [&#x27;z&#x27;, &#x27;abc&#x27;, &#x27;321&#x27;, &#x27;Hello&#x27;, &#x27;xyzuvw&#x27;]def list2 = [7, 4, -6, -1, 11, 2, 3, -9, 5, -13]assert list2.sort &#123; a, b -&gt; a == b ? 0 : Math.abs(a) &lt; Math.abs(b) ? -1 : 1 &#125; == [-1, 2, 3, 4, 5, -6, 7, -9, 11, -13]Comparator mc = &#123; a, b -&gt; a == b ? 0 : Math.abs(a) &lt; Math.abs(b) ? -1 : 1 &#125;// JDK 8+ only// list2.sort(mc)// assert list2 == [-1, 2, 3, 4, 5, -6, 7, -9, 11, -13]def list3 = [6, -3, 9, 2, -7, 1, 5]Collections.sort(list3)assert list3 == [-7, -3, 1, 2, 5, 6, 9]Collections.sort(list3, mc)assert list3 == [1, 2, -3, 5, 6, -7, 9] Duplicating elementsroovy development kit还通过重载操作符的方式, 内部提供了一些方法进行list元素复制. 123456assert [1, 2, 3] * 3 == [1, 2, 3, 1, 2, 3, 1, 2, 3]assert [1, 2, 3].multiply(2) == [1, 2, 3, 1, 2, 3]assert Collections.nCopies(3, &#x27;b&#x27;) == [&#x27;b&#x27;, &#x27;b&#x27;, &#x27;b&#x27;]// nCopies from the JDK has different semantics than multiply for listsassert Collections.nCopies(2, [1, 2]) == [[1, 2], [1, 2]] //not [1,2,1,2] ArraysGroovy 数组重用了list符号, 但是如果想要创建数组, 那么就必须强制地显式定义数组类型 123456789String[] arrStr = [&#x27;Ananas&#x27;, &#x27;Banana&#x27;, &#x27;Kiwi&#x27;] (1)assert arrStr instanceof String[] (2)assert !(arrStr instanceof List)def numArr = [1, 2, 3] as int[] (3)assert numArr instanceof int[] (4)assert numArr.size() == 3 使用显式变量类型定义了一个字符串数组 断言刚才创建的数组是否是string类型 使用操作符定义一个int数组 断言刚才创建的数组是否是int类型 我们也可以创建出一个多维数组 123456def matrix3 = new Integer[3][3] (1)assert matrix3.size() == 3Integer[][] matrix2 (2)matrix2 = [[1, 2], [3, 4]]assert matrix2 instanceof Integer[][] 我们指定了新数组的边界 当然我们也可以不指定它的边界 访问数组元素和访问list元素的方式相同 12345String[] names = [&#x27;Cédric&#x27;, &#x27;Guillaume&#x27;, &#x27;Jochen&#x27;, &#x27;Paul&#x27;]assert names[0] == &#x27;Cédric&#x27; (1)names[2] = &#x27;Blackdrag&#x27; (2)assert names[2] == &#x27;Blackdrag&#x27; 1 Retrieve the first element of the array2 Set the value of the third element of the array to a new value 检索数组中第一个元素 对数组中第三个元素重新赋值 Groovy不支持Java数组初始化语法, 因为Java数组中的花括号可能被会Groovy无解成闭包 Maps有时候我们在其他语言中称map为 字典或者关联数组. Map将key和value关联起来, 在Groovy中map被[]括起来, 通过,分割键值对, 键值通过:分割 123456789101112def colors = [red: &#x27;#FF0000&#x27;, green: &#x27;#00FF00&#x27;, blue: &#x27;#0000FF&#x27;] (1)assert colors[&#x27;red&#x27;] == &#x27;#FF0000&#x27; (2)assert colors.green == &#x27;#00FF00&#x27; (3)colors[&#x27;pink&#x27;] = &#x27;#FF00FF&#x27; (4)colors.yellow = &#x27;#FFFF00&#x27; (5)assert colors.pink == &#x27;#FF00FF&#x27;assert colors[&#x27;yellow&#x27;] == &#x27;#FFFF00&#x27;assert colors instanceof java.util.LinkedHashMap 我们定义了一个string类型的代表颜色名字的数组, 然后使用下标来检索map中是否包含red这个key 我们还可以直接使用.来索引到某个key 我们可以使用下标向map中添加一个新的键值对 我们也可以使用.添加一个新的键值对 Groovy创建的map类型默认的是java.util.LinkedHashMap 当你想要访问一个不存在的key时： 1assert colors.unknown == null 你将检索出一个null的结果 在上面的例子中我们使用的是以string作为key, 但是你还可以使用其他类型作为map的key： 123def numbers = [1: &#x27;one&#x27;, 2: &#x27;two&#x27;]assert numbers[1] == &#x27;one&#x27; 我们使用了number作为了map新的key类型, number类型就会直接被解释为number类型, 因此Groovy不会像先前那样创建一个string类型的key. 但是假设你想要传递一个变量作为key,是变量的值作为key： 12345def key = &#x27;name&#x27;def person = [key: &#x27;Guillaume&#x27;] (1)assert !person.containsKey(&#x27;name&#x27;) (2)assert person.containsKey(&#x27;key&#x27;) (3) 与\\&#39;Guillaume&#39; 关联的key实际上是&quot;key&quot;这个字符串, 而不是这个key的引用值&#39;name&#39; map中不包含&#39;name&#39;key 取而代之的是map中包含一个&quot;key&quot;的字符串 你可以向map中传递一个引号字符串作为key,例如[&quot;name&quot;: &quot;Guillaume&quot;]. 1234person = [(key): &#x27;Guillaume&#x27;] (1)assert person.containsKey(&#x27;name&#x27;) (2)assert !person.containsKey(&#x27;key&#x27;) (3) 1 This time, we surround the key variable with parentheses, to instruct the parser we are passing a variable rather than defining a string key2 The map does contain the name key3 But the map doesn’t contain the key key as before1.2.3. Map literals在Groovy中可以使用[:] 创建一个map. 123456789101112def map = [name: &#x27;Gromit&#x27;, likes: &#x27;cheese&#x27;, id: 1234]assert map.get(&#x27;name&#x27;) == &#x27;Gromit&#x27;assert map.get(&#x27;id&#x27;) == 1234assert map[&#x27;name&#x27;] == &#x27;Gromit&#x27;assert map[&#x27;id&#x27;] == 1234assert map instanceof java.util.Mapdef emptyMap = [:]assert emptyMap.size() == 0emptyMap.put(&quot;foo&quot;, 5)assert emptyMap.size() == 1assert emptyMap.get(&quot;foo&quot;) == 5 Map的key默认是string, 例如[a:1]等同于[&#39;a&#39;:1]. 比较荣誉造成疑惑的就是,如果你创建了一个变量a(值为b), 但是你将变量aput进map后, map的key会是a,而不是b. 如果你遇到了这个情况的话,那么你必须对使用()key进行转义了. 1234567def a = &#x27;Bob&#x27;def ages = [a: 43]assert ages[&#x27;Bob&#x27;] == null // `Bob` is not foundassert ages[&#x27;a&#x27;] == 43 // because `a` is a literal!ages = [(a): 43] // now we escape `a` by using parenthesisassert ages[&#x27;Bob&#x27;] == 43 // and the value is found! 通过下面的方式你可以轻松克隆一个map 123456789def map = [ simple : 123, complex: [a: 1, b: 2]]def map2 = map.clone()assert map2.get(&#x27;simple&#x27;) == map.get(&#x27;simple&#x27;)assert map2.get(&#x27;complex&#x27;) == map.get(&#x27;complex&#x27;)map2.get(&#x27;complex&#x27;).put(&#x27;c&#x27;, 3)assert map.get(&#x27;complex&#x27;).get(&#x27;c&#x27;) == 3 Map property notationMaps和beans也是非常相像的, 所以你可以对map使用get/set操作元素,当然这也有个前提,那就是map中的key必须是符合Groovy标识符的key. 123456789def map = [name: &#x27;Gromit&#x27;, likes: &#x27;cheese&#x27;, id: 1234]assert map.name == &#x27;Gromit&#x27; // can be used instead of map.get(&#x27;Gromit&#x27;)assert map.id == 1234def emptyMap = [:]assert emptyMap.size() == 0emptyMap.foo = 5assert emptyMap.size() == 1assert emptyMap.foo == 5 注意:map.foo总是会在map中查找keyfoo. 这意味着, 1234567891011121314151617def map = [name: &#x27;Gromit&#x27;, likes: &#x27;cheese&#x27;, id: 1234]assert map.class == nullassert map.get(&#x27;class&#x27;) == nullassert map.getClass() == LinkedHashMap // this is probably what you wantmap = [1 : &#x27;a&#x27;, (true) : &#x27;p&#x27;, (false): &#x27;q&#x27;, (null) : &#x27;x&#x27;, &#x27;null&#x27; : &#x27;z&#x27;]assert map.containsKey(1) // 1 is not an identifier so used as isassert map.true == nullassert map.false == nullassert map.get(true) == &#x27;p&#x27;assert map.get(false) == &#x27;q&#x27;assert map.null == &#x27;z&#x27;assert map.get(null) == &#x27;x&#x27; Iterating on mapsGroovy development kit还提供了eachWithIndex方法遍历map.值得注意的是,map会保留put元素的顺序,也就是说,当你遍历一个map的时候,无论进行多少次,你获得的元素的顺序是一定的. 12345678910111213141516171819202122232425def map = [ Bob : 42, Alice: 54, Max : 33]// `entry` is a map entrymap.each &#123; entry -&gt; println &quot;Name: $entry.key Age: $entry.value&quot;&#125;// `entry` is a map entry, `i` the index in the mapmap.eachWithIndex &#123; entry, i -&gt; println &quot;$i - Name: $entry.key Age: $entry.value&quot;&#125;// Alternatively you can use key and value directlymap.each &#123; key, value -&gt; println &quot;Name: $key Age: $value&quot;&#125;// Key, value and i as the index in the mapmap.eachWithIndex &#123; key, value, i -&gt; println &quot;$i - Name: $key Age: $value&quot;&#125; Manipulating mapsAdding or removing elements向map中添加元素你可以使用put方法, 下标, putAll方法. 12345678def defaults = [1: &#x27;a&#x27;, 2: &#x27;b&#x27;, 3: &#x27;c&#x27;, 4: &#x27;d&#x27;]def overrides = [2: &#x27;z&#x27;, 5: &#x27;x&#x27;, 13: &#x27;x&#x27;]def result = new LinkedHashMap(defaults)result.put(15, &#x27;t&#x27;)result[17] = &#x27;u&#x27;result.putAll(overrides)assert result == [1: &#x27;a&#x27;, 2: &#x27;z&#x27;, 3: &#x27;c&#x27;, 4: &#x27;d&#x27;, 5: &#x27;x&#x27;, 13: &#x27;x&#x27;, 15: &#x27;t&#x27;, 17: &#x27;u&#x27;] 如果想要删除map中全部的元素,可以使用clear方法. 1234def m = [1:&#x27;a&#x27;, 2:&#x27;b&#x27;]assert m.get(1) == &#x27;a&#x27;m.clear()assert m == [:] 通过map字面量标记创建的map会使用object的equals方法和hashcode方法. 还要注意的是,不要使用GString作为map的key, 因为GString的hashcode方法和String的hashcode方法不一样. 12345def key = &#x27;some key&#x27;def map = [:]def gstringKey = &quot;$&#123;key.toUpperCase()&#125;&quot;map.put(gstringKey,&#x27;value&#x27;)assert map.get(&#x27;SOME KEY&#x27;) == null Keys, values and entries我们可以在视图中inspectkeys, values, and entries 12345678910def map = [1:&#x27;a&#x27;, 2:&#x27;b&#x27;, 3:&#x27;c&#x27;]def entries = map.entrySet()entries.each &#123; entry -&gt; assert entry.key in [1,2,3] assert entry.value in [&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;]&#125;def keys = map.keySet()assert keys == [1,2,3] as Set Mutating values returned by the view (be it a map entry, a key or a value) is highly discouraged because success of the operation directly depends on the type of the map being manipulated. In particular, Groovy relies on collections from the JDK that in general make no guarantee that a collection can safely be manipulated through keySet, entrySet, or values. Filtering and searchingThe Groovy development kit contains filtering, searching and collecting methods similar to those found for lists: 12345678910111213141516171819202122232425262728293031323334353637def people = [ 1: [name:&#x27;Bob&#x27;, age: 32, gender: &#x27;M&#x27;], 2: [name:&#x27;Johnny&#x27;, age: 36, gender: &#x27;M&#x27;], 3: [name:&#x27;Claire&#x27;, age: 21, gender: &#x27;F&#x27;], 4: [name:&#x27;Amy&#x27;, age: 54, gender:&#x27;F&#x27;]]def bob = people.find &#123; it.value.name == &#x27;Bob&#x27; &#125; // find a single entrydef females = people.findAll &#123; it.value.gender == &#x27;F&#x27; &#125;// both return entries, but you can use collect to retrieve the ages for exampledef ageOfBob = bob.value.agedef agesOfFemales = females.collect &#123; it.value.age&#125;assert ageOfBob == 32assert agesOfFemales == [21,54]// but you could also use a key/pair value as the parameters of the closuresdef agesOfMales = people.findAll &#123; id, person -&gt; person.gender == &#x27;M&#x27;&#125;.collect &#123; id, person -&gt; person.age&#125;assert agesOfMales == [32, 36]// `every` returns true if all entries match the predicateassert people.every &#123; id, person -&gt; person.age &gt; 18&#125;// `any` returns true if any entry matches the predicateassert people.any &#123; id, person -&gt; person.age == 54&#125; GroupingWe can group a list into a map using some criteria: 12345678910111213141516171819assert [&#x27;a&#x27;, 7, &#x27;b&#x27;, [2, 3]].groupBy &#123; it.class&#125; == [(String) : [&#x27;a&#x27;, &#x27;b&#x27;], (Integer) : [7], (ArrayList): [[2, 3]]]assert [ [name: &#x27;Clark&#x27;, city: &#x27;London&#x27;], [name: &#x27;Sharma&#x27;, city: &#x27;London&#x27;], [name: &#x27;Maradona&#x27;, city: &#x27;LA&#x27;], [name: &#x27;Zhang&#x27;, city: &#x27;HK&#x27;], [name: &#x27;Ali&#x27;, city: &#x27;HK&#x27;], [name: &#x27;Liu&#x27;, city: &#x27;HK&#x27;],].groupBy &#123; it.city &#125; == [ London: [[name: &#x27;Clark&#x27;, city: &#x27;London&#x27;], [name: &#x27;Sharma&#x27;, city: &#x27;London&#x27;]], LA : [[name: &#x27;Maradona&#x27;, city: &#x27;LA&#x27;]], HK : [[name: &#x27;Zhang&#x27;, city: &#x27;HK&#x27;], [name: &#x27;Ali&#x27;, city: &#x27;HK&#x27;], [name: &#x27;Liu&#x27;, city: &#x27;HK&#x27;]],] RangesRanges allow you to create a list of sequential values. These can be used as List since Range extends java.util.List. Ranges defined with the .. notation are inclusive (that is the list contains the from and to value). Ranges defined with the ..&lt; notation are half-open, they include the first value but not the last value. 12345678910111213141516171819202122// an inclusive rangedef range = 5..8assert range.size() == 4assert range.get(2) == 7assert range[2] == 7assert range instanceof java.util.Listassert range.contains(5)assert range.contains(8)// lets use a half-open rangerange = 5..&lt;8assert range.size() == 3assert range.get(2) == 7assert range[2] == 7assert range instanceof java.util.Listassert range.contains(5)assert !range.contains(8)//get the end points of the range without using indexesrange = 1..10assert range.from == 1assert range.to == 10 Note that int ranges are implemented efficiently, creating a lightweight Java object containing a from and to value. Ranges can be used for any Java object which implements java.lang.Comparable for comparison and also have methods next() and previous() to return the next / previous item in the range. For example, you can create a range of String elements:","categories":[{"name":"Groovy","slug":"Groovy","permalink":"https://wangmingco.github.io/categories/Groovy/"}],"tags":[]},{"title":"Groovy IO","slug":"编程语言/Groovy IO","date":"2014-04-08T16:00:00.000Z","updated":"2021-11-18T02:27:56.455Z","comments":true,"path":"2014/04/09/编程语言/Groovy IO/","link":"","permalink":"https://wangmingco.github.io/2014/04/09/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Groovy%20IO/","excerpt":"","text":"本文是对Groovy部分官方文档进行了翻译 读文件作为第一个例子,让我们看一下,如何输出一个文本文件里的所有行 123new File(baseDir, &#x27;haiku.txt&#x27;).eachLine &#123; line -&gt; println line&#125; eachLine方法是Groovy自动添加到File Class的,同时呢,Groovy还添加了很多变量,例如,你如果想要知道每一行的行号,你可以使用这个变量: 123new File(baseDir, &#x27;haiku.txt&#x27;).eachLine &#123; line, nb -&gt; println &quot;Line $nb: $line&quot;&#125; 无论由于什么原因, 当eachLine中抛出了异常,这个方法都会确保,资源已经被正确的关闭掉了. 这对所有Groovy自动添加的关于I/O资源的方法都有效. 例如, 某种情况你使用了Reader, 但是你还想让Groovy自己管理资源. 下面这个例子, 即使抛出了exception, reader仍然会被自动关闭. 12345678def count = 0, MAXSIZE = 3new File(baseDir,&quot;haiku.txt&quot;).withReader &#123; reader -&gt; while (reader.readLine()) &#123; if (++count &gt; MAXSIZE) &#123; throw new RuntimeException(&#x27;Haiku should only have 3 verses&#x27;) &#125; &#125;&#125; 如果你想要把文本文件中每一行都放进一个list中, 你可以这么做: 1def list = new File(baseDir, &#x27;haiku.txt&#x27;).collect &#123;it&#125; 或者你想利用操作符将文件中每一行都添加到一个数组中: 1def array = new File(baseDir, &#x27;haiku.txt&#x27;) as String[] 下面这个示例,非常简单的实现了,将一个文件存进一个字节数组里: 1byte[] contents = file.bytes 如下例,我们轻松地获得了一个输入流. 123def is = new File(baseDir,&#x27;haiku.txt&#x27;).newInputStream()// do something ...is.close() 上个例子中我们获得了一个输入流,但是最后我们不得不手动关闭它, Groovy提供另一个方法withInputStream, 这个方法可以帮我们自动的关闭输入流. 123new File(baseDir,&#x27;haiku.txt&#x27;).withInputStream &#123; stream -&gt; // do something ...&#125; 写文件有时候,你需要的也许只是写文件,下面展示了,如何在Groovy中写文件 12345new File(baseDir,&#x27;haiku.txt&#x27;).withWriter(&#x27;utf-8&#x27;) &#123; writer -&gt; writer.writeLine &#x27;Into the ancient pond&#x27; writer.writeLine &#x27;A frog jumps&#x27; writer.writeLine &#x27;Water’s sound!&#x27;&#125; 但对于一个要求很简单的需求来说,我们可以使用&lt;&lt;向文件中写 123new File(baseDir,&#x27;haiku.txt&#x27;) &lt;&lt; &#x27;&#x27;&#x27;Into the ancient pondA frog jumpsWater’s sound!&#x27;&#x27;&#x27; 当然不是每一次我们都是向文件中输出文本,下面的例子演示了,我们如何向一个文件中写入字节: 1file.bytes = [66,22,11] 当然,你也可以直接打开一个输出流,下面的例子演示了如何开启一个输出流. 123def os = new File(baseDir,&#x27;data.bin&#x27;).newOutputStream()// do something ...os.close() 同newInputStream一样,newOutputStream同样需要手动关闭, ok,你大概想到了withOutputStream: 123new File(baseDir,&#x27;data.bin&#x27;).withOutputStream &#123; stream -&gt; // do something ...&#125; 遍历文件在脚本中, 有个很常用的需求就是,遍历一个目录,然后找到一个文件,进行某些操作. Groovy提供了很多方法,来达到这个效果. 下面的例子演示了将一个目录下的所有文件都执行某个操作: 123456dir.eachFile &#123; file -&gt; (1) println file.name&#125;dir.eachFileMatch(~/.*\\.txt/) &#123; file -&gt; (2) println file.name&#125; 在目录下的每个文件上执行闭包操作. 根据正则表达式在目录下找到符合条件的文件,然后执行闭包操作. 也许你想要遍历某个目录和目录里的所有子目录, 那么你可以使用eachFileRecurse 1234567dir.eachFileRecurse &#123; file -&gt; (1) println file.name&#125;dir.eachFileRecurse(FileType.FILES) &#123; file -&gt; (2) println file.name&#125; 对目录里的所有子目录进行递归, 然后对找到的文件和目录进行闭包操作 对目录里进行递归查找,但是只查找文件. 123456789dir.traverse &#123; file -&gt; if (file.directory &amp;&amp; file.name==&#x27;bin&#x27;) &#123; FileVisitResult.TERMINATE (1) &#125; else &#123; println file.name FileVisitResult.CONTINUE (2) &#125;&#125; 如果找到的文件是目录,且它的名字是”dir”, 则停止遍历 打印出文件的名字,接着遍历 序列化在java中会使用java.io.DataOutputStream 序列化数据也不罕见. Groovy对这个需求也做了非常简单的实现, 下面的例子演示了如何序列化和反序列化: 12345678910111213boolean b = trueString message = &#x27;Hello from Groovy&#x27;// Serialize data into a filefile.withDataOutputStream &#123; out -&gt; out.writeBoolean(b) out.writeUTF(message)&#125;// ...// Then read it backfile.withDataInputStream &#123; input -&gt; assert input.readBoolean() == b assert input.readUTF() == message&#125; 同样,如果这个数据实例了序列化接口Serializable, 你可以使用 object output stream将整个数据序列化到文件: 123456789101112Person p = new Person(name:&#x27;Bob&#x27;, age:76)// Serialize data into a filefile.withObjectOutputStream &#123; out -&gt; out.writeObject(p)&#125;// ...// Then read it backfile.withObjectInputStream &#123; input -&gt; def p2 = input.readObject() assert p2.name == p.name assert p2.age == p.age&#125; 执行命令前面的章节介绍了在Groovy中操作files, readers or streams非常简单. 然而, 像系统管理员或者开发者,可能更多的是执行一个系统命令. Groovy同样提供了非常简单的方式执行命令行命令. 只需要定义一个命令的字符串,然后执行这个字符串的execute(). 在类Unix系统中(如果在windows中也安装了类Unix命令行工具也算),你可以这样执行命令. 12def process = &quot;ls -l&quot;.execute() (1)println &quot;Found text $&#123;process.text&#125;&quot; (2) 在外部过程(external process)执行ls命令 获得命令的输出,并输出 execute()方法返回一个java.lang.Process实例, 随后选择一种输出流in/out/err, 同时检查exit值,查看是否命令执行完毕. 下面的例子使用了和刚才那个例子一样的命令,但是现在我们每次都会对获得的结果进行行输出. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364 def process = &quot;ls -l&quot;.execute() (1) process.in.eachLine &#123; line -&gt; (2) println line (3) &#125; assert process instanceof Process &#125; &#125; void testProcessConsumeOutput() &#123; if (unixlike) &#123; doInTmpDir &#123; b -&gt; File file = null def tmpDir = b.tmp &#123; file = &#x27;foo.tmp&#x27;(&#x27;foo&#x27;) &#125; assert file.exists() def p = &quot;rm -f foo.tmp&quot;.execute([], tmpDir) p.consumeProcessOutput() p.waitFor() assert !file.exists() &#125; &#125; &#125; void testProcessPipe() &#123; if (unixlike) &#123; doInTmpDir &#123; b -&gt; def proc1, proc2, proc3, proc4 proc1 = &#x27;ls&#x27;.execute() proc2 = &#x27;tr -d o&#x27;.execute() proc3 = &#x27;tr -d e&#x27;.execute() proc4 = &#x27;tr -d i&#x27;.execute() proc1 | proc2 | proc3 | proc4 proc4.waitFor() if (proc4.exitValue()) &#123; println proc4.err.text &#125; else &#123; println proc4.text &#125; def sout = new StringBuilder() def serr = new StringBuilder() proc2 = &#x27;tr -d o&#x27;.execute() proc3 = &#x27;tr -d e&#x27;.execute() proc4 = &#x27;tr -d i&#x27;.execute() proc4.consumeProcessOutput(sout, serr) proc2 | proc3 | proc4 [proc2, proc3].each &#123; it.consumeProcessErrorStream(serr) &#125; proc2.withWriter &#123; writer -&gt; writer &lt;&lt; &#x27;testfile.groovy&#x27; &#125; proc4.waitForOrKill(1000) println &quot;Standard output: $sout&quot; println &quot;Standard error: $serr&quot; &#125; &#125; &#125; public static class Person implements Serializable &#123; String name int age &#125;&#125; 1 executes the ls command in an external process2 for each line of the input stream of the process3 print the line 在外部进程中执行ls命令 It is worth noting that in corresponds to an input stream to the standard output of the command. out will refer to a stream where you can send data to the process (its standard input). Remember that many commands are shell built-ins and need special handling. So if you want a listing of files in a directory on a Windows machine and write: 12def process = &quot;dir&quot;.execute()println &quot;$&#123;process.text&#125;&quot; 接着你会收到一个异常IOException,异常信息为Cannot run program &quot;dir&quot;: CreateProcess error=2,系统找不到指定的文件. 这是因为dir是内建于windows shell(cmd.ext), 想要使用那个命令,你要像下面这个样操作: 12def process = &quot;cmd /c dir&quot;.execute()println &quot;$&#123;process.text&#125;&quot; 还有,因为上述的功能是在内部使用的java.lang.Process, 这个类的一些不足的地方,我们也要充分考虑. 在javadoc中,是这样描述这个类的: Because some native platforms only provide limited buffer size for standard input and output streams, failure to promptly write the input stream or read the output stream of the subprocess may cause the subprocess to block, and even deadlockBecause of this, Groovy provides some additional helper methods which make stream handling for processes easier. 现在演示一下,如何输出进程里所有的输出(包括error stream). 123def p = &quot;rm -f foo.tmp&quot;.execute([], tmpDir)p.consumeProcessOutput()p.waitFor() consumeProcessOutput仍然有很多对StringBuffer, InputStream, OutputStream等封装的变量, 如果想要获取一个完整的封装列表的,那可以参考 GDK API for java.lang.Process 另外, pipeTo命令 可以让一个进程的输出流连接到一个进程的输入流里. 如下例: 1234567891011proc1 = &#x27;ls&#x27;.execute()proc2 = &#x27;tr -d o&#x27;.execute()proc3 = &#x27;tr -d e&#x27;.execute()proc4 = &#x27;tr -d i&#x27;.execute()proc1 | proc2 | proc3 | proc4proc4.waitFor()if (proc4.exitValue()) &#123; println proc4.err.text&#125; else &#123; println proc4.text&#125; Consuming errors 1234567891011121314def sout = new StringBuilder()def serr = new StringBuilder()proc2 = &#x27;tr -d o&#x27;.execute()proc3 = &#x27;tr -d e&#x27;.execute()proc4 = &#x27;tr -d i&#x27;.execute()proc4.consumeProcessOutput(sout, serr)proc2 | proc3 | proc4[proc2, proc3].each &#123; it.consumeProcessErrorStream(serr) &#125;proc2.withWriter &#123; writer -&gt; writer &lt;&lt; &#x27;testfile.groovy&#x27;&#125;proc4.waitForOrKill(1000)println &quot;Standard output: $sout&quot;println &quot;Standard error: $serr&quot;","categories":[{"name":"Groovy","slug":"Groovy","permalink":"https://wangmingco.github.io/categories/Groovy/"}],"tags":[]},{"title":"Groovy 注释和标识符","slug":"编程语言/Groovy","date":"2014-04-07T16:00:00.000Z","updated":"2021-11-18T02:28:02.896Z","comments":true,"path":"2014/04/08/编程语言/Groovy/","link":"","permalink":"https://wangmingco.github.io/2014/04/08/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/Groovy/","excerpt":"","text":"本文是对Groovy部分官方文档进行了翻译 注释单行注释想要使用单行注释, 使用//就可以了. 本行中//后续的内容都会被认为是注释的一部分 12// a standalone single line commentprintln &quot;hello&quot; // a comment till the end of the line 多行注释多行注释从/*开始, 直到*/结束(跨行也包含在内) 12345/* a standalone multiline commentspanning two lines */println &quot;hello&quot; /* a multiline comment startingat the end of a statement */println 1 /* one */ + 2 /* two */ GroovyDoc 注释GroovyDoc 注释也是多行的, 但是它是以/**开始, */结束定义的.这种注释一般用于以下情况： 类型定义(包含 classes, interfaces, enums, annotations) 字段和属性定义 方法定义 1234567891011121314151617/** * A Class description */ class Person &#123; /** the name of the person */ String name /** * Creates a greeting method for a certain person. * * @param otherPerson the person to greet * @return ag reeting message */ String greet(String otherPerson) &#123; &quot;Hello $&#123;otherPerson&#125;&quot; &#125; &#125; Shebang line除了上面提到的单行注释外, 还有一种特殊的单行注释.这种注释在UNIX系统下通常称为shebang线, 这种注释允许脚本直接在命令行里执行( 但是前提是你已经在系统是安装了groovy,并且在PATH里进行了配置) 12#!/usr/bin/env groovyprintln &quot;Hello from the shebang line&quot; #字符必须是这个文件里的第一个字符,否则编译器将会抛出一个编译错误. 标识符普通标识符标识符以一个字母或者$或者_开始, 不能以数字打头.如果以字母打头,他们在下列范围内 ‘a’ to ‘z’ (lowercase ascii letter) ‘A’ to ‘Z’ (uppercase ascii letter) ‘\\u00C0’ to ‘\\u00D6’ ‘\\u00D8’ to ‘\\u00F6’ ‘\\u00F8’ to ‘\\u00FF’ ‘\\u0100’ to ‘\\uFFFE’ 剩下的字符就可以包含字母或者数字了. 下面列举了一些合法的标识符： 1234def namedef item3def with_underscoredef $dollarStart 下面是一些非法的标识符 123def 3tierdef a+bdef a#b .后面的关键字也是合法的标识符 12345foo.asfoo.assertfoo.breakfoo.casefoo.catch 带引号的标识符带引号的标识符出现在.\\. 例如person.name表达式中的name部分能通过这俩种方式引起来person.&quot;name&quot;或者person.\\&#39;name&#39;. 当特定标识符中包含非法字符(java语言禁止的字符),但是通过引号的方式可以达到在Groovy的合法. 例如,一个破折号,一个空格,一个感叹号, 1234567def map = [:]map.&quot;an identifier with a space and double quotes&quot; = &quot;ALLOWED&quot;map.&#x27;with-dash-signs-and-single-quotes&#x27; = &quot;ALLOWED&quot;assert map.&quot;an identifier with a space and double quotes&quot; == &quot;ALLOWED&quot;assert map.&#x27;with-dash-signs-and-single-quotes&#x27; == &quot;ALLOWED&quot; 正像一会我们在strings模块看到的一样, Groovy提供了不同的string字面量. 以下所列举的都是合法的 123456map.&#x27;single quote&#x27;map.&quot;double quote&quot;map.&#x27;&#x27;&#x27;triple single quote&#x27;&#x27;&#x27;map.&quot;&quot;&quot;triple double quote&quot;&quot;&quot;map./slashy string/map.$/dollar slashy string/$ strings 和 Groovy’s GStrings 在纯字符上面是有一点不同的,as in that the latter case, the interpolated values are inserted in the final string for evaluating the whole identifier: 1234def firstname = &quot;Homer&quot;map.&quot;Simson-$&#123;firstname&#125;&quot; = &quot;Homer Simson&quot;assert map.&#x27;Simson-Homer&#x27; == &quot;Homer Simson&quot;","categories":[{"name":"Groovy","slug":"Groovy","permalink":"https://wangmingco.github.io/categories/Groovy/"}],"tags":[]},{"title":"ZooKeeper Java客户端","slug":"zookeeper/ZooKeeper Java客户端","date":"2013-11-19T16:00:00.000Z","updated":"2021-11-18T02:43:56.586Z","comments":true,"path":"2013/11/20/zookeeper/ZooKeeper Java客户端/","link":"","permalink":"https://wangmingco.github.io/2013/11/20/zookeeper/ZooKeeper%20Java%E5%AE%A2%E6%88%B7%E7%AB%AF/","excerpt":"","text":"我们使用ZooKeeper官方java客户端进行测试,另外可以使用curator. 我们使用Maven添加相关依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.8&lt;/version&gt;&lt;/dependency&gt; 创建节点然后我们向zk服务器上添加俩个节点 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import org.apache.zookeeper.CreateMode;import org.apache.zookeeper.KeeperException;import org.apache.zookeeper.ZooDefs;import org.apache.zookeeper.ZooKeeper;import java.io.IOException;import java.util.List;import java.util.concurrent.TimeUnit;public class CreateNode &#123; private static final String ROOT_PATH = &quot;/Servers&quot;; private static ZooKeeper zooKeeper; public static void main(String[] args) throws IOException, KeeperException, InterruptedException &#123; // 连接ZooKeeper服务器 zooKeeper = new ZooKeeper(&quot;localhost:2181&quot;, 15000, event -&gt; &#123; // TODO &#125;); // 创建根节点, 子节点依赖于父节点, 我们不能直接创建出/Servers/server1 zooKeeper.create(ROOT_PATH, // 节点路径 &quot;create&quot;.getBytes(), // 节点数据 ZooDefs.Ids.OPEN_ACL_UNSAFE, // 权限控制(不使用节点权限控制) CreateMode.PERSISTENT, // 节点类型(临时节点不允许创建子节点,所以我们选择了持久节点) (rc, path, ctx, name) -&gt; &#123; // 节点创建成功之后的回调函数 // TODO &#125;, ROOT_PATH); // 创建子节点 zooKeeper.create(ROOT_PATH + &quot;/server1&quot;, // 节点路径 &quot;create&quot;.getBytes(), // 节点数据 ZooDefs.Ids.OPEN_ACL_UNSAFE, // 权限控制 CreateMode.PERSISTENT, // 节点类型 (rc, path, ctx, name) -&gt; &#123; // 节点创建成功之后的回调函数 // TODO &#125;, ROOT_PATH); // 获取节点下的所有子节点 List&lt;String&gt; children = zooKeeper.getChildren(ROOT_PATH, event -&gt; &#123; // TODO &#125;); children.forEach(child -&gt; System.out.println(child)); TimeUnit.SECONDS.sleep(1); &#125;&#125; watch1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253import org.apache.zookeeper.*;import java.io.IOException;import java.util.Random;import java.util.concurrent.TimeUnit;public class CreateNode &#123; private static final String ROOT_PATH = &quot;/Servers&quot; + new Random().nextInt(100000); private static ZooKeeper zooKeeper; public static void main(String[] args) throws IOException, KeeperException, InterruptedException &#123; // 连接ZooKeeper服务器 zooKeeper = new ZooKeeper(&quot;localhost:2181&quot;, 15000, event -&gt; &#123; System.out.println(&quot;事件变化 : &quot; + event.getPath() + &quot; -&gt; &quot; + event.getType()); &#125;); // 创建根节点, 子节点依赖于父节点, 我们不能直接创建出/Servers/server1 zooKeeper.create(ROOT_PATH, // 节点路径 &quot;create&quot;.getBytes(), // 节点数据 ZooDefs.Ids.OPEN_ACL_UNSAFE, // 权限控制(不使用节点权限控制) CreateMode.PERSISTENT, // 节点类型(临时节点不允许创建子节点,所以我们选择了持久节点) (rc, path, ctx, name) -&gt; &#123; // 节点创建成功之后的回调函数 try &#123; System.out.println(&quot;Create Node OK!&quot;); zooKeeper.getChildren(ROOT_PATH, event -&gt; &#123; System.out.println(&quot;Watch : &quot; + event.getPath() + &quot; -&gt; &quot; + event.getType()); &#125;); &#125; catch (final Exception e) &#123; e.printStackTrace(); &#125; &#125;, ROOT_PATH); // 在创建上个node的时候, 由于注册watch是异步执行的, 因此需要在这里等待一下 TimeUnit.SECONDS.sleep(3); zooKeeper.create(ROOT_PATH + &quot;/server1&quot;, // 节点路径 &quot;create&quot;.getBytes(), // 节点数据 ZooDefs.Ids.OPEN_ACL_UNSAFE, // 权限控制(不使用节点权限控制) CreateMode.PERSISTENT, // 节点类型(临时节点不允许创建子节点,所以我们选择了持久节点) (rc, path, ctx, name) -&gt; &#123; // 节点创建成功之后的回调函数 try &#123; System.out.println(&quot;Create Node OK!&quot;); zooKeeper.getChildren(ROOT_PATH, event -&gt; &#123; System.out.println(&quot;Watch : &quot; + event.getPath() + &quot; -&gt; &quot; + event.getType()); &#125;); &#125; catch (final Exception e) &#123; e.printStackTrace(); &#125; &#125;, ROOT_PATH); TimeUnit.SECONDS.sleep(3); &#125;&#125; 输出结果为 1234事件变化 : null -&gt; NoneCreate Node OK!Watch : /Servers53734 -&gt; NodeChildrenChangedCreate Node OK!","categories":[{"name":"ZooKeeper","slug":"ZooKeeper","permalink":"https://wangmingco.github.io/categories/ZooKeeper/"}],"tags":[]},{"title":"ZooKeeper 命令行客户端","slug":"zookeeper/ZooKeeper 命令行客户端","date":"2013-11-19T16:00:00.000Z","updated":"2021-11-18T02:43:52.468Z","comments":true,"path":"2013/11/20/zookeeper/ZooKeeper 命令行客户端/","link":"","permalink":"https://wangmingco.github.io/2013/11/20/zookeeper/ZooKeeper%20%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%AE%A2%E6%88%B7%E7%AB%AF/","excerpt":"","text":"我们执行 1bin/zkCli.cmd -server 127.0.0.1:2181 就连接上了刚才启动的服务器,进入shell 1234567891011121314151617E:\\zookeeper-3.4.6\\bin&gt;.\\zkCli.cmd -server 127.0.0.1:2181Connecting to 127.0.0.1:21812015-11-09 16:04:51,367 [myid:] - INFO [main:Environment@100] - Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT...2015-11-09 16:04:51,374 [myid:] - INFO [main:Environment@100] - Client environment:user.home=C:\\Users\\Administrator2015-11-09 16:04:51,374 [myid:] - INFO [main:Environment@100] - Client environment:user.dir=E:\\zookeeper-3.4.6\\bin2015-11-09 16:04:51,375 [myid:] - INFO [main:ZooKeeper@438] - Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=30000 watcher=org.apache.zookeeper.ZooKeeperMain$MyWatcher@277050dcWelcome to ZooKeeper!2015-11-09 16:04:51,514 [myid:] - INFO [main-SendThread(127.0.0.1:2181):ClientCnxn$SendThread@975] - Opening socket connection to server 127.0.0.1/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)2015-11-09 16:04:51,516 [myid:] - INFO [main-SendThread(127.0.0.1:2181):ClientCnxn$SendThread@852] - Socket connection established to 127.0.0.1/127.0.0.1:2181, initiating session2015-11-09 16:04:51,684 [myid:] - INFO [main-SendThread(127.0.0.1:2181):ClientCnxn$SendThread@1235] - Session establishment complete on server 127.0.0.1/127.0.0.1:2181, sessionid = 0x150eb438ceb0000, negotiated timeout = 30000WATCHER::WatchedEvent state:SyncConnected type:None path:nullJLine support is enabled[zk: 127.0.0.1:2181(CONNECTED) 0] 进入到shell之后,我们可以敲人help命令，查看我们都能使用哪些命令： 123456789101112131415161718192021222324[zk: 127.0.0.1:2181(CONNECTED) 1] helpZooKeeper -server host:port cmd args stat path [watch] set path data [version] ls path [watch] delquota [-n|-b] path ls2 path [watch] setAcl path acl setquota -n|-b val path history redo cmdno printwatches on|off delete path [version] sync path listquota path rmr path get path [watch] create [-s] [-e] path data acl addauth scheme auth quit getAcl path close connect host:port[zk: 127.0.0.1:2181(CONNECTED) 2] 看到了,我们能使用这么多命令，下来我们简单的接受几个命令. 我们使用create命令创建一个znode(这个node里和字符串”my_data”关联起来了). 12345[zk: 127.0.0.1:2181(CONNECTED) 1] create /zk_test my_dataCreated /zk_test[zk: 127.0.0.1:2181(CONNECTED) 3] ls /[zookeeper, zk_test][zk: 127.0.0.1:2181(CONNECTED) 4] 但是实际上，这个node还没有被创建出来. 下来我们使用get命令验证一下zk_test是不是真的和”my_data”关联起来了 1234567891011121314[zk: 127.0.0.1:2181(CONNECTED) 4] get /zk_testmy_datacZxid = 0x3ctime = Mon Nov 09 16:29:12 CST 2015mZxid = 0x3mtime = Mon Nov 09 16:29:12 CST 2015pZxid = 0x3cversion = 0dataVersion = 0aclVersion = 0ephemeralOwner = 0x0dataLength = 7numChildren = 0[zk: 127.0.0.1:2181(CONNECTED) 5] 我们还可以使用set命令将刚才那个node重新关联 1234567891011121314151617181920212223242526[zk: 127.0.0.1:2181(CONNECTED) 5] set /zk_test new_datacZxid = 0x3ctime = Mon Nov 09 16:29:12 CST 2015mZxid = 0x4mtime = Mon Nov 09 16:35:11 CST 2015pZxid = 0x3cversion = 0dataVersion = 1aclVersion = 0ephemeralOwner = 0x0dataLength = 8numChildren = 0[zk: 127.0.0.1:2181(CONNECTED) 7] get /zk_testnew_datacZxid = 0x3ctime = Mon Nov 09 16:29:12 CST 2015mZxid = 0x4mtime = Mon Nov 09 16:35:11 CST 2015pZxid = 0x3cversion = 0dataVersion = 1aclVersion = 0ephemeralOwner = 0x0dataLength = 8numChildren = 0[zk: 127.0.0.1:2181(CONNECTED) 8] 最后，我们将这个node删掉 1234[zk: 127.0.0.1:2181(CONNECTED) 9] delete /zk_test[zk: 127.0.0.1:2181(CONNECTED) 10] ls /[zookeeper][zk: 127.0.0.1:2181(CONNECTED) 11]","categories":[{"name":"ZooKeeper","slug":"ZooKeeper","permalink":"https://wangmingco.github.io/categories/ZooKeeper/"}],"tags":[]},{"title":"ZooKeeper 服务器","slug":"zookeeper/ZooKeeper 服务器","date":"2013-09-12T16:00:00.000Z","updated":"2021-11-18T02:43:51.486Z","comments":true,"path":"2013/09/13/zookeeper/ZooKeeper 服务器/","link":"","permalink":"https://wangmingco.github.io/2013/09/13/zookeeper/ZooKeeper%20%E6%9C%8D%E5%8A%A1%E5%99%A8/","excerpt":"","text":"演示windows系统下快速使用Zookeeper3.4.6版本 单机模式我们从Zookeeper官网下载下其最新的压缩包之后,然后解压得到下面的目录： 123456789├───bin├───conf├───contrib├───datadir├───dist-maven├───docs├───lib├───recipes└───src datadir是我自己创建的,用于存放内存数据的快照文件。 进入到conf目录，将zoo_sample.cfg修改为zoo.cfg文件 修改zoo.cfg文件内容,dataDir=E:/zookeeper-3.4.6/datadir这个是我修改过的路径 进入到bin目录, 执行.\\zkServer.cmd start .最后见到 Established session 0x150eb438ceb0000 with negotiated timeout 30000 for client /127.0.0.1:54408就启动成功了 如果遇到java.lang.NumberFormatException: For input string: &quot;E:\\zookeeper-3.4.6\\bin\\..\\conf\\zoo.cfg&quot;这个提示,那就要去修改bin/zkServer.cmd文件, 将%*这个去掉就好了 1call %JAVA% &quot;-Dzookeeper.log.dir=%ZOO_LOG_DIR%&quot; &quot;-Dzookeeper.root.logger=%ZOO_LOG4J_PROP%&quot; -cp &quot;%CLASSPATH%&quot; %ZOOMAIN% &quot;%ZOOCFG%&quot; %* 修改成 1call %JAVA% &quot;-Dzookeeper.log.dir=%ZOO_LOG_DIR%&quot; &quot;-Dzookeeper.root.logger=%ZOO_LOG4J_PROP%&quot; -cp &quot;%CLASSPATH%&quot; %ZOOMAIN% &quot;%ZOOCFG%&quot; 集群模式","categories":[{"name":"ZooKeeper","slug":"ZooKeeper","permalink":"https://wangmingco.github.io/categories/ZooKeeper/"}],"tags":[]},{"title":"Guava Cache","slug":"JavaLibrary/Guava CachesExplained","date":"2013-09-12T16:00:00.000Z","updated":"2021-11-18T02:46:39.374Z","comments":true,"path":"2013/09/13/JavaLibrary/Guava CachesExplained/","link":"","permalink":"https://wangmingco.github.io/2013/09/13/JavaLibrary/Guava%20CachesExplained/","excerpt":"","text":"Example12345678910LoadingCache&lt;Key, Graph&gt; graphs = CacheBuilder.newBuilder() .maximumSize(1000) .expireAfterWrite(10, TimeUnit.MINUTES) .removalListener(MY_LISTENER) .build( new CacheLoader&lt;Key, Graph&gt;() &#123; public Graph load(Key key) throws AnyException &#123; return createExpensiveGraph(key); &#125; &#125;); 适用范围缓存的使用范围是十分广泛的。每当计算或者通过一些方式生成一个值的时候，会造成资源严重浪费的时候我们可以考虑用缓存技术来存储该值。 缓存和CurrentMap十分相似(键值对形式),但是他们之间还是仍有诸多不同.他们之间最大的不同之处是ConcurrentMap里的元素在被明确地删除之前会一直被存储在Map里，但是对于cache来说，为了维护cache的内存占用，cache被设计成会自动删除其中的数据。在一些应用场合中，使用LoadingCache也是非常有用的，即使它不被允许自动删除其entries(由于它的自动内存加载机制，他不允许这么做)。 一般来说，Guava的缓存技术一般适用于以下场合 想要消耗掉一些内存来换取速度的提升 key(map中也有key)会在一段时间内被频繁的访问。 在cache存储的数据容量不会大于其RAM中存储的。 你可以按照上文中的例子(CacheBuilder的builder pattern)来创建一个Cache，但是定制属于自己应用程序的Cache才是最激动人心的事。 注：如果你的应用程序中不会用到上文提到的Cache的特性，那么你可以考虑ConcurrentHashMap，它在内存方面也许更有优势。但是ConcurrentHashMap是非常困难，甚至不可能的来模拟出Cache那样的强大功能。至于如何选择，就要看你的应用程序需求了,仔细看看下面提到的特性—-例如元素的存活期，元素的大小等等，这些特点都是在ConcurrentMap里所不存在的。 总体你应该先问自己第一个问题：你是否有特定的明确的通过某些keys的作参数生成Value的方法？如果你的回答是肯定的话，那么CacheLoader是适合你的。如果你不需要通过某些key来生成value或者你想要重载默认的方法或者想要使用get-if-absent-compute方式,你可以参考From A Callable。一般我们可以通过Cache.put直接将元素插入cache中，但是我们应该首先考虑它的自动缓存加载，因为它会考虑到所有缓存内容的一致性。 From A CacheLoader : LoadingCache通过一个附着的CacheLoader来创建。创建一个CacheLoader也是非常简单的，只要实现一个V load(K key) throws exception的方法就可以了.下面的例子展示出如何创建一个LoadingCache 123456789101112131415LoadingCache&lt;Key, Graph&gt; graphs = CacheBuilder.newBuilder() .maximumSize(1000) .build( new CacheLoader&lt;Key, Graph&gt;() &#123; public Graph load(Key key) throws AnyException &#123; return createExpensiveGraph(key); &#125; &#125;); ... try &#123; return graphs.get(key); &#125; catch (ExecutionException e) &#123; throw new OtherException(e.getCause()); &#125; 上面的例子也展示除了我们可以通过get(K)的方式对LoadingCache进行查询获取值。我们如果可以从cache中查找到该key，那么将会直接返回该key对应的value，否则会通过cache的CacheLoader自动加载一个新的键值对，然后返回该值。因为CacheLoader可能会抛出异常，所以get(K)可能会抛出Execution。如果在CacheLoader中定义了一个非异常检查的load方法，那么在查询取值时可以使用getUnchecked(Key);但是如果你声明了throws，则一定不要调用getUnchecked(Key). 下面是一个例子： 1234567891011LoadingCache&lt;Key, Graph&gt; graphs = CacheBuilder.newBuilder() .expireAfterAccess(10, TimeUnit.MINUTES) .build( new CacheLoader&lt;Key, Graph&gt;() &#123; public Graph load(Key key) &#123; // no checked exception return createExpensiveGraph(key); &#125; &#125;); ... return graphs.getUnchecked(key); 当我们想要获取N多值的时候，在查询时可以使用方法getAll(Iterable&lt;? extends K&gt;).在getAll中，对每一个不存在于cache里的key都会执行一个单独的对CacheLoader.load的方法调用来加载该值。看，guava提供了如此优秀的方法当进行一次getAll比多次get更有优势时，我们就应该重载CacheLoader.loadAll来实现这个功能。 可以通过实现CacheLoader.loadAll这个方法来加载那些不被包含的显示请求的值。 如果想要设定cache有一定的大小可以通过CacheBuilder.maximumSize(long)来设定。如此设定会使得cache在达到限定值时删除那些没有被使用过或者不经常使用的entries. From a Callable: 所有的Guava caches，不管是否是loading模式的，都支持get(K, Callable)方法。这个方法会从cache中返回与该key相关联的value，或者从Callable中计算该值并把它放进cache中。这个方法使用了一个非常简单的模式”if cached, return; otherwise create, cache and return” 12345678910111213141516Cache&lt;Key, Value&gt; cache = CacheBuilder.newBuilder() .maximumSize(1000) .build(); // look Ma, no CacheLoader ... try &#123; // If the key wasn&#x27;t in the &quot;easy to compute&quot; group, we need to // do things the hard way. cache.get(key, new Callable&lt;Value&gt;() &#123; @Override public Value call() throws AnyException &#123; return doThingsTheHardWay(key); &#125; &#125;); &#125; catch (ExecutionException e) &#123; throw new OtherException(e.getCause()); &#125; Inserted Directly : Values也可以通过cache.put(key,value)直接将值插入cache中。该方法将重写先前与key匹配的entry。 Eviction一个不能避免的问题：由于内存原因，我们不能将所有的东西都加载进cache中。那么你必须下决定：一个cache entry应该何时被抛弃。Guava提供了三种entry释放策略：size-basd evicton，time-based eviction 和reference-based eviction Size-based Eviction如果你的cache不允许扩容,即不允许超过设定的最大值，那么使用CacheBuilder.maxmuSize(long)即可。在这种条件下，cache会自己释放掉那些最近没有或者不经常使用的entries内存。注意：cache并不是在超过限定时才会删除掉那些entries，而是在即将达到这个限定值时，那么你就要小心考虑这种情况了，因为很明显即使没有达到这个限定值，cache仍然会进行删除操作。 还有一种情况：cache里不同的entries可能会有不同的weight。例如：如果你的cache values有着截然不同的内存占用—-你可以使用CacheBuilder.weigher(Weigher)设定weigh和使用CacheBuilder.maximumWeight(long)设定一个最大值。下面代码展示了对weight的使用 12345678910111213LoadingCache&lt;Key, Graph&gt; graphs = CacheBuilder.newBuilder() .maximumWeight(100000) .weigher(new Weigher&lt;Key, Graph&gt;() &#123; public int weigh(Key k, Graph g) &#123; return g.vertices().size(); &#125; &#125;) .build( new CacheLoader&lt;Key, Graph&gt;() &#123; public Graph load(Key key) &#123; // no checked exception return createExpensiveGraph(key); &#125; &#125;); Timed EvictionCacheBuilder 提供了俩种方式来实现这一模式expireAfterAccess(long, TimeUnit)从最后一次访问(读或者写)开始计时，过了这段指定的时间就会释放掉该entries。注意：那些被删掉的entries的顺序时和size-based eviction是十分相似的。expireAfterWrite(long,TimeUnit)它是从entries被创建或者最后一次被修改值的点来计时的，如果从这个点开始超过了那段指定的时间，entries就会被删除掉。这点设计的很精明，因为数据会随着时间变得越来越陈旧。如果想要测试Timed Eviction，使用Ticker interface和CacheBuilder.ticker(Ticker)方法对你的cache设定一个时间即可，那么你就不需要去等待系统时间了。 Reference-based EvictionGuava为你准备了entries的垃圾回收器，对于keys或者values可以使用weak reference ，对于values可以使用 soft reference. CacheBuilder.weakKeys()通过weak reference存储keys。在这种情况下，如果keys没有被strong或者soft引用，那么entries会被垃圾回收。这种条件下的垃圾回收器是建立在标识符(引用)之上的，那么这会造成整个cache是使用==来比较俩个key的，而不是equals(); CacheBuilder.weakValues() 通过weak referene 存储values.在这种情况下，如果valves没有被strong或者soft引用，那么entries会被垃圾回收。这种条件下的垃圾回收器是建立在标识符(引用)之上的，那么这会造成整个cache是使用==来比较俩个values的，而不是equals();CacheBuilder.softValues() Explicit Removals也许在某年某月某天你不想再等cache释放entries，而是自己能手动的去释放掉这些entries，下面三个方法会帮助你 单个释放：Cache.invalidate(key) 多个释放：Cache.invalidateAll(keys) 全部释放：Cache.invalidateAll() Removal Listenerscache允许你指定一个removal listener监听entry的移除操作(例如CacheBuilder.removalListener(RemovalListener)).通过RemovaNotification获得的RemovalListener制定了RemovalCause,key和value`。 注意RemovalListener抛出的任何异常都会被Logger记录然后被丢弃 12345678910111213141516CacheLoader&lt;Key, DatabaseConnection&gt; loader = new CacheLoader&lt;Key, DatabaseConnection&gt; () &#123; public DatabaseConnection load(Key key) throws Exception &#123; return openConnection(key); &#125; &#125;; RemovalListener&lt;Key, DatabaseConnection&gt; removalListener = new RemovalListener&lt;Key, DatabaseConnection&gt;() &#123; public void onRemoval(RemovalNotification&lt;Key, DatabaseConnection&gt; removal) &#123; DatabaseConnection conn = removal.getValue(); conn.close(); // tear down properly &#125; &#125;; return CacheBuilder.newBuilder() .expireAfterWrite(2, TimeUnit.MINUTES) .removalListener(removalListener) .build(loader); 警告：removal listeners是被默认同步执行的，而且cache的维护是在其普通操作中维护的，那么“昂贵的”removal listener会降低cache操作(某些方法)的效率。如果你在使用一个”昂贵的”removal listener，你可以使用RemovalListener.asynchronous(RemovalListener,Executor),将其布置成异步操作.","categories":[{"name":"Java 类库","slug":"Java-类库","permalink":"https://wangmingco.github.io/categories/Java-%E7%B1%BB%E5%BA%93/"}],"tags":[{"name":"Guava","slug":"Guava","permalink":"https://wangmingco.github.io/tags/Guava/"}]}],"categories":[{"name":"知乎","slug":"知乎","permalink":"https://wangmingco.github.io/categories/%E7%9F%A5%E4%B9%8E/"},{"name":"Javasist","slug":"Javasist","permalink":"https://wangmingco.github.io/categories/Javasist/"},{"name":"前端","slug":"前端","permalink":"https://wangmingco.github.io/categories/%E5%89%8D%E7%AB%AF/"},{"name":"Java","slug":"Java","permalink":"https://wangmingco.github.io/categories/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://wangmingco.github.io/categories/JVM/"},{"name":"算法","slug":"算法","permalink":"https://wangmingco.github.io/categories/%E7%AE%97%E6%B3%95/"},{"name":"Java 类库","slug":"Java-类库","permalink":"https://wangmingco.github.io/categories/Java-%E7%B1%BB%E5%BA%93/"},{"name":"Jedis","slug":"Jedis","permalink":"https://wangmingco.github.io/categories/Jedis/"},{"name":"Java 网络库","slug":"Java-网络库","permalink":"https://wangmingco.github.io/categories/Java-%E7%BD%91%E7%BB%9C%E5%BA%93/"},{"name":"数据库","slug":"数据库","permalink":"https://wangmingco.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"性能监控","slug":"性能监控","permalink":"https://wangmingco.github.io/categories/%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7/"},{"name":"ZooKeeper","slug":"ZooKeeper","permalink":"https://wangmingco.github.io/categories/ZooKeeper/"},{"name":"Nginx","slug":"Nginx","permalink":"https://wangmingco.github.io/categories/Nginx/"},{"name":"Mybatis","slug":"Mybatis","permalink":"https://wangmingco.github.io/categories/Mybatis/"},{"name":"Netty","slug":"Netty","permalink":"https://wangmingco.github.io/categories/Netty/"},{"name":"ASM","slug":"ASM","permalink":"https://wangmingco.github.io/categories/ASM/"},{"name":"PHP","slug":"PHP","permalink":"https://wangmingco.github.io/categories/PHP/"},{"name":"NoSql","slug":"NoSql","permalink":"https://wangmingco.github.io/categories/NoSql/"},{"name":"awk","slug":"awk","permalink":"https://wangmingco.github.io/categories/awk/"},{"name":"Shell","slug":"Shell","permalink":"https://wangmingco.github.io/categories/Shell/"},{"name":"vertx","slug":"vertx","permalink":"https://wangmingco.github.io/categories/vertx/"},{"name":"PYTHON2","slug":"PYTHON2","permalink":"https://wangmingco.github.io/categories/PYTHON2/"},{"name":"haskell","slug":"haskell","permalink":"https://wangmingco.github.io/categories/haskell/"},{"name":"Groovy","slug":"Groovy","permalink":"https://wangmingco.github.io/categories/Groovy/"}],"tags":[{"name":"PEG.js","slug":"PEG-js","permalink":"https://wangmingco.github.io/tags/PEG-js/"},{"name":"Jackson","slug":"Jackson","permalink":"https://wangmingco.github.io/tags/Jackson/"},{"name":"Jetty","slug":"Jetty","permalink":"https://wangmingco.github.io/tags/Jetty/"},{"name":"ReflectASM","slug":"ReflectASM","permalink":"https://wangmingco.github.io/tags/ReflectASM/"},{"name":"mysql","slug":"mysql","permalink":"https://wangmingco.github.io/tags/mysql/"},{"name":"CRaSH","slug":"CRaSH","permalink":"https://wangmingco.github.io/tags/CRaSH/"},{"name":"Log4J2","slug":"Log4J2","permalink":"https://wangmingco.github.io/tags/Log4J2/"},{"name":"JMeter","slug":"JMeter","permalink":"https://wangmingco.github.io/tags/JMeter/"},{"name":"Netty","slug":"Netty","permalink":"https://wangmingco.github.io/tags/Netty/"},{"name":"MessagePack","slug":"MessagePack","permalink":"https://wangmingco.github.io/tags/MessagePack/"},{"name":"Typesafe Config","slug":"Typesafe-Config","permalink":"https://wangmingco.github.io/tags/Typesafe-Config/"},{"name":"Retrofit","slug":"Retrofit","permalink":"https://wangmingco.github.io/tags/Retrofit/"},{"name":"OWNER","slug":"OWNER","permalink":"https://wangmingco.github.io/tags/OWNER/"},{"name":"asm","slug":"asm","permalink":"https://wangmingco.github.io/tags/asm/"},{"name":"Lombok","slug":"Lombok","permalink":"https://wangmingco.github.io/tags/Lombok/"},{"name":"Guice","slug":"Guice","permalink":"https://wangmingco.github.io/tags/Guice/"},{"name":"Redis","slug":"Redis","permalink":"https://wangmingco.github.io/tags/Redis/"},{"name":"Memcached","slug":"Memcached","permalink":"https://wangmingco.github.io/tags/Memcached/"},{"name":"Archiva","slug":"Archiva","permalink":"https://wangmingco.github.io/tags/Archiva/"},{"name":"JavaScript","slug":"JavaScript","permalink":"https://wangmingco.github.io/tags/JavaScript/"},{"name":"vertx3","slug":"vertx3","permalink":"https://wangmingco.github.io/tags/vertx3/"},{"name":"vertx2","slug":"vertx2","permalink":"https://wangmingco.github.io/tags/vertx2/"},{"name":"Dropwizard","slug":"Dropwizard","permalink":"https://wangmingco.github.io/tags/Dropwizard/"},{"name":"MongoDB","slug":"MongoDB","permalink":"https://wangmingco.github.io/tags/MongoDB/"},{"name":"Guava","slug":"Guava","permalink":"https://wangmingco.github.io/tags/Guava/"}]}